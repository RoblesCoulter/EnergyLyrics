{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.models.doc2vec as d2v\n",
    "import multiprocessing\n",
    "import sklearn.manifold\n",
    "import re\n",
    "import time\n",
    "import pprint as pp\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyrics_data = pd.read_csv(\"LyricsFreak.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_lyric(lyrics):   \n",
    "    splitted_lyrics = re.sub(' +', ' ', clean_lyric(lyrics)).split(' ')\n",
    "    return [ word.lower() for word in splitted_lyrics if word != '']\n",
    "\n",
    "def clean_lyric(lyric):\n",
    "    punct_str = '!\\\"#$%&\\\\()*+,-./:;<=>/?@[]^_`{|}~«»\\n'\n",
    "    for p in punct_str:\n",
    "        lyric = lyric.replace(p,' ')\n",
    "    return lyric\n",
    "\n",
    "def cbow_songVector(row):\n",
    "    vector_sum = 0\n",
    "    words = split_lyric(row)\n",
    "    for word in words:\n",
    "        vector_sum = vector_sum + cbow_model[word]\n",
    "    vector_sum = vector_sum.reshape(1,-1)\n",
    "    normalised_vector_sum = sklearn.preprocessing.normalize(vector_sum)\n",
    "    return normalised_vector_sum\n",
    "    \n",
    "def sg_songVector(row):\n",
    "    vector_sum = 0\n",
    "    words = split_lyric(row)\n",
    "    for word in words:\n",
    "        vector_sum = vector_sum + sg_model[word]\n",
    "    vector_sum = vector_sum.reshape(1,-1)\n",
    "    normalised_vector_sum = sklearn.preprocessing.normalize(vector_sum)\n",
    "    return normalised_vector_sum\n",
    "\n",
    "def sum_vectors(lista,model):\n",
    "    vector_sum = 0\n",
    "    for word in lista:\n",
    "        vector_sum = vector_sum + model[word]\n",
    "    vector_sum = vector_sum.reshape(1,-1)\n",
    "    normalised_vector_sum = sklearn.preprocessing.normalize(vector_sum)\n",
    "    return normalised_vector_sum\n",
    "\n",
    "def display_most_common(word, models, num):\n",
    "    print(word)\n",
    "    for model in models:\n",
    "        print(model[0])\n",
    "        predictions = model[1].most_similar(positive=[word],topn=num)\n",
    "        pp.pprint(list(map(lambda x: x[0] + ' => ' + str(x[1]),predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "class LyricsIterator(object):\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "    def __iter__(self):\n",
    "        analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "        lyrics_data = pd.read_csv(self.dataset_name)\n",
    "        for i, lyric in enumerate(lyrics_data[\"text\"]):\n",
    "            yield analyzedDocument(split_lyric(lyric),[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a8ae3354224b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_lyric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __new__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "#lyrics_data = pd.read_csv(\"LyricsFreak.csv\")\n",
    "#energy_data = pd.read_csv(\"EnergyScores.csv\")\n",
    "#lyrics_test = lyrics_data.sample(n= 1000)\n",
    "lyrics = LyricsIterator('LyricsFreak.csv')\n",
    "docs = []\n",
    "analyzedDocument = namedtuple('AnalyzedDoc', 'WordTags')\n",
    "for i , lyric in enumerate(lyrics_data['text']):\n",
    "    words = split_lyric(lyric)\n",
    "    tags = [i]\n",
    "    docs.append(analyzedDocument(words,tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 100\n",
    "# Minimum word count threshold. For pruning dictionary\n",
    "min_word_count = 1\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "# Context window length.\n",
    "context_size = 5\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3be885ca08fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_word_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/gensim-3.1.0-py3.5-macosx-10.6-x86_64.egg/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/gensim-3.1.0-py3.5-macosx-10.6-x86_64.egg/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, keep_raw_vocab, trim_rule, progress_per, update)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0mEach\u001b[0m \u001b[0msentence\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0municode\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \"\"\"\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# initial survey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# trim by min_count & precalculate downsampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build tables & arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/gensim-3.1.0-py3.5-macosx-10.6-x86_64.egg/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, progress_per, trim_rule, update)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mchecked_string_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-ac7af35515f0>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlyrics_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0manalyzedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_lyric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __new__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "d2v_model = d2v.Doc2Vec(\n",
    "    lyrics,\n",
    "    seed = seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count = min_word_count,\n",
    "    window = context_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gensim.models.doc2vec' from '/Users/roblescoulter/anaconda/lib/python3.5/site-packages/gensim-3.1.0-py3.5-macosx-10.6-x86_64.egg/gensim/models/doc2vec.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
