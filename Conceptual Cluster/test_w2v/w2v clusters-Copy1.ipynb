{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "# from glove import Corpus, Glove\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "# from sklearn.svm import SVC\n",
    "# import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "# from collections import Counter, defaultdict\n",
    "# from tabulate import tabulate\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_glove(data, LEARNING_RATE=0.05, EPOCHS=5, NO_THREADS=4, EMBEDDING_DIM=100):\n",
    "    model = None\n",
    "    corpus = Corpus()\n",
    "    corpus.fit(data, window=10)\n",
    "    model = Glove(no_components=EMBEDDING_DIM,learning_rate=LEARNING_RATE)\n",
    "    model.fit(corpus.matrix, epochs=EPOCHS,no_threads=NO_THREADS,verbose=True)\n",
    "    model.add_dictionary(corpus.dictionary)\n",
    "    return model\n",
    "\n",
    "def create_word2vec(data,EMBEDDING_DIM=100):\n",
    "    model = word2vec.Word2Vec(data, size=EMBEDDING_DIM)\n",
    "    return model\n",
    "\n",
    "def preprocess_text(posts):\n",
    "    text = str(posts['post_title'])+'. '+ str(posts['post_text'])\n",
    "    text =  re.sub('tl[;]?dr','',text,flags=re.IGNORECASE)\n",
    "    text = re.sub('[ \\(\\[]+[0-9]+[s]?[ /\\(,)]*f[ \\]\\)]+',' ',text,flags=re.IGNORECASE)\n",
    "    text = re.sub('[ \\(\\[]+[0-9]+[s]?[ /\\(,)]*m[ \\]\\)]+',' ',text,flags=re.IGNORECASE)\n",
    "    text = re.sub('[ \\(\\[]+f[ /\\(,)]*[0-9]+[s]?[ \\]\\)]+',' ',text,flags=re.IGNORECASE)\n",
    "    text = re.sub('[ \\(\\[]+m[ /\\(,)]*[0-9]+[s]?[ \\]\\)]+',' ',text,flags=re.IGNORECASE)\n",
    "    text = re.sub('[0-9]+','NUM',text,flags=re.IGNORECASE)\n",
    "    text = re.sub('u/[^\\s]+','AT_USER',text,flags=re.IGNORECASE)\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',text,flags=re.IGNORECASE)  #Convert www.* or https?://* to <url>\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*[eE]dit\")[0]\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*EDIT\")[0]\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*big edit\")[0]\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*important edit\")[0]\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*[uU]pdate\")[0]\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*UPDATE\")[0]\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*big update\")[0]\n",
    "    text = text.split(\"[.]?\\n[\\* \\[\\(/]*important update\")[0]\n",
    "    text = text.split(\"[.]?\\nfor an update\")[0]\n",
    "    text = text.replace('\\r', '')\n",
    "    return text\n",
    "\n",
    "#calculate two things,\n",
    "#specificness how good is the cluster and the elements similar to each other/ how well can other elements be described by their neighbors\n",
    "#uniqueness is how differnet this cluster to others\n",
    "def cluster_score(clean_cluster,c_syn,k):\n",
    "    unique_clusters = clean_cluster.loc[:,['cluster']]\n",
    "    unique_clusters = unique_clusters.drop_duplicates()\n",
    "    tot_spec = 0\n",
    "    tot_uni = 0\n",
    "    for num,c in unique_clusters.iterrows():\n",
    "        union = clean_cluster[clean_cluster['cluster']==c['cluster']].merge(c_syn[c_syn['cluster']==c['cluster']],how='inner',left_on=['word'],right_on=['syn'])\n",
    "        specificness = len(union)/len(clean_cluster[clean_cluster['cluster']==c['cluster']])\n",
    "        union = clean_cluster[clean_cluster['cluster']!=c['cluster']].merge(c_syn[c_syn['cluster']==c['cluster']],how='inner',left_on=['word'],right_on=['syn'])\n",
    "        uniqueness = 1 - (len(union)/(len(clean_cluster)-len(clean_cluster[clean_cluster['cluster']==c['cluster']])))\n",
    "        tot_spec = tot_spec + specificness\n",
    "        tot_uni = tot_uni + uniqueness\n",
    "    tot_spec = tot_spec/len(unique_clusters)\n",
    "    tot_uni = tot_uni/len(unique_clusters)\n",
    "    return {'spec':tot_spec,'uni':tot_uni,'k':k}\n",
    "\n",
    "    \n",
    "def generate_syn_info(cluster):\n",
    "    cluster_syn = pd.DataFrame()\n",
    "    unique_clusters = cluster.loc[:,['cluster']]\n",
    "    unique_clusters = unique_clusters.drop_duplicates()\n",
    "    for cnum,c in unique_clusters.iterrows():\n",
    "#         print('starting cluster...',c[0])\n",
    "        cur_cluster = cluster[cluster['cluster']==c['cluster']]\n",
    "        syns = []\n",
    "        for wnum,word in cur_cluster.iterrows():\n",
    "            for s in wn.synsets(word['word']):\n",
    "                syn = s.name().split('.')[0]\n",
    "                if syn.find('_')<0:  #filter out composed words\n",
    "                    syns.append(syn)\n",
    "            #syns.append(word['word'])\n",
    "        this_cluster = pd.DataFrame(syns,columns=['syn'])\n",
    "        this_cluster['cluster'] = c[0]\n",
    "        this_cluster = this_cluster.drop_duplicates()\n",
    "        cluster_syn = pd.concat([cluster_syn,this_cluster])         \n",
    "    return cluster_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359557"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare sentences\n",
    "c_train = pd.read_csv('data/c_train2.csv')\n",
    "c_test = pd.read_csv('data/c_test2.csv')\n",
    "c_data = pd.concat([c_train,c_test],sort=False)\n",
    "c_data = c_data.loc[:,['post_created_utc', 'full_link', 'post_id', 'post_num_comments',\n",
    "       'post_score', 'subreddit', 'post_title', 'post_text']]\n",
    "\n",
    "nc_train = pd.read_csv('data/nc_train2.csv')\n",
    "nc_test = pd.read_csv('data/nc_test2.csv')\n",
    "nc_data = pd.concat([nc_train,nc_test],sort=False)\n",
    "nc_data = nc_data.loc[:,['post_created_utc', 'full_link', 'post_id', 'post_num_comments',\n",
    "       'post_score', 'subreddit', 'post_title', 'post_text']]\n",
    "\n",
    "full_data = pd.concat([c_data,nc_data],sort=False)\n",
    "full_data = full_data.sample(len(full_data))\n",
    "posts = full_data.apply(preprocess_text,axis=1)\n",
    "data_sentences = []\n",
    "for post in posts:\n",
    "    sent_tokenize_list = sent_tokenize(post)\n",
    "    data = [nltk.word_tokenize(sentence) for sentence in sent_tokenize_list]\n",
    "    data_sentences = data_sentences + data \n",
    "len(data_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richie\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "print('start training...')\n",
    "# gloveModel = create_glove(data_sentences)\n",
    "w2vModel = create_word2vec(data_sentences)\n",
    "#is ok to train the model with the full dataset as we are not providing labels.\n",
    "w2v = {w: vec for w, vec in zip(w2vModel.wv.index2word, w2vModel.wv.syn0)}\n",
    "# glove = {w: vec for w, vec in zip(gloveModel.dictionary, gloveModel.word_vectors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21456987528821345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richie\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#clustering w2v\n",
    "print (w2vModel.similarity('this', 'is'))\n",
    "# w2vModel.wv.index2word\n",
    "# print (w2vModel.most_similar(positive=['hello'], negative=[], topn=10))\n",
    "\n",
    "# w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from nltk.cluster import KMeansClusterer\n",
    "# import nltk\n",
    "# X = w2vModel[w2vModel.wv.index2word]\n",
    "# NUM_CLUSTERS=10\n",
    "# kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "# assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
    "# # print (assigned_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# words = pd.DataFrame(list(w2vModel.wv.index2word),columns=['word'])\n",
    "# clusters = pd.DataFrame(list(assigned_clusters),columns=['cluster'])\n",
    "# features = pd.DataFrame(w2vModel.wv.syn0)\n",
    "\n",
    "# result = words.merge(clusters,left_index=True,right_index=True)\n",
    "# result = result.merge(features,left_index=True,right_index=True)\n",
    "# result.to_csv('nltk_clusters10.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richie\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "\n",
    "final_vals = pd.read_csv('cluster_eval.csv')\n",
    "init_val = int(final_vals.k.max() - 1)\n",
    "kfold = 2000\n",
    "for i in range(init_val,kfold):\n",
    "    print(i)\n",
    "    X = w2vModel[w2vModel.wv.index2word]\n",
    "    NUM_CLUSTERS=i+2\n",
    "    kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    words = pd.DataFrame(list(w2vModel.wv.index2word),columns=['word'])\n",
    "    clusters = pd.DataFrame(list(labels),columns=['cluster'])\n",
    "    features = pd.DataFrame(w2vModel.wv.vectors)\n",
    "    result = words.merge(clusters,left_index=True,right_index=True)\n",
    "    result = result.merge(features,left_index=True,right_index=True)\n",
    "    \n",
    "    clean_cluster = result\n",
    "    clean_cluster = clean_cluster[clean_cluster['word']==clean_cluster['word']]\n",
    "\n",
    "    for num,c in result.iterrows():\n",
    "        try:\n",
    "            w1 = wn.synsets(c['word'])\n",
    "            if len(w1)==0:\n",
    "                clean_cluster = clean_cluster[clean_cluster['word']!=c['word']]\n",
    "        except:\n",
    "            clean_cluster = clean_cluster[clean_cluster['word']!=c['word']]\n",
    "    clean_cluster['word'] = clean_cluster.apply(lambda row: row['word'].lower(),axis=1)\n",
    "    clean_cluster = clean_cluster.loc[:,['word','cluster']]\n",
    "    clean_cluster = clean_cluster.drop_duplicates()\n",
    "    \n",
    "    c_syn = generate_syn_info(clean_cluster)\n",
    "    score = cluster_score(clean_cluster,c_syn,NUM_CLUSTERS)\n",
    "    final_vals = final_vals.append(score,ignore_index=True)\n",
    "    final_vals.to_csv('cluster_eval.csv',encoding='utf-8',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>spec</th>\n",
       "      <th>uni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.705829</td>\n",
       "      <td>0.581182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.714255</td>\n",
       "      <td>0.730760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.689490</td>\n",
       "      <td>0.799573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.685451</td>\n",
       "      <td>0.830179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.694096</td>\n",
       "      <td>0.858262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.714711</td>\n",
       "      <td>0.875957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.685145</td>\n",
       "      <td>0.890216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.713638</td>\n",
       "      <td>0.903003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.719913</td>\n",
       "      <td>0.913042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.699059</td>\n",
       "      <td>0.919799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.699669</td>\n",
       "      <td>0.925128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.695895</td>\n",
       "      <td>0.930886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.665813</td>\n",
       "      <td>0.934582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.696414</td>\n",
       "      <td>0.938514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.699866</td>\n",
       "      <td>0.942284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.665397</td>\n",
       "      <td>0.945771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.700963</td>\n",
       "      <td>0.948083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.667885</td>\n",
       "      <td>0.949427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.668441</td>\n",
       "      <td>0.950855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.718175</td>\n",
       "      <td>0.954461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.666194</td>\n",
       "      <td>0.956568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.646906</td>\n",
       "      <td>0.956327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.651208</td>\n",
       "      <td>0.957579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.701142</td>\n",
       "      <td>0.960653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.702561</td>\n",
       "      <td>0.960819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.670061</td>\n",
       "      <td>0.963842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.700238</td>\n",
       "      <td>0.963959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.718697</td>\n",
       "      <td>0.963551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.663130</td>\n",
       "      <td>0.965791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.695597</td>\n",
       "      <td>0.965242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>263.0</td>\n",
       "      <td>0.709881</td>\n",
       "      <td>0.994658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>264.0</td>\n",
       "      <td>0.712775</td>\n",
       "      <td>0.994622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>265.0</td>\n",
       "      <td>0.715313</td>\n",
       "      <td>0.994462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>266.0</td>\n",
       "      <td>0.714745</td>\n",
       "      <td>0.994607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>267.0</td>\n",
       "      <td>0.712136</td>\n",
       "      <td>0.994754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>268.0</td>\n",
       "      <td>0.719332</td>\n",
       "      <td>0.994508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>269.0</td>\n",
       "      <td>0.692483</td>\n",
       "      <td>0.994775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>270.0</td>\n",
       "      <td>0.686072</td>\n",
       "      <td>0.994779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>271.0</td>\n",
       "      <td>0.706700</td>\n",
       "      <td>0.994758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>272.0</td>\n",
       "      <td>0.719659</td>\n",
       "      <td>0.994793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>273.0</td>\n",
       "      <td>0.693755</td>\n",
       "      <td>0.994719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>274.0</td>\n",
       "      <td>0.709833</td>\n",
       "      <td>0.994924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>275.0</td>\n",
       "      <td>0.712213</td>\n",
       "      <td>0.994676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>276.0</td>\n",
       "      <td>0.710120</td>\n",
       "      <td>0.994766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>277.0</td>\n",
       "      <td>0.716277</td>\n",
       "      <td>0.994675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>278.0</td>\n",
       "      <td>0.713649</td>\n",
       "      <td>0.994672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>279.0</td>\n",
       "      <td>0.702752</td>\n",
       "      <td>0.994801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>280.0</td>\n",
       "      <td>0.714111</td>\n",
       "      <td>0.994823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>281.0</td>\n",
       "      <td>0.707635</td>\n",
       "      <td>0.994906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.714732</td>\n",
       "      <td>0.994992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>283.0</td>\n",
       "      <td>0.710617</td>\n",
       "      <td>0.994749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>284.0</td>\n",
       "      <td>0.695871</td>\n",
       "      <td>0.994934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>285.0</td>\n",
       "      <td>0.717032</td>\n",
       "      <td>0.994972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>286.0</td>\n",
       "      <td>0.717294</td>\n",
       "      <td>0.994991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>287.0</td>\n",
       "      <td>0.697788</td>\n",
       "      <td>0.994728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>288.0</td>\n",
       "      <td>0.701100</td>\n",
       "      <td>0.994924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>289.0</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.994801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>290.0</td>\n",
       "      <td>0.705664</td>\n",
       "      <td>0.995010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>291.0</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.994999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>292.0</td>\n",
       "      <td>0.722888</td>\n",
       "      <td>0.994937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         k      spec       uni\n",
       "0      2.0  0.705829  0.581182\n",
       "1      3.0  0.714255  0.730760\n",
       "2      4.0  0.689490  0.799573\n",
       "3      5.0  0.685451  0.830179\n",
       "4      6.0  0.694096  0.858262\n",
       "5      7.0  0.714711  0.875957\n",
       "6      8.0  0.685145  0.890216\n",
       "7      9.0  0.713638  0.903003\n",
       "8     10.0  0.719913  0.913042\n",
       "9     11.0  0.699059  0.919799\n",
       "10    12.0  0.699669  0.925128\n",
       "11    13.0  0.695895  0.930886\n",
       "12    14.0  0.665813  0.934582\n",
       "13    15.0  0.696414  0.938514\n",
       "14    16.0  0.699866  0.942284\n",
       "15    17.0  0.665397  0.945771\n",
       "16    18.0  0.700963  0.948083\n",
       "17    19.0  0.667885  0.949427\n",
       "18    20.0  0.668441  0.950855\n",
       "19    21.0  0.718175  0.954461\n",
       "20    22.0  0.666194  0.956568\n",
       "21    23.0  0.646906  0.956327\n",
       "22    24.0  0.651208  0.957579\n",
       "23    25.0  0.701142  0.960653\n",
       "24    26.0  0.702561  0.960819\n",
       "25    27.0  0.670061  0.963842\n",
       "26    28.0  0.700238  0.963959\n",
       "27    29.0  0.718697  0.963551\n",
       "28    30.0  0.663130  0.965791\n",
       "29    31.0  0.695597  0.965242\n",
       "..     ...       ...       ...\n",
       "261  263.0  0.709881  0.994658\n",
       "262  264.0  0.712775  0.994622\n",
       "263  265.0  0.715313  0.994462\n",
       "264  266.0  0.714745  0.994607\n",
       "265  267.0  0.712136  0.994754\n",
       "266  268.0  0.719332  0.994508\n",
       "267  269.0  0.692483  0.994775\n",
       "268  270.0  0.686072  0.994779\n",
       "269  271.0  0.706700  0.994758\n",
       "270  272.0  0.719659  0.994793\n",
       "271  273.0  0.693755  0.994719\n",
       "272  274.0  0.709833  0.994924\n",
       "273  275.0  0.712213  0.994676\n",
       "274  276.0  0.710120  0.994766\n",
       "275  277.0  0.716277  0.994675\n",
       "276  278.0  0.713649  0.994672\n",
       "277  279.0  0.702752  0.994801\n",
       "278  280.0  0.714111  0.994823\n",
       "279  281.0  0.707635  0.994906\n",
       "280  282.0  0.714732  0.994992\n",
       "281  283.0  0.710617  0.994749\n",
       "282  284.0  0.695871  0.994934\n",
       "283  285.0  0.717032  0.994972\n",
       "284  286.0  0.717294  0.994991\n",
       "285  287.0  0.697788  0.994728\n",
       "286  288.0  0.701100  0.994924\n",
       "287  289.0  0.710993  0.994801\n",
       "288  290.0  0.705664  0.995010\n",
       "289  291.0  0.719457  0.994999\n",
       "290  292.0  0.722888  0.994937\n",
       "\n",
       "[291 rows x 3 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7042699059843707"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = clean_cluster[clean_cluster['cluster']==1]\n",
    "cs = c_syn[c_syn['cluster']==1]\n",
    "\n",
    "len(cc.merge(cs,how='inner',left_on='word',right_on='syn'))\n",
    "(845/1052 + 7481/12359 )/2\n",
    "# len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spec': 1.1523101492404357, 'uni': 1.0679645566819487}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cluster_score(clean_cluster,c_syn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good = wn.synsets('goodness')\n",
    "good1 = good[0]\n",
    "good1.name().split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bash.n.02'),\n",
       " Synset('do.n.02'),\n",
       " Synset('doctor_of_osteopathy.n.01'),\n",
       " Synset('make.v.01'),\n",
       " Synset('perform.v.01'),\n",
       " Synset('do.v.03'),\n",
       " Synset('do.v.04'),\n",
       " Synset('cause.v.01'),\n",
       " Synset('practice.v.01'),\n",
       " Synset('suffice.v.01'),\n",
       " Synset('do.v.08'),\n",
       " Synset('act.v.02'),\n",
       " Synset('serve.v.09'),\n",
       " Synset('do.v.11'),\n",
       " Synset('dress.v.16'),\n",
       " Synset('do.v.13')]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t = 'gola como star'\n",
    "# t.split()\n",
    "print(range(4:5))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
