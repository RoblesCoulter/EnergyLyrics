{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "\n",
    "#Data handling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Pickling\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Models \n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "#HTTP\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import seaborn\n",
    "import codecs\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "no_alignment_file = [4764]\n",
    "wrong_alignment = [3730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfief_path = 'Pattern_construction_code/luis_pattern_half/patterns_ignore_5'\n",
    "# pat_table = pd.read_csv('Pattern_construction_code/luis_pattern_half/patterns_ignore_5',sep='\\t')\n",
    "# pat_table\n",
    "\n",
    "with codecs.open(pfief_path,'r','utf-8') as content_file:\n",
    "    content = content_file.read()\n",
    "len(set(map(lambda x: x.split('\\t')[0] ,content.split('\\n'))))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern(text):\n",
    "    text = json.dumps(text)\n",
    "    url = 'http://192.168.2.101:7878/api/get_patt'\n",
    "    data = dict(input_tweets = text)\n",
    "    resp = requests.post(url=url, data=data)\n",
    "    r = json.loads(resp.text)\n",
    "    return map(lambda x: x['pattern'],r)\n",
    "    \n",
    "def get_deep_emotion(text):\n",
    "    text = json.dumps(text)\n",
    "    url = 'http://192.168.2.101:7878/api/get_emo'\n",
    "    data = dict(input_tweets = text)\n",
    "    resp = requests.post(url=url, data=data)\n",
    "    r = json.loads(resp.text)\n",
    "    return r\n",
    "\n",
    "def clean_text(text, remove_actions = True):\n",
    "    punct_str = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~«»“…‘”'\n",
    "    if(remove_actions):\n",
    "        text = re.sub(r\" ?\\[[^)]+\\]\", \"\", text)\n",
    "    for p in punct_str:\n",
    "        text = text.replace(p,' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "def get_f1_score(precision,recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def get_patterns_load(data,patterns_df, emotion):\n",
    "    index = data[data.emotion == emotion ]['index']\n",
    "    patterns = patterns_df.loc[list(index)]\n",
    "    load = []\n",
    "    for pat in patterns.iterrows():\n",
    "        load = load + list(pat[1].dropna())\n",
    "    return load\n",
    "\n",
    "\n",
    "def extract_patterns(data,extract=False):\n",
    "    if(extract):\n",
    "        patterns = {}\n",
    "        for index, row in data.iterrows():\n",
    "            patterns[row['index']] = set(get_pattern([row['text']])[0].values())\n",
    "            print('Extracted pattern from '+ row['index'] + ' index:'+ str(index))\n",
    "            print('Size: ', len(patterns[row['index']]), 'Patterns size', len(patterns))\n",
    "        try:\n",
    "            print('Saving Pickle')\n",
    "            with open('pickles/patterns/pattern.pickle','wb') as f:\n",
    "                save = {\n",
    "                    'patterns' : patterns\n",
    "                }\n",
    "                pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "                print('Successfully saved in pattern.pickle')\n",
    "                return patterns\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to pickle', e)\n",
    "            print('Patterns probably not saved.')\n",
    "            return patterns\n",
    "    else:\n",
    "        try:\n",
    "            with open('pickles/patterns/pattern.pickle','rb') as f:\n",
    "                save = pickle.load(f)\n",
    "                patterns = save['patterns']\n",
    "                del save\n",
    "                returning = {}\n",
    "                for key in list(data['index']):\n",
    "                    returning[key] = patterns[key]\n",
    "                return returning\n",
    "        except Exception as e:\n",
    "            print('Error loading base datasets pickle: ', e)\n",
    "            \n",
    "def build_emotions_counter(data,patterns_df):\n",
    "    emotions_counter ={}\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for emotion in emotions_list:\n",
    "        load = get_patterns_load(data,patterns_df,emotion)\n",
    "        emotions_counter[emotion] = collections.Counter(load)\n",
    "    return emotions_counter\n",
    "\n",
    "def build_frequencyframe(all_patterns,emotions_counter):\n",
    "    df_patt = {}\n",
    "    for pattern in all_patterns:\n",
    "        df_patt[pattern] = {}\n",
    "        for emotion in emotions_counter:\n",
    "            df_patt[pattern][emotion] = emotions_counter[emotion][pattern]\n",
    "    return pd.DataFrame(df_patt).T\n",
    "\n",
    "def build_pfief(df_patt):\n",
    "    ief = ((df_patt+1).rdiv(df_patt.sum(axis=1)+1, axis=0)+1).apply(np.log10)\n",
    "    pf = ((df_patt.sum(axis=0)+1)/(df_patt+1)).apply(np.log10)\n",
    "    return ief * pf\n",
    "\n",
    "def balance_data(data):\n",
    "    min_sample = min(data.groupby('emotion').count()['index'])\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    samples = []\n",
    "    for emotion in emotions_list:\n",
    "        samples.append(data[data.emotion == emotion].sample(n=min_sample))\n",
    "    result = pd.concat(samples).sample(frac=1)\n",
    "    return result\n",
    "        \n",
    "def two_emotions(data,emotional_mapping,emotion1,emotion2):\n",
    "    emotion_code = emotional_mapping[emotion1]\n",
    "    emotion_sample = data[data.emotion_code == emotion_code]\n",
    "    emotion_code2 = emotional_mapping[emotion2]\n",
    "    emotion_sample2 = data[data.emotion_code == emotion_code2]\n",
    "    if(len(emotion_sample2) < len(emotion_sample)):\n",
    "        emotion_sample = emotion_sample.sample(n=len(emotion_sample2))\n",
    "    else:\n",
    "        emotion_sample2 = emotion_sample2.sample(n=len(emotion_sample))\n",
    "    sample = pd.concat([emotion_sample,emotion_sample2]).sample(frac=1)\n",
    "    return sample\n",
    "\n",
    "def filter_word_count(data, n_count):\n",
    "    return data[list(map(lambda x: len(x.split(' ')) >= n_count,data['text']))]\n",
    "\n",
    "def remove_empty_patterns(data,patterns):\n",
    "    empty_patterns = [k for k, v in patterns.items() if len(v) < 1]\n",
    "    patterns = { k:v for k, v in patterns.items() if len(v) > 1 }\n",
    "    data = filter(lambda x: x[1]['index'] not in empty_patterns ,data.iterrows())\n",
    "    data = pd.DataFrame.from_items(data).T\n",
    "    return data,patterns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(word_count,emotional_mapping):\n",
    "    # full = generate_IEMOCAP_df()\n",
    "    data = pd.read_csv('data/IEMOCAP_sentences_votebased.csv',index_col=0)\n",
    "    data['emotion_code'] = data['emotion'].map( emotional_mapping ).astype(int)\n",
    "    # Take away fear, surprise,disgust, xxx and others. Not enough data\n",
    "    data = data[data.emotion_code < 4]\n",
    "    # Clean Transcripts\n",
    "    try:\n",
    "        data = data.drop(no_alignment_file)\n",
    "    except Exception as e:\n",
    "        print('Error at: ',e)\n",
    "    # Remove rows that have wrong Alignment file\n",
    "    try:\n",
    "        data = data.drop(wrong_alignment)\n",
    "    except Exception as e:\n",
    "        print('Error at: ',e)\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    # Filter Word Count\n",
    "    data = filter_word_count(data, word_count)\n",
    "    patterns = extract_patterns(data)\n",
    "    data,patterns = remove_empty_patterns(data,patterns)\n",
    "    return data,patterns\n",
    "\n",
    "def build_model(data,patterns):\n",
    "    transcript_order = list(data['index'])\n",
    "    patterns_df = pd.DataFrame.from_dict(patterns, orient='index')\n",
    "    patterns_df = patterns_df.loc[transcript_order]\n",
    "    emotions_counter = build_emotions_counter(X_train,patterns_df)\n",
    "    all_patterns = []\n",
    "    for pat in patterns_df.iterrows():\n",
    "        all_patterns = all_patterns + list(pat[1].dropna())\n",
    "        \n",
    "    df_patt = build_frequencyframe(all_patterns,emotions_counter)\n",
    "    em_df = build_pfief(df_patt)\n",
    "    return em_df\n",
    "\n",
    "def get_frequency_vectors(data,patterns_list):\n",
    "    patterns = extract_patterns(data)\n",
    "    transcript_order = list(data['index'])\n",
    "    frequency_vectors = []\n",
    "    for index in patterns:\n",
    "        frequency_vectors.append(np.isin(patterns_list,np.array(list(patterns[index]))))\n",
    "    vectors = pd.DataFrame(frequency_vectors,columns=patterns_list,index=patterns.keys())\n",
    "    vectors = vectors.loc[transcript_order]\n",
    "    vectors = vectors * 1\n",
    "    return vectors\n",
    "    \n",
    "def calculate_scores(em_df,vectors):\n",
    "    em_matrix = em_df.T.as_matrix()\n",
    "    emotional_scores = []\n",
    "    for index, vector in vectors.iterrows():\n",
    "        emotional_scores.append(em_matrix.dot(vector))\n",
    "    emotions_list = list(em_df.columns)\n",
    "    scores = pd.DataFrame(emotional_scores,columns=emotions_list,index=list(vectors.index))\n",
    "    scores['pred_emotion'] = list(map(lambda x: x[1].idxmin(),scores.iterrows()))\n",
    "    scores['pred_code'] = scores['pred_emotion'].map(emotional_mapping).astype(int)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at:  labels [4764] not contained in axis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "ang    220\n",
       "hap    127\n",
       "neu    274\n",
       "sad    221\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotional_mapping = {'ang': 0, 'sad': 1, 'hap': 2, 'neu': 3,'fru': 4,'exc': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "data,patterns = load_data(3,emotional_mapping)\n",
    "# data = two_emotions(data,emotional_mapping,'sad','exc')\n",
    "# Balance Data\n",
    "# data = balance_data(data)\n",
    "y = data.emotion_code\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "X_train.groupby('emotion').count()['index'] #  6,453 Total\n",
    "X_test.groupby('emotion').count()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>text</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>alignment_path</th>\n",
       "      <th>emotion</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9076</th>\n",
       "      <td>Ses05M_impro02_M007</td>\n",
       "      <td>42.91</td>\n",
       "      <td>47.78</td>\n",
       "      <td>i don't have a choice i have to go if i don't ...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Ses01F_impro06_F022</td>\n",
       "      <td>217.5</td>\n",
       "      <td>222.41</td>\n",
       "      <td>she used to have these poetry parties on memor...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>Ses03M_impro06_M029</td>\n",
       "      <td>209.011</td>\n",
       "      <td>212.856</td>\n",
       "      <td>he actually wanted to do something</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>Ses03M_impro06_F009</td>\n",
       "      <td>100.1</td>\n",
       "      <td>103.191</td>\n",
       "      <td>how are they</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8565</th>\n",
       "      <td>Ses05F_script01_1_M003</td>\n",
       "      <td>31.97</td>\n",
       "      <td>38.22</td>\n",
       "      <td>i don't know but when it cracked he ran back i...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>Ses03F_script02_2_F051</td>\n",
       "      <td>433.999</td>\n",
       "      <td>437.005</td>\n",
       "      <td>i'm sorry augie</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Ses03M_impro06_M008</td>\n",
       "      <td>60.8439</td>\n",
       "      <td>68.7049</td>\n",
       "      <td>you know i was always the one to tell him to b...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>Ses03M_script01_3_M041</td>\n",
       "      <td>370.332</td>\n",
       "      <td>375.114</td>\n",
       "      <td>otherwise what you have is loot and there's bl...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>Ses03F_impro06_M002</td>\n",
       "      <td>48.6398</td>\n",
       "      <td>55.4484</td>\n",
       "      <td>i didn't know him tricia but uh i heard that h...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>Ses02M_impro02_F008</td>\n",
       "      <td>64.7625</td>\n",
       "      <td>67.7895</td>\n",
       "      <td>i'll send you lots of pictures</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>Ses05M_impro02_M018</td>\n",
       "      <td>111.65</td>\n",
       "      <td>119.95</td>\n",
       "      <td>i know but i'll i'll send the pictures all the...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Ses01M_script01_3_F021</td>\n",
       "      <td>253.41</td>\n",
       "      <td>256.44</td>\n",
       "      <td>you got to tell me</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8356</th>\n",
       "      <td>Ses05F_impro06_M006</td>\n",
       "      <td>67.72</td>\n",
       "      <td>69.16</td>\n",
       "      <td>it's the think</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>Ses02F_script01_3_M023</td>\n",
       "      <td>200.09</td>\n",
       "      <td>207.24</td>\n",
       "      <td>it's all mixed up with so many other things yo...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Ses01M_impro02_M011</td>\n",
       "      <td>82.09</td>\n",
       "      <td>86.28</td>\n",
       "      <td>i just got i feel like i'm in shock actually</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>Ses01M_script01_1_M007</td>\n",
       "      <td>69.4734</td>\n",
       "      <td>72.3994</td>\n",
       "      <td>i guess he is</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Ses01F_script01_3_M028</td>\n",
       "      <td>272.44</td>\n",
       "      <td>283.502</td>\n",
       "      <td>you can't just toss off a thing like that beca...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>Ses02M_impro02_F001</td>\n",
       "      <td>15.5524</td>\n",
       "      <td>23.3599</td>\n",
       "      <td>i'm going to miss you too i don't know what i'...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Ses01F_script02_2_F034</td>\n",
       "      <td>339.34</td>\n",
       "      <td>343.81</td>\n",
       "      <td>i know you are augie i know</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>Ses05F_script02_2_F016</td>\n",
       "      <td>197.721</td>\n",
       "      <td>203.703</td>\n",
       "      <td>dancing barefoot in the sand drinking champagn...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>Ses04M_impro06_M006</td>\n",
       "      <td>91.11</td>\n",
       "      <td>97.43</td>\n",
       "      <td>i mean they're you know they're upset it's lik...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>Ses05F_impro02_F022</td>\n",
       "      <td>169.17</td>\n",
       "      <td>182.02</td>\n",
       "      <td>well we can try it baby don't beg me i mean if...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5024</th>\n",
       "      <td>Ses03M_impro06_F019</td>\n",
       "      <td>231.986</td>\n",
       "      <td>234.955</td>\n",
       "      <td>i would've loved to</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>Ses05F_impro02_M026</td>\n",
       "      <td>189.28</td>\n",
       "      <td>200.16</td>\n",
       "      <td>why has to be you there's all those other peop...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>Ses05F_script01_1_M007</td>\n",
       "      <td>63.8</td>\n",
       "      <td>70.23</td>\n",
       "      <td>i don't know the meaning of it but i know one ...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>Ses03F_script02_2_F036</td>\n",
       "      <td>313.386</td>\n",
       "      <td>318.235</td>\n",
       "      <td>things have never turned out anything the way ...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>3</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8697</th>\n",
       "      <td>Ses05F_script01_3_M031</td>\n",
       "      <td>298.402</td>\n",
       "      <td>308.047</td>\n",
       "      <td>and i got an ideal watching them all go down e...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>Ses02F_impro02_F004</td>\n",
       "      <td>63.2468</td>\n",
       "      <td>75.4222</td>\n",
       "      <td>well we can do the best we can and and with um...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>Ses03F_script02_1_F011</td>\n",
       "      <td>157.9</td>\n",
       "      <td>160.651</td>\n",
       "      <td>i don't know i just don't</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>Ses05F_impro06_M003</td>\n",
       "      <td>50.17</td>\n",
       "      <td>53.88</td>\n",
       "      <td>i am so sorry it's</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>Ses01M_impro06_M024</td>\n",
       "      <td>193.13</td>\n",
       "      <td>197.51</td>\n",
       "      <td>you know it's like affecting a lot of people i...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>Ses03F_impro02_F025</td>\n",
       "      <td>169.312</td>\n",
       "      <td>171.28</td>\n",
       "      <td>it's going to be okay</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>Ses03M_impro06_F004</td>\n",
       "      <td>36.8471</td>\n",
       "      <td>40.23</td>\n",
       "      <td>you guys were real close huh</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>Ses03F_script01_3_F032</td>\n",
       "      <td>388.038</td>\n",
       "      <td>391.43</td>\n",
       "      <td>and you still feel that way</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>Ses01M_script01_3_M041</td>\n",
       "      <td>460.4</td>\n",
       "      <td>463.85</td>\n",
       "      <td>i want you to know annie</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>Ses03M_impro06_M030</td>\n",
       "      <td>219.233</td>\n",
       "      <td>221.374</td>\n",
       "      <td>i can't do that</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>Ses04M_impro06_M013</td>\n",
       "      <td>211.46</td>\n",
       "      <td>220.33</td>\n",
       "      <td>there should just be some sort of rule that pe...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>Ses05F_impro06_M001</td>\n",
       "      <td>15.67</td>\n",
       "      <td>21.0373</td>\n",
       "      <td>oh no i'm so sorry what happened</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>Ses05M_script01_3_F024</td>\n",
       "      <td>406.5</td>\n",
       "      <td>409.18</td>\n",
       "      <td>do you still feel like that</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Ses03M_impro02_M016</td>\n",
       "      <td>110.054</td>\n",
       "      <td>113.218</td>\n",
       "      <td>i don't know what to do</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7179</th>\n",
       "      <td>Ses04M_impro06_F003</td>\n",
       "      <td>44.56</td>\n",
       "      <td>49.5</td>\n",
       "      <td>i'm sorry it's never easy</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4361</th>\n",
       "      <td>Ses03F_script02_2_F022</td>\n",
       "      <td>196.094</td>\n",
       "      <td>202.081</td>\n",
       "      <td>i told myself finally this is how happy i'm su...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>Ses01M_impro06_M008</td>\n",
       "      <td>71.79</td>\n",
       "      <td>76.0581</td>\n",
       "      <td>it's just really really messed up</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>Ses04F_script02_2_F041</td>\n",
       "      <td>372.819</td>\n",
       "      <td>376.5</td>\n",
       "      <td>somebody who knew how to enjoy herself and did...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Ses01F_script01_3_M021</td>\n",
       "      <td>216.48</td>\n",
       "      <td>220.04</td>\n",
       "      <td>hey let's drive some place huh let's get out o...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>Ses04F_script01_1_M026</td>\n",
       "      <td>207.42</td>\n",
       "      <td>210.353</td>\n",
       "      <td>i wanted to get this settled first</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>Ses05M_impro06_M014</td>\n",
       "      <td>148.23</td>\n",
       "      <td>155.775</td>\n",
       "      <td>you always think you know when you were you kn...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>Ses04F_impro02_M000</td>\n",
       "      <td>7.3037</td>\n",
       "      <td>11.59</td>\n",
       "      <td>so you're leaving tomorrow</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8567</th>\n",
       "      <td>Ses05F_script01_1_M005</td>\n",
       "      <td>46.11</td>\n",
       "      <td>49.33</td>\n",
       "      <td>i could hear him right through the floor of my...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>Ses03M_script01_1_M005</td>\n",
       "      <td>49.0414</td>\n",
       "      <td>51.432</td>\n",
       "      <td>i could hear it right through the floor</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9827</th>\n",
       "      <td>Ses05M_script02_2_F026</td>\n",
       "      <td>313.83</td>\n",
       "      <td>318.297</td>\n",
       "      <td>but this isn't at all what i wanted it to be</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>Ses02M_impro06_M019</td>\n",
       "      <td>223.926</td>\n",
       "      <td>233.621</td>\n",
       "      <td>well you know i appreciate you coming over and...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>Ses02F_script01_1_M027</td>\n",
       "      <td>212.7</td>\n",
       "      <td>225.662</td>\n",
       "      <td>well if she does then that's the end of it but...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>Ses01M_impro02_M001</td>\n",
       "      <td>13.76</td>\n",
       "      <td>17.52</td>\n",
       "      <td>i have to go back</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>Ses01M_impro06_M000</td>\n",
       "      <td>12.4633</td>\n",
       "      <td>16.51</td>\n",
       "      <td>yeah i'm just yeah</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session1/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>Ses05F_impro06_M004</td>\n",
       "      <td>54.92</td>\n",
       "      <td>58.55</td>\n",
       "      <td>it's the worst when they go like that was he y...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session5/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>Ses04F_impro06_F007</td>\n",
       "      <td>184.47</td>\n",
       "      <td>187.39</td>\n",
       "      <td>thank you for being here</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>Ses04F_script01_3_M031</td>\n",
       "      <td>214.783</td>\n",
       "      <td>224.951</td>\n",
       "      <td>for instance one time it had been raining seve...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session4/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>Ses03M_script01_3_M033</td>\n",
       "      <td>286.262</td>\n",
       "      <td>297.918</td>\n",
       "      <td>a little more selfish and they'd still be here...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session3/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>Ses02M_impro02_M001</td>\n",
       "      <td>26.7598</td>\n",
       "      <td>31.4253</td>\n",
       "      <td>you won't be i'll be back i'll be back before ...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/w...</td>\n",
       "      <td>data/IEMOCAP_full_release/Session2/sentences/F...</td>\n",
       "      <td>sad</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       index start_time end_time  \\\n",
       "9076     Ses05M_impro02_M007      42.91    47.78   \n",
       "280      Ses01F_impro06_F022      217.5   222.41   \n",
       "5055     Ses03M_impro06_M029    209.011  212.856   \n",
       "5014     Ses03M_impro06_F009      100.1  103.191   \n",
       "8565  Ses05F_script01_1_M003      31.97    38.22   \n",
       "4390  Ses03F_script02_2_F051    433.999  437.005   \n",
       "5034     Ses03M_impro06_M008    60.8439  68.7049   \n",
       "5431  Ses03M_script01_3_M041    370.332  375.114   \n",
       "3896     Ses03F_impro06_M002    48.6398  55.4484   \n",
       "2764     Ses02M_impro02_F008    64.7625  67.7895   \n",
       "9087     Ses05M_impro02_M018     111.65   119.95   \n",
       "1419  Ses01M_script01_3_F021     253.41   256.44   \n",
       "8356     Ses05F_impro06_M006      67.72    69.16   \n",
       "2375  Ses02F_script01_3_M023     200.09   207.24   \n",
       "959      Ses01M_impro02_M011      82.09    86.28   \n",
       "1329  Ses01M_script01_1_M007    69.4734  72.3994   \n",
       "528   Ses01F_script01_3_M028     272.44  283.502   \n",
       "2757     Ses02M_impro02_F001    15.5524  23.3599   \n",
       "644   Ses01F_script02_2_F034     339.34   343.81   \n",
       "8778  Ses05F_script02_2_F016    197.721  203.703   \n",
       "7202     Ses04M_impro06_M006      91.11    97.43   \n",
       "7940     Ses05F_impro02_F022     169.17   182.02   \n",
       "5024     Ses03M_impro06_F019    231.986  234.955   \n",
       "7983     Ses05F_impro02_M026     189.28   200.16   \n",
       "8569  Ses05F_script01_1_M007       63.8    70.23   \n",
       "4375  Ses03F_script02_2_F036    313.386  318.235   \n",
       "8697  Ses05F_script01_3_M031    298.402  308.047   \n",
       "1872     Ses02F_impro02_F004    63.2468  75.4222   \n",
       "4283  Ses03F_script02_1_F011      157.9  160.651   \n",
       "8353     Ses05F_impro06_M003      50.17    53.88   \n",
       "...                      ...        ...      ...   \n",
       "1202     Ses01M_impro06_M024     193.13   197.51   \n",
       "3679     Ses03F_impro02_F025    169.312   171.28   \n",
       "5009     Ses03M_impro06_F004    36.8471    40.23   \n",
       "4221  Ses03F_script01_3_F032    388.038   391.43   \n",
       "1470  Ses01M_script01_3_M041      460.4   463.85   \n",
       "5056     Ses03M_impro06_M030    219.233  221.374   \n",
       "7209     Ses04M_impro06_M013     211.46   220.33   \n",
       "8351     Ses05F_impro06_M001      15.67  21.0373   \n",
       "9699  Ses05M_script01_3_F024      406.5   409.18   \n",
       "4698     Ses03M_impro02_M016    110.054  113.218   \n",
       "7179     Ses04M_impro06_F003      44.56     49.5   \n",
       "4361  Ses03F_script02_2_F022    196.094  202.081   \n",
       "1186     Ses01M_impro06_M008      71.79  76.0581   \n",
       "6654  Ses04F_script02_2_F041    372.819    376.5   \n",
       "521   Ses01F_script01_3_M021     216.48   220.04   \n",
       "6407  Ses04F_script01_1_M026     207.42  210.353   \n",
       "9319     Ses05M_impro06_M014     148.23  155.775   \n",
       "5840     Ses04F_impro02_M000     7.3037    11.59   \n",
       "8567  Ses05F_script01_1_M005      46.11    49.33   \n",
       "5274  Ses03M_script01_1_M005    49.0414   51.432   \n",
       "9827  Ses05M_script02_2_F026     313.83  318.297   \n",
       "2990     Ses02M_impro06_M019    223.926  233.621   \n",
       "2266  Ses02F_script01_1_M027      212.7  225.662   \n",
       "949      Ses01M_impro02_M001      13.76    17.52   \n",
       "1178     Ses01M_impro06_M000    12.4633    16.51   \n",
       "8354     Ses05F_impro06_M004      54.92    58.55   \n",
       "6092     Ses04F_impro06_F007     184.47   187.39   \n",
       "6530  Ses04F_script01_3_M031    214.783  224.951   \n",
       "5423  Ses03M_script01_3_M033    286.262  297.918   \n",
       "2772     Ses02M_impro02_M001    26.7598  31.4253   \n",
       "\n",
       "                                                   text  \\\n",
       "9076  i don't have a choice i have to go if i don't ...   \n",
       "280   she used to have these poetry parties on memor...   \n",
       "5055                 he actually wanted to do something   \n",
       "5014                                       how are they   \n",
       "8565  i don't know but when it cracked he ran back i...   \n",
       "4390                                    i'm sorry augie   \n",
       "5034  you know i was always the one to tell him to b...   \n",
       "5431  otherwise what you have is loot and there's bl...   \n",
       "3896  i didn't know him tricia but uh i heard that h...   \n",
       "2764                     i'll send you lots of pictures   \n",
       "9087  i know but i'll i'll send the pictures all the...   \n",
       "1419                                 you got to tell me   \n",
       "8356                                     it's the think   \n",
       "2375  it's all mixed up with so many other things yo...   \n",
       "959        i just got i feel like i'm in shock actually   \n",
       "1329                                      i guess he is   \n",
       "528   you can't just toss off a thing like that beca...   \n",
       "2757  i'm going to miss you too i don't know what i'...   \n",
       "644                         i know you are augie i know   \n",
       "8778  dancing barefoot in the sand drinking champagn...   \n",
       "7202  i mean they're you know they're upset it's lik...   \n",
       "7940  well we can try it baby don't beg me i mean if...   \n",
       "5024                                i would've loved to   \n",
       "7983  why has to be you there's all those other peop...   \n",
       "8569  i don't know the meaning of it but i know one ...   \n",
       "4375  things have never turned out anything the way ...   \n",
       "8697  and i got an ideal watching them all go down e...   \n",
       "1872  well we can do the best we can and and with um...   \n",
       "4283                          i don't know i just don't   \n",
       "8353                                 i am so sorry it's   \n",
       "...                                                 ...   \n",
       "1202  you know it's like affecting a lot of people i...   \n",
       "3679                              it's going to be okay   \n",
       "5009                       you guys were real close huh   \n",
       "4221                        and you still feel that way   \n",
       "1470                           i want you to know annie   \n",
       "5056                                    i can't do that   \n",
       "7209  there should just be some sort of rule that pe...   \n",
       "8351                   oh no i'm so sorry what happened   \n",
       "9699                        do you still feel like that   \n",
       "4698                            i don't know what to do   \n",
       "7179                          i'm sorry it's never easy   \n",
       "4361  i told myself finally this is how happy i'm su...   \n",
       "1186                  it's just really really messed up   \n",
       "6654  somebody who knew how to enjoy herself and did...   \n",
       "521   hey let's drive some place huh let's get out o...   \n",
       "6407                 i wanted to get this settled first   \n",
       "9319  you always think you know when you were you kn...   \n",
       "5840                         so you're leaving tomorrow   \n",
       "8567  i could hear him right through the floor of my...   \n",
       "5274            i could hear it right through the floor   \n",
       "9827       but this isn't at all what i wanted it to be   \n",
       "2990  well you know i appreciate you coming over and...   \n",
       "2266  well if she does then that's the end of it but...   \n",
       "949                                   i have to go back   \n",
       "1178                                 yeah i'm just yeah   \n",
       "8354  it's the worst when they go like that was he y...   \n",
       "6092                           thank you for being here   \n",
       "6530  for instance one time it had been raining seve...   \n",
       "5423  a little more selfish and they'd still be here...   \n",
       "2772  you won't be i'll be back i'll be back before ...   \n",
       "\n",
       "                                               wav_path  \\\n",
       "9076  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "280   data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "5055  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "5014  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "8565  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "4390  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "5034  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "5431  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "3896  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "2764  data/IEMOCAP_full_release/Session2/sentences/w...   \n",
       "9087  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "1419  data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "8356  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "2375  data/IEMOCAP_full_release/Session2/sentences/w...   \n",
       "959   data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "1329  data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "528   data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "2757  data/IEMOCAP_full_release/Session2/sentences/w...   \n",
       "644   data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "8778  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "7202  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "7940  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "5024  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "7983  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "8569  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "4375  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "8697  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "1872  data/IEMOCAP_full_release/Session2/sentences/w...   \n",
       "4283  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "8353  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "...                                                 ...   \n",
       "1202  data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "3679  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "5009  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "4221  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "1470  data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "5056  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "7209  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "8351  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "9699  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "4698  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "7179  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "4361  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "1186  data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "6654  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "521   data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "6407  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "9319  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "5840  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "8567  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "5274  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "9827  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "2990  data/IEMOCAP_full_release/Session2/sentences/w...   \n",
       "2266  data/IEMOCAP_full_release/Session2/sentences/w...   \n",
       "949   data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "1178  data/IEMOCAP_full_release/Session1/sentences/w...   \n",
       "8354  data/IEMOCAP_full_release/Session5/sentences/w...   \n",
       "6092  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "6530  data/IEMOCAP_full_release/Session4/sentences/w...   \n",
       "5423  data/IEMOCAP_full_release/Session3/sentences/w...   \n",
       "2772  data/IEMOCAP_full_release/Session2/sentences/w...   \n",
       "\n",
       "                                         alignment_path emotion valence  \\\n",
       "9076  data/IEMOCAP_full_release/Session5/sentences/F...     sad       2   \n",
       "280   data/IEMOCAP_full_release/Session1/sentences/F...     sad       4   \n",
       "5055  data/IEMOCAP_full_release/Session3/sentences/F...     sad     2.5   \n",
       "5014  data/IEMOCAP_full_release/Session3/sentences/F...     sad       2   \n",
       "8565  data/IEMOCAP_full_release/Session5/sentences/F...     sad     2.5   \n",
       "4390  data/IEMOCAP_full_release/Session3/sentences/F...     sad       3   \n",
       "5034  data/IEMOCAP_full_release/Session3/sentences/F...     sad       3   \n",
       "5431  data/IEMOCAP_full_release/Session3/sentences/F...     sad       2   \n",
       "3896  data/IEMOCAP_full_release/Session3/sentences/F...     sad     2.5   \n",
       "2764  data/IEMOCAP_full_release/Session2/sentences/F...     sad       4   \n",
       "9087  data/IEMOCAP_full_release/Session5/sentences/F...     sad       2   \n",
       "1419  data/IEMOCAP_full_release/Session1/sentences/F...     sad     2.5   \n",
       "8356  data/IEMOCAP_full_release/Session5/sentences/F...     sad     2.5   \n",
       "2375  data/IEMOCAP_full_release/Session2/sentences/F...     sad     2.5   \n",
       "959   data/IEMOCAP_full_release/Session1/sentences/F...     sad     2.5   \n",
       "1329  data/IEMOCAP_full_release/Session1/sentences/F...     sad       3   \n",
       "528   data/IEMOCAP_full_release/Session1/sentences/F...     sad  1.6667   \n",
       "2757  data/IEMOCAP_full_release/Session2/sentences/F...     sad     1.5   \n",
       "644   data/IEMOCAP_full_release/Session1/sentences/F...     sad     2.5   \n",
       "8778  data/IEMOCAP_full_release/Session5/sentences/F...     sad       4   \n",
       "7202  data/IEMOCAP_full_release/Session4/sentences/F...     sad       2   \n",
       "7940  data/IEMOCAP_full_release/Session5/sentences/F...     sad     1.5   \n",
       "5024  data/IEMOCAP_full_release/Session3/sentences/F...     sad     2.5   \n",
       "7983  data/IEMOCAP_full_release/Session5/sentences/F...     sad     1.5   \n",
       "8569  data/IEMOCAP_full_release/Session5/sentences/F...     sad       2   \n",
       "4375  data/IEMOCAP_full_release/Session3/sentences/F...     sad  1.6667   \n",
       "8697  data/IEMOCAP_full_release/Session5/sentences/F...     sad     2.5   \n",
       "1872  data/IEMOCAP_full_release/Session2/sentences/F...     sad       2   \n",
       "4283  data/IEMOCAP_full_release/Session3/sentences/F...     sad       2   \n",
       "8353  data/IEMOCAP_full_release/Session5/sentences/F...     sad       2   \n",
       "...                                                 ...     ...     ...   \n",
       "1202  data/IEMOCAP_full_release/Session1/sentences/F...     sad     1.5   \n",
       "3679  data/IEMOCAP_full_release/Session3/sentences/F...     sad     1.5   \n",
       "5009  data/IEMOCAP_full_release/Session3/sentences/F...     sad       2   \n",
       "4221  data/IEMOCAP_full_release/Session3/sentences/F...     sad       3   \n",
       "1470  data/IEMOCAP_full_release/Session1/sentences/F...     sad       2   \n",
       "5056  data/IEMOCAP_full_release/Session3/sentences/F...     sad     2.5   \n",
       "7209  data/IEMOCAP_full_release/Session4/sentences/F...     sad       2   \n",
       "8351  data/IEMOCAP_full_release/Session5/sentences/F...     sad     1.5   \n",
       "9699  data/IEMOCAP_full_release/Session5/sentences/F...     sad       3   \n",
       "4698  data/IEMOCAP_full_release/Session3/sentences/F...     sad     1.5   \n",
       "7179  data/IEMOCAP_full_release/Session4/sentences/F...     sad     2.5   \n",
       "4361  data/IEMOCAP_full_release/Session3/sentences/F...     sad  3.6667   \n",
       "1186  data/IEMOCAP_full_release/Session1/sentences/F...     sad       2   \n",
       "6654  data/IEMOCAP_full_release/Session4/sentences/F...     sad       2   \n",
       "521   data/IEMOCAP_full_release/Session1/sentences/F...     sad  2.6667   \n",
       "6407  data/IEMOCAP_full_release/Session4/sentences/F...     sad     2.5   \n",
       "9319  data/IEMOCAP_full_release/Session5/sentences/F...     sad     1.5   \n",
       "5840  data/IEMOCAP_full_release/Session4/sentences/F...     sad     2.5   \n",
       "8567  data/IEMOCAP_full_release/Session5/sentences/F...     sad       2   \n",
       "5274  data/IEMOCAP_full_release/Session3/sentences/F...     sad       2   \n",
       "9827  data/IEMOCAP_full_release/Session5/sentences/F...     sad       2   \n",
       "2990  data/IEMOCAP_full_release/Session2/sentences/F...     sad       2   \n",
       "2266  data/IEMOCAP_full_release/Session2/sentences/F...     sad       2   \n",
       "949   data/IEMOCAP_full_release/Session1/sentences/F...     sad       2   \n",
       "1178  data/IEMOCAP_full_release/Session1/sentences/F...     sad       3   \n",
       "8354  data/IEMOCAP_full_release/Session5/sentences/F...     sad       2   \n",
       "6092  data/IEMOCAP_full_release/Session4/sentences/F...     sad       2   \n",
       "6530  data/IEMOCAP_full_release/Session4/sentences/F...     sad     2.5   \n",
       "5423  data/IEMOCAP_full_release/Session3/sentences/F...     sad     2.5   \n",
       "2772  data/IEMOCAP_full_release/Session2/sentences/F...     sad     3.5   \n",
       "\n",
       "     arousal dominance gender emotion_code  \n",
       "9076  3.6667    2.3333      M            1  \n",
       "280        3       3.5      F            1  \n",
       "5055       3       3.5      M            1  \n",
       "5014       2         3      F            1  \n",
       "8565       3       3.5      M            1  \n",
       "4390  2.3333    1.6667      F            1  \n",
       "5034     2.5       3.5      M            1  \n",
       "5431       3       3.5      M            1  \n",
       "3896     1.5         3      M            1  \n",
       "2764       3         3      F            1  \n",
       "9087  3.3333    2.3333      M            1  \n",
       "1419     1.5       2.5      F            1  \n",
       "8356       2       2.5      M            1  \n",
       "2375     2.5       3.5      M            1  \n",
       "959      2.5       3.5      M            1  \n",
       "1329  2.3333         2      M            1  \n",
       "528   3.3333    3.6667      M            1  \n",
       "2757     2.5       4.5      F            1  \n",
       "644        2         2      F            1  \n",
       "8778     2.5       3.5      F            1  \n",
       "7202     2.5         2      M            1  \n",
       "7940     3.5       2.5      F            1  \n",
       "5024       2         3      F            1  \n",
       "7983     3.5       1.5      M            1  \n",
       "8569     3.5       3.5      M            1  \n",
       "4375       3    2.6667      F            1  \n",
       "8697     3.5         4      M            1  \n",
       "1872     2.5       2.5      F            1  \n",
       "4283       3         4      F            1  \n",
       "8353     2.5       2.5      M            1  \n",
       "...      ...       ...    ...          ...  \n",
       "1202       3       3.5      M            1  \n",
       "3679       2         2      F            1  \n",
       "5009       2         3      F            1  \n",
       "4221       2       2.5      F            1  \n",
       "1470     1.5         2      M            1  \n",
       "5056       2         3      M            1  \n",
       "7209       2         3      M            1  \n",
       "8351       3         3      M            1  \n",
       "9699       2         2      F            1  \n",
       "4698       3         3      M            1  \n",
       "7179       2       2.5      F            1  \n",
       "4361  2.3333         3      F            1  \n",
       "1186       2         3      M            1  \n",
       "6654       4         3      F            1  \n",
       "521   2.6667    2.6667      M            1  \n",
       "6407       2         3      M            1  \n",
       "9319       3       2.5      M            1  \n",
       "5840     1.5         2      M            1  \n",
       "8567       3         3      M            1  \n",
       "5274     2.5         3      M            1  \n",
       "9827  2.3333         2      F            1  \n",
       "2990       2         4      M            1  \n",
       "2266       3         4      M            1  \n",
       "949        2       3.5      M            1  \n",
       "1178     2.5         2      M            1  \n",
       "8354     2.5         3      M            1  \n",
       "6092     2.5       2.5      F            1  \n",
       "6530     2.5         4      M            1  \n",
       "5423     2.5       4.5      M            1  \n",
       "2772       3       3.5      M            1  \n",
       "\n",
       "[765 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "em_df = build_model(X_train,patterns)\n",
    "patterns_list = np.array(list(em_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5732\n"
     ]
    }
   ],
   "source": [
    "print(len(em_df))\n",
    "# em_df.head()\n",
    "# em_df.to_pickle('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Macro 0.03846249145519912\n",
      "Recall Macro 0.07496104767939242\n",
      "F1 Macro 0.05083933507700077\n",
      " \n",
      "Precision Micro 0.050933786078098474\n",
      "Recall Micro 0.050933786078098474\n",
      "F1 Micro 0.050933786078098474\n",
      " \n",
      "Precision Weighted 0.03823185184053815\n",
      "Recall Weighted 0.050933786078098474\n",
      "F1 Weighted 0.043678103100488655\n"
     ]
    }
   ],
   "source": [
    "# pred_y, y_train\n",
    "precision = precision_score(list(y_train),pred_y,average='macro')\n",
    "recall = recall_score(list(y_train),pred_y,average='macro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Macro',precision)\n",
    "print('Recall Macro',recall)\n",
    "print('F1 Macro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='micro')\n",
    "recall = recall_score(list(y_train),pred_y,average='micro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Micro',precision)\n",
    "print('Recall Micro',recall)\n",
    "print('F1 Micro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Macro 0.626538733670343\n",
      "Recall Macro 0.5235144012549827\n",
      "F1 Macro 0.5704119923846513\n",
      " \n",
      "Precision Micro 0.5930324623911323\n",
      "Recall Micro 0.5930324623911323\n",
      "F1 Micro 0.5930324623911323\n",
      " \n",
      "Precision Weighted 0.6143713968148123\n",
      "Recall Weighted 0.5930324623911323\n",
      "F1 Weighted 0.6035133638141245\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_test),pred_y,average='macro')\n",
    "recall = recall_score(list(y_test),pred_y,average='macro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Macro',precision)\n",
    "print('Recall Macro',recall)\n",
    "print('F1 Macro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='micro')\n",
    "recall = recall_score(list(y_test),pred_y,average='micro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Micro',precision)\n",
    "print('Recall Micro',recall)\n",
    "print('F1 Micro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without multiple wild-card patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "ang    1141\n",
       "hap     680\n",
       "neu    1440\n",
       "sad     947\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_multiwildcard(patterns):\n",
    "    for index, patt in patterns.items():\n",
    "        flt_patt = {p for p in patt if p.split(' ').count('.+') == 1}\n",
    "        patterns[index] = flt_patt\n",
    "    return patterns\n",
    "\n",
    "patterns = remove_multiwildcard(patterns)\n",
    "# data = two_emotions(data,emotional_mapping,'sad','exc')\n",
    "# Balance Data\n",
    "# data = balance_data(data)\n",
    "y = data.emotion_code\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3)\n",
    "\n",
    "data.groupby('emotion').count()['index'] #  6,453 Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "em_df = build_model(X_train,patterns)\n",
    "patterns_list = np.array(list(em_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5749\n"
     ]
    }
   ],
   "source": [
    "print(len(em_df))\n",
    "em_df.head()\n",
    "# em_df.to_pickle('pickles/patterns/pfief_matrix.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.7311524992723947\n",
      "Recall Weighted 0.699151103565365\n",
      "F1 Weighted 0.7147938042338186\n"
     ]
    }
   ],
   "source": [
    "# pred_y, y_train\n",
    "# precision = precision_score(list(y_train),pred_y,average='macro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='macro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Macro',precision)\n",
    "# print('Recall Macro',recall)\n",
    "# print('F1 Macro',f1)\n",
    "# print(' ')\n",
    "# precision = precision_score(list(y_train),pred_y,average='micro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='micro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Micro',precision)\n",
    "# print('Recall Micro',recall)\n",
    "# print('F1 Micro',f1)\n",
    "# print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)\n",
    "\n",
    "\n",
    "# Precision Macro 0.7664926811354967\n",
    "# Recall Macro 0.6423609709732143\n",
    "# F1 Macro 0.6989583086378197\n",
    " \n",
    "# Precision Micro 0.6947368421052632\n",
    "# Recall Micro 0.6947368421052632\n",
    "# F1 Micro 0.6947368421052632\n",
    " \n",
    "# Precision Weighted 0.7386741269995074\n",
    "# Recall Weighted 0.6947368421052632\n",
    "# F1 Weighted 0.7160320960247799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.622545876774059\n",
      "Recall Weighted 0.5827395091053048\n",
      "F1 Weighted 0.6019853602757568\n"
     ]
    }
   ],
   "source": [
    "# precision = precision_score(list(y_test),pred_y,average='macro')\n",
    "# recall = recall_score(list(y_test),pred_y,average='macro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Macro',precision)\n",
    "# print('Recall Macro',recall)\n",
    "# print('F1 Macro',f1)\n",
    "# print(' ')\n",
    "# precision = precision_score(list(y_test),pred_y,average='micro')\n",
    "# recall = recall_score(list(y_test),pred_y,average='micro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Micro',precision)\n",
    "# print('Recall Micro',recall)\n",
    "# print('F1 Micro',f1)\n",
    "# print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)\n",
    "\n",
    "\n",
    "# Precision Macro 0.6295216882336137\n",
    "# Recall Macro 0.5249158266314806\n",
    "# F1 Macro 0.5724794856483989\n",
    " \n",
    "# Precision Micro 0.5874901029295329\n",
    "# Recall Micro 0.5874901029295329\n",
    "# F1 Micro 0.5874901029295329\n",
    " \n",
    "# Precision Weighted 0.6153167839850325\n",
    "# Recall Weighted 0.5874901029295329\n",
    "# F1 Weighted 0.6010815612885869"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('pickles/patterns/scaled_pattern_features4emo.pickle','rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        full_feature_table = save['full_feature_table']\n",
    "        wc_feature_table = save['wc_feature_table']\n",
    "        cw_feature_table = save['cw_feature_table']\n",
    "        del save\n",
    "except Exception as e:\n",
    "    print('Error loading pattern features pickle: ', e)\n",
    "    \n",
    "\n",
    "def calculate_final_matrix(em_df,matrix):\n",
    "    final = []\n",
    "    for val, val2 in zip(em_df.iterrows(),matrix.iterrows()):\n",
    "        final.append(val[1] + (val[1]*val2[1]))\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "def build_acumatrix(data,feature_table,saveToPickle = False, savePath = ''):\n",
    "    matrix = {}\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for index, row in data.iterrows():\n",
    "        emo = row.emotion\n",
    "        key = row['index']\n",
    "        patts = feature_table[key].keys()\n",
    "        for patt in patts:\n",
    "            tpatt = patt.split('_')[1]\n",
    "            if(tpatt not in matrix):\n",
    "                matrix[tpatt] = {}\n",
    "            if(emo not in matrix[tpatt]):\n",
    "                matrix[tpatt][emo] = []\n",
    "            matrix[tpatt][emo].append(feature_table[key][patt])\n",
    "    for val in matrix:\n",
    "        for emo in matrix[val].keys():\n",
    "            matrix[val][emo] = np.mean(matrix[val][emo])\n",
    "    matrix = pd.DataFrame(matrix).T\n",
    "    if(saveToPickle and savePath != ''):\n",
    "        matrix.to_pickle(savePath)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.335948</td>\n",
       "      <td>1.900873</td>\n",
       "      <td>1.183167</td>\n",
       "      <td>1.734590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.737349</td>\n",
       "      <td>4.226652</td>\n",
       "      <td>1.756493</td>\n",
       "      <td>3.078385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.607381</td>\n",
       "      <td>2.443553</td>\n",
       "      <td>1.623349</td>\n",
       "      <td>2.563002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.645587</td>\n",
       "      <td>3.158246</td>\n",
       "      <td>2.219460</td>\n",
       "      <td>2.152346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>2.070842</td>\n",
       "      <td>1.936470</td>\n",
       "      <td>1.228016</td>\n",
       "      <td>2.031131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.335948  1.900873  1.183167  1.734590\n",
       ".+ a big  1.737349  4.226652  1.756493  3.078385\n",
       ".+ a bit  1.607381  2.443553  1.623349  2.563002\n",
       ".+ a day  1.645587  3.158246  2.219460  2.152346\n",
       ".+ a dog  2.070842  1.936470  1.228016  2.031131"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = build_acumatrix(X_train,full_feature_table)\n",
    "matrix = matrix.fillna(np.min(matrix))\n",
    "\n",
    "summatrix = em_df + matrix\n",
    "mulmatrix = calculate_final_matrix(em_df,matrix)\n",
    "em_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>0.089627</td>\n",
       "      <td>0.032742</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>0.018379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>0.060808</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.019379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.025979</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>0.117548</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.072628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      0.089627  0.032742  0.027693  0.018379\n",
       ".+ a big  0.060808  0.002155  0.015315  0.019379\n",
       ".+ a bit  0.010465  0.002155  0.025979  0.000531\n",
       ".+ a day  0.117548  0.002155  0.008552  0.072628\n",
       ".+ a dog  0.003351  0.002155  0.028417  0.000531"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.455686</td>\n",
       "      <td>1.963112</td>\n",
       "      <td>1.215933</td>\n",
       "      <td>1.766470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.842994</td>\n",
       "      <td>4.235759</td>\n",
       "      <td>1.783394</td>\n",
       "      <td>3.138041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.624203</td>\n",
       "      <td>2.448818</td>\n",
       "      <td>1.665521</td>\n",
       "      <td>2.564363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.839023</td>\n",
       "      <td>3.165051</td>\n",
       "      <td>2.238441</td>\n",
       "      <td>2.308667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>2.077782</td>\n",
       "      <td>1.940642</td>\n",
       "      <td>1.262913</td>\n",
       "      <td>2.032210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.455686  1.963112  1.215933  1.766470\n",
       ".+ a big  1.842994  4.235759  1.783394  3.138041\n",
       ".+ a bit  1.624203  2.448818  1.665521  2.564363\n",
       ".+ a day  1.839023  3.165051  2.238441  2.308667\n",
       ".+ a dog  2.077782  1.940642  1.262913  2.032210"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulmatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pattern Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.7471977150105737\n",
      "Recall Weighted 0.7042444821731749\n",
      "F1 Weighted 0.7250855306668259\n"
     ]
    }
   ],
   "source": [
    "# pred_y, y_train\n",
    "# precision = precision_score(list(y_train),pred_y,average='macro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='macro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Macro',precision)\n",
    "# print('Recall Macro',recall)\n",
    "# print('F1 Macro',f1)\n",
    "# print(' ')\n",
    "# precision = precision_score(list(y_train),pred_y,average='micro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='micro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Micro',precision)\n",
    "# print('Recall Micro',recall)\n",
    "# print('F1 Micro',f1)\n",
    "# print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.6327815855434922\n",
      "Recall Weighted 0.5827395091053048\n",
      "F1 Weighted 0.6067304502634466\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WildCard Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = build_acumatrix(X_train,wc_feature_table)\n",
    "matrix = matrix.fillna(np.min(matrix))\n",
    "mulmatrix = calculate_final_matrix(em_df,matrix)\n",
    "# mulmatrix = em_df + matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.7464544072310809\n",
      "Recall Weighted 0.7049235993208829\n",
      "F1 Weighted 0.7250948065891478\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.6334115933210114\n",
      "Recall Weighted 0.5835312747426762\n",
      "F1 Weighted 0.6074491813662626\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContentWord Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = build_acumatrix(X_train,cw_feature_table)\n",
    "matrix = matrix.fillna(np.min(matrix))\n",
    "\n",
    "mulmatrix = calculate_final_matrix(em_df,matrix)\n",
    "# mulmatrix = em_df + matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.7477816420949193\n",
      "Recall Weighted 0.7066213921901529\n",
      "F1 Weighted 0.7266190904931528\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.6330080569132552\n",
      "Recall Weighted 0.5851148060174188\n",
      "F1 Weighted 0.6081199158140121\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
