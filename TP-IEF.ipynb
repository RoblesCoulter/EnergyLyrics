{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "\n",
    "#Data handling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Pickling\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Models \n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "#HTTP\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import seaborn\n",
    "import codecs\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "no_alignment_file = [4764]\n",
    "wrong_alignment = [3730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfief_path = 'Pattern_construction_code/luis_pattern_half/patterns_ignore_5'\n",
    "# pat_table = pd.read_csv('Pattern_construction_code/luis_pattern_half/patterns_ignore_5',sep='\\t')\n",
    "# pat_table\n",
    "\n",
    "with codecs.open(pfief_path,'r','utf-8') as content_file:\n",
    "    content = content_file.read()\n",
    "len(set(map(lambda x: x.split('\\t')[0] ,content.split('\\n'))))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern(text):\n",
    "    text = json.dumps(text)\n",
    "    url = 'http://192.168.2.101:7878/api/get_patt'\n",
    "    data = dict(input_tweets = text)\n",
    "    resp = requests.post(url=url, data=data)\n",
    "    r = json.loads(resp.text)\n",
    "    return map(lambda x: x['pattern'],r)\n",
    "    \n",
    "def get_deep_emotion(text):\n",
    "    text = json.dumps(text)\n",
    "    url = 'http://192.168.2.101:7878/api/get_emo'\n",
    "    data = dict(input_tweets = text)\n",
    "    resp = requests.post(url=url, data=data)\n",
    "    r = json.loads(resp.text)\n",
    "    return r\n",
    "\n",
    "def clean_text(text, remove_actions = True):\n",
    "    punct_str = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~«»“…‘”'\n",
    "    if(remove_actions):\n",
    "        text = re.sub(r\" ?\\[[^)]+\\]\", \"\", text)\n",
    "    for p in punct_str:\n",
    "        text = text.replace(p,' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "def get_f1_score(precision,recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def get_patterns_load(data,patterns_df, emotion):\n",
    "    index = data[data.emotion == emotion ]['index']\n",
    "    patterns = patterns_df.loc[list(index)]\n",
    "    load = []\n",
    "    for pat in patterns.iterrows():\n",
    "        load = load + list(pat[1].dropna())\n",
    "    return load\n",
    "\n",
    "\n",
    "def extract_patterns(data,extract=False):\n",
    "    if(extract):\n",
    "        patterns = {}\n",
    "        for index, row in data.iterrows():\n",
    "            patterns[row['index']] = set(get_pattern([row['text']])[0].values())\n",
    "            print('Extracted pattern from '+ row['index'] + ' index:'+ str(index))\n",
    "            print('Size: ', len(patterns[row['index']]), 'Patterns size', len(patterns))\n",
    "        try:\n",
    "            print('Saving Pickle')\n",
    "            with open('pickles/patterns/pattern.pickle','wb') as f:\n",
    "                save = {\n",
    "                    'patterns' : patterns\n",
    "                }\n",
    "                pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "                print('Successfully saved in pattern.pickle')\n",
    "                return patterns\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to pickle', e)\n",
    "            print('Patterns probably not saved.')\n",
    "            return patterns\n",
    "    else:\n",
    "        try:\n",
    "            with open('pickles/patterns/pattern.pickle','rb') as f:\n",
    "                save = pickle.load(f)\n",
    "                patterns = save['patterns']\n",
    "                del save\n",
    "                returning = {}\n",
    "                for key in list(data['index']):\n",
    "                    returning[key] = patterns[key]\n",
    "                return returning\n",
    "        except Exception as e:\n",
    "            print('Error loading base datasets pickle: ', e)\n",
    "            \n",
    "def build_emotions_counter(data,patterns_df):\n",
    "    emotions_counter ={}\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for emotion in emotions_list:\n",
    "        load = get_patterns_load(data,patterns_df,emotion)\n",
    "        emotions_counter[emotion] = collections.Counter(load)\n",
    "    return emotions_counter\n",
    "\n",
    "def build_frequencyframe(all_patterns,emotions_counter):\n",
    "    df_patt = {}\n",
    "    for pattern in all_patterns:\n",
    "        df_patt[pattern] = {}\n",
    "        for emotion in emotions_counter:\n",
    "            df_patt[pattern][emotion] = emotions_counter[emotion][pattern]\n",
    "    return pd.DataFrame(df_patt).T\n",
    "\n",
    "def build_pfief(df_patt):\n",
    "    ief = ((df_patt+1).rdiv(df_patt.sum(axis=1)+1, axis=0)+1).apply(np.log10)\n",
    "    pf = ((df_patt.sum(axis=0)+1)/(df_patt+1)).apply(np.log10)\n",
    "    return ief * pf\n",
    "\n",
    "def balance_data(data):\n",
    "    min_sample = min(data.groupby('emotion').count()['index'])\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    samples = []\n",
    "    for emotion in emotions_list:\n",
    "        samples.append(data[data.emotion == emotion].sample(n=min_sample))\n",
    "    result = pd.concat(samples).sample(frac=1)\n",
    "    return result\n",
    "        \n",
    "def two_emotions(data,emotional_mapping,emotion1,emotion2):\n",
    "    emotion_code = emotional_mapping[emotion1]\n",
    "    emotion_sample = data[data.emotion_code == emotion_code]\n",
    "    emotion_code2 = emotional_mapping[emotion2]\n",
    "    emotion_sample2 = data[data.emotion_code == emotion_code2]\n",
    "    if(len(emotion_sample2) < len(emotion_sample)):\n",
    "        emotion_sample = emotion_sample.sample(n=len(emotion_sample2))\n",
    "    else:\n",
    "        emotion_sample2 = emotion_sample2.sample(n=len(emotion_sample))\n",
    "    sample = pd.concat([emotion_sample,emotion_sample2]).sample(frac=1)\n",
    "    return sample\n",
    "\n",
    "def filter_word_count(data, n_count):\n",
    "    return data[list(map(lambda x: len(x.split(' ')) >= n_count,data['text']))]\n",
    "\n",
    "def remove_empty_patterns(data,patterns):\n",
    "    empty_patterns = [k for k, v in patterns.items() if len(v) < 1]\n",
    "    patterns = { k:v for k, v in patterns.items() if len(v) > 1 }\n",
    "    data = filter(lambda x: x[1]['index'] not in empty_patterns ,data.iterrows())\n",
    "    data = pd.DataFrame.from_items(data).T\n",
    "    return data,patterns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(word_count,emotional_mapping):\n",
    "    # full = generate_IEMOCAP_df()\n",
    "    data = pd.read_csv('data/IEMOCAP_sentences_votebased.csv',index_col=0)\n",
    "    data['emotion_code'] = data['emotion'].map( emotional_mapping ).astype(int)\n",
    "    # Take away fear, surprise,disgust, xxx and others. Not enough data\n",
    "    data = data[data.emotion_code < 4]\n",
    "    # Clean Transcripts\n",
    "    try:\n",
    "        data = data.drop(no_alignment_file)\n",
    "    except Exception as e:\n",
    "        print('Error at: ',e)\n",
    "    # Remove rows that have wrong Alignment file\n",
    "    try:\n",
    "        data = data.drop(wrong_alignment)\n",
    "    except Exception as e:\n",
    "        print('Error at: ',e)\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    # Filter Word Count\n",
    "    data = filter_word_count(data, word_count)\n",
    "    patterns = extract_patterns(data)\n",
    "    data,patterns = remove_empty_patterns(data,patterns)\n",
    "    return data,patterns\n",
    "\n",
    "def build_model(data,patterns):\n",
    "    transcript_order = list(data['index'])\n",
    "    patterns_df = pd.DataFrame.from_dict(patterns, orient='index')\n",
    "    patterns_df = patterns_df.loc[transcript_order]\n",
    "    emotions_counter = build_emotions_counter(X_train,patterns_df)\n",
    "    all_patterns = []\n",
    "    for pat in patterns_df.iterrows():\n",
    "        all_patterns = all_patterns + list(pat[1].dropna())\n",
    "        \n",
    "    df_patt = build_frequencyframe(all_patterns,emotions_counter)\n",
    "    em_df = build_pfief(df_patt)\n",
    "    return em_df\n",
    "\n",
    "def get_frequency_vectors(data,patterns_list):\n",
    "    patterns = extract_patterns(data)\n",
    "    transcript_order = list(data['index'])\n",
    "    frequency_vectors = []\n",
    "    for index in patterns:\n",
    "        frequency_vectors.append(np.isin(patterns_list,np.array(list(patterns[index]))))\n",
    "    vectors = pd.DataFrame(frequency_vectors,columns=patterns_list,index=patterns.keys())\n",
    "    vectors = vectors.loc[transcript_order]\n",
    "    vectors = vectors * 1\n",
    "    return vectors\n",
    "    \n",
    "def calculate_scores(em_df,vectors):\n",
    "    em_matrix = em_df.T.as_matrix()\n",
    "    emotional_scores = []\n",
    "    for index, vector in vectors.iterrows():\n",
    "        emotional_scores.append(em_matrix.dot(vector))\n",
    "    emotions_list = list(em_df.columns)\n",
    "    scores = pd.DataFrame(emotional_scores,columns=emotions_list,index=list(vectors.index))\n",
    "    scores['pred_emotion'] = list(map(lambda x: x[1].idxmin(),scores.iterrows()))\n",
    "    scores['pred_code'] = scores['pred_emotion'].map(emotional_mapping).astype(int)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at:  labels [4764] not contained in axis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "ang    235\n",
       "hap    141\n",
       "neu    276\n",
       "sad    190\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotional_mapping = {'ang': 0, 'sad': 1, 'hap': 2, 'neu': 3,'fru': 4,'exc': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "data,patterns = load_data(3,emotional_mapping)\n",
    "# data = two_emotions(data,emotional_mapping,'sad','exc')\n",
    "# Balance Data\n",
    "# data = balance_data(data)\n",
    "y = data.emotion_code\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "X_train.groupby('emotion').count()['index'] #  6,453 Total\n",
    "X_test.groupby('emotion').count()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "em_df = build_model(X_train,patterns)\n",
    "patterns_list = np.array(list(em_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5928\n"
     ]
    }
   ],
   "source": [
    "print(len(em_df))\n",
    "# em_df.head()\n",
    "# em_df.to_pickle('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Macro 0.7560774144162135\n",
      "Recall Macro 0.6190157085313921\n",
      "F1 Macro 0.6807157836499023\n",
      " \n",
      "Precision Micro 0.6830065359477124\n",
      "Recall Micro 0.6830065359477124\n",
      "F1 Micro 0.6830065359477124\n",
      " \n",
      "Precision Weighted 0.7273584910326966\n",
      "Recall Weighted 0.6830065359477124\n",
      "F1 Weighted 0.7044851422840877\n"
     ]
    }
   ],
   "source": [
    "# pred_y, y_train\n",
    "precision = precision_score(list(y_train),pred_y,average='macro')\n",
    "recall = recall_score(list(y_train),pred_y,average='macro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Macro',precision)\n",
    "print('Recall Macro',recall)\n",
    "print('F1 Macro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='micro')\n",
    "recall = recall_score(list(y_train),pred_y,average='micro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Micro',precision)\n",
    "print('Recall Micro',recall)\n",
    "print('F1 Micro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Macro 0.6081145163271687\n",
      "Recall Macro 0.4898913854942629\n",
      "F1 Macro 0.5426383636891221\n",
      " \n",
      "Precision Micro 0.5498812351543944\n",
      "Recall Micro 0.5498812351543944\n",
      "F1 Micro 0.5498812351543944\n",
      " \n",
      "Precision Weighted 0.5912229312072166\n",
      "Recall Weighted 0.5498812351543944\n",
      "F1 Weighted 0.5698031875572036\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_test),pred_y,average='macro')\n",
    "recall = recall_score(list(y_test),pred_y,average='macro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Macro',precision)\n",
    "print('Recall Macro',recall)\n",
    "print('F1 Macro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='micro')\n",
    "recall = recall_score(list(y_test),pred_y,average='micro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Micro',precision)\n",
    "print('Recall Micro',recall)\n",
    "print('F1 Micro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without multiple wild-card patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "ang    1141\n",
       "hap     680\n",
       "neu    1440\n",
       "sad     947\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_multiwildcard(patterns):\n",
    "    for index, patt in patterns.items():\n",
    "        flt_patt = {p for p in patt if p.split(' ').count('.+') == 1}\n",
    "        patterns[index] = flt_patt\n",
    "    return patterns\n",
    "\n",
    "patterns = remove_multiwildcard(patterns)\n",
    "# data = two_emotions(data,emotional_mapping,'sad','exc')\n",
    "# Balance Data\n",
    "# data = balance_data(data)\n",
    "y = data.emotion_code\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3)\n",
    "\n",
    "data.groupby('emotion').count()['index'] #  6,453 Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "em_df = build_model(X_train,patterns)\n",
    "patterns_list = np.array(list(em_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5614\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.335632</td>\n",
       "      <td>1.773339</td>\n",
       "      <td>1.233435</td>\n",
       "      <td>1.653975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.514692</td>\n",
       "      <td>3.875035</td>\n",
       "      <td>2.202922</td>\n",
       "      <td>2.782855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.218580</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>2.090332</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.387807</td>\n",
       "      <td>3.667312</td>\n",
       "      <td>2.665174</td>\n",
       "      <td>2.600678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>2.075031</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>1.228233</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.335632  1.773339  1.233435  1.653975\n",
       ".+ a big  1.514692  3.875035  2.202922  2.782855\n",
       ".+ a bit  1.218580  1.937517  2.090332  2.043222\n",
       ".+ a day  1.387807  3.667312  2.665174  2.600678\n",
       ".+ a dog  2.075031  1.937517  1.228233  2.043222"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(em_df))\n",
    "em_df.head()\n",
    "# em_df.to_pickle('pickles/patterns/pfief_matrix.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.7558028038759393\n",
      "Recall Weighted 0.7256366723259763\n",
      "F1 Weighted 0.740412605913883\n"
     ]
    }
   ],
   "source": [
    "# pred_y, y_train\n",
    "# precision = precision_score(list(y_train),pred_y,average='macro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='macro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Macro',precision)\n",
    "# print('Recall Macro',recall)\n",
    "# print('F1 Macro',f1)\n",
    "# print(' ')\n",
    "# precision = precision_score(list(y_train),pred_y,average='micro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='micro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Micro',precision)\n",
    "# print('Recall Micro',recall)\n",
    "# print('F1 Micro',f1)\n",
    "# print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)\n",
    "\n",
    "\n",
    "# Precision Macro 0.7664926811354967\n",
    "# Recall Macro 0.6423609709732143\n",
    "# F1 Macro 0.6989583086378197\n",
    " \n",
    "# Precision Micro 0.6947368421052632\n",
    "# Recall Micro 0.6947368421052632\n",
    "# F1 Micro 0.6947368421052632\n",
    " \n",
    "# Precision Weighted 0.7386741269995074\n",
    "# Recall Weighted 0.6947368421052632\n",
    "# F1 Weighted 0.7160320960247799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.6200686604247473\n",
      "Recall Weighted 0.5874901029295329\n",
      "F1 Weighted 0.6033399155241551\n"
     ]
    }
   ],
   "source": [
    "# precision = precision_score(list(y_test),pred_y,average='macro')\n",
    "# recall = recall_score(list(y_test),pred_y,average='macro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Macro',precision)\n",
    "# print('Recall Macro',recall)\n",
    "# print('F1 Macro',f1)\n",
    "# print(' ')\n",
    "# precision = precision_score(list(y_test),pred_y,average='micro')\n",
    "# recall = recall_score(list(y_test),pred_y,average='micro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Micro',precision)\n",
    "# print('Recall Micro',recall)\n",
    "# print('F1 Micro',f1)\n",
    "# print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)\n",
    "\n",
    "\n",
    "# Precision Macro 0.6295216882336137\n",
    "# Recall Macro 0.5249158266314806\n",
    "# F1 Macro 0.5724794856483989\n",
    " \n",
    "# Precision Micro 0.5874901029295329\n",
    "# Recall Micro 0.5874901029295329\n",
    "# F1 Micro 0.5874901029295329\n",
    " \n",
    "# Precision Weighted 0.6153167839850325\n",
    "# Recall Weighted 0.5874901029295329\n",
    "# F1 Weighted 0.6010815612885869"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('pickles/patterns/scaledmfcc20_pattern_features4emo.pickle','rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        full_feature_table = save['full_feature_table']\n",
    "        wc_feature_table = save['wc_feature_table']\n",
    "        cw_feature_table = save['cw_feature_table']\n",
    "        del save\n",
    "except Exception as e:\n",
    "    print('Error loading pattern features pickle: ', e)\n",
    "    \n",
    "\n",
    "def calculate_final_matrix(em_df,matrix):\n",
    "    final = []\n",
    "    for val in em_df.iterrows():\n",
    "        final.append(val[1] * matrix.loc[val[0]])\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "def calculate_final_matrix_mul(em_df,matrix):\n",
    "    final = []\n",
    "    for val in em_df.iterrows():\n",
    "        final.append(val[1] + (val[1] * matrix.loc[val[0]]))\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "def calculate_final_matrix_sum(em_df,matrix):\n",
    "    final = []\n",
    "    for val in em_df.iterrows():\n",
    "        final.append(val[1] + matrix.loc[val[0]])\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "\n",
    "def build_acumatrix(data,feature_table,saveToPickle = False, savePath = ''):\n",
    "    matrix = {}\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for index, row in data.iterrows():\n",
    "        emo = row.emotion\n",
    "        key = row['index']\n",
    "        patts = feature_table[key].keys()\n",
    "        for patt in patts:\n",
    "            tpatt = patt.split('_')[1]\n",
    "            if(tpatt not in matrix):\n",
    "                matrix[tpatt] = {}\n",
    "            if(emo not in matrix[tpatt]):\n",
    "                matrix[tpatt][emo] = []\n",
    "            matrix[tpatt][emo].append(feature_table[key][patt])\n",
    "    for val in matrix:\n",
    "        for emo in matrix[val].keys():\n",
    "            matrix[val][emo] = np.mean(matrix[val][emo])\n",
    "    matrix = pd.DataFrame(matrix).T\n",
    "    if(saveToPickle and savePath != ''):\n",
    "        matrix.to_pickle(savePath)\n",
    "    return matrix\n",
    "\n",
    "def build_multiacumatrix(data,feature_table,saveToPickle = False, savePath = '',size = 20):\n",
    "    multimatrix = []\n",
    "    for i in range(size):\n",
    "        multimatrix.append(dict())\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for index, row in data.iterrows():\n",
    "        emo = row.emotion\n",
    "        key = row['index']\n",
    "        patts = feature_table[key].keys()\n",
    "        for patt in patts:\n",
    "            tpatt = patt.split('_')[1]\n",
    "            if(tpatt not in multimatrix[0]):\n",
    "                for matrix in multimatrix:\n",
    "                    matrix[tpatt] = {}\n",
    "                    for emotion in emotions_list:\n",
    "                        matrix[tpatt][emotion] = []\n",
    "            for i in range(size):\n",
    "                sub_feature = feature_table[key][patt][i]\n",
    "                multimatrix[i][tpatt][emo].append(sub_feature)\n",
    "    for i in range(size):\n",
    "        for val in multimatrix[i]:\n",
    "            for emo in multimatrix[i][val].keys():\n",
    "                if(len(multimatrix[i][val][emo]) > 0):\n",
    "                    multimatrix[i][val][emo] = np.mean(multimatrix[i][val][emo])\n",
    "                else:\n",
    "                    multimatrix[i][val][emo] = np.nan()\n",
    "        multimatrix[i] = pd.DataFrame(multimatrix[i]).T\n",
    "    if(saveToPickle and savePath != ''):\n",
    "        try:\n",
    "            print('Saving Pickle')\n",
    "            with open(savePath,'wb') as f:\n",
    "                save = {\n",
    "                    'multimatrix' : multimatrix\n",
    "                }\n",
    "                pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "                print('Successfully saved matrix to '+savePath)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to pickle', e)\n",
    "            print('Patterns probably not saved.')\n",
    "    return multimatrix\n",
    "\n",
    "def get_cumatrix(filePath):\n",
    "    try:\n",
    "        matrix = pd.read_pickle(filePath)\n",
    "        return matrix\n",
    "    except Exception as e:\n",
    "        print('Error loading matrix: ', e)\n",
    "\n",
    "def get_multiacumatrix(filePath):\n",
    "    try:\n",
    "        with open(filePath,'rb') as f:\n",
    "            save = pickle.load(f)\n",
    "            multimatrix = save['multimatrix']\n",
    "            del save\n",
    "            return multimatrix\n",
    "    except Exception as e:\n",
    "        print('Error loading matrix: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_matrix = build_acumatrix(X_train,full_feature_table)\n",
    "# full_matrix = full_matrix.fillna(np.max(full_matrix))\n",
    "\n",
    "# wc_matrix = build_acumatrix(X_train,wc_feature_table)\n",
    "# wc_matrix = wc_matrix.fillna(np.max(wc_matrix))\n",
    "\n",
    "# cw_matrix = build_acumatrix(X_train,cw_feature_table)\n",
    "# cw_matrix = cw_matrix.fillna(np.max(cw_matrix))\n",
    "\n",
    "#FOR MFCC 20 \n",
    "\n",
    "# full_matrices = build_multiacumatrix(X_train,full_feature_table,saveToPickle=True,savePath = 'pickles/patterns/full_mfcc20_matrix.pickle')\n",
    "# for i in range(20):\n",
    "#     full_matrices[i] = full_matrices[i].fillna(np.max(full_matrices[i]))\n",
    "# full_matrices[0]\n",
    "# wc_matrices = build_multiacumatrix(X_train,wc_feature_table,saveToPickle=True,savePath = 'pickles/patterns/wc_mfcc20_matrix.pickle')\n",
    "# for i in wc_matrices:\n",
    "#     wc_matrices[i] = wc_matrices[i].fillna(np.max(wc_matrices[i]))\n",
    "# # wc_matrices = wc_matrix.fillna(np.max(wc_matrix))\n",
    "\n",
    "# cw_matrices = build_multiacumatrix(X_train,cw_feature_table,saveToPickle=True,savePath= 'pickles/patterns/cw_mfcc20_matrix.pickle')\n",
    "# for i in cw_matrices:\n",
    "#     cw_matrices[i] = cw_matrices[i].fillna(np.max(cw_matrices[i]))\n",
    "# cw_matrix = cw_matrix.fillna(np.max(cw_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_matrix\n",
    "\n",
    "np.mean([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.330367</td>\n",
       "      <td>1.728037</td>\n",
       "      <td>1.196536</td>\n",
       "      <td>1.769234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.623602</td>\n",
       "      <td>4.072397</td>\n",
       "      <td>1.932672</td>\n",
       "      <td>2.933993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.603251</td>\n",
       "      <td>2.451827</td>\n",
       "      <td>1.622258</td>\n",
       "      <td>2.567150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.380523</td>\n",
       "      <td>3.677741</td>\n",
       "      <td>2.662913</td>\n",
       "      <td>2.588625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a few</th>\n",
       "      <td>3.026475</td>\n",
       "      <td>1.799399</td>\n",
       "      <td>1.435312</td>\n",
       "      <td>2.980369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.330367  1.728037  1.196536  1.769234\n",
       ".+ a big  1.623602  4.072397  1.932672  2.933993\n",
       ".+ a bit  1.603251  2.451827  1.622258  2.567150\n",
       ".+ a day  1.380523  3.677741  2.662913  2.588625\n",
       ".+ a few  3.026475  1.799399  1.435312  2.980369"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summatrix = calculate_final_matrix_sum(em_df,full_matrix)\n",
    "mulmatrix = calculate_final_matrix(em_df,full_matrix)\n",
    "mul2matrix = calculate_final_matrix_mul(em_df,full_matrix)\n",
    "em_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set1 =set(full_matrix.index)\n",
    "set2 = set(em_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.+ pants'}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1.difference(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>0.263903</td>\n",
       "      <td>0.226839</td>\n",
       "      <td>0.142655</td>\n",
       "      <td>0.161814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>0.409879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097358</td>\n",
       "      <td>0.226219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>0.117136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213028</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>0.250383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179725</td>\n",
       "      <td>0.385733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a few</th>\n",
       "      <td>0.023776</td>\n",
       "      <td>0.223846</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      0.263903  0.226839  0.142655  0.161814\n",
       ".+ a big  0.409879  0.000000  0.097358  0.226219\n",
       ".+ a bit  0.117136  0.000000  0.213028  0.000000\n",
       ".+ a day  0.250383  0.000000  0.179725  0.385733\n",
       ".+ a few  0.023776  0.223846  0.140013  0.000000"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulmatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5611, 4) (5611, 4) (5611, 4) (5612, 4) (5612, 4) (5612, 4)\n"
     ]
    }
   ],
   "source": [
    "print(summatrix.shape,mulmatrix.shape,em_df.shape,full_matrix.shape,cw_matrix.shape,wc_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pattern Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24978847049199454\n",
      "0.2601018675721562\n",
      "0.2548408660561287\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754382442165381\n",
      "0.7140916808149406\n",
      "0.7336843294314903\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74539261834061\n",
      "0.700169779286927\n",
      "0.7220738252768559\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2355038243640479\n",
      "0.2596991290577989\n",
      "0.24701039302980007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6018295286493484\n",
      "0.5827395091053048\n",
      "0.5921306954889984\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.604586204950291\n",
      "0.5922406967537609\n",
      "0.5983497776623551\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WildCard Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.330367</td>\n",
       "      <td>1.728037</td>\n",
       "      <td>1.196536</td>\n",
       "      <td>1.769234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.623602</td>\n",
       "      <td>4.072397</td>\n",
       "      <td>1.932672</td>\n",
       "      <td>2.933993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.603251</td>\n",
       "      <td>2.451827</td>\n",
       "      <td>1.622258</td>\n",
       "      <td>2.567150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.380523</td>\n",
       "      <td>3.677741</td>\n",
       "      <td>2.662913</td>\n",
       "      <td>2.588625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a few</th>\n",
       "      <td>3.026475</td>\n",
       "      <td>1.799399</td>\n",
       "      <td>1.435312</td>\n",
       "      <td>2.980369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.330367  1.728037  1.196536  1.769234\n",
       ".+ a big  1.623602  4.072397  1.932672  2.933993\n",
       ".+ a bit  1.603251  2.451827  1.622258  2.567150\n",
       ".+ a day  1.380523  3.677741  2.662913  2.588625\n",
       ".+ a few  3.026475  1.799399  1.435312  2.980369"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summatrix = calculate_final_matrix_sum(em_df,wc_matrix)\n",
    "mulmatrix = calculate_final_matrix(em_df,wc_matrix)\n",
    "mul2matrix = calculate_final_matrix_mul(em_df,wc_matrix)\n",
    "em_df.head()\n",
    "\n",
    "# mulmatrix = em_df + matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7553726542222787\n",
      "0.7147707979626485\n",
      "0.7345110628696748\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2352463709263634\n",
      "0.2614601018675722\n",
      "0.2476615203357769\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7480388196605868\n",
      "0.7052631578947368\n",
      "0.7260214715583349\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6004792694299194\n",
      "0.5914489311163895\n",
      "0.5959298922520592\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2094549375087102\n",
      "0.26128266033254155\n",
      "0.23251570957167425\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598300604043489\n",
      "0.5851148060174188\n",
      "0.5916342459272065\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContentWord Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.330367</td>\n",
       "      <td>1.728037</td>\n",
       "      <td>1.196536</td>\n",
       "      <td>1.769234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.623602</td>\n",
       "      <td>4.072397</td>\n",
       "      <td>1.932672</td>\n",
       "      <td>2.933993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.603251</td>\n",
       "      <td>2.451827</td>\n",
       "      <td>1.622258</td>\n",
       "      <td>2.567150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.380523</td>\n",
       "      <td>3.677741</td>\n",
       "      <td>2.662913</td>\n",
       "      <td>2.588625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a few</th>\n",
       "      <td>3.026475</td>\n",
       "      <td>1.799399</td>\n",
       "      <td>1.435312</td>\n",
       "      <td>2.980369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.330367  1.728037  1.196536  1.769234\n",
       ".+ a big  1.623602  4.072397  1.932672  2.933993\n",
       ".+ a bit  1.603251  2.451827  1.622258  2.567150\n",
       ".+ a day  1.380523  3.677741  2.662913  2.588625\n",
       ".+ a few  3.026475  1.799399  1.435312  2.980369"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summatrix = calculate_final_matrix_sum(em_df,cw_matrix)\n",
    "mulmatrix = calculate_final_matrix(em_df,cw_matrix)\n",
    "mul2matrix = calculate_final_matrix_mul(em_df,cw_matrix)\n",
    "em_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7556017582404628\n",
      "0.7171477079796265\n",
      "0.7358727081508172\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2547370178861727\n",
      "0.26553480475382\n",
      "0.2600238620063823\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7444354201785992\n",
      "0.702546689303905\n",
      "0.7228847356434576\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6038484179750068\n",
      "0.5922406967537609\n",
      "0.5979882324675635\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26036006843556897\n",
      "0.26920031670625494\n",
      "0.26470640496171755\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6013929020878835\n",
      "0.5890736342042755\n",
      "0.5951695265974676\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
