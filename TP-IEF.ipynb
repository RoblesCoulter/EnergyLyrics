{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "\n",
    "#Data handling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Pickling\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Models \n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "#HTTP\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import seaborn\n",
    "import codecs\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "no_alignment_file = [4764]\n",
    "wrong_alignment = [3730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfief_path = 'Pattern_construction_code/luis_pattern_half/patterns_ignore_5'\n",
    "# pat_table = pd.read_csv('Pattern_construction_code/luis_pattern_half/patterns_ignore_5',sep='\\t')\n",
    "# pat_table\n",
    "\n",
    "with codecs.open(pfief_path,'r','utf-8') as content_file:\n",
    "    content = content_file.read()\n",
    "len(set(map(lambda x: x.split('\\t')[0] ,content.split('\\n'))))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern(text):\n",
    "    text = json.dumps(text)\n",
    "    url = 'http://192.168.2.101:7878/api/get_patt'\n",
    "    data = dict(input_tweets = text)\n",
    "    resp = requests.post(url=url, data=data)\n",
    "    r = json.loads(resp.text)\n",
    "    return map(lambda x: x['pattern'],r)\n",
    "    \n",
    "def get_deep_emotion(text):\n",
    "    text = json.dumps(text)\n",
    "    url = 'http://192.168.2.101:7878/api/get_emo'\n",
    "    data = dict(input_tweets = text)\n",
    "    resp = requests.post(url=url, data=data)\n",
    "    r = json.loads(resp.text)\n",
    "    return r\n",
    "\n",
    "def clean_text(text, remove_actions = True):\n",
    "    punct_str = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~«»“…‘”'\n",
    "    if(remove_actions):\n",
    "        text = re.sub(r\" ?\\[[^)]+\\]\", \"\", text)\n",
    "    for p in punct_str:\n",
    "        text = text.replace(p,' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "def get_f1_score(precision,recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def get_patterns_load(data,patterns_df, emotion):\n",
    "    index = data[data.emotion == emotion ]['index']\n",
    "    patterns = patterns_df.loc[list(index)]\n",
    "    load = []\n",
    "    for pat in patterns.iterrows():\n",
    "        load = load + list(pat[1].dropna())\n",
    "    return load\n",
    "\n",
    "\n",
    "def extract_patterns(data,extract=False):\n",
    "    if(extract):\n",
    "        patterns = {}\n",
    "        for index, row in data.iterrows():\n",
    "            patterns[row['index']] = set(get_pattern([row['text']])[0].values())\n",
    "            print('Extracted pattern from '+ row['index'] + ' index:'+ str(index))\n",
    "            print('Size: ', len(patterns[row['index']]), 'Patterns size', len(patterns))\n",
    "        try:\n",
    "            print('Saving Pickle')\n",
    "            with open('pickles/patterns/pattern.pickle','wb') as f:\n",
    "                save = {\n",
    "                    'patterns' : patterns\n",
    "                }\n",
    "                pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "                print('Successfully saved in pattern.pickle')\n",
    "                return patterns\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to pickle', e)\n",
    "            print('Patterns probably not saved.')\n",
    "            return patterns\n",
    "    else:\n",
    "        try:\n",
    "            with open('pickles/patterns/pattern.pickle','rb') as f:\n",
    "                save = pickle.load(f)\n",
    "                patterns = save['patterns']\n",
    "                del save\n",
    "                returning = {}\n",
    "                for key in list(data['index']):\n",
    "                    returning[key] = patterns[key]\n",
    "                return returning\n",
    "        except Exception as e:\n",
    "            print('Error loading base datasets pickle: ', e)\n",
    "            \n",
    "def build_emotions_counter(data,patterns_df):\n",
    "    emotions_counter ={}\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for emotion in emotions_list:\n",
    "        load = get_patterns_load(data,patterns_df,emotion)\n",
    "        emotions_counter[emotion] = collections.Counter(load)\n",
    "    return emotions_counter\n",
    "\n",
    "def build_frequencyframe(all_patterns,emotions_counter):\n",
    "    df_patt = {}\n",
    "    for pattern in all_patterns:\n",
    "        df_patt[pattern] = {}\n",
    "        for emotion in emotions_counter:\n",
    "            df_patt[pattern][emotion] = emotions_counter[emotion][pattern]\n",
    "    return pd.DataFrame(df_patt).T\n",
    "\n",
    "def build_pfief(df_patt):\n",
    "    ief = ((df_patt+1).rdiv(df_patt.sum(axis=1)+1, axis=0)+1).apply(np.log10)\n",
    "    pf = ((df_patt.sum(axis=0)+1)/(df_patt+1)).apply(np.log10)\n",
    "    return ief * pf\n",
    "\n",
    "def balance_data(data):\n",
    "    min_sample = min(data.groupby('emotion').count()['index'])\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    samples = []\n",
    "    for emotion in emotions_list:\n",
    "        samples.append(data[data.emotion == emotion].sample(n=min_sample))\n",
    "    result = pd.concat(samples).sample(frac=1)\n",
    "    return result\n",
    "        \n",
    "def two_emotions(data,emotional_mapping,emotion1,emotion2):\n",
    "    emotion_code = emotional_mapping[emotion1]\n",
    "    emotion_sample = data[data.emotion_code == emotion_code]\n",
    "    emotion_code2 = emotional_mapping[emotion2]\n",
    "    emotion_sample2 = data[data.emotion_code == emotion_code2]\n",
    "    if(len(emotion_sample2) < len(emotion_sample)):\n",
    "        emotion_sample = emotion_sample.sample(n=len(emotion_sample2))\n",
    "    else:\n",
    "        emotion_sample2 = emotion_sample2.sample(n=len(emotion_sample))\n",
    "    sample = pd.concat([emotion_sample,emotion_sample2]).sample(frac=1)\n",
    "    return sample\n",
    "\n",
    "def filter_word_count(data, n_count):\n",
    "    return data[list(map(lambda x: len(x.split(' ')) >= n_count,data['text']))]\n",
    "\n",
    "def remove_empty_patterns(data,patterns):\n",
    "    empty_patterns = [k for k, v in patterns.items() if len(v) < 1]\n",
    "    patterns = { k:v for k, v in patterns.items() if len(v) >= 1 }\n",
    "    data = filter(lambda x: x[1]['index'] not in empty_patterns ,data.iterrows())\n",
    "    data = pd.DataFrame.from_items(data).T\n",
    "    return data,patterns\n",
    "\n",
    "\n",
    "def remove_multiwildcard(patterns):\n",
    "    for index, patt in patterns.items():\n",
    "        flt_patt = {p for p in patt if p.split(' ').count('.+') == 1}\n",
    "        patterns[index] = flt_patt\n",
    "    return patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(word_count,emotional_mapping):\n",
    "    # full = generate_IEMOCAP_df()\n",
    "    data = pd.read_csv('data/IEMOCAP_sentences_votebased.csv',index_col=0)\n",
    "    data['emotion_code'] = data['emotion'].map( emotional_mapping ).astype(int)\n",
    "    # Take away fear, surprise,disgust, xxx and others. Not enough data\n",
    "    data = data[data.emotion_code < 4]\n",
    "    # Clean Transcripts\n",
    "    \n",
    "    try:\n",
    "        data = data.drop(no_alignment_file)\n",
    "    except Exception as e:\n",
    "        print('Error at: ',e)\n",
    "    # Remove rows that have wrong Alignment file\n",
    "    try:\n",
    "        data = data.drop(wrong_alignment)\n",
    "    except Exception as e:\n",
    "        print('Error at: ',e)\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    # Filter Word Count\n",
    "    data = filter_word_count(data, word_count)\n",
    "    patterns = extract_patterns(data)\n",
    "    data,patterns = remove_empty_patterns(data,patterns)\n",
    "    return data,patterns\n",
    "\n",
    "def build_model(data,patterns):\n",
    "    transcript_order = list(data['index'])\n",
    "    patterns_df = pd.DataFrame.from_dict(patterns, orient='index')\n",
    "    patterns_df = patterns_df.loc[transcript_order]\n",
    "    emotions_counter = build_emotions_counter(X_train,patterns_df)\n",
    "    all_patterns = []\n",
    "    for pat in patterns_df.iterrows():\n",
    "        all_patterns = all_patterns + list(pat[1].dropna())\n",
    "        \n",
    "    df_patt = build_frequencyframe(all_patterns,emotions_counter)\n",
    "    em_df = build_pfief(df_patt)\n",
    "    return em_df\n",
    "\n",
    "def get_frequency_vectors(data,patterns_list):\n",
    "    patterns = extract_patterns(data)\n",
    "    transcript_order = list(data['index'])\n",
    "    frequency_vectors = []\n",
    "    for index in patterns:\n",
    "        frequency_vectors.append(np.isin(patterns_list,np.array(list(patterns[index]))))\n",
    "    vectors = pd.DataFrame(frequency_vectors,columns=patterns_list,index=patterns.keys())\n",
    "    vectors = vectors.loc[transcript_order]\n",
    "    vectors = vectors * 1\n",
    "    return vectors\n",
    "    \n",
    "def calculate_scores(em_df,vectors):\n",
    "    em_matrix = em_df.T.as_matrix()\n",
    "    emotional_scores = []\n",
    "    for index, vector in vectors.iterrows():\n",
    "        emotional_scores.append(em_matrix.dot(vector))\n",
    "    emotions_list = list(em_df.columns)\n",
    "    scores = pd.DataFrame(emotional_scores,columns=emotions_list,index=list(vectors.index))\n",
    "    scores['pred_emotion'] = list(map(lambda x: x[1].idxmin(),scores.iterrows()))\n",
    "    scores['pred_code'] = scores['pred_emotion'].map(emotional_mapping).astype(int)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at:  labels [4764] not contained in axis\n"
     ]
    }
   ],
   "source": [
    "emotional_mapping = {'ang': 0, 'sad': 1, 'hap': 2, 'neu': 3,'fru': 4,'exc': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "data,patterns = load_data(3,emotional_mapping)\n",
    "# data = two_emotions(data,emotional_mapping,'sad','exc')\n",
    "# Balance Data\n",
    "# data = balance_data(data)\n",
    "y = data.emotion_code\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "\n",
    "# X_train.groupby('emotion').count()['index'] #  6,453 Total\n",
    "# X_test.groupby('emotion').count()['index']\n",
    "try:\n",
    "    with open('pickles/matrix_basedata.pickle','rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        X_train = save['X_train']\n",
    "        X_test = save['X_test']\n",
    "        y_train = save['y_train']\n",
    "        y_test = save['y_test']\n",
    "        del save\n",
    "except Exception as e:\n",
    "    print('Error loading base datasets pickle: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "ang    1141\n",
       "hap     680\n",
       "neu    1440\n",
       "sad     947\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('emotion').count()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     print('Saving Pickle')\n",
    "#     with open('pickles/matrix_basedata.pickle','wb') as f:\n",
    "#         save = {\n",
    "#             'X_train' : X_train,\n",
    "#             'X_test' : X_test,\n",
    "#             'y_train' : y_train,\n",
    "#             'y_test': y_test\n",
    "#         }\n",
    "#         pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "#         print('Successfully saved in matrix_basedata.pickle')\n",
    "# except Exception as e:\n",
    "#     print('Unable to save data to pickle', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_df = build_model(X_train,patterns)\n",
    "patterns_list = np.array(list(em_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5953\n"
     ]
    }
   ],
   "source": [
    "print(len(em_df))\n",
    "# em_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Macro 0.75391121567249\n",
      "Recall Macro 0.6167756377209378\n",
      "F1 Macro 0.6784833015362706\n",
      " \n",
      "Precision Micro 0.6838978015448604\n",
      "Recall Micro 0.6838978015448604\n",
      "F1 Micro 0.6838978015448604\n",
      " \n",
      "Precision Weighted 0.7256284813320032\n",
      "Recall Weighted 0.6838978015448604\n",
      "F1 Weighted 0.7041453985638744\n"
     ]
    }
   ],
   "source": [
    "# pred_y, y_train\n",
    "precision = precision_score(list(y_train),pred_y,average='macro')\n",
    "recall = recall_score(list(y_train),pred_y,average='macro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Macro',precision)\n",
    "print('Recall Macro',recall)\n",
    "print('F1 Macro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='micro')\n",
    "recall = recall_score(list(y_train),pred_y,average='micro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Micro',precision)\n",
    "print('Recall Micro',recall)\n",
    "print('F1 Micro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Macro 0.6599539131684076\n",
      "Recall Macro 0.5276922251210888\n",
      "F1 Macro 0.5864584368855466\n",
      " \n",
      "Precision Micro 0.5831353919239906\n",
      "Recall Micro 0.5831353919239906\n",
      "F1 Micro 0.5831353919239906\n",
      " \n",
      "Precision Weighted 0.633415830621282\n",
      "Recall Weighted 0.5831353919239906\n",
      "F1 Weighted 0.6072365582230232\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_test),pred_y,average='macro')\n",
    "recall = recall_score(list(y_test),pred_y,average='macro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Macro',precision)\n",
    "print('Recall Macro',recall)\n",
    "print('F1 Macro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='micro')\n",
    "recall = recall_score(list(y_test),pred_y,average='micro')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Micro',precision)\n",
    "print('Recall Micro',recall)\n",
    "print('F1 Micro',f1)\n",
    "print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without multiple wild-card patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiwildcard(patterns):\n",
    "    for index, patt in patterns.items():\n",
    "        flt_patt = {p for p in patt if p.split(' ').count('.+') == 1}\n",
    "        patterns[index] = flt_patt\n",
    "    return patterns\n",
    "\n",
    "\n",
    "patterns = remove_multiwildcard(patterns)\n",
    "# data = two_emotions(data,emotional_mapping,'sad','exc')\n",
    "# Balance Data\n",
    "# data = balance_data(data)\n",
    "# y = data.emotion_code\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3)\n",
    "\n",
    "# data.groupby('emotion').count()['index'] #  6,453 Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_df = build_model(X_train,patterns)\n",
    "patterns_list = np.array(list(em_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5648\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.392265</td>\n",
       "      <td>1.770622</td>\n",
       "      <td>1.215614</td>\n",
       "      <td>1.678883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.786332</td>\n",
       "      <td>3.886300</td>\n",
       "      <td>1.525532</td>\n",
       "      <td>4.065756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.609671</td>\n",
       "      <td>2.451982</td>\n",
       "      <td>1.621270</td>\n",
       "      <td>2.565206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.489879</td>\n",
       "      <td>3.441792</td>\n",
       "      <td>2.452887</td>\n",
       "      <td>2.383968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>2.073588</td>\n",
       "      <td>1.943150</td>\n",
       "      <td>1.226444</td>\n",
       "      <td>2.032878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.392265  1.770622  1.215614  1.678883\n",
       ".+ a big  1.786332  3.886300  1.525532  4.065756\n",
       ".+ a bit  1.609671  2.451982  1.621270  2.565206\n",
       ".+ a day  1.489879  3.441792  2.452887  2.383968\n",
       ".+ a dog  2.073588  1.943150  1.226444  2.032878"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(em_df))\n",
    "em_df.head()\n",
    "# em_df.to_pickle('pickles/patterns/pfief_matrix.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.752504104064495\n",
      "Recall Weighted 0.7225806451612903\n",
      "F1 Weighted 0.7372388620882049\n"
     ]
    }
   ],
   "source": [
    "# pred_y, y_train\n",
    "# precision = precision_score(list(y_train),pred_y,average='macro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='macro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Macro',precision)\n",
    "# print('Recall Macro',recall)\n",
    "# print('F1 Macro',f1)\n",
    "# print(' ')\n",
    "# precision = precision_score(list(y_train),pred_y,average='micro')\n",
    "# recall = recall_score(list(y_train),pred_y,average='micro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Micro',precision)\n",
    "# print('Recall Micro',recall)\n",
    "# print('F1 Micro',f1)\n",
    "# print(' ')\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)\n",
    "\n",
    "\n",
    "# Precision Macro 0.7664926811354967\n",
    "# Recall Macro 0.6423609709732143\n",
    "# F1 Macro 0.6989583086378197\n",
    " \n",
    "# Precision Micro 0.6947368421052632\n",
    "# Recall Micro 0.6947368421052632\n",
    "# F1 Micro 0.6947368421052632\n",
    " \n",
    "# Precision Weighted 0.7386741269995074\n",
    "# Recall Weighted 0.6947368421052632\n",
    "# F1 Weighted 0.7160320960247799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_scores(em_df,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Weighted 0.6081336974610542\n",
      "Recall Weighted 0.5843230403800475\n",
      "F1 Weighted 0.5959906465057085\n"
     ]
    }
   ],
   "source": [
    "# precision = precision_score(list(y_test),pred_y,average='macro')\n",
    "# recall = recall_score(list(y_test),pred_y,average='macro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Macro',precision)\n",
    "# print('Recall Macro',recall)\n",
    "# print('F1 Macro',f1)\n",
    "# print(' ')\n",
    "# precision = precision_score(list(y_test),pred_y,average='micro')\n",
    "# recall = recall_score(list(y_test),pred_y,average='micro')\n",
    "# f1 = get_f1_score(precision,recall)\n",
    "# print('Precision Micro',precision)\n",
    "# print('Recall Micro',recall)\n",
    "# print('F1 Micro',f1)\n",
    "# print(' ')\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print('Precision Weighted',precision)\n",
    "print('Recall Weighted',recall)\n",
    "print('F1 Weighted',f1)\n",
    "\n",
    "\n",
    "# Precision Macro 0.6295216882336137\n",
    "# Recall Macro 0.5249158266314806\n",
    "# F1 Macro 0.5724794856483989\n",
    " \n",
    "# Precision Micro 0.5874901029295329\n",
    "# Recall Micro 0.5874901029295329\n",
    "# F1 Micro 0.5874901029295329\n",
    " \n",
    "# Precision Weighted 0.6153167839850325\n",
    "# Recall Weighted 0.5874901029295329\n",
    "# F1 Weighted 0.6010815612885869"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('pickles/patterns/scaledmfcc20_pattern_features4emo.pickle','rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        full_feature_table = save['full_feature_table']\n",
    "        wc_feature_table = save['wc_feature_table']\n",
    "        cw_feature_table = save['cw_feature_table']\n",
    "        del save\n",
    "except Exception as e:\n",
    "    print('Error loading pattern features pickle: ', e)\n",
    "    \n",
    "\n",
    "##############################MATRIX OPERATIONS###############################################\n",
    "def calculate_final_matrix(em_df,matrix):\n",
    "    final = []\n",
    "    for val in em_df.iterrows():\n",
    "        final.append(val[1] * matrix.loc[val[0]])\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "def calculate_final_matrix_mul(em_df,matrix):\n",
    "    final = []\n",
    "    for val in em_df.iterrows():\n",
    "        final.append(val[1] + (val[1] * matrix.loc[val[0]]))\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "def calculate_final_matrix_sum(em_df,matrix):\n",
    "    final = []\n",
    "    for val in em_df.iterrows():\n",
    "        final.append(val[1] + matrix.loc[val[0]])\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "##############################MULTI MATRIX OPERATIONS###############################################\n",
    "def calculate_final_multimatrix(em_df,multimatrix):\n",
    "    final = []\n",
    "    mmatrix_size = len(multimatrix)\n",
    "    for val in em_df.iterrows():\n",
    "        temp_val = val[1]\n",
    "        for i in range(mmatrix_size):\n",
    "            temp_val = temp_val * multimatrix[i].loc[val[0]]\n",
    "        final.append(temp_val)\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "def calculate_final_multimatrix_mul(em_df,multimatrix):\n",
    "    final = []\n",
    "    mmatrix_size = len(multimatrix)\n",
    "    for val in em_df.iterrows():\n",
    "        temp_val = val[1]\n",
    "        for i in range(mmatrix_size):\n",
    "            temp_val = temp_val ( 1 + multimatrix[i].loc[val[0]])\n",
    "        final.append(temp_val)\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "def calculate_final_multimatrix_sum(em_df,multimatrix):\n",
    "    final = []\n",
    "    mmatrix_size = len(multimatrix)\n",
    "    for val in em_df.iterrows():\n",
    "        temp_val = val[1]\n",
    "        for i in range(mmatrix_size):\n",
    "            temp_val = temp_val + multimatrix[i].loc[val[0]]\n",
    "        final.append(temp_val)\n",
    "    return pd.DataFrame(final)\n",
    "\n",
    "\n",
    "################################### MATRIX BUILD OPERATIONS ######################################################\n",
    "\n",
    "def build_acumatrix(data,feature_table,saveToPickle = False, savePath = ''):\n",
    "    matrix = {}\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for index, row in data.iterrows():\n",
    "        emo = row.emotion\n",
    "        key = row['index']\n",
    "        patts = feature_table[key].keys()\n",
    "        for patt in patts:\n",
    "            tpatt = patt.split('_')[1]\n",
    "            if(tpatt not in matrix):\n",
    "                matrix[tpatt] = {}\n",
    "            if(emo not in matrix[tpatt]):\n",
    "                matrix[tpatt][emo] = []\n",
    "            matrix[tpatt][emo].append(feature_table[key][patt])\n",
    "    for val in matrix:\n",
    "        for emo in matrix[val].keys():\n",
    "            matrix[val][emo] = np.mean(matrix[val][emo])\n",
    "    matrix = pd.DataFrame(matrix).T\n",
    "    if(saveToPickle and savePath != ''):\n",
    "        matrix.to_pickle(savePath)\n",
    "    return matrix\n",
    "\n",
    "def build_multiacumatrix(data,feature_table,saveToPickle = False, savePath = '',size = 20):\n",
    "    multimatrix = []\n",
    "    count = 0\n",
    "    for i in range(size):\n",
    "        multimatrix.append(dict())\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    for index, row in data.iterrows():\n",
    "        emo = row.emotion\n",
    "        key = row['index']\n",
    "        patts = feature_table[key].keys()\n",
    "        for patt in patts:\n",
    "            tpatt = patt.split('_')[1]\n",
    "            if(tpatt not in multimatrix[0]):\n",
    "                for matrix in multimatrix:\n",
    "                    matrix[tpatt] = {}\n",
    "                    for emotion in emotions_list:\n",
    "                        matrix[tpatt][emotion] = []\n",
    "            for i in range(size):\n",
    "                sub_feature = feature_table[key][patt][i]\n",
    "                multimatrix[i][tpatt][emo].append(sub_feature)\n",
    "    for i in range(size):\n",
    "        for val in multimatrix[i]:\n",
    "            for emo in multimatrix[i][val].keys():\n",
    "                if(len(multimatrix[i][val][emo]) > 0):\n",
    "                    multimatrix[i][val][emo] = np.mean(multimatrix[i][val][emo])\n",
    "                else:\n",
    "                    multimatrix[i][val][emo] = np.nan\n",
    "        multimatrix[i] = pd.DataFrame(multimatrix[i]).T\n",
    "    if(saveToPickle and savePath != ''):\n",
    "        try:\n",
    "            print('Saving Pickle')\n",
    "            with open(savePath,'wb') as f:\n",
    "                save = {\n",
    "                    'multimatrix' : multimatrix\n",
    "                }\n",
    "                pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "                print('Successfully saved matrix to '+savePath)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to pickle', e)\n",
    "            print('Patterns probably not saved.')\n",
    "    return multimatrix\n",
    "\n",
    "############################## LOAD MATRICES ###############################################\n",
    "\n",
    "def get_acumatrix(filePath):\n",
    "    try:\n",
    "        matrix = pd.read_pickle(filePath)\n",
    "        return matrix\n",
    "    except Exception as e:\n",
    "        print('Error loading matrix: ', e)\n",
    "\n",
    "def get_multiacumatrix(filePath):\n",
    "    try:\n",
    "        with open(filePath,'rb') as f:\n",
    "            save = pickle.load(f)\n",
    "            multimatrix = save['multimatrix']\n",
    "            del save\n",
    "            return multimatrix\n",
    "    except Exception as e:\n",
    "        print('Error loading matrix: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Pickle\n",
      "Successfully saved matrix to pickles/patterns/full_mfcc20_matrix_fd.pickle\n",
      "Saving Pickle\n",
      "Successfully saved matrix to pickles/patterns/wc_mfcc20_matrix_fd.pickle\n",
      "Saving Pickle\n",
      "Successfully saved matrix to pickles/patterns/cw_mfcc20_matrix_fd.pickle\n"
     ]
    }
   ],
   "source": [
    "# full_matrix = build_acumatrix(X_train,full_feature_table,saveToPickle=True,savePath = 'pickles/patterns/full_rmse_matrix_fd.pickle')\n",
    "# full_matrix = full_matrix.fillna(np.max(full_matrix))\n",
    "\n",
    "# wc_matrix = build_acumatrix(X_train,wc_feature_table,saveToPickle=True,savePath = 'pickles/patterns/wc_rmse_matrix_fd.pickle')\n",
    "# wc_matrix = wc_matrix.fillna(np.max(wc_matrix))\n",
    "\n",
    "# cw_matrix = build_acumatrix(X_train,cw_feature_table,saveToPickle=True,savePath = 'pickles/patterns/cw_rmse_matrix_fd.pickle')\n",
    "# cw_matrix = cw_matrix.fillna(np.max(cw_matrix))\n",
    "\n",
    "#FOR MFCC 20 \n",
    "MATRIX_SIZE = 20\n",
    "savePath = 'pickles/patterns/full_mfcc20_matrix_fd.pickle'\n",
    "# full_matrices = get_multiacumatrix(savePath)\n",
    "full_matrices = build_multiacumatrix(data,full_feature_table,size = MATRIX_SIZE,saveToPickle=True,savePath=savePath)\n",
    "for i in range(MATRIX_SIZE):\n",
    "    full_matrices[i] = full_matrices[i].fillna(np.max(full_matrices[i]))\n",
    "    \n",
    "savePath = 'pickles/patterns/wc_mfcc20_matrix_fd.pickle'\n",
    "# wc_matrices = get_multiacumatrix(savePath)\n",
    "wc_matrices = build_multiacumatrix(data,wc_feature_table,size = MATRIX_SIZE,saveToPickle=True,savePath=savePath)\n",
    "for i in range(MATRIX_SIZE):\n",
    "    wc_matrices[i] = wc_matrices[i].fillna(np.max(wc_matrices[i]))\n",
    "\n",
    "savePath = 'pickles/patterns/cw_mfcc20_matrix_fd.pickle'\n",
    "# cw_matrices = get_multiacumatrix(savePath)\n",
    "cw_matrices = build_multiacumatrix(data,cw_feature_table,size = MATRIX_SIZE,saveToPickle=True,savePath=savePath)\n",
    "for i in range(MATRIX_SIZE):\n",
    "    cw_matrices[i] = cw_matrices[i].fillna(np.max(cw_matrices[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC 1 \n",
    "full_matrix = full_matrices[0]\n",
    "wc_matrix = wc_matrices[0]\n",
    "cw_matrix = cw_matrices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.335632</td>\n",
       "      <td>1.773339</td>\n",
       "      <td>1.233435</td>\n",
       "      <td>1.653975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.514692</td>\n",
       "      <td>3.875035</td>\n",
       "      <td>2.202922</td>\n",
       "      <td>2.782855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.218580</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>2.090332</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.387807</td>\n",
       "      <td>3.667312</td>\n",
       "      <td>2.665174</td>\n",
       "      <td>2.600678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>2.075031</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>1.228233</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.335632  1.773339  1.233435  1.653975\n",
       ".+ a big  1.514692  3.875035  2.202922  2.782855\n",
       ".+ a bit  1.218580  1.937517  2.090332  2.043222\n",
       ".+ a day  1.387807  3.667312  2.665174  2.600678\n",
       ".+ a dog  2.075031  1.937517  1.228233  2.043222"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summatrix = calculate_final_matrix_sum(em_df,full_matrix)\n",
    "mulmatrix = calculate_final_matrix(em_df,full_matrix)\n",
    "mul2matrix = calculate_final_matrix_mul(em_df,full_matrix)\n",
    "em_df.head()\n",
    "\n",
    "########### FOR MFCC 20 ################\n",
    "# summatrix = calculate_final_multimatrix_sum(em_df,full_matrices)\n",
    "# mulmatrix = calculate_final_multimatrix(em_df,full_matrices)\n",
    "# mul2matrix = calculate_final_multimatrix_mul(em_df,full_matrices)\n",
    "# em_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>0.652080</td>\n",
       "      <td>0.680055</td>\n",
       "      <td>0.435924</td>\n",
       "      <td>0.479885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>0.648942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765781</td>\n",
       "      <td>0.806431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>0.287830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>0.738959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613493</td>\n",
       "      <td>1.219806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420985</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      0.652080  0.680055  0.435924  0.479885\n",
       ".+ a big  0.648942  0.000000  0.765781  0.806431\n",
       ".+ a bit  0.287830  0.000000  0.000000  0.000000\n",
       ".+ a day  0.738959  0.000000  0.613493  1.219806\n",
       ".+ a dog  0.000000  0.000000  0.420985  0.000000"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulmatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(summatrix.shape,mulmatrix.shape,em_df.shape,full_matrix.shape,cw_matrix.shape,wc_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pattern Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3187676633676476\n",
      "0.30220713073005095\n",
      "0.3102665738819127\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7448454113066184\n",
      "0.702546689303905\n",
      "0.7230779794030133\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222409677772846\n",
      "0.669269949066214\n",
      "0.6947472274444265\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28410839933825766\n",
      "0.2921615201900237\n",
      "0.2880786903379087\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5986706435045359\n",
      "0.5629453681710214\n",
      "0.5802586438778765\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6113322892569504\n",
      "0.5748218527315915\n",
      "0.5925151659567698\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WildCard Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.335632</td>\n",
       "      <td>1.773339</td>\n",
       "      <td>1.233435</td>\n",
       "      <td>1.653975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.514692</td>\n",
       "      <td>3.875035</td>\n",
       "      <td>2.202922</td>\n",
       "      <td>2.782855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.218580</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>2.090332</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.387807</td>\n",
       "      <td>3.667312</td>\n",
       "      <td>2.665174</td>\n",
       "      <td>2.600678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>2.075031</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>1.228233</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.335632  1.773339  1.233435  1.653975\n",
       ".+ a big  1.514692  3.875035  2.202922  2.782855\n",
       ".+ a bit  1.218580  1.937517  2.090332  2.043222\n",
       ".+ a day  1.387807  3.667312  2.665174  2.600678\n",
       ".+ a dog  2.075031  1.937517  1.228233  2.043222"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summatrix = calculate_final_matrix_sum(em_df,wc_matrix)\n",
    "mulmatrix = calculate_final_matrix(em_df,wc_matrix)\n",
    "mul2matrix = calculate_final_matrix_mul(em_df,wc_matrix)\n",
    "em_df.head()\n",
    "\n",
    "# mulmatrix = em_df + matrix\n",
    "\n",
    "######## FOR MFCC 20 #########\n",
    "# summatrix = calculate_final_multimatrix_sum(em_df,wc_matrices)\n",
    "# mulmatrix = calculate_final_multimatrix(em_df,wc_matrices)\n",
    "# mul2matrix = calculate_final_multimatrix_mul(em_df,wc_matrices)\n",
    "# em_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7415662562860448\n",
      "0.700169779286927\n",
      "0.7202737105535195\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3466977506030511\n",
      "0.31171477079796267\n",
      "0.3282768973938682\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7205521557316455\n",
      "0.6706281833616299\n",
      "0.694694382369676\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6146234821838491\n",
      "0.5748218527315915\n",
      "0.594056739541341\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3049228908295152\n",
      "0.3008709422011085\n",
      "0.3028833654631287\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6072264621141198\n",
      "0.564528899445764\n",
      "0.5850997531008266\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ContentWord Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ang</th>\n",
       "      <th>hap</th>\n",
       "      <th>neu</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.+ a</th>\n",
       "      <td>1.335632</td>\n",
       "      <td>1.773339</td>\n",
       "      <td>1.233435</td>\n",
       "      <td>1.653975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a big</th>\n",
       "      <td>1.514692</td>\n",
       "      <td>3.875035</td>\n",
       "      <td>2.202922</td>\n",
       "      <td>2.782855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a bit</th>\n",
       "      <td>1.218580</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>2.090332</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a day</th>\n",
       "      <td>1.387807</td>\n",
       "      <td>3.667312</td>\n",
       "      <td>2.665174</td>\n",
       "      <td>2.600678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.+ a dog</th>\n",
       "      <td>2.075031</td>\n",
       "      <td>1.937517</td>\n",
       "      <td>1.228233</td>\n",
       "      <td>2.043222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ang       hap       neu       sad\n",
       ".+ a      1.335632  1.773339  1.233435  1.653975\n",
       ".+ a big  1.514692  3.875035  2.202922  2.782855\n",
       ".+ a bit  1.218580  1.937517  2.090332  2.043222\n",
       ".+ a day  1.387807  3.667312  2.665174  2.600678\n",
       ".+ a dog  2.075031  1.937517  1.228233  2.043222"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summatrix = calculate_final_matrix_sum(em_df,cw_matrix)\n",
    "mulmatrix = calculate_final_matrix(em_df,cw_matrix)\n",
    "mul2matrix = calculate_final_matrix_mul(em_df,cw_matrix)\n",
    "em_df.head()\n",
    "\n",
    "############ FOR MFCC 20 ############\n",
    "# summatrix = calculate_final_multimatrix_sum(em_df,cw_matrices)\n",
    "# mulmatrix = calculate_final_multimatrix(em_df,cw_matrices)\n",
    "# mul2matrix = calculate_final_multimatrix_mul(em_df,cw_matrices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7420164285845253\n",
      "0.7011884550084889\n",
      "0.7210249342488\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3257189908340611\n",
      "0.31069609507640067\n",
      "0.3180302314788517\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7229990440256301\n",
      "0.6730050933786078\n",
      "0.6971068725367464\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_train,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_train),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_train),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6152201537413479\n",
      "0.5756136183689627\n",
      "0.5947582392813809\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(summatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27840602671199105\n",
      "0.2921615201900237\n",
      "0.285117961706323\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mulmatrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5972116221812408\n",
      "0.5613618368962787\n",
      "0.5787320788625733\n"
     ]
    }
   ],
   "source": [
    "vectors = get_frequency_vectors(X_test,patterns_list)\n",
    "scores = calculate_scores(mul2matrix,vectors)\n",
    "pred_y = list(scores['pred_code'])\n",
    "\n",
    "precision = precision_score(list(y_test),pred_y,average='weighted')\n",
    "recall = recall_score(list(y_test),pred_y,average='weighted')\n",
    "f1 = get_f1_score(precision,recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
