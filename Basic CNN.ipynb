{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Input, Dense, Flatten, Dropout, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(word_count, emotional_mapping):\n",
    "    # full = generate_IEMOCAP_df()\n",
    "    data = pd.read_csv('data/IEMOCAP_sentences.csv',index_col=0)\n",
    "    data['emotion_code'] = data['emotion'].map( emotional_mapping ).astype(int)\n",
    "    # Take away fear, surprise,disgust, xxx and others. Not enough data\n",
    "    data = data[data.emotion_code < 6]\n",
    "    # Clean Transcripts\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    # Filter Word Count\n",
    "    data = filter_word_count(data, word_count)\n",
    "#     data,patterns = remove_empty_patterns(data,patterns)\n",
    "    return data\n",
    "\n",
    "def clean_text(text):\n",
    "    punct_str = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~«»“…‘”\\t'\n",
    "    for p in punct_str:\n",
    "        text = text.replace(p,' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = re.sub(\".*?\\[(.*?)\\]\",\"\",text) # Take out any [action] text in the transcript\n",
    "    return text.lower().strip()\n",
    "\n",
    "def filter_word_count(data, n_count):\n",
    "    return data[list(map(lambda x: len(x.split(' ')) >= n_count,data['text']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is there a problem</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>well what's the problem let me change it</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what i'm getting an id this is why i'm here my...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how am i supposed to get an id without an id h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i'm here to get an id</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion_code\n",
       "2                                 is there a problem             3\n",
       "5           well what's the problem let me change it             3\n",
       "6  what i'm getting an id this is why i'm here my...             4\n",
       "7  how am i supposed to get an id without an id h...             4\n",
       "8                              i'm here to get an id             4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotional_mapping = {'ang': 0, 'sad': 1, 'exc': 2, 'neu': 3,'fru': 4,'hap': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "data = load_data(3, emotional_mapping)\n",
    "df = data[['text','emotion_code']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "TEST_SIZE      = 0.2\n",
    "\n",
    "# EMBEDDING\n",
    "MAX_NUM_WORDS  = 2500 # 2954, 2000, 2700\n",
    "EMBEDDING_DIM  = 200\n",
    "MAX_SEQ_LENGTH = 100\n",
    "USE_GLOVE      = True\n",
    "\n",
    "# MODEL\n",
    "FILTER_SIZES   = [3,4,5]\n",
    "FEATURE_MAPS   = [10,10,10]\n",
    "DROPOUT_RATE   = 0.5\n",
    "\n",
    "# LEARNING\n",
    "BATCH_SIZE     = 200\n",
    "NB_EPOCHS      = 40\n",
    "RUNS           = 5\n",
    "VAL_SIZE       = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.text, data.emotion_code, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text informations:\n",
      "max length: 100 / min length: 3 / mean length: 13 / limit length: 100\n",
      "vocabulary size: 2952 / limit: 2500\n"
     ]
    }
   ],
   "source": [
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])\n",
    "\n",
    "tokenizer = Tokenizer()#num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "length = max_length(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "result = [len(x.split()) for x in x_train]\n",
    "print('Text informations:')\n",
    "print('max length: %i / min length: %i / mean length: %i / limit length: %i' % (np.max(result),\n",
    "                                                                                np.min(result),\n",
    "                                                                                np.mean(result),\n",
    "                                                                                MAX_SEQ_LENGTH))\n",
    "\n",
    "print('vocabulary size: %i / limit: %i' % (len(word_index), MAX_NUM_WORDS))\n",
    "\n",
    "# Padding all sequences to same length of `MAX_SEQ_LENGTH`\n",
    "data   = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5116, 5116)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_embeddings(data = None, use_text8 = False, LEARNING_RATE=0.05, EPOCHS=30, NO_THREADS=4):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = Glove.load('models/glovetext8.model')\n",
    "    else:\n",
    "        if(data != None):\n",
    "            corpus = Corpus()\n",
    "            corpus.fit(data, window=10)\n",
    "            model = Glove(no_components=EMBEDDING_DIM,learning_rate=LEARNING_RATE)\n",
    "            model.fit(corpus.matrix, epochs=EPOCHS,no_threads=NO_THREADS,verbose=True)\n",
    "            model.add_dictionary(corpus.dictionary)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = Glove.load('models/glovetext8.model')\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word,index in model.dictionary.items():\n",
    "        embeddings_index[word] = model.word_vectors[index]\n",
    "    \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM,\n",
    "                     weights=[embedding_matrix], trainable=True)\n",
    "    \n",
    "def create_word2vec_embeddings(data = None, use_text8 = False):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    else:\n",
    "        if(data != None):  \n",
    "            model = word2vec.Word2Vec(data, size=EMBEDDING_DIM)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word in model.wv.index2word:\n",
    "        embeddings_index[word] = model[word]\n",
    "        \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length = MAX_SEQ_LENGTH,\n",
    "                    weights= [embedding_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "embedding_data = [x.split() for x in x_train]\n",
    "model = word2vec.Word2Vec(embedding_data, size=EMBEDDING_DIM)\n",
    "emb_layers = [create_word2vec_embeddings(use_text8=True),\n",
    "              create_word2vec_embeddings(embedding_data),\n",
    "              create_glove_embeddings(use_text8=True),\n",
    "              create_glove_embeddings(embedding_data)\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5116 5116\n"
     ]
    }
   ],
   "source": [
    "print(len(data),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "WARNING:tensorflow:From /Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Train on 4604 samples, validate on 512 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[170,6] = 2935 is not in [0, 2500)\n\t [[Node: embedding_32/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_32/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_32/embeddings/read, _arg_input_1_0_3)]]\n\nCaused by op 'embedding_32/embedding_lookup', defined at:\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-82-a7a4dcceaef8>\", line 21, in <module>\n    dropout_rate=DROPOUT_RATE\n  File \"/Users/roblescoulter/Dev/EnergyLyrics/cnn_model.py\", line 62, in build_cnn\n    emb_layer = embedding_layer(x_in)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 460, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 139, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1225, in gather\n    return tf.nn.embedding_lookup(reference, indices)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 327, in embedding_lookup\n    transform_fn=None)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 151, in _embedding_lookup_and_transform\n    result = _clip(_gather(params[0], ids, name=name), ids, max_norm)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 55, in _gather\n    return array_ops.gather(params, ids, name=name)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2698, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2672, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[170,6] = 2935 is not in [0, 2500)\n\t [[Node: embedding_32/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_32/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_32/embeddings/read, _arg_input_1_0_3)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[170,6] = 2935 is not in [0, 2500)\n\t [[Node: embedding_32/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_32/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_32/embeddings/read, _arg_input_1_0_3)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-a7a4dcceaef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n\u001b[1;32m     37\u001b[0m                                    verbose=1, save_best_only=True, mode='min'),\n\u001b[0;32m---> 38\u001b[0;31m                    \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                   ]\n\u001b[1;32m     40\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[170,6] = 2935 is not in [0, 2500)\n\t [[Node: embedding_32/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_32/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_32/embeddings/read, _arg_input_1_0_3)]]\n\nCaused by op 'embedding_32/embedding_lookup', defined at:\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-82-a7a4dcceaef8>\", line 21, in <module>\n    dropout_rate=DROPOUT_RATE\n  File \"/Users/roblescoulter/Dev/EnergyLyrics/cnn_model.py\", line 62, in build_cnn\n    emb_layer = embedding_layer(x_in)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 460, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 139, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1225, in gather\n    return tf.nn.embedding_lookup(reference, indices)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 327, in embedding_lookup\n    transform_fn=None)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 151, in _embedding_lookup_and_transform\n    result = _clip(_gather(params[0], ids, name=name), ids, max_norm)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 55, in _gather\n    return array_ops.gather(params, ids, name=name)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2698, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2672, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[170,6] = 2935 is not in [0, 2500)\n\t [[Node: embedding_32/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_32/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_32/embeddings/read, _arg_input_1_0_3)]]\n"
     ]
    }
   ],
   "source": [
    "import cnn_model\n",
    "\n",
    "histories = []\n",
    "\n",
    "for i in range(RUNS):\n",
    "    print('Running iteration %i/%i' % (i+1, RUNS))\n",
    "    \n",
    "    X_train, X_val, labels, y_val = train_test_split(data, y_train, test_size=VAL_SIZE, random_state=42)\n",
    "    \n",
    "    emb_layer = None\n",
    "    if USE_GLOVE:\n",
    "        emb_layer = emb_layers[2]#create_word2vec_embeddings(result)\n",
    "        \n",
    "    model = cnn_model.build_cnn(\n",
    "        embedding_layer=emb_layer,\n",
    "        num_words=MAX_NUM_WORDS,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        filter_sizes=FILTER_SIZES,\n",
    "        feature_maps=FEATURE_MAPS,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        dropout_rate=DROPOUT_RATE\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adadelta(clipvalue=3),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, labels,\n",
    "        epochs=NB_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n",
    "                                   verbose=1, save_best_only=True, mode='min'),\n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.01)\n",
    "                  ]\n",
    "    )\n",
    "    histories.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'of',\n",
       " 'and',\n",
       " 'one',\n",
       " 'in',\n",
       " 'a',\n",
       " 'to',\n",
       " 'zero',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'is',\n",
       " 'as',\n",
       " 'eight',\n",
       " 'for',\n",
       " 's',\n",
       " 'five',\n",
       " 'three',\n",
       " 'was',\n",
       " 'by',\n",
       " 'that',\n",
       " 'four',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'with',\n",
       " 'on',\n",
       " 'are',\n",
       " 'it',\n",
       " 'from',\n",
       " 'or',\n",
       " 'his',\n",
       " 'an',\n",
       " 'be',\n",
       " 'this',\n",
       " 'which',\n",
       " 'at',\n",
       " 'he',\n",
       " 'also',\n",
       " 'not',\n",
       " 'have',\n",
       " 'were',\n",
       " 'has',\n",
       " 'but',\n",
       " 'other',\n",
       " 'their',\n",
       " 'its',\n",
       " 'first',\n",
       " 'they',\n",
       " 'some',\n",
       " 'had',\n",
       " 'all',\n",
       " 'more',\n",
       " 'most',\n",
       " 'can',\n",
       " 'been',\n",
       " 'such',\n",
       " 'many',\n",
       " 'who',\n",
       " 'new',\n",
       " 'used',\n",
       " 'there',\n",
       " 'after',\n",
       " 'when',\n",
       " 'into',\n",
       " 'american',\n",
       " 'time',\n",
       " 'these',\n",
       " 'only',\n",
       " 'see',\n",
       " 'may',\n",
       " 'than',\n",
       " 'world',\n",
       " 'i',\n",
       " 'b',\n",
       " 'would',\n",
       " 'd',\n",
       " 'no',\n",
       " 'however',\n",
       " 'between',\n",
       " 'about',\n",
       " 'over',\n",
       " 'years',\n",
       " 'states',\n",
       " 'people',\n",
       " 'war',\n",
       " 'during',\n",
       " 'united',\n",
       " 'known',\n",
       " 'if',\n",
       " 'called',\n",
       " 'use',\n",
       " 'th',\n",
       " 'system',\n",
       " 'often',\n",
       " 'state',\n",
       " 'so',\n",
       " 'history',\n",
       " 'will',\n",
       " 'up',\n",
       " 'while',\n",
       " 'where',\n",
       " 'city',\n",
       " 'being',\n",
       " 'english',\n",
       " 'then',\n",
       " 'any',\n",
       " 'both',\n",
       " 'under',\n",
       " 'out',\n",
       " 'made',\n",
       " 'well',\n",
       " 'her',\n",
       " 'e',\n",
       " 'number',\n",
       " 'government',\n",
       " 'them',\n",
       " 'm',\n",
       " 'later',\n",
       " 'since',\n",
       " 'him',\n",
       " 'part',\n",
       " 'name',\n",
       " 'c',\n",
       " 'century',\n",
       " 'through',\n",
       " 'because',\n",
       " 'x',\n",
       " 'university',\n",
       " 'early',\n",
       " 'life',\n",
       " 'british',\n",
       " 'year',\n",
       " 'like',\n",
       " 'same',\n",
       " 'including',\n",
       " 'became',\n",
       " 'example',\n",
       " 'day',\n",
       " 'each',\n",
       " 'even',\n",
       " 'work',\n",
       " 'language',\n",
       " 'although',\n",
       " 'several',\n",
       " 'form',\n",
       " 'john',\n",
       " 'u',\n",
       " 'national',\n",
       " 'very',\n",
       " 'much',\n",
       " 'g',\n",
       " 'french',\n",
       " 'before',\n",
       " 'general',\n",
       " 'what',\n",
       " 't',\n",
       " 'against',\n",
       " 'n',\n",
       " 'high',\n",
       " 'links',\n",
       " 'could',\n",
       " 'based',\n",
       " 'those',\n",
       " 'now',\n",
       " 'second',\n",
       " 'de',\n",
       " 'music',\n",
       " 'another',\n",
       " 'large',\n",
       " 'she',\n",
       " 'f',\n",
       " 'external',\n",
       " 'german',\n",
       " 'different',\n",
       " 'modern',\n",
       " 'great',\n",
       " 'do',\n",
       " 'common',\n",
       " 'set',\n",
       " 'list',\n",
       " 'south',\n",
       " 'series',\n",
       " 'major',\n",
       " 'game',\n",
       " 'power',\n",
       " 'long',\n",
       " 'country',\n",
       " 'king',\n",
       " 'law',\n",
       " 'group',\n",
       " 'film',\n",
       " 'still',\n",
       " 'until',\n",
       " 'north',\n",
       " 'international',\n",
       " 'term',\n",
       " 'we',\n",
       " 'end',\n",
       " 'book',\n",
       " 'found',\n",
       " 'own',\n",
       " 'political',\n",
       " 'party',\n",
       " 'order',\n",
       " 'usually',\n",
       " 'president',\n",
       " 'church',\n",
       " 'you',\n",
       " 'death',\n",
       " 'theory',\n",
       " 'area',\n",
       " 'around',\n",
       " 'include',\n",
       " 'god',\n",
       " 'ii',\n",
       " 'way',\n",
       " 'did',\n",
       " 'military',\n",
       " 'population',\n",
       " 'using',\n",
       " 'though',\n",
       " 'small',\n",
       " 'following',\n",
       " 'within',\n",
       " 'non',\n",
       " 'human',\n",
       " 'left',\n",
       " 'main',\n",
       " 'among',\n",
       " 'point',\n",
       " 'r',\n",
       " 'due',\n",
       " 'p',\n",
       " 'considered',\n",
       " 'public',\n",
       " 'popular',\n",
       " 'computer',\n",
       " 'west',\n",
       " 'family',\n",
       " 'east',\n",
       " 'information',\n",
       " 'important',\n",
       " 'european',\n",
       " 'man',\n",
       " 'sometimes',\n",
       " 'right',\n",
       " 'old',\n",
       " 'free',\n",
       " 'word',\n",
       " 'without',\n",
       " 'last',\n",
       " 'us',\n",
       " 'members',\n",
       " 'given',\n",
       " 'times',\n",
       " 'roman',\n",
       " 'make',\n",
       " 'h',\n",
       " 'age',\n",
       " 'place',\n",
       " 'l',\n",
       " 'thus',\n",
       " 'science',\n",
       " 'case',\n",
       " 'become',\n",
       " 'systems',\n",
       " 'union',\n",
       " 'born',\n",
       " 'york',\n",
       " 'line',\n",
       " 'countries',\n",
       " 'does',\n",
       " 'isbn',\n",
       " 'st',\n",
       " 'control',\n",
       " 'various',\n",
       " 'others',\n",
       " 'house',\n",
       " 'article',\n",
       " 'island',\n",
       " 'should',\n",
       " 'led',\n",
       " 'back',\n",
       " 'period',\n",
       " 'player',\n",
       " 'europe',\n",
       " 'languages',\n",
       " 'central',\n",
       " 'water',\n",
       " 'few',\n",
       " 'western',\n",
       " 'home',\n",
       " 'began',\n",
       " 'generally',\n",
       " 'less',\n",
       " 'k',\n",
       " 'similar',\n",
       " 'written',\n",
       " 'original',\n",
       " 'best',\n",
       " 'must',\n",
       " 'according',\n",
       " 'school',\n",
       " 'france',\n",
       " 'air',\n",
       " 'single',\n",
       " 'force',\n",
       " 'v',\n",
       " 'land',\n",
       " 'groups',\n",
       " 'down',\n",
       " 'how',\n",
       " 'works',\n",
       " 'development',\n",
       " 'official',\n",
       " 'support',\n",
       " 'england',\n",
       " 'j',\n",
       " 'rather',\n",
       " 'data',\n",
       " 'space',\n",
       " 'greek',\n",
       " 'km',\n",
       " 'named',\n",
       " 'germany',\n",
       " 'just',\n",
       " 'games',\n",
       " 'said',\n",
       " 'version',\n",
       " 'late',\n",
       " 'earth',\n",
       " 'company',\n",
       " 'every',\n",
       " 'economic',\n",
       " 'short',\n",
       " 'published',\n",
       " 'black',\n",
       " 'army',\n",
       " 'off',\n",
       " 'london',\n",
       " 'million',\n",
       " 'body',\n",
       " 'field',\n",
       " 'christian',\n",
       " 'either',\n",
       " 'social',\n",
       " 'empire',\n",
       " 'o',\n",
       " 'developed',\n",
       " 'standard',\n",
       " 'court',\n",
       " 'service',\n",
       " 'kingdom',\n",
       " 'along',\n",
       " 'college',\n",
       " 'republic',\n",
       " 'sea',\n",
       " 'america',\n",
       " 'today',\n",
       " 'result',\n",
       " 'held',\n",
       " 'team',\n",
       " 'light',\n",
       " 'means',\n",
       " 'never',\n",
       " 'especially',\n",
       " 'third',\n",
       " 'further',\n",
       " 'character',\n",
       " 'forces',\n",
       " 'take',\n",
       " 'men',\n",
       " 'society',\n",
       " 'show',\n",
       " 'open',\n",
       " 'possible',\n",
       " 'fact',\n",
       " 'battle',\n",
       " 'took',\n",
       " 'former',\n",
       " 'books',\n",
       " 'soviet',\n",
       " 'river',\n",
       " 'children',\n",
       " 'having',\n",
       " 'good',\n",
       " 'local',\n",
       " 'current',\n",
       " 'son',\n",
       " 'process',\n",
       " 'natural',\n",
       " 'present',\n",
       " 'himself',\n",
       " 'islands',\n",
       " 'total',\n",
       " 'near',\n",
       " 'white',\n",
       " 'days',\n",
       " 'person',\n",
       " 'itself',\n",
       " 'seen',\n",
       " 'culture',\n",
       " 'little',\n",
       " 'above',\n",
       " 'software',\n",
       " 'largest',\n",
       " 'words',\n",
       " 'upon',\n",
       " 'level',\n",
       " 'father',\n",
       " 'created',\n",
       " 'side',\n",
       " 'red',\n",
       " 'references',\n",
       " 'press',\n",
       " 'full',\n",
       " 'region',\n",
       " 'almost',\n",
       " 'image',\n",
       " 'al',\n",
       " 'famous',\n",
       " 'play',\n",
       " 'came',\n",
       " 'role',\n",
       " 'once',\n",
       " 'certain',\n",
       " 'league',\n",
       " 'jewish',\n",
       " 'james',\n",
       " 'january',\n",
       " 'site',\n",
       " 'again',\n",
       " 'numbers',\n",
       " 'art',\n",
       " 'member',\n",
       " 'areas',\n",
       " 'movement',\n",
       " 'religious',\n",
       " 'type',\n",
       " 'march',\n",
       " 'community',\n",
       " 'story',\n",
       " 'played',\n",
       " 'production',\n",
       " 'released',\n",
       " 'center',\n",
       " 'rights',\n",
       " 'real',\n",
       " 'related',\n",
       " 'foreign',\n",
       " 'low',\n",
       " 'ancient',\n",
       " 'terms',\n",
       " 'view',\n",
       " 'source',\n",
       " 'act',\n",
       " 'minister',\n",
       " 'change',\n",
       " 'energy',\n",
       " 'produced',\n",
       " 'research',\n",
       " 'actor',\n",
       " 'making',\n",
       " 'civil',\n",
       " 'december',\n",
       " 'women',\n",
       " 'special',\n",
       " 'style',\n",
       " 'william',\n",
       " 'design',\n",
       " 'japanese',\n",
       " 'available',\n",
       " 'chinese',\n",
       " 'forms',\n",
       " 'canada',\n",
       " 'northern',\n",
       " 'died',\n",
       " 'class',\n",
       " 'living',\n",
       " 'next',\n",
       " 'particular',\n",
       " 'program',\n",
       " 'council',\n",
       " 'television',\n",
       " 'head',\n",
       " 'david',\n",
       " 'china',\n",
       " 'middle',\n",
       " 'established',\n",
       " 'hand',\n",
       " 'bc',\n",
       " 'far',\n",
       " 'july',\n",
       " 'function',\n",
       " 'position',\n",
       " 'y',\n",
       " 'built',\n",
       " 'george',\n",
       " 'band',\n",
       " 'together',\n",
       " 'w',\n",
       " 'latin',\n",
       " 'thought',\n",
       " 'eastern',\n",
       " 'charles',\n",
       " 'parts',\n",
       " 'instead',\n",
       " 'study',\n",
       " 'might',\n",
       " 'india',\n",
       " 'code',\n",
       " 'included',\n",
       " 'meaning',\n",
       " 'trade',\n",
       " 'per',\n",
       " 'june',\n",
       " 'least',\n",
       " 'half',\n",
       " 'model',\n",
       " 'economy',\n",
       " 'prime',\n",
       " 'traditional',\n",
       " 'always',\n",
       " 'capital',\n",
       " 'range',\n",
       " 'november',\n",
       " 'emperor',\n",
       " 'young',\n",
       " 'anti',\n",
       " 'final',\n",
       " 'text',\n",
       " 'players',\n",
       " 'uk',\n",
       " 'april',\n",
       " 'run',\n",
       " 'september',\n",
       " 'addition',\n",
       " 'radio',\n",
       " 'live',\n",
       " 'august',\n",
       " 'taken',\n",
       " 'note',\n",
       " 'italian',\n",
       " 'lost',\n",
       " 'nature',\n",
       " 'project',\n",
       " 'technology',\n",
       " 'spanish',\n",
       " 'october',\n",
       " 'recent',\n",
       " 'rate',\n",
       " 'won',\n",
       " 'true',\n",
       " 'value',\n",
       " 'uses',\n",
       " 'russian',\n",
       " 'est',\n",
       " 'wrote',\n",
       " 'effect',\n",
       " 'album',\n",
       " 'southern',\n",
       " 'africa',\n",
       " 'whose',\n",
       " 'top',\n",
       " 'historical',\n",
       " 'australia',\n",
       " 'catholic',\n",
       " 'particularly',\n",
       " 'self',\n",
       " 'structure',\n",
       " 'record',\n",
       " 'evidence',\n",
       " 'rule',\n",
       " 'themselves',\n",
       " 'influence',\n",
       " 'cases',\n",
       " 'subject',\n",
       " 'referred',\n",
       " 'continued',\n",
       " 'nations',\n",
       " 'below',\n",
       " 'rock',\n",
       " 'japan',\n",
       " 'com',\n",
       " 'song',\n",
       " 'throughout',\n",
       " 'names',\n",
       " 'female',\n",
       " 'title',\n",
       " 'therefore',\n",
       " 'our',\n",
       " 'office',\n",
       " 'star',\n",
       " 'paul',\n",
       " 'too',\n",
       " 'cities',\n",
       " 'february',\n",
       " 'independent',\n",
       " 'author',\n",
       " 'problem',\n",
       " 'species',\n",
       " 'education',\n",
       " 'done',\n",
       " 'philosophy',\n",
       " 'come',\n",
       " 'higher',\n",
       " 'originally',\n",
       " 'market',\n",
       " 'town',\n",
       " 'my',\n",
       " 'season',\n",
       " 'love',\n",
       " 'strong',\n",
       " 'israel',\n",
       " 'irish',\n",
       " 'writer',\n",
       " 'films',\n",
       " 'elements',\n",
       " 'robert',\n",
       " 'whether',\n",
       " 'despite',\n",
       " 'eventually',\n",
       " 'here',\n",
       " 'football',\n",
       " 'action',\n",
       " 'internet',\n",
       " 'individual',\n",
       " 'sound',\n",
       " 'network',\n",
       " 'described',\n",
       " 'practice',\n",
       " 'characters',\n",
       " 're',\n",
       " 'royal',\n",
       " 'la',\n",
       " 'events',\n",
       " 'formed',\n",
       " 'commonly',\n",
       " 'base',\n",
       " 'received',\n",
       " 'african',\n",
       " 'problems',\n",
       " 'food',\n",
       " 'jews',\n",
       " 'able',\n",
       " 'male',\n",
       " 'typically',\n",
       " 'mass',\n",
       " 'complex',\n",
       " 'lower',\n",
       " 'includes',\n",
       " 'outside',\n",
       " 'legal',\n",
       " 'complete',\n",
       " 'significant',\n",
       " 'parliament',\n",
       " 'actually',\n",
       " 'business',\n",
       " 'fiction',\n",
       " 'physical',\n",
       " 'followed',\n",
       " 'deaths',\n",
       " 'key',\n",
       " 'leader',\n",
       " 'widely',\n",
       " 'page',\n",
       " 'basic',\n",
       " 'types',\n",
       " 'henry',\n",
       " 'elected',\n",
       " 'beginning',\n",
       " 'fire',\n",
       " 'building',\n",
       " 'independence',\n",
       " 'went',\n",
       " 'movie',\n",
       " 'aircraft',\n",
       " 'ever',\n",
       " 'canadian',\n",
       " 'material',\n",
       " 'births',\n",
       " 'video',\n",
       " 'news',\n",
       " 'future',\n",
       " 'scientific',\n",
       " 'simply',\n",
       " 'go',\n",
       " 'defined',\n",
       " 'laws',\n",
       " 'get',\n",
       " 'close',\n",
       " 'industry',\n",
       " 'specific',\n",
       " 'examples',\n",
       " 'believe',\n",
       " 'services',\n",
       " 'idea',\n",
       " 'method',\n",
       " 'introduced',\n",
       " 'points',\n",
       " 'return',\n",
       " 'cause',\n",
       " 'indian',\n",
       " 'britain',\n",
       " 'features',\n",
       " 'majority',\n",
       " 'size',\n",
       " 'post',\n",
       " 'lead',\n",
       " 'organization',\n",
       " 'cannot',\n",
       " 'designed',\n",
       " 'ireland',\n",
       " 'cross',\n",
       " 'classical',\n",
       " 'personal',\n",
       " 'writing',\n",
       " 'concept',\n",
       " 'associated',\n",
       " 'required',\n",
       " 'soon',\n",
       " 'changes',\n",
       " 'california',\n",
       " 'located',\n",
       " 'sense',\n",
       " 'believed',\n",
       " 'away',\n",
       " 'started',\n",
       " 'co',\n",
       " 'religion',\n",
       " 'mother',\n",
       " 'county',\n",
       " 'rules',\n",
       " 'studies',\n",
       " 'yet',\n",
       " 'find',\n",
       " 'knowledge',\n",
       " 'put',\n",
       " 'founded',\n",
       " 'policy',\n",
       " 'currently',\n",
       " 'provide',\n",
       " 'working',\n",
       " 'media',\n",
       " 'election',\n",
       " 'australian',\n",
       " 'me',\n",
       " 'thomas',\n",
       " 'allowed',\n",
       " 'russia',\n",
       " 'earlier',\n",
       " 'greater',\n",
       " 'limited',\n",
       " 'object',\n",
       " 'brought',\n",
       " 'online',\n",
       " 'association',\n",
       " 'lord',\n",
       " 'mostly',\n",
       " 'blue',\n",
       " 'constitution',\n",
       " 'across',\n",
       " 'added',\n",
       " 'interest',\n",
       " 'things',\n",
       " 'relations',\n",
       " 'speed',\n",
       " 'federal',\n",
       " 'singer',\n",
       " 'effects',\n",
       " 'growth',\n",
       " 'sources',\n",
       " 'your',\n",
       " 'remains',\n",
       " 'z',\n",
       " 'probably',\n",
       " 'gave',\n",
       " 'simple',\n",
       " 'attack',\n",
       " 'longer',\n",
       " 'reference',\n",
       " 'saint',\n",
       " 'success',\n",
       " 'killed',\n",
       " 'past',\n",
       " 'career',\n",
       " 'need',\n",
       " 'park',\n",
       " 'definition',\n",
       " 'say',\n",
       " 'etc',\n",
       " 'give',\n",
       " 'peace',\n",
       " 'chief',\n",
       " 'stories',\n",
       " 'security',\n",
       " 'wide',\n",
       " 'ball',\n",
       " 'saw',\n",
       " 'machine',\n",
       " 'better',\n",
       " 'cell',\n",
       " 'leading',\n",
       " 'becomes',\n",
       " 'spain',\n",
       " 'larger',\n",
       " 'products',\n",
       " 'parties',\n",
       " 'night',\n",
       " 'remained',\n",
       " 'prize',\n",
       " 'months',\n",
       " 'website',\n",
       " 'big',\n",
       " 'cultural',\n",
       " 'money',\n",
       " 'help',\n",
       " 'territory',\n",
       " 'private',\n",
       " 'moved',\n",
       " 'letter',\n",
       " 'wife',\n",
       " 'politics',\n",
       " 'lines',\n",
       " 'largely',\n",
       " 'contains',\n",
       " 'companies',\n",
       " 'lake',\n",
       " 'perhaps',\n",
       " 'green',\n",
       " 'already',\n",
       " 'dead',\n",
       " 'iii',\n",
       " 'library',\n",
       " 'separate',\n",
       " 'refer',\n",
       " 'makes',\n",
       " 'appeared',\n",
       " 'dutch',\n",
       " 'holy',\n",
       " 'era',\n",
       " 'novel',\n",
       " 'successful',\n",
       " 'italy',\n",
       " 'letters',\n",
       " 'results',\n",
       " 'matter',\n",
       " 'produce',\n",
       " 'origin',\n",
       " 'claim',\n",
       " 'whole',\n",
       " 'directly',\n",
       " 'attempt',\n",
       " 'actress',\n",
       " 'surface',\n",
       " 'revolution',\n",
       " 'highly',\n",
       " 'caused',\n",
       " 'status',\n",
       " 'musical',\n",
       " 'richard',\n",
       " 'commercial',\n",
       " 'division',\n",
       " 'color',\n",
       " 'health',\n",
       " 'coast',\n",
       " 'release',\n",
       " 'latter',\n",
       " 'authority',\n",
       " 'treaty',\n",
       " 'turn',\n",
       " 'michael',\n",
       " 'nation',\n",
       " 'direct',\n",
       " 'asia',\n",
       " 'edition',\n",
       " 'programming',\n",
       " 'playing',\n",
       " 'date',\n",
       " 'mary',\n",
       " 'native',\n",
       " 'whom',\n",
       " 'married',\n",
       " 'towards',\n",
       " 'issues',\n",
       " 'double',\n",
       " 'primary',\n",
       " 'basis',\n",
       " 'allow',\n",
       " 'enough',\n",
       " 'memory',\n",
       " 'reason',\n",
       " 'web',\n",
       " 'exist',\n",
       " 'provided',\n",
       " 'oil',\n",
       " 'course',\n",
       " 'functions',\n",
       " 'alexander',\n",
       " 'analysis',\n",
       " 'chemical',\n",
       " 'mid',\n",
       " 'replaced',\n",
       " 'queen',\n",
       " 'claims',\n",
       " 'tv',\n",
       " 'sun',\n",
       " 'literature',\n",
       " 'metal',\n",
       " 'amount',\n",
       " 'divided',\n",
       " 'blood',\n",
       " 'likely',\n",
       " 'access',\n",
       " 'average',\n",
       " 'length',\n",
       " 'smaller',\n",
       " 'medical',\n",
       " 'property',\n",
       " 'students',\n",
       " 'degree',\n",
       " 'elections',\n",
       " 'club',\n",
       " 'claimed',\n",
       " 'performance',\n",
       " 'director',\n",
       " 'digital',\n",
       " 'front',\n",
       " 'museum',\n",
       " 'difficult',\n",
       " 'tradition',\n",
       " 'nearly',\n",
       " 'schools',\n",
       " 'washington',\n",
       " 'gas',\n",
       " 'jesus',\n",
       " 'map',\n",
       " 'louis',\n",
       " 'rome',\n",
       " 'unit',\n",
       " 'baseball',\n",
       " 'mind',\n",
       " 'peter',\n",
       " 'mark',\n",
       " 'collection',\n",
       " 'product',\n",
       " 'congress',\n",
       " 'programs',\n",
       " 'changed',\n",
       " 'ideas',\n",
       " 'moon',\n",
       " 'entire',\n",
       " 'user',\n",
       " 'ground',\n",
       " 'records',\n",
       " 'frequently',\n",
       " 'increase',\n",
       " 'highest',\n",
       " 'sent',\n",
       " 'finally',\n",
       " 'board',\n",
       " 'don',\n",
       " 'notable',\n",
       " 'read',\n",
       " 'methods',\n",
       " 'recently',\n",
       " 'bit',\n",
       " 'involved',\n",
       " 'variety',\n",
       " 'call',\n",
       " 'democratic',\n",
       " 'ten',\n",
       " 'served',\n",
       " 'minor',\n",
       " 'hard',\n",
       " 'birth',\n",
       " 'objects',\n",
       " 'nuclear',\n",
       " 'increased',\n",
       " 'section',\n",
       " 'street',\n",
       " 'windows',\n",
       " 'relatively',\n",
       " 'car',\n",
       " 'move',\n",
       " 'create',\n",
       " 'returned',\n",
       " 'bank',\n",
       " 'conditions',\n",
       " 'operation',\n",
       " 'adopted',\n",
       " 'relationship',\n",
       " 'christ',\n",
       " 'hall',\n",
       " 'appear',\n",
       " 'rest',\n",
       " 'child',\n",
       " 'element',\n",
       " 'appears',\n",
       " 'takes',\n",
       " 'fall',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "sentences = list(itertools.islice(word2vec.Text8Corpus('data/text8'),None))\n",
    "corpus = Corpus()\n",
    "corpus.fit(sentences, window=10)\n",
    "glove = Glove(no_components=EMBEDDING_DIM,learning_rate=0.05)\n",
    "glove.fit(corpus.matrix, epochs=30,no_threads=4,verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save('models/glovetext8.model')\n",
    "# model = word2vec.Word2Vec(sentences, size=EMBEDDING_DIM)\n",
    "# model.save('models/text8.model')\n",
    "# model.wv.save_word2vec_format('models/text8.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "# # model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
