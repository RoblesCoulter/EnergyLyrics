{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Pickling\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Input, Dense, Flatten, Dropout, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_word2vec_text8(saveTo = 'models/text8.model'):\n",
    "    sentences = word2vec.Text8Corpus('data/text8')\n",
    "    model = word2vec.Word2Vec(sentences, size=EMBEDDING_DIM)\n",
    "    model.save(saveTo)\n",
    "    model.wv.save_word2vec_format(saveTo + '.bin', binary=True)\n",
    "    print('DONE! Saved to', saveTo)\n",
    "\n",
    "def generate_glove_text8(saveTo = 'models/glovetext8.model'):\n",
    "    import itertools\n",
    "    sentences = list(itertools.islice(word2vec.Text8Corpus('data/text8'),None))\n",
    "    corpus = Corpus()\n",
    "    corpus.fit(sentences, window=10)\n",
    "    glove = Glove(no_components=EMBEDDING_DIM,learning_rate=0.05)\n",
    "    glove.fit(corpus.matrix, epochs=30,no_threads=4,verbose=True)\n",
    "    glove.add_dictionary(corpus.dictionary)\n",
    "    glove.save(saveTo)\n",
    "    print('DONE! Saved to', saveTo)\n",
    "    \n",
    "def load_data(word_count, emotional_mapping):\n",
    "    # full = generate_IEMOCAP_df()\n",
    "    data = pd.read_csv('data/IEMOCAP_sentences.csv',index_col=0)\n",
    "    data['emotion_code'] = data['emotion'].map( emotional_mapping ).astype(int)\n",
    "    # Take away fear, surprise,disgust, xxx and others. Not enough data\n",
    "    data = data[data.emotion_code < 4]\n",
    "    # Clean Transcripts\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    # Filter Word Count\n",
    "    data = filter_word_count(data, word_count)\n",
    "#     data,patterns = remove_empty_patterns(data,patterns)\n",
    "    return data\n",
    "\n",
    "def clean_text(text):\n",
    "    punct_str = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~«»“…‘”\\t'\n",
    "    for p in punct_str:\n",
    "        text = text.replace(p,' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = re.sub(\".*?\\[(.*?)\\]\",\"\",text) # Take out any [action] text in the transcript\n",
    "    return text.lower().strip()\n",
    "\n",
    "def filter_word_count(data, n_count):\n",
    "    return data[list(map(lambda x: len(x.split(' ')) >= n_count,data['text']))]\n",
    "\n",
    "def balance_data(data):\n",
    "    min_sample = min(data.groupby('emotion').count()['emotion_code'])\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    samples = []\n",
    "    for emotion in emotions_list:\n",
    "        samples.append(data[data.emotion == emotion].sample(n=min_sample))\n",
    "    result = pd.concat(samples).sample(frac=1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text\n",
       "emotion_code      \n",
       "0              878\n",
       "1              782\n",
       "2              412\n",
       "3             1209"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotional_mapping = {'ang': 0, 'sad': 1, 'hap': 2, 'neu': 3,'fru': 4,'exc': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "data = load_data(5, emotional_mapping)\n",
    "# data = balance_data(data)\n",
    "df = data[['text','emotion_code']]\n",
    "df.groupby('emotion_code').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "ang    26.760134\n",
       "hap    12.557147\n",
       "neu    36.848522\n",
       "sad    23.834197\n",
       "Name: emotion_code, dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(data.groupby('emotion').count()['emotion_code'])\n",
    "((data.groupby('emotion').count() / total) * 100)['emotion_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_balanced = balance_data(data)\n",
    "# df_balanced = data_balanced[['text','emotion_code']]\n",
    "# df_balanced.head()\n",
    "# data_balanced.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "TEST_SIZE      = 0.2\n",
    "\n",
    "# EMBEDDING\n",
    "MAX_NUM_WORDS  = 2200 #2954, 2500, 2000, 2700\n",
    "# MAX_NUM_WORDS  = # 1800, 2000, 2201\n",
    "EMBEDDING_DIM  = 200\n",
    "MAX_SEQ_LENGTH = 100\n",
    "USE_GLOVE      = True\n",
    "\n",
    "# MODEL\n",
    "FILTER_SIZES   = [2,3,5]\n",
    "FEATURE_MAPS   = [10,10,10] #50,100\n",
    "DROPOUT_RATE   = 0.5\n",
    "\n",
    "# LEARNING\n",
    "BATCH_SIZE     = 200\n",
    "NB_EPOCHS      = 40\n",
    "RUNS           = 5\n",
    "VAL_SIZE       = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.text, data.emotion_code, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text informations:\n",
      "max length: 91 / min length: 5 / mean length: 14 / limit length: 100\n",
      "vocabulary size: 2263 / limit: 2200\n"
     ]
    }
   ],
   "source": [
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])\n",
    "\n",
    "tokenizer = Tokenizer()#num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "length = max_length(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "result = [len(x.split()) for x in x_train]\n",
    "print('Text informations:')\n",
    "print('max length: %i / min length: %i / mean length: %i / limit length: %i' % (np.max(result),\n",
    "                                                                                np.min(result),\n",
    "                                                                                np.mean(result),\n",
    "                                                                                MAX_SEQ_LENGTH))\n",
    "\n",
    "print('vocabulary size: %i / limit: %i' % (len(word_index), MAX_NUM_WORDS))\n",
    "\n",
    "# Padding all sequences to same length of `MAX_SEQ_LENGTH`\n",
    "data   = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 2624)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_glove_embeddings(data = None, use_text8 = False, LEARNING_RATE=0.05, EPOCHS=30, NO_THREADS=4):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = Glove.load('models/glovetext8.model')\n",
    "    else:\n",
    "        if(data != None):\n",
    "            corpus = Corpus()\n",
    "            corpus.fit(data, window=10)\n",
    "            model = Glove(no_components=EMBEDDING_DIM,learning_rate=LEARNING_RATE)\n",
    "            model.fit(corpus.matrix, epochs=EPOCHS,no_threads=NO_THREADS,verbose=True)\n",
    "            model.add_dictionary(corpus.dictionary)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = Glove.load('models/glovetext8.model')\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word,index in model.dictionary.items():\n",
    "        embeddings_index[word] = model.word_vectors[index]\n",
    "    \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM,\n",
    "                     weights=[embedding_matrix], trainable=True)\n",
    "    \n",
    "def create_word2vec_embeddings(data = None, use_text8 = False):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    else:\n",
    "        if(data != None):  \n",
    "            model = word2vec.Word2Vec(data, size=EMBEDDING_DIM)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word in model.wv.index2word:\n",
    "        embeddings_index[word] = model[word]\n",
    "        \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length = MAX_SEQ_LENGTH,\n",
    "                    weights= [embedding_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "embedding_data = [x.split() for x in x_train]\n",
    "emb_layers = [create_word2vec_embeddings(use_text8=True),\n",
    "              create_word2vec_embeddings(embedding_data),\n",
    "              create_glove_embeddings(use_text8=True),\n",
    "              create_glove_embeddings(embedding_data)\n",
    "             ]\n",
    "\n",
    "emb_layers_names = ['word2vectext8','word2veciemocap','glovetext8','gloveiemocap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2624, 2624)\n"
     ]
    }
   ],
   "source": [
    "print(len(data),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 6, 9]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 4s 2ms/step - loss: 2.2000 - acc: 0.2461 - val_loss: 2.2893 - val_acc: 0.2129\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.28926, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1946 - acc: 0.2342 - val_loss: 2.2854 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.28926 to 2.28540, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2013 - acc: 0.2346 - val_loss: 2.2816 - val_acc: 0.2167\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.28540 to 2.28156, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1928 - acc: 0.2402 - val_loss: 2.2777 - val_acc: 0.2243\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.28156 to 2.27767, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1898 - acc: 0.2414 - val_loss: 2.2738 - val_acc: 0.2167\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.27767 to 2.27379, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1733 - acc: 0.2452 - val_loss: 2.2698 - val_acc: 0.2129\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.27379 to 2.26981, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1578 - acc: 0.2270 - val_loss: 2.2658 - val_acc: 0.2091\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.26981 to 2.26579, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1849 - acc: 0.2330 - val_loss: 2.2618 - val_acc: 0.2091\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.26579 to 2.26175, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1635 - acc: 0.2469 - val_loss: 2.2577 - val_acc: 0.2091\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.26175 to 2.25772, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1660 - acc: 0.2393 - val_loss: 2.2536 - val_acc: 0.2129\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.25772 to 2.25362, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1416 - acc: 0.2393 - val_loss: 2.2495 - val_acc: 0.2129\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.25362 to 2.24948, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1459 - acc: 0.2393 - val_loss: 2.2453 - val_acc: 0.2129\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.24948 to 2.24532, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1255 - acc: 0.2457 - val_loss: 2.2411 - val_acc: 0.2091\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.24532 to 2.24107, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1375 - acc: 0.2351 - val_loss: 2.2368 - val_acc: 0.2129\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.24107 to 2.23684, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1418 - acc: 0.2330 - val_loss: 2.2326 - val_acc: 0.2167\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.23684 to 2.23258, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1217 - acc: 0.2478 - val_loss: 2.2283 - val_acc: 0.2167\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.23258 to 2.22826, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1141 - acc: 0.2368 - val_loss: 2.2239 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.22826 to 2.22387, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0967 - acc: 0.2397 - val_loss: 2.2195 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.22387 to 2.21945, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1113 - acc: 0.2355 - val_loss: 2.2150 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.21945 to 2.21502, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1064 - acc: 0.2423 - val_loss: 2.2106 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.21502 to 2.21058, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0949 - acc: 0.2389 - val_loss: 2.2060 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.21058 to 2.20603, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0909 - acc: 0.2359 - val_loss: 2.2014 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.20603 to 2.20143, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0899 - acc: 0.2376 - val_loss: 2.1969 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.20143 to 2.19685, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0653 - acc: 0.2236 - val_loss: 2.1922 - val_acc: 0.2243\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.19685 to 2.19221, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0543 - acc: 0.2376 - val_loss: 2.1875 - val_acc: 0.2243\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.19221 to 2.18754, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0586 - acc: 0.2418 - val_loss: 2.1828 - val_acc: 0.2243\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.18754 to 2.18281, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0576 - acc: 0.2520 - val_loss: 2.1780 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.18281 to 2.17802, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0474 - acc: 0.2330 - val_loss: 2.1731 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.17802 to 2.17313, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0563 - acc: 0.2338 - val_loss: 2.1683 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.17313 to 2.16827, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0432 - acc: 0.2351 - val_loss: 2.1634 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.16827 to 2.16336, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0222 - acc: 0.2330 - val_loss: 2.1584 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.16336 to 2.15841, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0198 - acc: 0.2334 - val_loss: 2.1534 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.15841 to 2.15335, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0138 - acc: 0.2363 - val_loss: 2.1483 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.15335 to 2.14825, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0033 - acc: 0.2410 - val_loss: 2.1431 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.14825 to 2.14313, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0062 - acc: 0.2355 - val_loss: 2.1379 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.14313 to 2.13788, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0090 - acc: 0.2359 - val_loss: 2.1326 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.13788 to 2.13262, saving model to model-1.h5\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 3s 1ms/step - loss: 1.9959 - acc: 0.2368 - val_loss: 2.1272 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.13262 to 2.12725, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 1.9709 - acc: 0.2397 - val_loss: 2.1219 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.12725 to 2.12187, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 1.9678 - acc: 0.2402 - val_loss: 2.1164 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.12187 to 2.11643, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 1.9647 - acc: 0.2406 - val_loss: 2.1109 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.11643 to 2.11093, saving model to model-1.h5\n",
      "('Iteration', 1)\n",
      "--- 119.468204975 seconds on ---\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 6, 9]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 4s 2ms/step - loss: 2.3955 - acc: 0.2452 - val_loss: 2.4085 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.40852, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3647 - acc: 0.2431 - val_loss: 2.4047 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.40852 to 2.40475, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3571 - acc: 0.2389 - val_loss: 2.4009 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.40475 to 2.40094, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3872 - acc: 0.2482 - val_loss: 2.3970 - val_acc: 0.2814\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.40094 to 2.39702, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3430 - acc: 0.2452 - val_loss: 2.3931 - val_acc: 0.2814\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.39702 to 2.39306, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3461 - acc: 0.2402 - val_loss: 2.3891 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.39306 to 2.38906, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3459 - acc: 0.2380 - val_loss: 2.3851 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.38906 to 2.38509, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3425 - acc: 0.2406 - val_loss: 2.3810 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.38509 to 2.38104, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3404 - acc: 0.2440 - val_loss: 2.3769 - val_acc: 0.2624\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.38104 to 2.37695, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3313 - acc: 0.2380 - val_loss: 2.3728 - val_acc: 0.2662\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.37695 to 2.37285, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3233 - acc: 0.2592 - val_loss: 2.3687 - val_acc: 0.2624\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.37285 to 2.36874, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3412 - acc: 0.2406 - val_loss: 2.3646 - val_acc: 0.2700\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.36874 to 2.36458, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3253 - acc: 0.2402 - val_loss: 2.3604 - val_acc: 0.2700\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.36458 to 2.36043, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3066 - acc: 0.2435 - val_loss: 2.3562 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.36043 to 2.35622, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2996 - acc: 0.2308 - val_loss: 2.3520 - val_acc: 0.2662\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.35622 to 2.35200, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2891 - acc: 0.2389 - val_loss: 2.3476 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.35200 to 2.34763, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2893 - acc: 0.2423 - val_loss: 2.3432 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.34763 to 2.34324, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2821 - acc: 0.2287 - val_loss: 2.3389 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.34324 to 2.33887, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2944 - acc: 0.2423 - val_loss: 2.3345 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.33887 to 2.33450, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2810 - acc: 0.2397 - val_loss: 2.3300 - val_acc: 0.2243\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.33450 to 2.33005, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2675 - acc: 0.2342 - val_loss: 2.3256 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.33005 to 2.32559, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2522 - acc: 0.2423 - val_loss: 2.3211 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.32559 to 2.32108, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2659 - acc: 0.2385 - val_loss: 2.3165 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.32108 to 2.31655, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2556 - acc: 0.2440 - val_loss: 2.3119 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.31655 to 2.31191, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2318 - acc: 0.2325 - val_loss: 2.3072 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.31191 to 2.30718, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2284 - acc: 0.2499 - val_loss: 2.3024 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.30718 to 2.30240, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2294 - acc: 0.2474 - val_loss: 2.2976 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.30240 to 2.29757, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2205 - acc: 0.2355 - val_loss: 2.2927 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.29757 to 2.29272, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2372 - acc: 0.2317 - val_loss: 2.2878 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.29272 to 2.28783, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2191 - acc: 0.2440 - val_loss: 2.2829 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.28783 to 2.28292, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2116 - acc: 0.2482 - val_loss: 2.2779 - val_acc: 0.2243\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.28292 to 2.27794, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2021 - acc: 0.2346 - val_loss: 2.2729 - val_acc: 0.2243\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.27794 to 2.27294, saving model to model-2.h5\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2064 - acc: 0.2351 - val_loss: 2.2679 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.27294 to 2.26786, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1859 - acc: 0.2423 - val_loss: 2.2627 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.26786 to 2.26271, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1755 - acc: 0.2402 - val_loss: 2.2575 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.26271 to 2.25754, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1756 - acc: 0.2355 - val_loss: 2.2524 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.25754 to 2.25236, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1662 - acc: 0.2461 - val_loss: 2.2471 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.25236 to 2.24712, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1649 - acc: 0.2291 - val_loss: 2.2419 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.24712 to 2.24186, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1554 - acc: 0.2406 - val_loss: 2.2365 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.24186 to 2.23650, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1345 - acc: 0.2402 - val_loss: 2.2311 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.23650 to 2.23109, saving model to model-2.h5\n",
      "('Iteration', 2)\n",
      "--- 117.527955055 seconds on ---\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 6, 9]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 5s 2ms/step - loss: 2.4270 - acc: 0.2558 - val_loss: 2.3689 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.36891, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4199 - acc: 0.2507 - val_loss: 2.3650 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.36891 to 2.36497, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3877 - acc: 0.2520 - val_loss: 2.3610 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.36497 to 2.36103, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4066 - acc: 0.2444 - val_loss: 2.3571 - val_acc: 0.3080\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.36103 to 2.35706, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3971 - acc: 0.2507 - val_loss: 2.3531 - val_acc: 0.3042\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.35706 to 2.35310, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3811 - acc: 0.2520 - val_loss: 2.3491 - val_acc: 0.2966\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.35310 to 2.34910, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3767 - acc: 0.2478 - val_loss: 2.3451 - val_acc: 0.2966\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.34910 to 2.34510, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3677 - acc: 0.2541 - val_loss: 2.3411 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.34510 to 2.34110, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3611 - acc: 0.2533 - val_loss: 2.3371 - val_acc: 0.2814\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.34110 to 2.33708, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3604 - acc: 0.2613 - val_loss: 2.3330 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.33708 to 2.33299, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3600 - acc: 0.2478 - val_loss: 2.3289 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.33299 to 2.32893, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3560 - acc: 0.2418 - val_loss: 2.3248 - val_acc: 0.3042\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.32893 to 2.32485, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3517 - acc: 0.2474 - val_loss: 2.3208 - val_acc: 0.3080\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.32485 to 2.32075, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3494 - acc: 0.2397 - val_loss: 2.3166 - val_acc: 0.3080\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.32075 to 2.31664, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3255 - acc: 0.2571 - val_loss: 2.3125 - val_acc: 0.2966\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.31664 to 2.31252, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3249 - acc: 0.2550 - val_loss: 2.3084 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.31252 to 2.30841, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3353 - acc: 0.2440 - val_loss: 2.3043 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.30841 to 2.30425, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3113 - acc: 0.2507 - val_loss: 2.3001 - val_acc: 0.2966\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.30425 to 2.30011, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3269 - acc: 0.2537 - val_loss: 2.2959 - val_acc: 0.3042\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.30011 to 2.29591, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3117 - acc: 0.2520 - val_loss: 2.2917 - val_acc: 0.3042\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.29591 to 2.29168, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3173 - acc: 0.2351 - val_loss: 2.2874 - val_acc: 0.3080\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.29168 to 2.28744, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3062 - acc: 0.2516 - val_loss: 2.2832 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.28744 to 2.28317, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3015 - acc: 0.2448 - val_loss: 2.2789 - val_acc: 0.2966\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.28317 to 2.27892, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2903 - acc: 0.2334 - val_loss: 2.2746 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.27892 to 2.27464, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3023 - acc: 0.2448 - val_loss: 2.2703 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.27464 to 2.27033, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2738 - acc: 0.2507 - val_loss: 2.2660 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.27033 to 2.26603, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2642 - acc: 0.2499 - val_loss: 2.2617 - val_acc: 0.2814\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.26603 to 2.26170, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2722 - acc: 0.2495 - val_loss: 2.2573 - val_acc: 0.2700\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.26170 to 2.25733, saving model to model-3.h5\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2527 - acc: 0.2469 - val_loss: 2.2528 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.25733 to 2.25285, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2475 - acc: 0.2490 - val_loss: 2.2484 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.25285 to 2.24836, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2543 - acc: 0.2465 - val_loss: 2.2439 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.24836 to 2.24386, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2191 - acc: 0.2520 - val_loss: 2.2393 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.24386 to 2.23927, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2357 - acc: 0.2389 - val_loss: 2.2347 - val_acc: 0.2510\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.23927 to 2.23472, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2147 - acc: 0.2605 - val_loss: 2.2302 - val_acc: 0.2510\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.23472 to 2.23016, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2207 - acc: 0.2486 - val_loss: 2.2255 - val_acc: 0.2510\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.23016 to 2.22550, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2216 - acc: 0.2529 - val_loss: 2.2209 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.22550 to 2.22089, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2077 - acc: 0.2469 - val_loss: 2.2162 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.22089 to 2.21620, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2174 - acc: 0.2283 - val_loss: 2.2115 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.21620 to 2.21150, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1859 - acc: 0.2533 - val_loss: 2.2068 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.21150 to 2.20677, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1946 - acc: 0.2609 - val_loss: 2.2020 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.20677 to 2.20201, saving model to model-3.h5\n",
      "('Iteration', 3)\n",
      "--- 118.078747034 seconds on ---\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 6, 9]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 5s 2ms/step - loss: 2.2802 - acc: 0.2435 - val_loss: 2.3267 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.32668, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2771 - acc: 0.2524 - val_loss: 2.3227 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.32668 to 2.32271, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2965 - acc: 0.2380 - val_loss: 2.3187 - val_acc: 0.2510\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.32271 to 2.31870, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2653 - acc: 0.2444 - val_loss: 2.3147 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.31870 to 2.31469, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2617 - acc: 0.2452 - val_loss: 2.3106 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.31469 to 2.31064, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2544 - acc: 0.2368 - val_loss: 2.3066 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.31064 to 2.30658, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2387 - acc: 0.2402 - val_loss: 2.3025 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.30658 to 2.30251, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2590 - acc: 0.2486 - val_loss: 2.2984 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.30251 to 2.29838, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2416 - acc: 0.2385 - val_loss: 2.2942 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.29838 to 2.29421, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2336 - acc: 0.2351 - val_loss: 2.2899 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.29421 to 2.28994, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2254 - acc: 0.2258 - val_loss: 2.2857 - val_acc: 0.2281\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.28994 to 2.28565, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2211 - acc: 0.2338 - val_loss: 2.2813 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.28565 to 2.28129, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2229 - acc: 0.2393 - val_loss: 2.2769 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.28129 to 2.27689, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2147 - acc: 0.2440 - val_loss: 2.2724 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.27689 to 2.27245, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2178 - acc: 0.2406 - val_loss: 2.2680 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.27245 to 2.26796, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1971 - acc: 0.2499 - val_loss: 2.2634 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.26796 to 2.26338, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2043 - acc: 0.2499 - val_loss: 2.2588 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.26338 to 2.25876, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1923 - acc: 0.2461 - val_loss: 2.2541 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.25876 to 2.25411, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1787 - acc: 0.2393 - val_loss: 2.2494 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.25411 to 2.24942, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1668 - acc: 0.2418 - val_loss: 2.2447 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.24942 to 2.24470, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1706 - acc: 0.2418 - val_loss: 2.2399 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.24470 to 2.23991, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1545 - acc: 0.2342 - val_loss: 2.2351 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.23991 to 2.23507, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1607 - acc: 0.2346 - val_loss: 2.2302 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.23507 to 2.23022, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1451 - acc: 0.2418 - val_loss: 2.2253 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.23022 to 2.22528, saving model to model-4.h5\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1291 - acc: 0.2435 - val_loss: 2.2203 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.22528 to 2.22033, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1419 - acc: 0.2389 - val_loss: 2.2154 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.22033 to 2.21536, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1208 - acc: 0.2368 - val_loss: 2.2103 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.21536 to 2.21034, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1151 - acc: 0.2380 - val_loss: 2.2053 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.21034 to 2.20531, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1243 - acc: 0.2516 - val_loss: 2.2003 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.20531 to 2.20027, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1050 - acc: 0.2448 - val_loss: 2.1951 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.20027 to 2.19514, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1029 - acc: 0.2389 - val_loss: 2.1900 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.19514 to 2.18999, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.1050 - acc: 0.2355 - val_loss: 2.1849 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.18999 to 2.18488, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0701 - acc: 0.2397 - val_loss: 2.1796 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.18488 to 2.17962, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0829 - acc: 0.2363 - val_loss: 2.1743 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.17962 to 2.17430, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0689 - acc: 0.2393 - val_loss: 2.1690 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.17430 to 2.16896, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0715 - acc: 0.2465 - val_loss: 2.1636 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.16896 to 2.16361, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0480 - acc: 0.2406 - val_loss: 2.1582 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.16361 to 2.15822, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0515 - acc: 0.2372 - val_loss: 2.1528 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.15822 to 2.15278, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0483 - acc: 0.2385 - val_loss: 2.1473 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.15278 to 2.14729, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.0341 - acc: 0.2300 - val_loss: 2.1418 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.14729 to 2.14180, saving model to model-4.h5\n",
      "('Iteration', 4)\n",
      "--- 117.546005011 seconds on ---\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 6, 9]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 5s 2ms/step - loss: 2.5822 - acc: 0.2490 - val_loss: 2.5036 - val_acc: 0.2814\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.50360, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5519 - acc: 0.2359 - val_loss: 2.4985 - val_acc: 0.2814\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.50360 to 2.49850, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5622 - acc: 0.2613 - val_loss: 2.4934 - val_acc: 0.2852\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.49850 to 2.49336, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5437 - acc: 0.2512 - val_loss: 2.4882 - val_acc: 0.2852\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.49336 to 2.48820, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5314 - acc: 0.2457 - val_loss: 2.4830 - val_acc: 0.2814\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.48820 to 2.48303, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5410 - acc: 0.2516 - val_loss: 2.4778 - val_acc: 0.2852\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.48303 to 2.47783, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5303 - acc: 0.2567 - val_loss: 2.4726 - val_acc: 0.2852\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.47783 to 2.47262, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5144 - acc: 0.2482 - val_loss: 2.4674 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.47262 to 2.46744, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5133 - acc: 0.2461 - val_loss: 2.4622 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.46744 to 2.46224, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.5117 - acc: 0.2668 - val_loss: 2.4570 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.46224 to 2.45701, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4944 - acc: 0.2448 - val_loss: 2.4518 - val_acc: 0.2852\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.45701 to 2.45179, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4772 - acc: 0.2592 - val_loss: 2.4466 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.45179 to 2.44655, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4869 - acc: 0.2427 - val_loss: 2.4412 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.44655 to 2.44125, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4744 - acc: 0.2486 - val_loss: 2.4359 - val_acc: 0.2966\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.44125 to 2.43592, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4790 - acc: 0.2490 - val_loss: 2.4306 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.43592 to 2.43061, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4810 - acc: 0.2431 - val_loss: 2.4252 - val_acc: 0.2928\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.43061 to 2.42522, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4466 - acc: 0.2402 - val_loss: 2.4198 - val_acc: 0.2852\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.42522 to 2.41981, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4560 - acc: 0.2520 - val_loss: 2.4143 - val_acc: 0.2852\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.41981 to 2.41431, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4462 - acc: 0.2418 - val_loss: 2.4088 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.41431 to 2.40885, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4408 - acc: 0.2330 - val_loss: 2.4034 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.40885 to 2.40336, saving model to model-5.h5\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4353 - acc: 0.2363 - val_loss: 2.3979 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.40336 to 2.39790, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4181 - acc: 0.2660 - val_loss: 2.3924 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.39790 to 2.39237, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4236 - acc: 0.2385 - val_loss: 2.3869 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.39237 to 2.38685, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4062 - acc: 0.2435 - val_loss: 2.3814 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.38685 to 2.38136, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4011 - acc: 0.2440 - val_loss: 2.3759 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.38136 to 2.37586, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3890 - acc: 0.2541 - val_loss: 2.3703 - val_acc: 0.2738\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.37586 to 2.37033, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.4097 - acc: 0.2431 - val_loss: 2.3648 - val_acc: 0.2700\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.37033 to 2.36477, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3809 - acc: 0.2444 - val_loss: 2.3592 - val_acc: 0.2662\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.36477 to 2.35918, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3760 - acc: 0.2418 - val_loss: 2.3536 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.35918 to 2.35356, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3711 - acc: 0.2499 - val_loss: 2.3479 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.35356 to 2.34787, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3426 - acc: 0.2533 - val_loss: 2.3422 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.34787 to 2.34220, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3360 - acc: 0.2457 - val_loss: 2.3365 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.34220 to 2.33645, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3499 - acc: 0.2575 - val_loss: 2.3307 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.33645 to 2.33072, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3416 - acc: 0.2562 - val_loss: 2.3249 - val_acc: 0.2357\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.33072 to 2.32489, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3129 - acc: 0.2584 - val_loss: 2.3191 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.32489 to 2.31907, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3281 - acc: 0.2461 - val_loss: 2.3133 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.31907 to 2.31328, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3220 - acc: 0.2346 - val_loss: 2.3074 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.31328 to 2.30737, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3037 - acc: 0.2435 - val_loss: 2.3015 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.30737 to 2.30151, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.3142 - acc: 0.2546 - val_loss: 2.2956 - val_acc: 0.2395\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.30151 to 2.29560, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 3s 1ms/step - loss: 2.2917 - acc: 0.2546 - val_loss: 2.2896 - val_acc: 0.2510\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.29560 to 2.28962, saving model to model-5.h5\n",
      "('Iteration', 5)\n",
      "--- 119.213541031 seconds on ---\n"
     ]
    }
   ],
   "source": [
    "import cnn_model\n",
    "\n",
    "histories = []\n",
    "\n",
    "import time\n",
    "for i in range(RUNS):\n",
    "    print('Running iteration %i/%i' % (i+1, RUNS))\n",
    "    start_time = time.time()\n",
    "    X_train, X_val, labels, y_val = train_test_split(data, y_train, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "    emb_layer = None\n",
    "    if USE_GLOVE:\n",
    "        emb_layer = emb_layers[2] #create_word2vec_embeddings(result)\n",
    "\n",
    "    model = cnn_model.build_cnn(\n",
    "        embedding_layer=emb_layer,\n",
    "        num_words=MAX_NUM_WORDS,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        filter_sizes=FILTER_SIZES,\n",
    "        feature_maps=FEATURE_MAPS,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        dropout_rate=DROPOUT_RATE\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adadelta(clipvalue=3,lr=0.001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, labels,\n",
    "        epochs=NB_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n",
    "                                   verbose=1, save_best_only=True, mode='min'),\n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.01)\n",
    "                  ]\n",
    "    )\n",
    "    histories.append(history.history)\n",
    "    print('Iteration', i+1)\n",
    "    print(\"--- %s seconds on ---\" % (time.time() - start_time))\n",
    "    \n",
    "with open('history/unbalanced_'+emb_layers_names[2]+'_'+str(MAX_NUM_WORDS)+'.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 1s 310us/step\n",
      "263/263 [==============================] - 0s 307us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3., 15., 39., 70., 55., 42., 20., 14.,  3.,  2.]),\n",
       " array([0.45167357, 0.46947835, 0.48728313, 0.50508792, 0.5228927 ,\n",
       "        0.54069749, 0.55850227, 0.57630705, 0.59411184, 0.61191662,\n",
       "        0.6297214 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_predictions = model.predict(X_train, verbose=1)\n",
    "plt.hist(train_predictions)\n",
    "test_predictions = model.predict(X_val,verbose=1)\n",
    "plt.hist(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 10s 4ms/step - loss: -2.4648 - acc: 0.2401 - val_loss: -8.7223 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.72228, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 3s 902us/step - loss: -7.5640 - acc: 0.2372 - val_loss: -8.9320 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.72228 to -8.93195, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 3s 900us/step - loss: -7.7602 - acc: 0.2372 - val_loss: -9.1199 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.93195 to -9.11994, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 3s 904us/step - loss: -7.9424 - acc: 0.2372 - val_loss: -9.2947 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.11994 to -9.29474, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 3s 909us/step - loss: -8.1128 - acc: 0.2372 - val_loss: -9.4579 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.29474 to -9.45788, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 3s 903us/step - loss: -8.2723 - acc: 0.2372 - val_loss: -9.6162 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.45788 to -9.61615, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 3s 909us/step - loss: -8.4249 - acc: 0.2372 - val_loss: -9.7607 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.61615 to -9.76073, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 3s 904us/step - loss: -8.5629 - acc: 0.2372 - val_loss: -9.8889 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.76073 to -9.88894, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 3s 909us/step - loss: -8.6850 - acc: 0.2372 - val_loss: -10.0051 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.88894 to -10.00512, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 3s 905us/step - loss: -8.7914 - acc: 0.2372 - val_loss: -10.1024 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.00512 to -10.10238, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 3s 905us/step - loss: -8.8791 - acc: 0.2372 - val_loss: -10.1782 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.10238 to -10.17819, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 3s 914us/step - loss: -8.9462 - acc: 0.2372 - val_loss: -10.2300 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.17819 to -10.22999, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 3s 922us/step - loss: -8.9936 - acc: 0.2372 - val_loss: -10.2776 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.22999 to -10.27761, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 3s 899us/step - loss: -9.0329 - acc: 0.2372 - val_loss: -10.3066 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.27761 to -10.30658, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 3s 904us/step - loss: -9.0580 - acc: 0.2372 - val_loss: -10.3251 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.30658 to -10.32510, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 3s 908us/step - loss: -9.0762 - acc: 0.2372 - val_loss: -10.3468 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.32510 to -10.34682, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 3s 906us/step - loss: -9.0922 - acc: 0.2372 - val_loss: -10.3576 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.34682 to -10.35763, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 3s 937us/step - loss: -9.1020 - acc: 0.2372 - val_loss: -10.3371 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -10.35763\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 3s 901us/step - loss: -9.1053 - acc: 0.2372 - val_loss: -10.3686 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.35763 to -10.36863, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 3s 906us/step - loss: -9.1111 - acc: 0.2372 - val_loss: -10.3722 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.36863 to -10.37222, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 3s 907us/step - loss: -9.1124 - acc: 0.2372 - val_loss: -10.3722 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.37222 to -10.37222, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 3s 913us/step - loss: -9.1149 - acc: 0.2372 - val_loss: -10.3768 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.37222 to -10.37675, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 3s 900us/step - loss: -9.1180 - acc: 0.2372 - val_loss: -10.3779 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.37675 to -10.37790, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 3s 905us/step - loss: -9.1173 - acc: 0.2372 - val_loss: -10.3771 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -10.37790\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 3s 907us/step - loss: -9.1178 - acc: 0.2372 - val_loss: -10.3754 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -10.37790\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 3s 909us/step - loss: -9.1164 - acc: 0.2372 - val_loss: -10.3765 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -10.37790\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 3s 906us/step - loss: -9.1174 - acc: 0.2372 - val_loss: -10.3775 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -10.37790\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 3s 932us/step - loss: -9.1180 - acc: 0.2372 - val_loss: -10.3776 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -10.37790\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 3s 909us/step - loss: -9.1182 - acc: 0.2372 - val_loss: -10.3778 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -10.37790\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 3s 907us/step - loss: -9.1183 - acc: 0.2372 - val_loss: -10.3780 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.37790 to -10.37796, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 3s 900us/step - loss: -9.1186 - acc: 0.2372 - val_loss: -10.3782 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.37796 to -10.37822, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 890us/step - loss: -9.1189 - acc: 0.2372 - val_loss: -10.3786 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.37822 to -10.37858, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 898us/step - loss: -9.1193 - acc: 0.2372 - val_loss: -10.3790 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.37858 to -10.37903, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 3s 900us/step - loss: -9.1198 - acc: 0.2372 - val_loss: -10.3796 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.37903 to -10.37960, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 3s 900us/step - loss: -9.1204 - acc: 0.2372 - val_loss: -10.3803 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.37960 to -10.38026, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 898us/step - loss: -9.1211 - acc: 0.2372 - val_loss: -10.3810 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.38026 to -10.38100, saving model to model-1.h5\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.1219 - acc: 0.2372 - val_loss: -10.3818 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.38100 to -10.38177, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.1224 - acc: 0.2372 - val_loss: -10.3823 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.38177 to -10.38232, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1227 - acc: 0.2372 - val_loss: -10.3823 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss improved from -10.38232 to -10.38233, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -9.1229 - acc: 0.2372 - val_loss: -10.3824 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.38233 to -10.38239, saving model to model-1.h5\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 9s 3ms/step - loss: -3.7958 - acc: 0.2372 - val_loss: -8.7430 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.74299, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -7.5640 - acc: 0.2372 - val_loss: -8.9167 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.74299 to -8.91672, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -7.7344 - acc: 0.2372 - val_loss: -9.0842 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.91672 to -9.08425, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 893us/step - loss: -7.8997 - acc: 0.2372 - val_loss: -9.2438 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.08425 to -9.24378, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 890us/step - loss: -8.0561 - acc: 0.2372 - val_loss: -9.4004 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.24378 to -9.40035, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.2111 - acc: 0.2372 - val_loss: -9.5542 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.40035 to -9.55417, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -8.3625 - acc: 0.2372 - val_loss: -9.7027 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.55417 to -9.70266, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -8.5057 - acc: 0.2372 - val_loss: -9.8380 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.70266 to -9.83797, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.6357 - acc: 0.2372 - val_loss: -9.9599 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.83797 to -9.95991, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 3s 902us/step - loss: -8.7494 - acc: 0.2372 - val_loss: -10.0587 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.95991 to -10.05873, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -8.8418 - acc: 0.2372 - val_loss: -10.1455 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.05873 to -10.14550, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 880us/step - loss: -8.9183 - acc: 0.2372 - val_loss: -10.2121 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.14550 to -10.21209, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -8.9760 - acc: 0.2372 - val_loss: -10.2515 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.21209 to -10.25149, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 889us/step - loss: -9.0085 - acc: 0.2372 - val_loss: -10.2859 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.25149 to -10.28591, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 892us/step - loss: -9.0394 - acc: 0.2372 - val_loss: -10.3072 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.28591 to -10.30721, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -9.0585 - acc: 0.2372 - val_loss: -10.3296 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.30721 to -10.32963, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.0757 - acc: 0.2372 - val_loss: -10.3420 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.32963 to -10.34197, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 879us/step - loss: -9.0878 - acc: 0.2372 - val_loss: -10.3487 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.34197 to -10.34872, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 882us/step - loss: -9.0948 - acc: 0.2372 - val_loss: -10.3604 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.34872 to -10.36037, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.1038 - acc: 0.2372 - val_loss: -10.3676 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.36037 to -10.36764, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.1012 - acc: 0.2372 - val_loss: -10.3643 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -10.36764\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.1065 - acc: 0.2372 - val_loss: -10.3681 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.36764 to -10.36810, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -9.1103 - acc: 0.2372 - val_loss: -10.3718 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.36810 to -10.37182, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.1129 - acc: 0.2372 - val_loss: -10.3716 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -10.37182\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1142 - acc: 0.2372 - val_loss: -10.3760 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.37182 to -10.37602, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.1164 - acc: 0.2372 - val_loss: -10.3765 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.37602 to -10.37654, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.1180 - acc: 0.2372 - val_loss: -10.3790 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.37654 to -10.37901, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.1203 - acc: 0.2372 - val_loss: -10.3806 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.37901 to -10.38064, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.1005 - acc: 0.2372 - val_loss: -10.3767 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -10.38064\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1175 - acc: 0.2372 - val_loss: -10.3773 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -10.38064\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.1181 - acc: 0.2372 - val_loss: -10.3780 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -10.38064\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.1189 - acc: 0.2372 - val_loss: -10.3789 - val_acc: 0.2516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_loss did not improve from -10.38064\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1194 - acc: 0.2372 - val_loss: -10.3790 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.38064\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1195 - acc: 0.2372 - val_loss: -10.3791 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.38064\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.1197 - acc: 0.2372 - val_loss: -10.3793 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.38064\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1199 - acc: 0.2372 - val_loss: -10.3796 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.38064\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.1201 - acc: 0.2372 - val_loss: -10.3796 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.38064\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -9.1201 - acc: 0.2372 - val_loss: -10.3797 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.38064\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -9.1202 - acc: 0.2372 - val_loss: -10.3797 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.38064\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.1203 - acc: 0.2372 - val_loss: -10.3798 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.38064\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 9s 3ms/step - loss: -5.0626 - acc: 0.2394 - val_loss: -8.7596 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.75964, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -7.5805 - acc: 0.2372 - val_loss: -8.9310 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.75964 to -8.93104, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -7.7470 - acc: 0.2372 - val_loss: -9.0941 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.93104 to -9.09413, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -7.9087 - acc: 0.2372 - val_loss: -9.2535 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.09413 to -9.25349, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -8.0647 - acc: 0.2372 - val_loss: -9.4095 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.25349 to -9.40952, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.2199 - acc: 0.2372 - val_loss: -9.5602 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.40952 to -9.56022, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.3685 - acc: 0.2372 - val_loss: -9.7088 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.56022 to -9.70885, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.5118 - acc: 0.2372 - val_loss: -9.8422 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.70885 to -9.84221, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.6409 - acc: 0.2372 - val_loss: -9.9670 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.84221 to -9.96701, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -8.7558 - acc: 0.2372 - val_loss: -10.0695 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.96701 to -10.06947, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.8515 - acc: 0.2372 - val_loss: -10.1492 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.06947 to -10.14922, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.9230 - acc: 0.2372 - val_loss: -10.2182 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.14922 to -10.21824, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.9813 - acc: 0.2372 - val_loss: -10.2656 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.21824 to -10.26563, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.0221 - acc: 0.2372 - val_loss: -10.3029 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.26563 to -10.30290, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.0558 - acc: 0.2372 - val_loss: -10.3285 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.30290 to -10.32850, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.0756 - acc: 0.2372 - val_loss: -10.3432 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.32850 to -10.34318, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 893us/step - loss: -9.0918 - acc: 0.2372 - val_loss: -10.3564 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.34318 to -10.35644, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 886us/step - loss: -9.1026 - acc: 0.2372 - val_loss: -10.3679 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.35644 to -10.36790, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.0619 - acc: 0.2372 - val_loss: -10.3629 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -10.36790\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.1039 - acc: 0.2372 - val_loss: -10.3640 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -10.36790\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.1051 - acc: 0.2372 - val_loss: -10.3653 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -10.36790\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.1064 - acc: 0.2372 - val_loss: -10.3667 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -10.36790\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.1072 - acc: 0.2372 - val_loss: -10.3668 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -10.36790\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.1075 - acc: 0.2372 - val_loss: -10.3671 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -10.36790\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1077 - acc: 0.2372 - val_loss: -10.3674 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -10.36790\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.1081 - acc: 0.2372 - val_loss: -10.3679 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -10.36790\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.1084 - acc: 0.2372 - val_loss: -10.3679 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.36790 to -10.36792, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.1085 - acc: 0.2372 - val_loss: -10.3680 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.36792 to -10.36801, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.1086 - acc: 0.2372 - val_loss: -10.3681 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.36801 to -10.36811, saving model to model-3.h5\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.1087 - acc: 0.2372 - val_loss: -10.3682 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.36811 to -10.36824, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.1088 - acc: 0.2372 - val_loss: -10.3684 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.36824 to -10.36840, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1090 - acc: 0.2372 - val_loss: -10.3686 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.36840 to -10.36858, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.1092 - acc: 0.2372 - val_loss: -10.3688 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.36858 to -10.36878, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.1094 - acc: 0.2372 - val_loss: -10.3690 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.36878 to -10.36899, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.1096 - acc: 0.2372 - val_loss: -10.3692 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.36899 to -10.36922, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.1098 - acc: 0.2372 - val_loss: -10.3695 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.36922 to -10.36945, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 879us/step - loss: -9.1101 - acc: 0.2372 - val_loss: -10.3697 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.36945 to -10.36969, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.1103 - acc: 0.2372 - val_loss: -10.3699 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.36969 to -10.36994, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.1105 - acc: 0.2372 - val_loss: -10.3702 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss improved from -10.36994 to -10.37018, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -9.1108 - acc: 0.2372 - val_loss: -10.3704 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.37018 to -10.37043, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 9s 3ms/step - loss: -5.0758 - acc: 0.2401 - val_loss: -8.7879 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.78789, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -7.6045 - acc: 0.2372 - val_loss: -8.9508 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.78789 to -8.95081, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -7.7622 - acc: 0.2372 - val_loss: -9.1049 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.95081 to -9.10493, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -7.9155 - acc: 0.2372 - val_loss: -9.2553 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.10493 to -9.25527, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 880us/step - loss: -8.0645 - acc: 0.2372 - val_loss: -9.4037 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.25527 to -9.40367, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 882us/step - loss: -8.2123 - acc: 0.2372 - val_loss: -9.5475 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.40367 to -9.54746, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -8.3545 - acc: 0.2372 - val_loss: -9.6904 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.54746 to -9.69038, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -8.4919 - acc: 0.2372 - val_loss: -9.8232 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.69038 to -9.82322, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 884us/step - loss: -8.6201 - acc: 0.2372 - val_loss: -9.9427 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.82322 to -9.94267, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -8.7338 - acc: 0.2372 - val_loss: -10.0479 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.94267 to -10.04786, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -8.8313 - acc: 0.2372 - val_loss: -10.1369 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.04786 to -10.13688, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -8.8620 - acc: 0.2372 - val_loss: -10.1808 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.13688 to -10.18076, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 880us/step - loss: -8.9299 - acc: 0.2372 - val_loss: -10.1993 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.18076 to -10.19925, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -8.9479 - acc: 0.2372 - val_loss: -10.2169 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.19925 to -10.21687, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 880us/step - loss: -8.9655 - acc: 0.2372 - val_loss: -10.2345 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.21687 to -10.23453, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -8.9834 - acc: 0.2372 - val_loss: -10.2530 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.23453 to -10.25296, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.0018 - acc: 0.2372 - val_loss: -10.2711 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.25296 to -10.27115, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 890us/step - loss: -9.0209 - acc: 0.2372 - val_loss: -10.2905 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.27115 to -10.29049, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 3s 912us/step - loss: -9.0389 - acc: 0.2372 - val_loss: -10.3059 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.29049 to -10.30589, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 893us/step - loss: -9.0557 - acc: 0.2372 - val_loss: -10.3256 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.30589 to -10.32564, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 892us/step - loss: -9.0727 - acc: 0.2372 - val_loss: -10.3386 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.32564 to -10.33865, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.0852 - acc: 0.2372 - val_loss: -10.3527 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.33865 to -10.35269, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0969 - acc: 0.2372 - val_loss: -10.3625 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.35269 to -10.36249, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.1027 - acc: 0.2372 - val_loss: -10.3677 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.36249 to -10.36768, saving model to model-4.h5\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1107 - acc: 0.2372 - val_loss: -10.3733 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.36768 to -10.37335, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.1137 - acc: 0.2372 - val_loss: -10.3758 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.37335 to -10.37579, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1166 - acc: 0.2372 - val_loss: -10.3769 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.37579 to -10.37692, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1192 - acc: 0.2372 - val_loss: -10.3778 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.37692 to -10.37782, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1205 - acc: 0.2372 - val_loss: -10.3822 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.37782 to -10.38223, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.0687 - acc: 0.2372 - val_loss: -10.3780 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -10.38223\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.1187 - acc: 0.2372 - val_loss: -10.3784 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -10.38223\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.1191 - acc: 0.2372 - val_loss: -10.3788 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -10.38223\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1195 - acc: 0.2372 - val_loss: -10.3793 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.38223\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1198 - acc: 0.2372 - val_loss: -10.3794 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.38223\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1199 - acc: 0.2372 - val_loss: -10.3794 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.38223\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.1200 - acc: 0.2372 - val_loss: -10.3796 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.38223\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.1201 - acc: 0.2372 - val_loss: -10.3797 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.38223\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.1202 - acc: 0.2372 - val_loss: -10.3797 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.38223\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.1203 - acc: 0.2372 - val_loss: -10.3798 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.38223\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1203 - acc: 0.2372 - val_loss: -10.3798 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.38223\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 9s 3ms/step - loss: -4.7673 - acc: 0.2441 - val_loss: -8.7510 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.75100, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -7.5575 - acc: 0.2372 - val_loss: -8.8933 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.75100 to -8.89334, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -7.6979 - acc: 0.2372 - val_loss: -9.0332 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.89334 to -9.03322, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -7.8383 - acc: 0.2372 - val_loss: -9.1743 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.03322 to -9.17429, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -7.9806 - acc: 0.2372 - val_loss: -9.3173 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.17429 to -9.31731, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -8.1253 - acc: 0.2372 - val_loss: -9.4631 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.31731 to -9.46314, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.2703 - acc: 0.2372 - val_loss: -9.6074 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.46314 to -9.60739, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.4122 - acc: 0.2372 - val_loss: -9.7470 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.60739 to -9.74700, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -8.5482 - acc: 0.2372 - val_loss: -9.8772 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.74700 to -9.87722, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.6728 - acc: 0.2372 - val_loss: -9.9930 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.87722 to -9.99302, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -8.7798 - acc: 0.2372 - val_loss: -10.0855 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.99302 to -10.08548, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.8644 - acc: 0.2372 - val_loss: -10.1631 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.08548 to -10.16313, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -8.9338 - acc: 0.2372 - val_loss: -10.2222 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.16313 to -10.22215, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -8.9861 - acc: 0.2372 - val_loss: -10.2705 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.22215 to -10.27054, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.0257 - acc: 0.2372 - val_loss: -10.3017 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.27054 to -10.30172, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.0447 - acc: 0.2372 - val_loss: -10.3231 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.30172 to -10.32305, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.0653 - acc: 0.2372 - val_loss: -10.3268 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.32305 to -10.32685, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0690 - acc: 0.2372 - val_loss: -10.3305 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.32685 to -10.33053, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.0728 - acc: 0.2372 - val_loss: -10.3343 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.33053 to -10.33434, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.0767 - acc: 0.2372 - val_loss: -10.3385 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.33434 to -10.33852, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.0812 - acc: 0.2372 - val_loss: -10.3433 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.33852 to -10.34328, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.0863 - acc: 0.2372 - val_loss: -10.3488 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.34328 to -10.34878, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.0921 - acc: 0.2372 - val_loss: -10.3550 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.34878 to -10.35500, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.0968 - acc: 0.2372 - val_loss: -10.3569 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.35500 to -10.35692, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.1005 - acc: 0.2372 - val_loss: -10.3635 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.35692 to -10.36346, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.1062 - acc: 0.2372 - val_loss: -10.3680 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.36346 to -10.36804, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.0820 - acc: 0.2372 - val_loss: -10.3681 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.36804 to -10.36812, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1090 - acc: 0.2372 - val_loss: -10.3688 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.36812 to -10.36884, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.1097 - acc: 0.2372 - val_loss: -10.3696 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.36884 to -10.36961, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.1105 - acc: 0.2372 - val_loss: -10.3705 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.36961 to -10.37051, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.1115 - acc: 0.2372 - val_loss: -10.3716 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.37051 to -10.37163, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.1127 - acc: 0.2372 - val_loss: -10.3730 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.37163 to -10.37303, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1143 - acc: 0.2372 - val_loss: -10.3747 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.37303 to -10.37475, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1157 - acc: 0.2372 - val_loss: -10.3747 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.37475\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1164 - acc: 0.2372 - val_loss: -10.3774 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.37475 to -10.37741, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1183 - acc: 0.2372 - val_loss: -10.3787 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.37741 to -10.37870, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1194 - acc: 0.2372 - val_loss: -10.3800 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.37870 to -10.37998, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1028 - acc: 0.2372 - val_loss: -10.3771 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.37998\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1178 - acc: 0.2372 - val_loss: -10.3775 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.37998\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.1181 - acc: 0.2372 - val_loss: -10.3779 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.37998\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 9s 3ms/step - loss: -2.6800 - acc: 0.2434 - val_loss: -8.8992 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.89921, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -7.8182 - acc: 0.2372 - val_loss: -9.2651 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.89921 to -9.26511, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.1364 - acc: 0.2372 - val_loss: -9.5325 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.26511 to -9.53253, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -8.3719 - acc: 0.2372 - val_loss: -9.7381 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.53253 to -9.73815, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -8.5537 - acc: 0.2372 - val_loss: -9.8861 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.73815 to -9.88613, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -8.6907 - acc: 0.2372 - val_loss: -10.0151 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.88613 to -10.01506, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -8.8026 - acc: 0.2372 - val_loss: -10.1130 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -10.01506 to -10.11296, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -8.8886 - acc: 0.2372 - val_loss: -10.1875 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.11296 to -10.18749, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -8.9543 - acc: 0.2372 - val_loss: -10.2440 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.18749 to -10.24404, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.0040 - acc: 0.2372 - val_loss: -10.2810 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.24404 to -10.28098, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.0400 - acc: 0.2372 - val_loss: -10.3135 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.28098 to -10.31354, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.0672 - acc: 0.2372 - val_loss: -10.3366 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.31354 to -10.33660, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.0851 - acc: 0.2372 - val_loss: -10.3435 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.33660 to -10.34350, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0899 - acc: 0.2372 - val_loss: -10.3558 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.34350 to -10.35577, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1006 - acc: 0.2372 - val_loss: -10.3627 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.35577 to -10.36269, saving model to model-1.h5\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1056 - acc: 0.2372 - val_loss: -10.3678 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.36269 to -10.36775, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1100 - acc: 0.2372 - val_loss: -10.3719 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.36775 to -10.37187, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1121 - acc: 0.2372 - val_loss: -10.3734 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.37187 to -10.37342, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1133 - acc: 0.2372 - val_loss: -10.3705 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -10.37342\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1117 - acc: 0.2372 - val_loss: -10.3720 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -10.37342\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.1133 - acc: 0.2372 - val_loss: -10.3737 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.37342 to -10.37368, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1150 - acc: 0.2372 - val_loss: -10.3755 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.37368 to -10.37552, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1170 - acc: 0.2372 - val_loss: -10.3776 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.37552 to -10.37758, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1186 - acc: 0.2372 - val_loss: -10.3782 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.37758 to -10.37817, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.1177 - acc: 0.2372 - val_loss: -10.3753 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -10.37817\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.1168 - acc: 0.2372 - val_loss: -10.3775 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -10.37817\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.1190 - acc: 0.2372 - val_loss: -10.3797 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.37817 to -10.37972, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1209 - acc: 0.2372 - val_loss: -10.3760 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -10.37972\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1173 - acc: 0.2372 - val_loss: -10.3776 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -10.37972\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.1189 - acc: 0.2372 - val_loss: -10.3792 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -10.37972\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1205 - acc: 0.2372 - val_loss: -10.3810 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.37972 to -10.38097, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1218 - acc: 0.2372 - val_loss: -10.3816 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.38097 to -10.38158, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1209 - acc: 0.2372 - val_loss: -10.3786 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.38158\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.1199 - acc: 0.2372 - val_loss: -10.3804 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.38158\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1218 - acc: 0.2372 - val_loss: -10.3822 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.38158 to -10.38224, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.1233 - acc: 0.2372 - val_loss: -10.3833 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.38224 to -10.38334, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1234 - acc: 0.2372 - val_loss: -10.3839 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.38334 to -10.38393, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1238 - acc: 0.2372 - val_loss: -10.3799 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.38393\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1220 - acc: 0.2372 - val_loss: -10.3832 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.38393\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1153 - acc: 0.2372 - val_loss: -10.3805 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.38393\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 10s 3ms/step - loss: -3.6585 - acc: 0.2344 - val_loss: -8.8268 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.82675, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -7.6905 - acc: 0.2372 - val_loss: -9.0869 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.82675 to -9.08691, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -7.9323 - acc: 0.2372 - val_loss: -9.3084 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.08691 to -9.30836, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.1395 - acc: 0.2372 - val_loss: -9.4976 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.30836 to -9.49756, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.3171 - acc: 0.2372 - val_loss: -9.6638 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.49756 to -9.66383, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -8.4718 - acc: 0.2372 - val_loss: -9.8037 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.66383 to -9.80374, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.6058 - acc: 0.2372 - val_loss: -9.9338 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.80374 to -9.93382, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.7231 - acc: 0.2372 - val_loss: -10.0395 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.93382 to -10.03945, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.8207 - acc: 0.2372 - val_loss: -10.1276 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.03945 to -10.12762, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -8.8982 - acc: 0.2372 - val_loss: -10.1832 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.12762 to -10.18322, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.9487 - acc: 0.2372 - val_loss: -10.2354 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.18322 to -10.23535, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.9926 - acc: 0.2372 - val_loss: -10.2634 - val_acc: 0.2516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss improved from -10.23535 to -10.26342, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.0197 - acc: 0.2372 - val_loss: -10.2963 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.26342 to -10.29631, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.0456 - acc: 0.2372 - val_loss: -10.3171 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.29631 to -10.31706, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.0646 - acc: 0.2372 - val_loss: -10.3327 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.31706 to -10.33267, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.0794 - acc: 0.2372 - val_loss: -10.3472 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.33267 to -10.34722, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.0901 - acc: 0.2372 - val_loss: -10.3567 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.34722 to -10.35667, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1000 - acc: 0.2372 - val_loss: -10.3647 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.35667 to -10.36473, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1061 - acc: 0.2372 - val_loss: -10.3689 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.36473 to -10.36887, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 3s 908us/step - loss: -9.1111 - acc: 0.2372 - val_loss: -10.3693 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.36887 to -10.36928, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1130 - acc: 0.2372 - val_loss: -10.3740 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.36928 to -10.37399, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1168 - acc: 0.2372 - val_loss: -10.3718 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -10.37399\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1157 - acc: 0.2372 - val_loss: -10.3787 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.37399 to -10.37867, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1197 - acc: 0.2372 - val_loss: -10.3809 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.37867 to -10.38093, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1200 - acc: 0.2372 - val_loss: -10.3763 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -10.38093\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1192 - acc: 0.2372 - val_loss: -10.3811 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.38093 to -10.38113, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1052 - acc: 0.2372 - val_loss: -10.3771 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -10.38113\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1178 - acc: 0.2372 - val_loss: -10.3775 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -10.38113\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1183 - acc: 0.2372 - val_loss: -10.3780 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -10.38113\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1188 - acc: 0.2372 - val_loss: -10.3786 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -10.38113\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.1191 - acc: 0.2372 - val_loss: -10.3787 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -10.38113\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1192 - acc: 0.2372 - val_loss: -10.3788 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -10.38113\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1194 - acc: 0.2372 - val_loss: -10.3789 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.38113\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1195 - acc: 0.2372 - val_loss: -10.3791 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.38113\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1196 - acc: 0.2372 - val_loss: -10.3792 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.38113\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.1197 - acc: 0.2372 - val_loss: -10.3792 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.38113\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1197 - acc: 0.2372 - val_loss: -10.3792 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.38113\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1198 - acc: 0.2372 - val_loss: -10.3793 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.38113\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.1198 - acc: 0.2372 - val_loss: -10.3794 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.38113\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1199 - acc: 0.2372 - val_loss: -10.3795 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.38113\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 10s 3ms/step - loss: -4.6132 - acc: 0.2358 - val_loss: -8.7935 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.79352, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -7.6329 - acc: 0.2372 - val_loss: -9.0025 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.79352 to -9.00251, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -7.8297 - acc: 0.2372 - val_loss: -9.1868 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.00251 to -9.18676, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.0055 - acc: 0.2372 - val_loss: -9.3542 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.18676 to -9.35419, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -8.1663 - acc: 0.2372 - val_loss: -9.5070 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.35419 to -9.50705, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.3145 - acc: 0.2372 - val_loss: -9.6496 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.50705 to -9.64956, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.4533 - acc: 0.2372 - val_loss: -9.7837 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.64956 to -9.78369, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -8.5817 - acc: 0.2372 - val_loss: -9.9053 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.78369 to -9.90533, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.6969 - acc: 0.2372 - val_loss: -10.0131 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.90533 to -10.01310, saving model to model-3.h5\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.7974 - acc: 0.2372 - val_loss: -10.1038 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.01310 to -10.10383, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -8.8780 - acc: 0.2372 - val_loss: -10.1579 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.10383 to -10.15787, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.9122 - acc: 0.2372 - val_loss: -10.1873 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.15787 to -10.18731, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.9406 - acc: 0.2372 - val_loss: -10.2149 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.18731 to -10.21489, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.9677 - acc: 0.2372 - val_loss: -10.2416 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.21489 to -10.24159, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -8.9942 - acc: 0.2372 - val_loss: -10.2673 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.24159 to -10.26731, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.0159 - acc: 0.2372 - val_loss: -10.2875 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.26731 to -10.28745, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.0368 - acc: 0.2372 - val_loss: -10.3060 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.28745 to -10.30598, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.0540 - acc: 0.2372 - val_loss: -10.3149 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.30598 to -10.31493, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0598 - acc: 0.2372 - val_loss: -10.3243 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.31493 to -10.32432, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0691 - acc: 0.2372 - val_loss: -10.3337 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.32432 to -10.33370, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.0786 - acc: 0.2372 - val_loss: -10.3433 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.33370 to -10.34328, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0869 - acc: 0.2372 - val_loss: -10.3501 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.34328 to -10.35010, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.0920 - acc: 0.2372 - val_loss: -10.3531 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.35010 to -10.35312, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.0976 - acc: 0.2372 - val_loss: -10.3616 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.35312 to -10.36162, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1041 - acc: 0.2372 - val_loss: -10.3657 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.36162 to -10.36574, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.1087 - acc: 0.2372 - val_loss: -10.3679 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.36574 to -10.36794, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1109 - acc: 0.2372 - val_loss: -10.3737 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.36794 to -10.37372, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.1135 - acc: 0.2372 - val_loss: -10.3738 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.37372 to -10.37381, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.1169 - acc: 0.2372 - val_loss: -10.3776 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.37381 to -10.37756, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.0986 - acc: 0.2372 - val_loss: -10.3746 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -10.37756\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.1152 - acc: 0.2372 - val_loss: -10.3750 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -10.37756\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.1157 - acc: 0.2372 - val_loss: -10.3754 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -10.37756\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1162 - acc: 0.2372 - val_loss: -10.3760 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.37756\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1166 - acc: 0.2372 - val_loss: -10.3761 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.37756\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.1166 - acc: 0.2372 - val_loss: -10.3762 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.37756\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 880us/step - loss: -9.1168 - acc: 0.2372 - val_loss: -10.3763 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.37756\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1169 - acc: 0.2372 - val_loss: -10.3765 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.37756\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1170 - acc: 0.2372 - val_loss: -10.3766 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.37756\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1171 - acc: 0.2372 - val_loss: -10.3766 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.37756\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.1171 - acc: 0.2372 - val_loss: -10.3767 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.37756\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 10s 3ms/step - loss: -4.9408 - acc: 0.2408 - val_loss: -8.8320 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.83195, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -7.6699 - acc: 0.2372 - val_loss: -9.0296 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.83195 to -9.02956, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -7.8559 - acc: 0.2372 - val_loss: -9.2024 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.02956 to -9.20239, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -8.0224 - acc: 0.2372 - val_loss: -9.3580 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.20239 to -9.35796, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -8.1736 - acc: 0.2372 - val_loss: -9.5056 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.35796 to -9.50563, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.3139 - acc: 0.2372 - val_loss: -9.6463 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.50563 to -9.64626, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -8.4483 - acc: 0.2372 - val_loss: -9.7706 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.64626 to -9.77061, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -8.5692 - acc: 0.2372 - val_loss: -9.8869 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.77061 to -9.88693, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -8.6809 - acc: 0.2372 - val_loss: -9.9907 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.88693 to -9.99068, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.7789 - acc: 0.2372 - val_loss: -10.0822 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.99068 to -10.08215, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -8.7918 - acc: 0.2372 - val_loss: -10.0953 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.08215 to -10.09525, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.8442 - acc: 0.2372 - val_loss: -10.1137 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.09525 to -10.11371, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -8.8631 - acc: 0.2372 - val_loss: -10.1333 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.11371 to -10.13330, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.8836 - acc: 0.2372 - val_loss: -10.1550 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.13330 to -10.15500, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.9066 - acc: 0.2372 - val_loss: -10.1796 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.15500 to -10.17957, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -8.9322 - acc: 0.2372 - val_loss: -10.2024 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.17957 to -10.20240, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -8.9611 - acc: 0.2372 - val_loss: -10.2325 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.20240 to -10.23246, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.9867 - acc: 0.2372 - val_loss: -10.2594 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.23246 to -10.25936, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.0139 - acc: 0.2372 - val_loss: -10.2871 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.25936 to -10.28707, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.0372 - acc: 0.2372 - val_loss: -10.3058 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.28707 to -10.30581, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.0582 - acc: 0.2372 - val_loss: -10.3276 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.30581 to -10.32761, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.0749 - acc: 0.2372 - val_loss: -10.3378 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.32761 to -10.33781, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.0857 - acc: 0.2372 - val_loss: -10.3553 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.33781 to -10.35526, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.0968 - acc: 0.2372 - val_loss: -10.3572 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.35526 to -10.35719, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1029 - acc: 0.2372 - val_loss: -10.3667 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.35719 to -10.36666, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1089 - acc: 0.2372 - val_loss: -10.3703 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.36666 to -10.37034, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.1093 - acc: 0.2372 - val_loss: -10.3675 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -10.37034\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1093 - acc: 0.2372 - val_loss: -10.3702 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -10.37034\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1120 - acc: 0.2372 - val_loss: -10.3729 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.37034 to -10.37290, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1147 - acc: 0.2372 - val_loss: -10.3756 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.37290 to -10.37563, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1062 - acc: 0.2372 - val_loss: -10.3735 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -10.37563\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1141 - acc: 0.2372 - val_loss: -10.3739 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -10.37563\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1146 - acc: 0.2372 - val_loss: -10.3744 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.37563\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1151 - acc: 0.2372 - val_loss: -10.3750 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.37563\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.1155 - acc: 0.2372 - val_loss: -10.3751 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.37563\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 879us/step - loss: -9.1156 - acc: 0.2372 - val_loss: -10.3752 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.37563\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.1157 - acc: 0.2372 - val_loss: -10.3753 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.37563\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.1159 - acc: 0.2372 - val_loss: -10.3755 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.37563\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.1160 - acc: 0.2372 - val_loss: -10.3756 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.37563\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.1161 - acc: 0.2372 - val_loss: -10.3756 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.37563\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 10s 3ms/step - loss: -5.0558 - acc: 0.2387 - val_loss: -8.8652 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.86518, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -7.7083 - acc: 0.2372 - val_loss: -9.0781 - val_acc: 0.2516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from -8.86518 to -9.07807, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -7.9092 - acc: 0.2372 - val_loss: -9.2608 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.07807 to -9.26078, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.0791 - acc: 0.2372 - val_loss: -9.4229 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.26078 to -9.42293, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -8.2302 - acc: 0.2372 - val_loss: -9.5677 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.42293 to -9.56772, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 3s 921us/step - loss: -8.3688 - acc: 0.2372 - val_loss: -9.6990 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.56772 to -9.69900, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -8.5011 - acc: 0.2372 - val_loss: -9.8263 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.69900 to -9.82630, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.6183 - acc: 0.2372 - val_loss: -9.9376 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.82630 to -9.93759, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.7242 - acc: 0.2372 - val_loss: -10.0343 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.93759 to -10.03426, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.8131 - acc: 0.2372 - val_loss: -10.1178 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.03426 to -10.11777, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.8885 - acc: 0.2372 - val_loss: -10.1833 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.11777 to -10.18334, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -8.9527 - acc: 0.2372 - val_loss: -10.2430 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.18334 to -10.24304, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -8.9999 - acc: 0.2372 - val_loss: -10.2834 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.24304 to -10.28344, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.0216 - acc: 0.2372 - val_loss: -10.2835 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.28344 to -10.28350, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.0282 - acc: 0.2372 - val_loss: -10.2926 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.28350 to -10.29259, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.0374 - acc: 0.2372 - val_loss: -10.3023 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.29259 to -10.30226, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0474 - acc: 0.2372 - val_loss: -10.3127 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.30226 to -10.31269, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0590 - acc: 0.2372 - val_loss: -10.3252 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.31269 to -10.32518, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.0689 - acc: 0.2372 - val_loss: -10.3366 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.32518 to -10.33659, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0800 - acc: 0.2372 - val_loss: -10.3474 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.33659 to -10.34735, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.0889 - acc: 0.2372 - val_loss: -10.3547 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.34735 to -10.35467, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0911 - acc: 0.2372 - val_loss: -10.3506 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -10.35467\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.0928 - acc: 0.2372 - val_loss: -10.3538 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -10.35467\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.0966 - acc: 0.2372 - val_loss: -10.3594 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.35467 to -10.35944, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.0999 - acc: 0.2372 - val_loss: -10.3652 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.35944 to -10.36516, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.1045 - acc: 0.2372 - val_loss: -10.3679 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.36516 to -10.36793, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.1073 - acc: 0.2372 - val_loss: -10.3718 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.36793 to -10.37180, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1080 - acc: 0.2372 - val_loss: -10.3744 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.37180 to -10.37443, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1121 - acc: 0.2372 - val_loss: -10.3708 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -10.37443\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.1141 - acc: 0.2372 - val_loss: -10.3780 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.37443 to -10.37804, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1157 - acc: 0.2372 - val_loss: -10.3728 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -10.37804\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.1158 - acc: 0.2372 - val_loss: -10.3805 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.37804 to -10.38053, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.1178 - acc: 0.2372 - val_loss: -10.3791 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.38053\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.1199 - acc: 0.2372 - val_loss: -10.3772 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.38053\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1189 - acc: 0.2372 - val_loss: -10.3784 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.38053\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.1204 - acc: 0.2372 - val_loss: -10.3803 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.38053\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.1216 - acc: 0.2372 - val_loss: -10.3807 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.38053 to -10.38074, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1220 - acc: 0.2372 - val_loss: -10.3810 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.38074 to -10.38099, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.1224 - acc: 0.2372 - val_loss: -10.3835 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss improved from -10.38099 to -10.38349, saving model to model-5.h5\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.1231 - acc: 0.2372 - val_loss: -10.3852 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.38349 to -10.38523, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -2.2465 - acc: 0.2474 - val_loss: -7.9127 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.91271, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -7.7696 - acc: 0.2435 - val_loss: -8.1605 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.91271 to -8.16046, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -7.9347 - acc: 0.2435 - val_loss: -8.3226 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.16046 to -8.32265, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.0911 - acc: 0.2435 - val_loss: -8.4741 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.32265 to -8.47411, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -8.2397 - acc: 0.2435 - val_loss: -8.6176 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.47411 to -8.61758, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -8.3830 - acc: 0.2435 - val_loss: -8.7603 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.61758 to -8.76035, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -8.5208 - acc: 0.2435 - val_loss: -8.8955 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.76035 to -8.89551, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -8.6523 - acc: 0.2435 - val_loss: -9.0224 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.89551 to -9.02241, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -8.7759 - acc: 0.2435 - val_loss: -9.1386 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.02241 to -9.13859, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -8.8888 - acc: 0.2435 - val_loss: -9.2469 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.13859 to -9.24686, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -8.9888 - acc: 0.2435 - val_loss: -9.3403 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.24686 to -9.34029, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.0760 - acc: 0.2435 - val_loss: -9.4185 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.34029 to -9.41849, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.1493 - acc: 0.2435 - val_loss: -9.4912 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.41849 to -9.49117, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.2101 - acc: 0.2435 - val_loss: -9.5455 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.49117 to -9.54551, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2579 - acc: 0.2435 - val_loss: -9.5867 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.54551 to -9.58667, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2940 - acc: 0.2435 - val_loss: -9.6163 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.58667 to -9.61634, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.3217 - acc: 0.2435 - val_loss: -9.6415 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.61634 to -9.64146, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.3423 - acc: 0.2435 - val_loss: -9.6524 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.64146 to -9.65244, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.3542 - acc: 0.2435 - val_loss: -9.6665 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.65244 to -9.66647, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.3647 - acc: 0.2435 - val_loss: -9.6755 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.66647 to -9.67553, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3727 - acc: 0.2435 - val_loss: -9.6800 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.67553 to -9.68003, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.3774 - acc: 0.2435 - val_loss: -9.6866 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.68003 to -9.68658, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.3798 - acc: 0.2435 - val_loss: -9.6894 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.68658 to -9.68941, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.3824 - acc: 0.2435 - val_loss: -9.6901 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.68941 to -9.69013, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.3766 - acc: 0.2435 - val_loss: -9.6848 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -9.69013\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3791 - acc: 0.2435 - val_loss: -9.6859 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -9.69013\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3802 - acc: 0.2435 - val_loss: -9.6870 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -9.69013\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.3813 - acc: 0.2435 - val_loss: -9.6881 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -9.69013\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.3819 - acc: 0.2435 - val_loss: -9.6882 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -9.69013\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3821 - acc: 0.2435 - val_loss: -9.6884 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -9.69013\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.3823 - acc: 0.2435 - val_loss: -9.6886 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -9.69013\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 883us/step - loss: -9.3825 - acc: 0.2435 - val_loss: -9.6889 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.69013\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.3827 - acc: 0.2435 - val_loss: -9.6889 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.69013\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.3827 - acc: 0.2435 - val_loss: -9.6889 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.69013\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.3827 - acc: 0.2435 - val_loss: -9.6890 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.69013\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 882us/step - loss: -9.3828 - acc: 0.2435 - val_loss: -9.6891 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.69013\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3829 - acc: 0.2435 - val_loss: -9.6891 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.69013\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.3830 - acc: 0.2435 - val_loss: -9.6892 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.69013\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3830 - acc: 0.2435 - val_loss: -9.6893 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.69013\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.3831 - acc: 0.2435 - val_loss: -9.6894 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.69013\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 9s 4ms/step - loss: -3.1049 - acc: 0.2478 - val_loss: -7.9909 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.99094, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -7.7621 - acc: 0.2435 - val_loss: -8.1364 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.99094 to -8.13645, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -7.9026 - acc: 0.2435 - val_loss: -8.2802 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.13645 to -8.28018, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.0403 - acc: 0.2435 - val_loss: -8.4163 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.28018 to -8.41630, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.1766 - acc: 0.2435 - val_loss: -8.5523 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.41630 to -8.55227, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.3126 - acc: 0.2435 - val_loss: -8.6909 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.55227 to -8.69092, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -8.4453 - acc: 0.2435 - val_loss: -8.8192 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.69092 to -8.81920, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.5772 - acc: 0.2435 - val_loss: -8.9456 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.81920 to -8.94563, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.7036 - acc: 0.2435 - val_loss: -9.0767 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.94563 to -9.07674, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.8229 - acc: 0.2435 - val_loss: -9.1902 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.07674 to -9.19018, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.9299 - acc: 0.2435 - val_loss: -9.2887 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.19018 to -9.28868, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.0254 - acc: 0.2435 - val_loss: -9.3754 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.28868 to -9.37539, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.1042 - acc: 0.2435 - val_loss: -9.4490 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.37539 to -9.44898, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.1713 - acc: 0.2435 - val_loss: -9.5010 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.44898 to -9.50102, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2179 - acc: 0.2435 - val_loss: -9.5502 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.50102 to -9.55025, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2582 - acc: 0.2435 - val_loss: -9.5827 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.55025 to -9.58273, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.2899 - acc: 0.2435 - val_loss: -9.6081 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.58273 to -9.60809, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3141 - acc: 0.2435 - val_loss: -9.6340 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.60809 to -9.63404, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.3334 - acc: 0.2435 - val_loss: -9.6492 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.63404 to -9.64919, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3486 - acc: 0.2435 - val_loss: -9.6587 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.64919 to -9.65866, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.3590 - acc: 0.2435 - val_loss: -9.6698 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.65866 to -9.66985, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3642 - acc: 0.2435 - val_loss: -9.6707 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.66985 to -9.67066, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3664 - acc: 0.2435 - val_loss: -9.6749 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.67066 to -9.67493, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3705 - acc: 0.2435 - val_loss: -9.6787 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.67493 to -9.67871, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.3741 - acc: 0.2435 - val_loss: -9.6822 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.67871 to -9.68218, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.3768 - acc: 0.2435 - val_loss: -9.6840 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.68218 to -9.68405, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.3771 - acc: 0.2435 - val_loss: -9.6824 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -9.68405\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.3776 - acc: 0.2435 - val_loss: -9.6854 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.68405 to -9.68537, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3804 - acc: 0.2435 - val_loss: -9.6861 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.68537 to -9.68607, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3812 - acc: 0.2435 - val_loss: -9.6891 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.68607 to -9.68907, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 888us/step - loss: -9.3819 - acc: 0.2435 - val_loss: -9.6888 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -9.68907\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 895us/step - loss: -9.3829 - acc: 0.2435 - val_loss: -9.6875 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.68907\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3829 - acc: 0.2435 - val_loss: -9.6909 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.68907 to -9.69088, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3844 - acc: 0.2435 - val_loss: -9.6893 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.69088\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3845 - acc: 0.2435 - val_loss: -9.6923 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss improved from -9.69088 to -9.69227, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.3855 - acc: 0.2435 - val_loss: -9.6927 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.69227 to -9.69273, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3852 - acc: 0.2435 - val_loss: -9.6892 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.69273\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3833 - acc: 0.2435 - val_loss: -9.6900 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.69273\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.3841 - acc: 0.2435 - val_loss: -9.6907 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.69273\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3848 - acc: 0.2435 - val_loss: -9.6915 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.69273\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -4.6354 - acc: 0.2376 - val_loss: -8.0395 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.03954, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -7.8045 - acc: 0.2435 - val_loss: -8.1857 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.03954 to -8.18566, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -7.9455 - acc: 0.2435 - val_loss: -8.3311 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.18566 to -8.33109, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.0860 - acc: 0.2435 - val_loss: -8.4665 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.33109 to -8.46645, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.2210 - acc: 0.2435 - val_loss: -8.6006 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.46645 to -8.60061, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.3537 - acc: 0.2435 - val_loss: -8.7274 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.60061 to -8.72745, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.4845 - acc: 0.2435 - val_loss: -8.8593 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.72745 to -8.85928, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.6099 - acc: 0.2435 - val_loss: -8.9809 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.85928 to -8.98094, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.7312 - acc: 0.2435 - val_loss: -9.1000 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.98094 to -9.10003, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.8445 - acc: 0.2435 - val_loss: -9.2105 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.10003 to -9.21054, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.9490 - acc: 0.2435 - val_loss: -9.3064 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.21054 to -9.30638, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.0402 - acc: 0.2435 - val_loss: -9.3912 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.30638 to -9.39118, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.1189 - acc: 0.2435 - val_loss: -9.4654 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.39118 to -9.46540, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.1851 - acc: 0.2435 - val_loss: -9.5216 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.46540 to -9.52156, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2368 - acc: 0.2435 - val_loss: -9.5652 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.52156 to -9.56515, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2750 - acc: 0.2435 - val_loss: -9.5998 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.56515 to -9.59977, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3048 - acc: 0.2435 - val_loss: -9.6151 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.59977 to -9.61510, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3160 - acc: 0.2435 - val_loss: -9.6304 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.61510 to -9.63040, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3302 - acc: 0.2435 - val_loss: -9.6435 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.63040 to -9.64347, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3425 - acc: 0.2435 - val_loss: -9.6548 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.64347 to -9.65481, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3518 - acc: 0.2435 - val_loss: -9.6615 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.65481 to -9.66151, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3585 - acc: 0.2435 - val_loss: -9.6674 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.66151 to -9.66738, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3651 - acc: 0.2435 - val_loss: -9.6737 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.66738 to -9.67371, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3708 - acc: 0.2435 - val_loss: -9.6790 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.67371 to -9.67902, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3705 - acc: 0.2435 - val_loss: -9.6775 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -9.67902\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3718 - acc: 0.2435 - val_loss: -9.6787 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -9.67902\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.3731 - acc: 0.2435 - val_loss: -9.6801 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.67902 to -9.68006, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3745 - acc: 0.2435 - val_loss: -9.6815 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.68006 to -9.68151, saving model to model-3.h5\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3760 - acc: 0.2435 - val_loss: -9.6831 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.68151 to -9.68313, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3777 - acc: 0.2435 - val_loss: -9.6849 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.68313 to -9.68494, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3796 - acc: 0.2435 - val_loss: -9.6869 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.68494 to -9.68695, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.3797 - acc: 0.2435 - val_loss: -9.6843 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.68695\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3790 - acc: 0.2435 - val_loss: -9.6862 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.68695\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3809 - acc: 0.2435 - val_loss: -9.6882 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss improved from -9.68695 to -9.68817, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3826 - acc: 0.2435 - val_loss: -9.6886 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss improved from -9.68817 to -9.68862, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3835 - acc: 0.2435 - val_loss: -9.6909 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.68862 to -9.69095, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3811 - acc: 0.2435 - val_loss: -9.6872 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.69095\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3813 - acc: 0.2435 - val_loss: -9.6880 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.69095\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3821 - acc: 0.2435 - val_loss: -9.6888 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.69095\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3829 - acc: 0.2435 - val_loss: -9.6897 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.69095\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -4.5544 - acc: 0.2457 - val_loss: -8.0561 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.05605, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -7.8056 - acc: 0.2435 - val_loss: -8.1802 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.05605 to -8.18019, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -7.9297 - acc: 0.2435 - val_loss: -8.3038 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.18019 to -8.30384, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -8.0528 - acc: 0.2435 - val_loss: -8.4271 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.30384 to -8.42713, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.1739 - acc: 0.2435 - val_loss: -8.5488 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.42713 to -8.54884, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -8.2993 - acc: 0.2435 - val_loss: -8.6749 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.54884 to -8.67491, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -8.4254 - acc: 0.2435 - val_loss: -8.7996 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.67491 to -8.79960, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.5496 - acc: 0.2435 - val_loss: -8.9240 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.79960 to -8.92403, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.6724 - acc: 0.2435 - val_loss: -9.0413 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.92403 to -9.04129, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.7873 - acc: 0.2435 - val_loss: -9.1560 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.04129 to -9.15600, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -8.8946 - acc: 0.2435 - val_loss: -9.2571 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.15600 to -9.25709, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.9933 - acc: 0.2435 - val_loss: -9.3483 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.25709 to -9.34826, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.0783 - acc: 0.2435 - val_loss: -9.4268 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.34826 to -9.42680, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.1492 - acc: 0.2435 - val_loss: -9.4919 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.42680 to -9.49186, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2100 - acc: 0.2435 - val_loss: -9.5450 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.49186 to -9.54503, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2536 - acc: 0.2435 - val_loss: -9.5727 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.54503 to -9.57273, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.2791 - acc: 0.2435 - val_loss: -9.5998 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.57273 to -9.59978, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3038 - acc: 0.2435 - val_loss: -9.6205 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.59978 to -9.62047, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3232 - acc: 0.2435 - val_loss: -9.6387 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.62047 to -9.63871, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3387 - acc: 0.2435 - val_loss: -9.6531 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.63871 to -9.65312, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3507 - acc: 0.2435 - val_loss: -9.6640 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.65312 to -9.66402, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3578 - acc: 0.2435 - val_loss: -9.6632 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -9.66402\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3586 - acc: 0.2435 - val_loss: -9.6666 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.66402 to -9.66662, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3619 - acc: 0.2435 - val_loss: -9.6699 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.66662 to -9.66995, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3652 - acc: 0.2435 - val_loss: -9.6733 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.66995 to -9.67334, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.3687 - acc: 0.2435 - val_loss: -9.6769 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.67334 to -9.67688, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3722 - acc: 0.2435 - val_loss: -9.6791 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.67688 to -9.67906, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3747 - acc: 0.2435 - val_loss: -9.6831 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.67906 to -9.68314, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.3771 - acc: 0.2435 - val_loss: -9.6828 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -9.68314\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3788 - acc: 0.2435 - val_loss: -9.6875 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.68314 to -9.68750, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3815 - acc: 0.2435 - val_loss: -9.6893 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.68750 to -9.68927, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3555 - acc: 0.2435 - val_loss: -9.6863 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.68927\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3803 - acc: 0.2435 - val_loss: -9.6868 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.68927\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.3807 - acc: 0.2435 - val_loss: -9.6872 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.68927\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3812 - acc: 0.2435 - val_loss: -9.6877 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.68927\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3815 - acc: 0.2435 - val_loss: -9.6877 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.68927\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.3816 - acc: 0.2435 - val_loss: -9.6878 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.68927\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3816 - acc: 0.2435 - val_loss: -9.6879 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.68927\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3817 - acc: 0.2435 - val_loss: -9.6880 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.68927\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3818 - acc: 0.2435 - val_loss: -9.6881 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.68927\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -5.3328 - acc: 0.2444 - val_loss: -8.0327 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.03271, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -7.7922 - acc: 0.2435 - val_loss: -8.1730 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.03271 to -8.17303, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -7.9263 - acc: 0.2435 - val_loss: -8.2995 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.17303 to -8.29948, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.0568 - acc: 0.2435 - val_loss: -8.4328 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.29948 to -8.43282, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.1849 - acc: 0.2435 - val_loss: -8.5621 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.43282 to -8.56205, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.3137 - acc: 0.2435 - val_loss: -8.6859 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.56205 to -8.68589, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.4411 - acc: 0.2435 - val_loss: -8.8175 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.68589 to -8.81747, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.5671 - acc: 0.2435 - val_loss: -8.9416 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.81747 to -8.94158, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -8.6906 - acc: 0.2435 - val_loss: -9.0626 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.94158 to -9.06256, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -8.8065 - acc: 0.2435 - val_loss: -9.1737 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.06256 to -9.17366, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.9121 - acc: 0.2435 - val_loss: -9.2739 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.17366 to -9.27395, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.0051 - acc: 0.2435 - val_loss: -9.3430 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.27395 to -9.34299, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.0589 - acc: 0.2435 - val_loss: -9.3913 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.34299 to -9.39132, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.1054 - acc: 0.2435 - val_loss: -9.4356 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.39132 to -9.43563, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.1482 - acc: 0.2435 - val_loss: -9.4768 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.43563 to -9.47682, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.1882 - acc: 0.2435 - val_loss: -9.4364 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -9.47682\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 883us/step - loss: -9.2162 - acc: 0.2435 - val_loss: -9.5401 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.47682 to -9.54014, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 882us/step - loss: -9.2473 - acc: 0.2435 - val_loss: -9.5693 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.54014 to -9.56926, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 879us/step - loss: -9.2742 - acc: 0.2435 - val_loss: -9.5942 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.56926 to -9.59424, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 880us/step - loss: -9.2975 - acc: 0.2435 - val_loss: -9.6162 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.59424 to -9.61623, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2885 - acc: 0.2435 - val_loss: -9.6136 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -9.61623\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.3090 - acc: 0.2435 - val_loss: -9.6171 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.61623 to -9.61713, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3126 - acc: 0.2435 - val_loss: -9.6209 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.61713 to -9.62087, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3165 - acc: 0.2435 - val_loss: -9.6251 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.62087 to -9.62509, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3210 - acc: 0.2435 - val_loss: -9.6300 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.62509 to -9.62996, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3262 - acc: 0.2435 - val_loss: -9.6357 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.62996 to -9.63565, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3323 - acc: 0.2435 - val_loss: -9.6423 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.63565 to -9.64226, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.3393 - acc: 0.2435 - val_loss: -9.6485 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.64226 to -9.64849, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3460 - acc: 0.2435 - val_loss: -9.6568 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.64849 to -9.65679, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3525 - acc: 0.2435 - val_loss: -9.6625 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.65679 to -9.66252, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3597 - acc: 0.2435 - val_loss: -9.6691 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.66252 to -9.66912, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.3666 - acc: 0.2435 - val_loss: -9.6759 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.66912 to -9.67593, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.3712 - acc: 0.2435 - val_loss: -9.6810 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.67593 to -9.68103, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.2916 - acc: 0.2435 - val_loss: -9.6790 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.68103\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3730 - acc: 0.2435 - val_loss: -9.6795 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.68103\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3735 - acc: 0.2435 - val_loss: -9.6801 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.68103\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.3742 - acc: 0.2435 - val_loss: -9.6807 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.68103\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.3746 - acc: 0.2435 - val_loss: -9.6808 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.68103\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3746 - acc: 0.2435 - val_loss: -9.6809 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.68103\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.3748 - acc: 0.2435 - val_loss: -9.6811 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss improved from -9.68103 to -9.68106, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -1.4624 - acc: 0.2410 - val_loss: -8.1710 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.17096, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.0135 - acc: 0.2435 - val_loss: -8.4870 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.17096 to -8.48701, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -8.2959 - acc: 0.2435 - val_loss: -8.7312 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.48701 to -8.73116, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -8.5160 - acc: 0.2435 - val_loss: -8.9243 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.73116 to -8.92433, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.6912 - acc: 0.2435 - val_loss: -9.0800 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.92433 to -9.08003, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.8336 - acc: 0.2435 - val_loss: -9.2038 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.08003 to -9.20380, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -8.9500 - acc: 0.2435 - val_loss: -9.3089 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.20380 to -9.30890, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.0446 - acc: 0.2435 - val_loss: -9.3977 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.30890 to -9.39772, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.1233 - acc: 0.2435 - val_loss: -9.4656 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.39772 to -9.46564, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 901us/step - loss: -9.1833 - acc: 0.2435 - val_loss: -9.5199 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.46564 to -9.51992, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2348 - acc: 0.2435 - val_loss: -9.5631 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.51992 to -9.56312, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.2747 - acc: 0.2435 - val_loss: -9.5938 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.56312 to -9.59383, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3036 - acc: 0.2435 - val_loss: -9.6236 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.59383 to -9.62361, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.3236 - acc: 0.2435 - val_loss: -9.6330 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.62361 to -9.63298, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.3344 - acc: 0.2435 - val_loss: -9.6492 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.63298 to -9.64918, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.3475 - acc: 0.2435 - val_loss: -9.6514 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.64918 to -9.65138, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3499 - acc: 0.2435 - val_loss: -9.6616 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.65138 to -9.66156, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3593 - acc: 0.2435 - val_loss: -9.6702 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.66156 to -9.67020, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3649 - acc: 0.2435 - val_loss: -9.6741 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.67020 to -9.67411, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3688 - acc: 0.2435 - val_loss: -9.6707 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -9.67411\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.3665 - acc: 0.2435 - val_loss: -9.6752 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.67411 to -9.67521, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.3709 - acc: 0.2435 - val_loss: -9.6794 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.67521 to -9.67943, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3748 - acc: 0.2435 - val_loss: -9.6820 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.67943 to -9.68205, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3761 - acc: 0.2435 - val_loss: -9.6836 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.68205 to -9.68358, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3756 - acc: 0.2435 - val_loss: -9.6813 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -9.68358\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3769 - acc: 0.2435 - val_loss: -9.6853 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.68358 to -9.68528, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3800 - acc: 0.2435 - val_loss: -9.6819 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -9.68528\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3768 - acc: 0.2435 - val_loss: -9.6844 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -9.68528\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3793 - acc: 0.2435 - val_loss: -9.6868 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.68528 to -9.68680, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3816 - acc: 0.2435 - val_loss: -9.6892 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.68680 to -9.68915, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3833 - acc: 0.2435 - val_loss: -9.6902 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.68915 to -9.69017, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3804 - acc: 0.2435 - val_loss: -9.6859 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.69017\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.3803 - acc: 0.2435 - val_loss: -9.6873 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.69017\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3818 - acc: 0.2435 - val_loss: -9.6888 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.69017\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3833 - acc: 0.2435 - val_loss: -9.6904 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss improved from -9.69017 to -9.69043, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.3850 - acc: 0.2435 - val_loss: -9.6921 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.69043 to -9.69209, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3753 - acc: 0.2435 - val_loss: -9.6881 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.69209\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3821 - acc: 0.2435 - val_loss: -9.6885 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.69209\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3825 - acc: 0.2435 - val_loss: -9.6890 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.69209\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3830 - acc: 0.2435 - val_loss: -9.6895 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.69209\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -4.1859 - acc: 0.2474 - val_loss: -8.0791 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.07912, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -7.8811 - acc: 0.2435 - val_loss: -8.3127 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.07912 to -8.31269, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -8.1001 - acc: 0.2435 - val_loss: -8.5152 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.31269 to -8.51519, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -8.2909 - acc: 0.2435 - val_loss: -8.6929 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.51519 to -8.69291, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -8.4584 - acc: 0.2435 - val_loss: -8.8479 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.69291 to -8.84793, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.6028 - acc: 0.2435 - val_loss: -8.9830 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.84793 to -8.98305, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.7335 - acc: 0.2435 - val_loss: -9.1059 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.98305 to -9.10594, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -8.8507 - acc: 0.2435 - val_loss: -9.2186 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.10594 to -9.21860, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.9542 - acc: 0.2435 - val_loss: -9.3112 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.21860 to -9.31124, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.0454 - acc: 0.2435 - val_loss: -9.3957 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.31124 to -9.39566, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.1243 - acc: 0.2435 - val_loss: -9.4686 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.39566 to -9.46863, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.1737 - acc: 0.2435 - val_loss: -9.5072 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.46863 to -9.50717, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2219 - acc: 0.2435 - val_loss: -9.5440 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.50717 to -9.54400, saving model to model-2.h5\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2559 - acc: 0.2435 - val_loss: -9.5799 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.54400 to -9.57990, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2878 - acc: 0.2435 - val_loss: -9.6055 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.57990 to -9.60549, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3093 - acc: 0.2435 - val_loss: -9.6267 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.60549 to -9.62667, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3291 - acc: 0.2435 - val_loss: -9.6434 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.62667 to -9.64336, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3416 - acc: 0.2435 - val_loss: -9.6454 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.64336 to -9.64536, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3415 - acc: 0.2435 - val_loss: -9.6506 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.64536 to -9.65059, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3467 - acc: 0.2435 - val_loss: -9.6558 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.65059 to -9.65580, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3520 - acc: 0.2435 - val_loss: -9.6611 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.65580 to -9.66114, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3574 - acc: 0.2435 - val_loss: -9.6667 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.66114 to -9.66669, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3631 - acc: 0.2435 - val_loss: -9.6716 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.66669 to -9.67156, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3671 - acc: 0.2435 - val_loss: -9.6687 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -9.67156\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3640 - acc: 0.2435 - val_loss: -9.6721 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.67156 to -9.67210, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3674 - acc: 0.2435 - val_loss: -9.6756 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.67210 to -9.67556, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3710 - acc: 0.2435 - val_loss: -9.6792 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.67556 to -9.67917, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3744 - acc: 0.2435 - val_loss: -9.6822 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.67917 to -9.68224, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3720 - acc: 0.2435 - val_loss: -9.6776 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -9.68224\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3719 - acc: 0.2435 - val_loss: -9.6788 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -9.68224\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3731 - acc: 0.2435 - val_loss: -9.6801 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -9.68224\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3745 - acc: 0.2435 - val_loss: -9.6816 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.68224\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3754 - acc: 0.2435 - val_loss: -9.6817 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.68224\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3756 - acc: 0.2435 - val_loss: -9.6820 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.68224\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3759 - acc: 0.2435 - val_loss: -9.6823 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss improved from -9.68224 to -9.68230, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3763 - acc: 0.2435 - val_loss: -9.6827 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.68230 to -9.68271, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3767 - acc: 0.2435 - val_loss: -9.6832 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss improved from -9.68271 to -9.68323, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3773 - acc: 0.2435 - val_loss: -9.6839 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.68323 to -9.68387, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.3780 - acc: 0.2435 - val_loss: -9.6846 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss improved from -9.68387 to -9.68464, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3788 - acc: 0.2435 - val_loss: -9.6855 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss improved from -9.68464 to -9.68552, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -4.1015 - acc: 0.2435 - val_loss: -8.0980 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.09796, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -7.8821 - acc: 0.2435 - val_loss: -8.2935 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.09796 to -8.29352, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.0658 - acc: 0.2435 - val_loss: -8.4638 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.29352 to -8.46384, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.2278 - acc: 0.2435 - val_loss: -8.6180 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.46384 to -8.61796, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.3758 - acc: 0.2435 - val_loss: -8.7566 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.61796 to -8.75659, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -8.5093 - acc: 0.2435 - val_loss: -8.8835 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.75659 to -8.88353, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.6321 - acc: 0.2435 - val_loss: -9.0041 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.88353 to -9.00407, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -8.7484 - acc: 0.2435 - val_loss: -9.1118 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.00407 to -9.11183, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.8536 - acc: 0.2435 - val_loss: -9.2161 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.11183 to -9.21613, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.9485 - acc: 0.2435 - val_loss: -9.2997 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.21613 to -9.29974, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.0326 - acc: 0.2435 - val_loss: -9.3836 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.29974 to -9.38358, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.0915 - acc: 0.2435 - val_loss: -9.4248 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.38358 to -9.42480, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.1406 - acc: 0.2435 - val_loss: -9.4726 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.42480 to -9.47256, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.1851 - acc: 0.2435 - val_loss: -9.5127 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.47256 to -9.51274, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2233 - acc: 0.2435 - val_loss: -9.5495 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.51274 to -9.54952, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.2570 - acc: 0.2435 - val_loss: -9.5797 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.54952 to -9.57972, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2855 - acc: 0.2435 - val_loss: -9.6057 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.57972 to -9.60574, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3099 - acc: 0.2435 - val_loss: -9.6271 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.60574 to -9.62707, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.1928 - acc: 0.2435 - val_loss: -9.6358 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.62707 to -9.63584, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3307 - acc: 0.2435 - val_loss: -9.6382 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.63584 to -9.63816, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.3330 - acc: 0.2435 - val_loss: -9.6406 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.63816 to -9.64057, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3355 - acc: 0.2435 - val_loss: -9.6432 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.64057 to -9.64317, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.3382 - acc: 0.2435 - val_loss: -9.6461 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.64317 to -9.64611, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.3414 - acc: 0.2435 - val_loss: -9.6495 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.64611 to -9.64953, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.3451 - acc: 0.2435 - val_loss: -9.6536 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.64953 to -9.65356, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.3498 - acc: 0.2435 - val_loss: -9.6585 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.65356 to -9.65851, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3526 - acc: 0.2435 - val_loss: -9.6616 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.65851 to -9.66164, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3565 - acc: 0.2435 - val_loss: -9.6599 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -9.66164\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3547 - acc: 0.2435 - val_loss: -9.6621 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.66164 to -9.66213, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.3570 - acc: 0.2435 - val_loss: -9.6646 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.66213 to -9.66462, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 887us/step - loss: -9.3596 - acc: 0.2435 - val_loss: -9.6675 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.66462 to -9.66746, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3627 - acc: 0.2435 - val_loss: -9.6707 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.66746 to -9.67072, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3662 - acc: 0.2435 - val_loss: -9.6781 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.67072 to -9.67806, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.3658 - acc: 0.2435 - val_loss: -9.6703 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.67806\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3654 - acc: 0.2435 - val_loss: -9.6733 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.67806\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.3684 - acc: 0.2435 - val_loss: -9.6763 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.67806\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3715 - acc: 0.2435 - val_loss: -9.6795 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss improved from -9.67806 to -9.67946, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3742 - acc: 0.2435 - val_loss: -9.6817 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.67946 to -9.68167, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3768 - acc: 0.2435 - val_loss: -9.6836 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss improved from -9.68167 to -9.68362, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3750 - acc: 0.2435 - val_loss: -9.6805 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.68362\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -4.5884 - acc: 0.2423 - val_loss: -8.1179 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.11791, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -7.8965 - acc: 0.2435 - val_loss: -8.3015 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.11791 to -8.30151, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.0697 - acc: 0.2435 - val_loss: -8.4629 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.30151 to -8.46290, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.2229 - acc: 0.2435 - val_loss: -8.6068 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.46290 to -8.60679, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -8.3610 - acc: 0.2435 - val_loss: -8.7388 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.60679 to -8.73880, saving model to model-4.h5\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.4885 - acc: 0.2435 - val_loss: -8.8638 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.73880 to -8.86375, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -8.6053 - acc: 0.2435 - val_loss: -8.9731 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.86375 to -8.97310, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -8.7167 - acc: 0.2435 - val_loss: -9.0859 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.97310 to -9.08589, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.8196 - acc: 0.2435 - val_loss: -9.1929 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.08589 to -9.19289, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.9136 - acc: 0.2435 - val_loss: -9.2797 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.19289 to -9.27968, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.0001 - acc: 0.2435 - val_loss: -9.3594 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.27968 to -9.35943, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.0754 - acc: 0.2435 - val_loss: -9.4198 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.35943 to -9.41985, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.1401 - acc: 0.2435 - val_loss: -9.4789 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.41985 to -9.47887, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.1972 - acc: 0.2435 - val_loss: -9.5278 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.47887 to -9.52778, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.2403 - acc: 0.2435 - val_loss: -9.5681 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.52778 to -9.56805, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.2758 - acc: 0.2435 - val_loss: -9.5967 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.56805 to -9.59665, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.3056 - acc: 0.2435 - val_loss: -9.6122 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.59665 to -9.61222, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.3090 - acc: 0.2435 - val_loss: -9.6187 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.61222 to -9.61874, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3154 - acc: 0.2435 - val_loss: -9.6252 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.61874 to -9.62516, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3219 - acc: 0.2435 - val_loss: -9.6317 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.62516 to -9.63170, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3285 - acc: 0.2435 - val_loss: -9.6386 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.63170 to -9.63855, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3356 - acc: 0.2435 - val_loss: -9.6459 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.63855 to -9.64587, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.3429 - acc: 0.2435 - val_loss: -9.6526 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.64587 to -9.65256, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3490 - acc: 0.2435 - val_loss: -9.6598 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.65256 to -9.65984, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.3210 - acc: 0.2435 - val_loss: -9.6576 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -9.65984\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 884us/step - loss: -9.3519 - acc: 0.2435 - val_loss: -9.6587 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -9.65984\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3531 - acc: 0.2435 - val_loss: -9.6600 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.65984 to -9.66000, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3544 - acc: 0.2435 - val_loss: -9.6615 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.66000 to -9.66150, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.3561 - acc: 0.2435 - val_loss: -9.6633 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.66150 to -9.66332, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3581 - acc: 0.2435 - val_loss: -9.6685 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.66332 to -9.66847, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.3607 - acc: 0.2435 - val_loss: -9.6677 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -9.66847\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3626 - acc: 0.2435 - val_loss: -9.6726 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.66847 to -9.67255, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3648 - acc: 0.2435 - val_loss: -9.6755 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.67255 to -9.67553, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3678 - acc: 0.2435 - val_loss: -9.6752 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.67553\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3703 - acc: 0.2435 - val_loss: -9.6737 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.67553\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3688 - acc: 0.2435 - val_loss: -9.6766 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.67553 to -9.67665, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3718 - acc: 0.2435 - val_loss: -9.6796 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss improved from -9.67665 to -9.67964, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3748 - acc: 0.2435 - val_loss: -9.6827 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.67964 to -9.68270, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3719 - acc: 0.2435 - val_loss: -9.6805 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.68270\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3754 - acc: 0.2435 - val_loss: -9.6830 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss improved from -9.68270 to -9.68297, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 10s 4ms/step - loss: -4.9493 - acc: 0.2431 - val_loss: -8.0883 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -8.08832, saving model to model-5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -7.8542 - acc: 0.2435 - val_loss: -8.2579 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss improved from -8.08832 to -8.25795, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.0175 - acc: 0.2435 - val_loss: -8.4109 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.25795 to -8.41094, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.1684 - acc: 0.2435 - val_loss: -8.5593 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.41094 to -8.55930, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.3114 - acc: 0.2435 - val_loss: -8.6996 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.55930 to -8.69961, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.4465 - acc: 0.2435 - val_loss: -8.8317 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.69961 to -8.83174, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.5758 - acc: 0.2435 - val_loss: -8.9624 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.83174 to -8.96241, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.6978 - acc: 0.2435 - val_loss: -9.0864 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.96241 to -9.08643, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -8.8112 - acc: 0.2435 - val_loss: -9.1804 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.08643 to -9.18041, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.9134 - acc: 0.2435 - val_loss: -9.2682 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.18041 to -9.26820, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.0020 - acc: 0.2435 - val_loss: -9.3630 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.26820 to -9.36296, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.0748 - acc: 0.2435 - val_loss: -9.4148 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.36296 to -9.41475, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.1372 - acc: 0.2435 - val_loss: -9.4687 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.41475 to -9.46873, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.1866 - acc: 0.2435 - val_loss: -8.7867 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -9.46873\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.1922 - acc: 0.2435 - val_loss: -9.5212 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.46873 to -9.52118, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2205 - acc: 0.2435 - val_loss: -9.5334 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.52118 to -9.53340, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.2327 - acc: 0.2435 - val_loss: -9.5456 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.53340 to -9.54564, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.2451 - acc: 0.2435 - val_loss: -9.5584 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.54564 to -9.55841, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.2583 - acc: 0.2435 - val_loss: -9.5774 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.55841 to -9.57740, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.2730 - acc: 0.2435 - val_loss: -9.6052 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.57740 to -9.60518, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.2872 - acc: 0.2435 - val_loss: -9.6179 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.60518 to -9.61788, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.3016 - acc: 0.2435 - val_loss: -9.6137 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -9.61788\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.3143 - acc: 0.2435 - val_loss: -9.6289 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.61788 to -9.62890, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.3283 - acc: 0.2435 - val_loss: -9.6352 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.62890 to -9.63523, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3329 - acc: 0.2435 - val_loss: -9.6437 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.63523 to -9.64372, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.3412 - acc: 0.2435 - val_loss: -9.6519 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.64372 to -9.65191, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3493 - acc: 0.2435 - val_loss: -9.6599 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.65191 to -9.65993, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.3553 - acc: 0.2435 - val_loss: -9.6650 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.65993 to -9.66503, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3622 - acc: 0.2435 - val_loss: -9.6655 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.66503 to -9.66548, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.3605 - acc: 0.2435 - val_loss: -9.6683 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.66548 to -9.66827, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.3634 - acc: 0.2435 - val_loss: -9.6712 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.66827 to -9.67120, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3664 - acc: 0.2435 - val_loss: -9.6743 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.67120 to -9.67434, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3696 - acc: 0.2435 - val_loss: -9.6778 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.67434 to -9.67777, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.3722 - acc: 0.2435 - val_loss: -9.6780 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00034: val_loss improved from -9.67777 to -9.67804, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.3737 - acc: 0.2435 - val_loss: -9.6822 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00035: val_loss improved from -9.67804 to -9.68220, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3775 - acc: 0.2435 - val_loss: -9.6852 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.68220 to -9.68520, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.3762 - acc: 0.2435 - val_loss: -9.6813 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.68520\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3758 - acc: 0.2435 - val_loss: -9.6829 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.68520\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.3775 - acc: 0.2435 - val_loss: -9.6847 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.68520\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.3793 - acc: 0.2435 - val_loss: -9.6865 - val_acc: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss improved from -9.68520 to -9.68653, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 11s 6ms/step - loss: -0.1353 - acc: 0.2467 - val_loss: -5.4936 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -5.49359, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 930us/step - loss: -7.4368 - acc: 0.2368 - val_loss: -6.8046 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -5.49359 to -6.80459, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -7.7107 - acc: 0.2368 - val_loss: -6.9216 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.80459 to -6.92163, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -7.8254 - acc: 0.2368 - val_loss: -7.0349 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.92163 to -7.03486, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -7.9378 - acc: 0.2368 - val_loss: -7.1450 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.03486 to -7.14502, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.0470 - acc: 0.2368 - val_loss: -7.2552 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.14502 to -7.25519, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.1574 - acc: 0.2368 - val_loss: -7.3657 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.25519 to -7.36570, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.2691 - acc: 0.2368 - val_loss: -7.4747 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.36570 to -7.47466, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.3764 - acc: 0.2368 - val_loss: -7.5752 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.47466 to -7.57520, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -8.4798 - acc: 0.2368 - val_loss: -7.6837 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.57520 to -7.68374, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.5832 - acc: 0.2368 - val_loss: -7.7745 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.68374 to -7.77451, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.6757 - acc: 0.2368 - val_loss: -7.8726 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.77451 to -7.87265, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -8.7640 - acc: 0.2368 - val_loss: -7.9570 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.87265 to -7.95705, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -8.8453 - acc: 0.2368 - val_loss: -8.0263 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.95705 to -8.02627, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.9145 - acc: 0.2368 - val_loss: -8.0927 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.02627 to -8.09270, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -8.9782 - acc: 0.2368 - val_loss: -8.1552 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.09270 to -8.15523, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.0294 - acc: 0.2368 - val_loss: -8.2032 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.15523 to -8.20319, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.0719 - acc: 0.2368 - val_loss: -8.2386 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.20319 to -8.23856, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.1033 - acc: 0.2368 - val_loss: -8.2677 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.23856 to -8.26765, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -9.1316 - acc: 0.2368 - val_loss: -8.2865 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.26765 to -8.28651, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.1542 - acc: 0.2368 - val_loss: -8.3081 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.28651 to -8.30812, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -9.1755 - acc: 0.2368 - val_loss: -8.3235 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.30812 to -8.32348, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.1867 - acc: 0.2368 - val_loss: -8.3364 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.32348 to -8.33642, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.1984 - acc: 0.2368 - val_loss: -8.3455 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.33642 to -8.34550, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.2087 - acc: 0.2368 - val_loss: -8.3509 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.34550 to -8.35088, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2136 - acc: 0.2368 - val_loss: -8.3527 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.35088 to -8.35272, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2150 - acc: 0.2368 - val_loss: -8.3596 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.35272 to -8.35957, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.2213 - acc: 0.2368 - val_loss: -8.3650 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.35957 to -8.36505, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.2230 - acc: 0.2368 - val_loss: -8.3616 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.36505\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.2223 - acc: 0.2368 - val_loss: -8.3650 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.36505\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2255 - acc: 0.2368 - val_loss: -8.3679 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.36505 to -8.36794, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -9.2283 - acc: 0.2368 - val_loss: -8.3706 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.36794 to -8.37059, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2308 - acc: 0.2368 - val_loss: -8.3708 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.37059 to -8.37081, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.2299 - acc: 0.2368 - val_loss: -8.3722 - val_acc: 0.2676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from -8.37081 to -8.37221, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.2323 - acc: 0.2368 - val_loss: -8.3704 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.37221\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.2308 - acc: 0.2368 - val_loss: -8.3731 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.37221 to -8.37310, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2330 - acc: 0.2368 - val_loss: -8.3737 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.37310 to -8.37367, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.2340 - acc: 0.2368 - val_loss: -8.3893 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.37367 to -8.38926, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2282 - acc: 0.2368 - val_loss: -8.3729 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.38926\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.2326 - acc: 0.2368 - val_loss: -8.3741 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.38926\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: -2.5557 - acc: 0.2368 - val_loss: -6.7040 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.70405, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -7.6126 - acc: 0.2368 - val_loss: -6.8260 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.70405 to -6.82598, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -7.7324 - acc: 0.2368 - val_loss: -6.9441 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.82598 to -6.94407, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -7.8496 - acc: 0.2368 - val_loss: -7.0574 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.94407 to -7.05738, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -7.9623 - acc: 0.2368 - val_loss: -7.1722 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.05738 to -7.17224, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.0711 - acc: 0.2368 - val_loss: -7.2799 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.17224 to -7.27990, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -8.1808 - acc: 0.2368 - val_loss: -7.3847 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.27990 to -7.38469, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -8.2927 - acc: 0.2368 - val_loss: -7.4974 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.38469 to -7.49742, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -8.3970 - acc: 0.2368 - val_loss: -7.5976 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.49742 to -7.59762, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -8.5004 - acc: 0.2368 - val_loss: -7.6998 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.59762 to -7.69976, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.6008 - acc: 0.2368 - val_loss: -7.8011 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.69976 to -7.80110, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.6955 - acc: 0.2368 - val_loss: -7.8864 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.80110 to -7.88637, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -8.7837 - acc: 0.2368 - val_loss: -7.9641 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.88637 to -7.96413, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.8564 - acc: 0.2368 - val_loss: -8.0386 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.96413 to -8.03862, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.9266 - acc: 0.2368 - val_loss: -8.1071 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.03862 to -8.10706, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -8.9856 - acc: 0.2368 - val_loss: -8.1516 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.10706 to -8.15162, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.0327 - acc: 0.2368 - val_loss: -8.2073 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.15162 to -8.20729, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.0717 - acc: 0.2368 - val_loss: -8.2350 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.20729 to -8.23503, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.1076 - acc: 0.2368 - val_loss: -8.2654 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.23503 to -8.26535, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.1340 - acc: 0.2368 - val_loss: -8.2893 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.26535 to -8.28934, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.1536 - acc: 0.2368 - val_loss: -8.3059 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.28934 to -8.30589, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.1729 - acc: 0.2368 - val_loss: -8.3230 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.30589 to -8.32296, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.1878 - acc: 0.2368 - val_loss: -8.3354 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.32296 to -8.33536, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.1974 - acc: 0.2368 - val_loss: -8.3436 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.33536 to -8.34362, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2077 - acc: 0.2368 - val_loss: -8.3534 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.34362 to -8.35343, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.2134 - acc: 0.2368 - val_loss: -8.3571 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.35343 to -8.35709, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.2197 - acc: 0.2368 - val_loss: -8.3634 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.35709 to -8.36335, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.2235 - acc: 0.2368 - val_loss: -8.3673 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.36335 to -8.36729, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.1725 - acc: 0.2368 - val_loss: -8.3641 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.36729\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.2236 - acc: 0.2368 - val_loss: -8.3647 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.36729\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.2242 - acc: 0.2368 - val_loss: -8.3653 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.36729\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -9.2248 - acc: 0.2368 - val_loss: -8.3660 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.36729\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.2253 - acc: 0.2368 - val_loss: -8.3661 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.36729\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.2253 - acc: 0.2368 - val_loss: -8.3662 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.36729\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.2254 - acc: 0.2368 - val_loss: -8.3663 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.36729\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.2256 - acc: 0.2368 - val_loss: -8.3664 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.36729\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.2256 - acc: 0.2368 - val_loss: -8.3664 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.36729\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.2257 - acc: 0.2368 - val_loss: -8.3664 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.36729\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2257 - acc: 0.2368 - val_loss: -8.3665 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.36729\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2257 - acc: 0.2368 - val_loss: -8.3665 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.36729\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: -3.3544 - acc: 0.2410 - val_loss: -6.7022 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.70217, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -7.6095 - acc: 0.2368 - val_loss: -6.8141 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.70217 to -6.81409, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -7.7196 - acc: 0.2368 - val_loss: -6.9223 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.81409 to -6.92226, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -7.8278 - acc: 0.2368 - val_loss: -7.0296 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.92226 to -7.02959, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -7.9346 - acc: 0.2368 - val_loss: -7.1363 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.02959 to -7.13625, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.0371 - acc: 0.2368 - val_loss: -7.2416 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.13625 to -7.24162, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.1468 - acc: 0.2368 - val_loss: -7.3475 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.24162 to -7.34747, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.2537 - acc: 0.2368 - val_loss: -7.4546 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.34747 to -7.45462, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.3594 - acc: 0.2368 - val_loss: -7.5602 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.45462 to -7.56021, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -8.4639 - acc: 0.2368 - val_loss: -7.6613 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.56021 to -7.66129, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -8.5636 - acc: 0.2368 - val_loss: -7.7617 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.66129 to -7.76166, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6614 - acc: 0.2368 - val_loss: -7.8536 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.76166 to -7.85355, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.7499 - acc: 0.2368 - val_loss: -7.9391 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.85355 to -7.93909, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.8289 - acc: 0.2368 - val_loss: -8.0113 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.93909 to -8.01133, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.9013 - acc: 0.2368 - val_loss: -8.0806 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.01133 to -8.08064, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.9645 - acc: 0.2368 - val_loss: -8.1361 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.08064 to -8.13613, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.0186 - acc: 0.2368 - val_loss: -8.1877 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.13613 to -8.18768, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.0669 - acc: 0.2368 - val_loss: -8.2279 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.18768 to -8.22788, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.1024 - acc: 0.2368 - val_loss: -8.2763 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.22788 to -8.27630, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.1321 - acc: 0.2368 - val_loss: -8.2892 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.27630 to -8.28923, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.1565 - acc: 0.2368 - val_loss: -8.3091 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.28923 to -8.30911, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.1740 - acc: 0.2368 - val_loss: -8.3198 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.30911 to -8.31983, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.1854 - acc: 0.2368 - val_loss: -8.3341 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.31983 to -8.33408, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.1985 - acc: 0.2368 - val_loss: -8.3457 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.33408 to -8.34566, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2006 - acc: 0.2368 - val_loss: -8.3427 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -8.34566\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.2038 - acc: 0.2368 - val_loss: -8.3470 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.34566 to -8.34699, saving model to model-3.h5\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.2080 - acc: 0.2368 - val_loss: -8.3510 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.34699 to -8.35099, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.2119 - acc: 0.2368 - val_loss: -8.3548 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.35099 to -8.35484, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.2157 - acc: 0.2368 - val_loss: -8.3586 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.35484 to -8.35858, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.2194 - acc: 0.2368 - val_loss: -8.3623 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.35858 to -8.36226, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.2226 - acc: 0.2368 - val_loss: -8.3652 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.36226 to -8.36517, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.2221 - acc: 0.2368 - val_loss: -8.3609 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.36517\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -9.2208 - acc: 0.2368 - val_loss: -8.3624 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.36517\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.2224 - acc: 0.2368 - val_loss: -8.3640 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.36517\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.2239 - acc: 0.2368 - val_loss: -8.3656 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.36517 to -8.36565, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.2256 - acc: 0.2368 - val_loss: -8.3674 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.36565 to -8.36737, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2274 - acc: 0.2368 - val_loss: -8.3692 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.36737 to -8.36919, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.2292 - acc: 0.2368 - val_loss: -8.3711 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.36919 to -8.37111, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.2282 - acc: 0.2368 - val_loss: -8.3680 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.37111\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2279 - acc: 0.2368 - val_loss: -8.3696 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.37111\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: -4.0410 - acc: 0.2405 - val_loss: -6.6909 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.69094, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -7.5956 - acc: 0.2368 - val_loss: -6.7956 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.69094 to -6.79559, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -7.6995 - acc: 0.2368 - val_loss: -6.8988 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.79559 to -6.89877, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -7.8020 - acc: 0.2368 - val_loss: -7.0010 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.89877 to -7.00105, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -7.9045 - acc: 0.2368 - val_loss: -7.1043 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.00105 to -7.10425, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.0051 - acc: 0.2368 - val_loss: -7.2061 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.10425 to -7.20612, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.1106 - acc: 0.2368 - val_loss: -7.3120 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.20612 to -7.31203, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.2175 - acc: 0.2368 - val_loss: -7.4274 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.31203 to -7.42742, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.3211 - acc: 0.2368 - val_loss: -7.5222 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.42742 to -7.52218, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.4267 - acc: 0.2368 - val_loss: -7.6273 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.52218 to -7.62729, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -8.5304 - acc: 0.2368 - val_loss: -7.7317 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.62729 to -7.73166, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6284 - acc: 0.2368 - val_loss: -7.8225 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.73166 to -7.82248, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.7204 - acc: 0.2368 - val_loss: -7.9122 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.82248 to -7.91222, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.8070 - acc: 0.2368 - val_loss: -7.9941 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.91222 to -7.99411, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.8831 - acc: 0.2368 - val_loss: -8.0681 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.99411 to -8.06811, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.9426 - acc: 0.2368 - val_loss: -8.1148 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.06811 to -8.11480, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.9972 - acc: 0.2368 - val_loss: -8.1671 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.11480 to -8.16711, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.0453 - acc: 0.2368 - val_loss: -8.2095 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.16711 to -8.20947, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.0839 - acc: 0.2368 - val_loss: -8.2417 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.20947 to -8.24171, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -9.1152 - acc: 0.2368 - val_loss: -8.2636 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.24171 to -8.26361, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -9.1308 - acc: 0.2368 - val_loss: -8.2816 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.26361 to -8.28159, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.1478 - acc: 0.2368 - val_loss: -8.2974 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.28159 to -8.29742, saving model to model-4.h5\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.1628 - acc: 0.2368 - val_loss: -8.3115 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.29742 to -8.31152, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.1751 - acc: 0.2368 - val_loss: -8.3216 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.31152 to -8.32159, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.1858 - acc: 0.2368 - val_loss: -8.3323 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.32159 to -8.33232, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.1938 - acc: 0.2368 - val_loss: -8.3403 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.33232 to -8.34032, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2011 - acc: 0.2368 - val_loss: -8.3416 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.34032 to -8.34158, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2034 - acc: 0.2368 - val_loss: -8.3475 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.34158 to -8.34745, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.2091 - acc: 0.2368 - val_loss: -8.3529 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.34745 to -8.35288, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2143 - acc: 0.2368 - val_loss: -8.3580 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.35288 to -8.35795, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.2186 - acc: 0.2368 - val_loss: -8.3610 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.35795 to -8.36100, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2215 - acc: 0.2368 - val_loss: -8.3638 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.36100 to -8.36379, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.2244 - acc: 0.2368 - val_loss: -8.3662 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.36379 to -8.36623, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.2273 - acc: 0.2368 - val_loss: -8.3681 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.36623 to -8.36807, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.2293 - acc: 0.2368 - val_loss: -7.9896 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.36807\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.1886 - acc: 0.2368 - val_loss: -8.3674 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.36807\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -9.2268 - acc: 0.2368 - val_loss: -8.3678 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.36807\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.2272 - acc: 0.2368 - val_loss: -8.3682 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.36807 to -8.36825, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.2277 - acc: 0.2368 - val_loss: -8.3687 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.36825 to -8.36874, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.2282 - acc: 0.2368 - val_loss: -8.3693 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.36874 to -8.36930, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: -3.6931 - acc: 0.2331 - val_loss: -6.7371 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.73708, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -7.6323 - acc: 0.2368 - val_loss: -6.8409 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.73708 to -6.84089, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -7.7380 - acc: 0.2368 - val_loss: -6.9463 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.84089 to -6.94625, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -7.8405 - acc: 0.2368 - val_loss: -7.0453 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.94625 to -7.04533, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -7.9413 - acc: 0.2368 - val_loss: -7.1449 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.04533 to -7.14486, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.0456 - acc: 0.2368 - val_loss: -7.2488 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.14486 to -7.24880, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.1495 - acc: 0.2368 - val_loss: -7.3520 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.24880 to -7.35204, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.2532 - acc: 0.2368 - val_loss: -7.4532 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.35204 to -7.45316, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.3577 - acc: 0.2368 - val_loss: -7.5608 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.45316 to -7.56078, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.4601 - acc: 0.2368 - val_loss: -7.6616 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.56078 to -7.66165, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.5608 - acc: 0.2368 - val_loss: -7.7556 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.66165 to -7.75558, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6551 - acc: 0.2368 - val_loss: -7.8512 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.75558 to -7.85120, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.7437 - acc: 0.2368 - val_loss: -7.9309 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.85120 to -7.93086, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.8242 - acc: 0.2368 - val_loss: -8.0093 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.93086 to -8.00927, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.8997 - acc: 0.2368 - val_loss: -8.0798 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.00927 to -8.07980, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.9632 - acc: 0.2368 - val_loss: -8.1380 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.07980 to -8.13805, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.0195 - acc: 0.2368 - val_loss: -8.1873 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.13805 to -8.18734, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.0671 - acc: 0.2368 - val_loss: -8.2334 - val_acc: 0.2676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_loss improved from -8.18734 to -8.23336, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -9.1022 - acc: 0.2368 - val_loss: -8.2592 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.23336 to -8.25923, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.1311 - acc: 0.2368 - val_loss: -8.2875 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.25923 to -8.28752, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.1564 - acc: 0.2368 - val_loss: -8.3083 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.28752 to -8.30831, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.1723 - acc: 0.2368 - val_loss: -8.3185 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.30831 to -8.31847, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.1837 - acc: 0.2368 - val_loss: -8.3320 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.31847 to -8.33205, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.1965 - acc: 0.2368 - val_loss: -8.3439 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.33205 to -8.34391, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2024 - acc: 0.2368 - val_loss: -8.3479 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.34391 to -8.34787, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.2110 - acc: 0.2368 - val_loss: -8.3534 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.34787 to -8.35342, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.2158 - acc: 0.2368 - val_loss: -8.3605 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.35342 to -8.36047, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2205 - acc: 0.2368 - val_loss: -8.3643 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.36047 to -8.36432, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.2239 - acc: 0.2368 - val_loss: -8.3674 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.36432 to -8.36741, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2271 - acc: 0.2368 - val_loss: -8.3696 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.36741 to -8.36959, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2246 - acc: 0.2368 - val_loss: -8.3673 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.36959\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2268 - acc: 0.2368 - val_loss: -8.3679 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.36959\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.2274 - acc: 0.2368 - val_loss: -8.3686 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.36959\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.2281 - acc: 0.2368 - val_loss: -8.3692 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.36959\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.2285 - acc: 0.2368 - val_loss: -8.3693 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.36959\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.2286 - acc: 0.2368 - val_loss: -8.3694 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.36959\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.2287 - acc: 0.2368 - val_loss: -8.3695 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.36959\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.2288 - acc: 0.2368 - val_loss: -8.3696 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.36959 to -8.36964, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.2289 - acc: 0.2368 - val_loss: -8.3697 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.36964 to -8.36965, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2289 - acc: 0.2368 - val_loss: -8.3697 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.36965 to -8.36967, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: -0.4281 - acc: 0.2295 - val_loss: -6.7289 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.72894, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -7.7071 - acc: 0.2368 - val_loss: -6.9961 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.72894 to -6.99612, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -7.9545 - acc: 0.2368 - val_loss: -7.2193 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.99612 to -7.21925, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -8.1618 - acc: 0.2368 - val_loss: -7.4069 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.21925 to -7.40694, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 888us/step - loss: -8.3346 - acc: 0.2368 - val_loss: -7.5612 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.40694 to -7.56122, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.4799 - acc: 0.2368 - val_loss: -7.6955 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.56122 to -7.69551, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 926us/step - loss: -8.6024 - acc: 0.2368 - val_loss: -7.8014 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.69551 to -7.80144, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 890us/step - loss: -8.7029 - acc: 0.2368 - val_loss: -7.8989 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.80144 to -7.89891, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.7961 - acc: 0.2368 - val_loss: -7.9840 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.89891 to -7.98402, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.8743 - acc: 0.2368 - val_loss: -8.0531 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.98402 to -8.05307, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.9397 - acc: 0.2368 - val_loss: -8.1167 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.05307 to -8.11667, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -8.9970 - acc: 0.2368 - val_loss: -8.1672 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.11667 to -8.16717, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -9.0454 - acc: 0.2368 - val_loss: -8.2121 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.16717 to -8.21214, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.0779 - acc: 0.2368 - val_loss: -8.2360 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.21214 to -8.23596, saving model to model-1.h5\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.1087 - acc: 0.2368 - val_loss: -8.2667 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.23596 to -8.26671, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.1347 - acc: 0.2368 - val_loss: -8.2870 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.26671 to -8.28699, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.1543 - acc: 0.2368 - val_loss: -8.3057 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.28699 to -8.30570, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.1712 - acc: 0.2368 - val_loss: -8.3207 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.30570 to -8.32070, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.1856 - acc: 0.2368 - val_loss: -8.3340 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.32070 to -8.33401, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -9.1957 - acc: 0.2368 - val_loss: -8.3422 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.33401 to -8.34219, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2053 - acc: 0.2368 - val_loss: -8.3504 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.34219 to -8.35038, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.2131 - acc: 0.2368 - val_loss: -8.3563 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.35038 to -8.35630, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2165 - acc: 0.2368 - val_loss: -8.3595 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.35630 to -8.35948, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -9.2222 - acc: 0.2368 - val_loss: -8.3670 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.35948 to -8.36699, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2254 - acc: 0.2368 - val_loss: -8.3685 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.36699 to -8.36847, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.2189 - acc: 0.2368 - val_loss: -8.3628 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.36847\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.2225 - acc: 0.2368 - val_loss: -8.3638 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.36847\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.2235 - acc: 0.2368 - val_loss: -8.3648 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.36847\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.2245 - acc: 0.2368 - val_loss: -8.3659 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.36847\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.2252 - acc: 0.2368 - val_loss: -8.3660 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.36847\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.2253 - acc: 0.2368 - val_loss: -8.3662 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.36847\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -9.2255 - acc: 0.2368 - val_loss: -8.3664 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.36847\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -9.2257 - acc: 0.2368 - val_loss: -8.3666 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.36847\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -9.2258 - acc: 0.2368 - val_loss: -8.3666 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.36847\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.2259 - acc: 0.2368 - val_loss: -8.3667 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.36847\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.2259 - acc: 0.2368 - val_loss: -8.3667 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.36847\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.2260 - acc: 0.2368 - val_loss: -8.3668 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.36847\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.2260 - acc: 0.2368 - val_loss: -8.3668 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.36847\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 908us/step - loss: -9.2261 - acc: 0.2368 - val_loss: -8.3669 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.36847\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 900us/step - loss: -9.2262 - acc: 0.2368 - val_loss: -8.3670 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.36847\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 10s 5ms/step - loss: -1.6872 - acc: 0.2389 - val_loss: -6.7402 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.74016, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.6925 - acc: 0.2368 - val_loss: -6.9510 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.74016 to -6.95103, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -7.8911 - acc: 0.2368 - val_loss: -7.1345 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.95103 to -7.13450, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.0647 - acc: 0.2368 - val_loss: -7.2957 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.13450 to -7.29572, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.2168 - acc: 0.2368 - val_loss: -7.4366 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.29572 to -7.43661, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.3507 - acc: 0.2368 - val_loss: -7.5638 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.43661 to -7.56381, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 895us/step - loss: -8.4706 - acc: 0.2368 - val_loss: -7.6736 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.56381 to -7.67360, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.5785 - acc: 0.2368 - val_loss: -7.7786 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.67360 to -7.77855, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.6767 - acc: 0.2368 - val_loss: -7.8689 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.77855 to -7.86894, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.7641 - acc: 0.2368 - val_loss: -7.9504 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.86894 to -7.95045, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.8426 - acc: 0.2368 - val_loss: -8.0240 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.95045 to -8.02399, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.9111 - acc: 0.2368 - val_loss: -8.0878 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.02399 to -8.08780, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.9719 - acc: 0.2368 - val_loss: -8.1425 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.08780 to -8.14246, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.0241 - acc: 0.2368 - val_loss: -8.1919 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.14246 to -8.19191, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.0676 - acc: 0.2368 - val_loss: -8.2317 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.19191 to -8.23167, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -9.1027 - acc: 0.2368 - val_loss: -8.2629 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.23167 to -8.26292, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.1326 - acc: 0.2368 - val_loss: -8.2874 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.26292 to -8.28742, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.1571 - acc: 0.2368 - val_loss: -8.3102 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.28742 to -8.31020, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.1744 - acc: 0.2368 - val_loss: -8.3206 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.31020 to -8.32058, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -9.1877 - acc: 0.2368 - val_loss: -8.3293 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.32058 to -8.32928, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.1953 - acc: 0.2368 - val_loss: -8.3442 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.32928 to -8.34424, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.2073 - acc: 0.2368 - val_loss: -8.3531 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.34424 to -8.35307, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2130 - acc: 0.2368 - val_loss: -8.3550 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.35307 to -8.35497, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 894us/step - loss: -9.2180 - acc: 0.2368 - val_loss: -8.3595 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.35497 to -8.35950, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.2220 - acc: 0.2368 - val_loss: -8.3660 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.35950 to -8.36603, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.2256 - acc: 0.2368 - val_loss: -8.3666 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.36603 to -8.36656, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.2283 - acc: 0.2368 - val_loss: -8.3678 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.36656 to -8.36776, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -9.2291 - acc: 0.2368 - val_loss: -8.3691 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.36776 to -8.36914, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2312 - acc: 0.2368 - val_loss: -6.3167 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.36914\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.0424 - acc: 0.2368 - val_loss: -8.3708 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.36914 to -8.37078, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2302 - acc: 0.2368 - val_loss: -8.3712 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.37078 to -8.37124, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.2307 - acc: 0.2368 - val_loss: -8.3717 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.37124 to -8.37171, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -9.2312 - acc: 0.2368 - val_loss: -8.3722 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.37171 to -8.37221, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.2317 - acc: 0.2368 - val_loss: -8.3728 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.37221 to -8.37277, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 898us/step - loss: -9.2323 - acc: 0.2368 - val_loss: -8.3734 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.37277 to -8.37338, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.2329 - acc: 0.2368 - val_loss: -8.3741 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.37338 to -8.37408, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.2336 - acc: 0.2368 - val_loss: -8.3749 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.37408 to -8.37487, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.2321 - acc: 0.2368 - val_loss: -8.3710 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.37487\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.2304 - acc: 0.2368 - val_loss: -8.3714 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.37487\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -9.2308 - acc: 0.2368 - val_loss: -8.3718 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.37487\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 11s 6ms/step - loss: -3.5712 - acc: 0.2441 - val_loss: -6.7567 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.75670, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -7.6996 - acc: 0.2368 - val_loss: -6.9466 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.75670 to -6.94660, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 959us/step - loss: -7.8781 - acc: 0.2368 - val_loss: -7.1102 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.94660 to -7.11024, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 920us/step - loss: -8.0336 - acc: 0.2368 - val_loss: -7.2560 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.11024 to -7.25602, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 986us/step - loss: -8.1721 - acc: 0.2368 - val_loss: -7.3870 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.25602 to -7.38698, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.2966 - acc: 0.2368 - val_loss: -7.5034 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.38698 to -7.50335, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.4105 - acc: 0.2368 - val_loss: -7.6130 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.50335 to -7.61299, saving model to model-3.h5\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.5164 - acc: 0.2368 - val_loss: -7.7138 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.61299 to -7.71381, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.6141 - acc: 0.2368 - val_loss: -7.8070 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.71381 to -7.80696, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.7054 - acc: 0.2368 - val_loss: -7.8912 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.80696 to -7.89118, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.7858 - acc: 0.2368 - val_loss: -7.9687 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.89118 to -7.96868, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.8595 - acc: 0.2368 - val_loss: -8.0417 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.96868 to -8.04168, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.9222 - acc: 0.2368 - val_loss: -8.0981 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.04168 to -8.09814, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.9807 - acc: 0.2368 - val_loss: -8.1372 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.09814 to -8.13717, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0131 - acc: 0.2368 - val_loss: -8.1752 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.13717 to -8.17516, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0492 - acc: 0.2368 - val_loss: -8.2089 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.17516 to -8.20890, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0809 - acc: 0.2368 - val_loss: -8.2366 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.20890 to -8.23655, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1074 - acc: 0.2368 - val_loss: -8.2603 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.23655 to -8.26029, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1261 - acc: 0.2368 - val_loss: -8.2732 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.26029 to -8.27316, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1407 - acc: 0.2368 - val_loss: -8.2920 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.27316 to -8.29205, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1586 - acc: 0.2368 - val_loss: -8.3054 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.29205 to -8.30540, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1715 - acc: 0.2368 - val_loss: -8.3211 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.30540 to -8.32105, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1753 - acc: 0.2368 - val_loss: -8.3183 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -8.32105\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1796 - acc: 0.2368 - val_loss: -8.3230 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.32105 to -8.32303, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1843 - acc: 0.2368 - val_loss: -8.3279 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.32303 to -8.32787, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1892 - acc: 0.2368 - val_loss: -8.3329 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.32787 to -8.33291, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1944 - acc: 0.2368 - val_loss: -8.3382 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.33291 to -8.33820, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1997 - acc: 0.2368 - val_loss: -8.3432 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.33820 to -8.34318, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2046 - acc: 0.2368 - val_loss: -7.6079 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.34318\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1255 - acc: 0.2368 - val_loss: -8.3439 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.34318 to -8.34386, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2034 - acc: 0.2368 - val_loss: -8.3447 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.34386 to -8.34467, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2043 - acc: 0.2368 - val_loss: -8.3456 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.34467 to -8.34558, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2053 - acc: 0.2368 - val_loss: -8.3466 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.34558 to -8.34663, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2064 - acc: 0.2368 - val_loss: -8.3479 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.34663 to -8.34786, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2077 - acc: 0.2368 - val_loss: -8.3493 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.34786 to -8.34933, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2093 - acc: 0.2368 - val_loss: -8.3511 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.34933 to -8.35108, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2112 - acc: 0.2368 - val_loss: -8.3532 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.35108 to -8.35316, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2134 - acc: 0.2368 - val_loss: -8.3556 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.35316 to -8.35559, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2159 - acc: 0.2368 - val_loss: -8.3560 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.35559 to -8.35598, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2167 - acc: 0.2368 - val_loss: -8.3595 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.35598 to -8.35946, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 33s 17ms/step - loss: -3.6931 - acc: 0.2405 - val_loss: -6.7449 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.74487, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -7.6863 - acc: 0.2368 - val_loss: -6.9310 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.74487 to -6.93097, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -7.8616 - acc: 0.2368 - val_loss: -7.0931 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.93097 to -7.09307, saving model to model-4.h5\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.0153 - acc: 0.2368 - val_loss: -7.2365 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.09307 to -7.23651, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.1516 - acc: 0.2368 - val_loss: -7.3639 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.23651 to -7.36391, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.2733 - acc: 0.2368 - val_loss: -7.4799 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.36391 to -7.47994, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.3861 - acc: 0.2368 - val_loss: -7.5882 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.47994 to -7.58823, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.4896 - acc: 0.2368 - val_loss: -7.6868 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.58823 to -7.68679, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.5868 - acc: 0.2368 - val_loss: -7.7821 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.68679 to -7.78212, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.6788 - acc: 0.2368 - val_loss: -7.8669 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.78212 to -7.86690, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.7636 - acc: 0.2368 - val_loss: -7.9485 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.86690 to -7.94848, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.8388 - acc: 0.2368 - val_loss: -8.0187 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.94848 to -8.01871, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.9095 - acc: 0.2368 - val_loss: -8.0713 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.01871 to -8.07135, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.9529 - acc: 0.2368 - val_loss: -8.1221 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.07135 to -8.12214, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0011 - acc: 0.2368 - val_loss: -8.1671 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.12214 to -8.16706, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0423 - acc: 0.2368 - val_loss: -8.2033 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.16706 to -8.20330, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0754 - acc: 0.2368 - val_loss: -8.2351 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.20330 to -8.23510, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1014 - acc: 0.2368 - val_loss: -8.2525 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.23510 to -8.25249, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1139 - acc: 0.2368 - val_loss: -8.2576 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.25249 to -8.25761, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1191 - acc: 0.2368 - val_loss: -8.2628 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.25761 to -8.26283, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1244 - acc: 0.2368 - val_loss: -8.2683 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.26283 to -8.26832, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1301 - acc: 0.2368 - val_loss: -8.2742 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.26832 to -8.27424, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1362 - acc: 0.2368 - val_loss: -8.2808 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.27424 to -8.28080, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1431 - acc: 0.2368 - val_loss: -8.2881 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.28080 to -8.28813, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1508 - acc: 0.2368 - val_loss: -8.2963 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.28813 to -8.29635, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 3s 1ms/step - loss: -9.1596 - acc: 0.2368 - val_loss: -8.3044 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.29635 to -8.30440, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1677 - acc: 0.2368 - val_loss: -8.3118 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.30440 to -8.31178, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1755 - acc: 0.2368 - val_loss: -8.3223 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.31178 to -8.32233, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1854 - acc: 0.2368 - val_loss: -8.3304 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.32233 to -8.33045, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1936 - acc: 0.2368 - val_loss: -8.3393 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.33045 to -8.33932, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1830 - acc: 0.2368 - val_loss: -8.3365 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.33932\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1963 - acc: 0.2368 - val_loss: -8.3378 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.33932\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1977 - acc: 0.2368 - val_loss: -8.3393 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.33932\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1992 - acc: 0.2368 - val_loss: -8.3409 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.33932 to -8.34094, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2010 - acc: 0.2368 - val_loss: -8.3428 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.34094 to -8.34282, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2030 - acc: 0.2368 - val_loss: -8.3450 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.34282 to -8.34500, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2053 - acc: 0.2368 - val_loss: -8.3475 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.34500 to -8.34755, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2080 - acc: 0.2368 - val_loss: -8.3505 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.34755 to -8.35049, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2115 - acc: 0.2368 - val_loss: -8.3542 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.35049 to -8.35418, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2144 - acc: 0.2368 - val_loss: -8.3507 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.35418\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -3.6758 - acc: 0.2410 - val_loss: -6.7645 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.76454, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -7.6941 - acc: 0.2368 - val_loss: -6.9241 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.76454 to -6.92414, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -7.8459 - acc: 0.2368 - val_loss: -7.0664 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.92414 to -7.06638, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -7.9814 - acc: 0.2368 - val_loss: -7.1932 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.06638 to -7.19324, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.1040 - acc: 0.2368 - val_loss: -7.3096 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.19324 to -7.30965, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.2173 - acc: 0.2368 - val_loss: -7.4194 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.30965 to -7.41936, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.3243 - acc: 0.2368 - val_loss: -7.5244 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.41936 to -7.52440, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.4272 - acc: 0.2368 - val_loss: -7.6245 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.52440 to -7.62454, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.5238 - acc: 0.2368 - val_loss: -7.7199 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.62454 to -7.71992, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.6174 - acc: 0.2368 - val_loss: -7.8069 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.71992 to -7.80690, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.7028 - acc: 0.2368 - val_loss: -7.8912 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.80690 to -7.89121, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.7844 - acc: 0.2368 - val_loss: -7.9699 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.89121 to -7.96992, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.8448 - acc: 0.2368 - val_loss: -8.0202 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.96992 to -8.02020, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.9039 - acc: 0.2368 - val_loss: -8.0761 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.02020 to -8.07608, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.9571 - acc: 0.2368 - val_loss: -8.1248 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.07608 to -8.12484, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0023 - acc: 0.2368 - val_loss: -8.1668 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.12484 to -8.16679, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0382 - acc: 0.2368 - val_loss: -8.1933 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.16679 to -8.19333, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0665 - acc: 0.2368 - val_loss: -8.2249 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.19333 to -8.22491, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0964 - acc: 0.2368 - val_loss: -8.2529 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.22491 to -8.25290, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1194 - acc: 0.2368 - val_loss: -8.2728 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.25290 to -8.27278, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1424 - acc: 0.2368 - val_loss: -8.2877 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.27278 to -8.28766, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1552 - acc: 0.2368 - val_loss: -8.3064 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.28766 to -8.30635, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1725 - acc: 0.2368 - val_loss: -8.3217 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.30635 to -8.32172, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1671 - acc: 0.2368 - val_loss: -8.3176 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -8.32172\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1787 - acc: 0.2368 - val_loss: -8.3220 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.32172 to -8.32202, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1831 - acc: 0.2368 - val_loss: -8.3264 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.32202 to -8.32644, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1876 - acc: 0.2368 - val_loss: -8.3310 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.32644 to -8.33101, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1923 - acc: 0.2368 - val_loss: -8.3358 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.33101 to -8.33581, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.1972 - acc: 0.2368 - val_loss: -8.3409 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.33581 to -8.34091, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2019 - acc: 0.2368 - val_loss: -8.3452 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.34091 to -8.34516, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2052 - acc: 0.2368 - val_loss: -8.3450 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.34516\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2063 - acc: 0.2368 - val_loss: -8.3497 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.34516 to -8.34970, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2109 - acc: 0.2368 - val_loss: -8.3543 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.34970 to -8.35429, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2148 - acc: 0.2368 - val_loss: -8.3562 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.35429 to -8.35623, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2175 - acc: 0.2368 - val_loss: -8.3610 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.35623 to -8.36103, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2213 - acc: 0.2368 - val_loss: -8.3635 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.36103 to -8.36352, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2206 - acc: 0.2368 - val_loss: -8.3608 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.36352\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2205 - acc: 0.2368 - val_loss: -8.3618 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.36352\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2215 - acc: 0.2368 - val_loss: -8.3628 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.36352\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2225 - acc: 0.2368 - val_loss: -8.3639 - val_acc: 0.2676\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.36352 to -8.36390, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 14s 5ms/step - loss: -3.5377 - acc: 0.2365 - val_loss: -6.1114 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.11140, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -8.3250 - acc: 0.2383 - val_loss: -6.3197 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.11140 to -6.31972, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -8.5123 - acc: 0.2383 - val_loss: -6.4990 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.31972 to -6.49904, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -8.6883 - acc: 0.2383 - val_loss: -6.6689 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.49904 to -6.66890, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -8.8550 - acc: 0.2383 - val_loss: -6.8324 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.66890 to -6.83235, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.0123 - acc: 0.2383 - val_loss: -6.9853 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.83235 to -6.98531, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.1631 - acc: 0.2383 - val_loss: -7.1196 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -6.98531 to -7.11959, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.3023 - acc: 0.2383 - val_loss: -7.2622 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.11959 to -7.26219, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.4256 - acc: 0.2383 - val_loss: -7.3785 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.26219 to -7.37850, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.5322 - acc: 0.2383 - val_loss: -7.4746 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.37850 to -7.47462, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.6205 - acc: 0.2383 - val_loss: -7.5526 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.47462 to -7.55264, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.6902 - acc: 0.2383 - val_loss: -7.6128 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.55264 to -7.61280, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -9.7438 - acc: 0.2383 - val_loss: -7.6597 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.61280 to -7.65972, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.7826 - acc: 0.2383 - val_loss: -7.6912 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.65972 to -7.69119, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -9.8096 - acc: 0.2383 - val_loss: -7.7144 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.69119 to -7.71438, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8223 - acc: 0.2383 - val_loss: -7.7197 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.71438 to -7.71968, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.8332 - acc: 0.2383 - val_loss: -7.7308 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.71968 to -7.73078, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.8434 - acc: 0.2383 - val_loss: -7.7399 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.73078 to -7.73993, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.8498 - acc: 0.2383 - val_loss: -7.7450 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.73993 to -7.74500, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8550 - acc: 0.2383 - val_loss: -7.7497 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.74500 to -7.74971, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.8582 - acc: 0.2383 - val_loss: -7.7531 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.74971 to -7.75309, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.8574 - acc: 0.2383 - val_loss: -7.7506 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -7.75309\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.8603 - acc: 0.2383 - val_loss: -7.7537 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -7.75309 to -7.75372, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.8633 - acc: 0.2383 - val_loss: -7.7565 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.75372 to -7.75652, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8630 - acc: 0.2383 - val_loss: -7.7555 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -7.75652\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.8651 - acc: 0.2383 - val_loss: -7.7566 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -7.75652 to -7.75660, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8661 - acc: 0.2383 - val_loss: -7.7547 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -7.75660\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8637 - acc: 0.2383 - val_loss: -7.7563 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -7.75660\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8646 - acc: 0.2383 - val_loss: -7.7565 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -7.75660\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.8648 - acc: 0.2383 - val_loss: -7.7567 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -7.75660 to -7.75670, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.8651 - acc: 0.2383 - val_loss: -7.7570 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -7.75670 to -7.75697, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.8654 - acc: 0.2383 - val_loss: -7.7573 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -7.75697 to -7.75732, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.8658 - acc: 0.2383 - val_loss: -7.7578 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -7.75732 to -7.75775, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.8662 - acc: 0.2383 - val_loss: -7.7583 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss improved from -7.75775 to -7.75828, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8668 - acc: 0.2383 - val_loss: -7.7589 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss improved from -7.75828 to -7.75888, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.8674 - acc: 0.2383 - val_loss: -7.7595 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss improved from -7.75888 to -7.75953, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8681 - acc: 0.2383 - val_loss: -7.7602 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss improved from -7.75953 to -7.76020, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8684 - acc: 0.2383 - val_loss: -7.7604 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss improved from -7.76020 to -7.76045, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.8686 - acc: 0.2383 - val_loss: -7.7603 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.76045\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.8688 - acc: 0.2383 - val_loss: -7.7604 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.76045\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -5.3880 - acc: 0.2390 - val_loss: -6.1173 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.11728, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -8.3148 - acc: 0.2383 - val_loss: -6.2993 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.11728 to -6.29933, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -8.4878 - acc: 0.2383 - val_loss: -6.4701 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.29933 to -6.47014, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.6532 - acc: 0.2383 - val_loss: -6.6325 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.47014 to -6.63253, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.8143 - acc: 0.2383 - val_loss: -6.7869 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.63253 to -6.78686, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.9689 - acc: 0.2383 - val_loss: -6.9436 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.78686 to -6.94357, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.1196 - acc: 0.2383 - val_loss: -7.0898 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -6.94357 to -7.08979, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.2620 - acc: 0.2383 - val_loss: -7.2263 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.08979 to -7.22630, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3909 - acc: 0.2383 - val_loss: -7.3469 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.22630 to -7.34690, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.5046 - acc: 0.2383 - val_loss: -7.4498 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.34690 to -7.44981, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.5989 - acc: 0.2383 - val_loss: -7.5352 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.44981 to -7.53524, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.6751 - acc: 0.2383 - val_loss: -7.5941 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.53524 to -7.59407, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.7288 - acc: 0.2383 - val_loss: -7.6486 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.59407 to -7.64862, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.7734 - acc: 0.2383 - val_loss: -7.6848 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.64862 to -7.68479, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8039 - acc: 0.2383 - val_loss: -7.7080 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.68479 to -7.70804, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.8265 - acc: 0.2383 - val_loss: -7.7268 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.70804 to -7.72683, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8397 - acc: 0.2383 - val_loss: -7.7394 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.72683 to -7.73937, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -9.8473 - acc: 0.2383 - val_loss: -7.7442 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.73937 to -7.74418, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.8564 - acc: 0.2383 - val_loss: -7.7520 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.74418 to -7.75196, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8596 - acc: 0.2383 - val_loss: -7.7500 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -7.75196\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.8619 - acc: 0.2383 - val_loss: -7.7572 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.75196 to -7.75723, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -9.8371 - acc: 0.2383 - val_loss: -7.7522 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -7.75723\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.8607 - acc: 0.2383 - val_loss: -7.7528 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -7.75723\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.8613 - acc: 0.2383 - val_loss: -7.7534 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -7.75723\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.8620 - acc: 0.2383 - val_loss: -7.7542 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -7.75723\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.8624 - acc: 0.2383 - val_loss: -7.7543 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -7.75723\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.8626 - acc: 0.2383 - val_loss: -7.7544 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -7.75723\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8627 - acc: 0.2383 - val_loss: -7.7546 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -7.75723\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8629 - acc: 0.2383 - val_loss: -7.7548 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -7.75723\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.8631 - acc: 0.2383 - val_loss: -7.7548 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -7.75723\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8631 - acc: 0.2383 - val_loss: -7.7549 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -7.75723\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8631 - acc: 0.2383 - val_loss: -7.7549 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -7.75723\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.8632 - acc: 0.2383 - val_loss: -7.7550 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -7.75723\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8633 - acc: 0.2383 - val_loss: -7.7551 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -7.75723\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.8634 - acc: 0.2383 - val_loss: -7.7552 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -7.75723\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.8635 - acc: 0.2383 - val_loss: -7.7553 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75723\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.8636 - acc: 0.2383 - val_loss: -7.7555 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -7.75723\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.8638 - acc: 0.2383 - val_loss: -7.7556 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.75723\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8639 - acc: 0.2383 - val_loss: -7.7557 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.75723\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.8641 - acc: 0.2383 - val_loss: -7.7559 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.75723\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -5.5084 - acc: 0.2434 - val_loss: -6.1070 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.10699, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -8.2924 - acc: 0.2383 - val_loss: -6.2744 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.10699 to -6.27443, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.4541 - acc: 0.2383 - val_loss: -6.4310 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.27443 to -6.43103, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -8.6104 - acc: 0.2383 - val_loss: -6.5883 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.43103 to -6.58833, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -8.7678 - acc: 0.2383 - val_loss: -6.7436 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.58833 to -6.74358, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -8.9220 - acc: 0.2383 - val_loss: -6.8953 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.74358 to -6.89530, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.0740 - acc: 0.2383 - val_loss: -7.0470 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -6.89530 to -7.04698, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.2213 - acc: 0.2383 - val_loss: -7.1880 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.04698 to -7.18796, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3568 - acc: 0.2383 - val_loss: -7.3158 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.18796 to -7.31582, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4756 - acc: 0.2383 - val_loss: -7.4262 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.31582 to -7.42623, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.5775 - acc: 0.2383 - val_loss: -7.5169 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.42623 to -7.51685, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.6592 - acc: 0.2383 - val_loss: -7.5897 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.51685 to -7.58969, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.7238 - acc: 0.2383 - val_loss: -7.6443 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.58969 to -7.64431, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.7664 - acc: 0.2383 - val_loss: -7.6712 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.64431 to -7.67124, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.7926 - acc: 0.2383 - val_loss: -7.6984 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.67124 to -7.69837, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8152 - acc: 0.2383 - val_loss: -7.7154 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.69837 to -7.71535, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8312 - acc: 0.2383 - val_loss: -7.7287 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.71535 to -7.72865, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8432 - acc: 0.2383 - val_loss: -7.7394 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.72865 to -7.73941, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8508 - acc: 0.2383 - val_loss: -7.7449 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.73941 to -7.74489, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.8429 - acc: 0.2383 - val_loss: -7.7460 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.74489 to -7.74603, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8547 - acc: 0.2383 - val_loss: -7.7470 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.74603 to -7.74704, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.8558 - acc: 0.2383 - val_loss: -7.7481 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.74704 to -7.74812, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8569 - acc: 0.2383 - val_loss: -7.7493 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -7.74812 to -7.74933, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8582 - acc: 0.2383 - val_loss: -7.7508 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.74933 to -7.75077, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8598 - acc: 0.2383 - val_loss: -7.7525 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -7.75077 to -7.75247, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.8616 - acc: 0.2383 - val_loss: -7.7545 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -7.75247 to -7.75447, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.8630 - acc: 0.2383 - val_loss: -7.7555 - val_acc: 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_loss improved from -7.75447 to -7.75551, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8641 - acc: 0.2383 - val_loss: -7.7567 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -7.75551 to -7.75669, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.8652 - acc: 0.2383 - val_loss: -7.7579 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -7.75669 to -7.75787, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8410 - acc: 0.2383 - val_loss: -7.7547 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -7.75787\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8631 - acc: 0.2383 - val_loss: -7.7550 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -7.75787\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.8634 - acc: 0.2383 - val_loss: -7.7554 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -7.75787\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.8638 - acc: 0.2383 - val_loss: -7.7558 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -7.75787\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8641 - acc: 0.2383 - val_loss: -7.7558 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -7.75787\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8641 - acc: 0.2383 - val_loss: -7.7559 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -7.75787\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 886us/step - loss: -9.8642 - acc: 0.2383 - val_loss: -7.7560 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75787\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8643 - acc: 0.2383 - val_loss: -7.7562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -7.75787\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8644 - acc: 0.2383 - val_loss: -7.7562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.75787\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8645 - acc: 0.2383 - val_loss: -7.7562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.75787\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8645 - acc: 0.2383 - val_loss: -7.7563 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.75787\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -4.7638 - acc: 0.2362 - val_loss: -6.1478 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.14784, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -8.3227 - acc: 0.2383 - val_loss: -6.2920 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.14784 to -6.29203, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -8.4631 - acc: 0.2383 - val_loss: -6.4293 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.29203 to -6.42929, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.6012 - acc: 0.2383 - val_loss: -6.5680 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.42929 to -6.56803, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.7403 - acc: 0.2383 - val_loss: -6.7069 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.56803 to -6.70688, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -8.8796 - acc: 0.2383 - val_loss: -6.8468 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.70688 to -6.84684, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.0199 - acc: 0.2383 - val_loss: -6.9868 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -6.84684 to -6.98680, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.1560 - acc: 0.2383 - val_loss: -7.1178 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -6.98680 to -7.11785, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.2856 - acc: 0.2383 - val_loss: -7.2444 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.11785 to -7.24435, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.4053 - acc: 0.2383 - val_loss: -7.3543 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.24435 to -7.35431, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.5091 - acc: 0.2383 - val_loss: -7.4514 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.35431 to -7.45140, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.5980 - acc: 0.2383 - val_loss: -7.5332 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.45140 to -7.53325, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.6687 - acc: 0.2383 - val_loss: -7.5953 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.53325 to -7.59531, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.7146 - acc: 0.2383 - val_loss: -7.6271 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.59531 to -7.62712, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.7517 - acc: 0.2383 - val_loss: -7.6614 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.62712 to -7.66139, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.7797 - acc: 0.2383 - val_loss: -7.6819 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.66139 to -7.68187, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.8006 - acc: 0.2383 - val_loss: -7.7038 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.68187 to -7.70377, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.8164 - acc: 0.2383 - val_loss: -7.7161 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.70377 to -7.71611, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8291 - acc: 0.2383 - val_loss: -7.7267 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.71611 to -7.72673, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8395 - acc: 0.2383 - val_loss: -7.7365 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.72673 to -7.73653, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.8463 - acc: 0.2383 - val_loss: -7.7418 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.73653 to -7.74177, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.8508 - acc: 0.2383 - val_loss: -7.7429 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.74177 to -7.74288, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.8535 - acc: 0.2383 - val_loss: -7.7480 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -7.74288 to -7.74795, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8583 - acc: 0.2383 - val_loss: -7.7523 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.74795 to -7.75232, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8561 - acc: 0.2383 - val_loss: -7.7483 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -7.75232\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8572 - acc: 0.2383 - val_loss: -7.7496 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -7.75232\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8586 - acc: 0.2383 - val_loss: -7.7511 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -7.75232\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8601 - acc: 0.2383 - val_loss: -7.7528 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -7.75232 to -7.75276, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8619 - acc: 0.2383 - val_loss: -7.7547 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -7.75276 to -7.75466, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8636 - acc: 0.2383 - val_loss: -7.7554 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -7.75466 to -7.75538, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8648 - acc: 0.2383 - val_loss: -7.7552 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -7.75538\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8649 - acc: 0.2383 - val_loss: -7.7583 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -7.75538 to -7.75831, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8663 - acc: 0.2383 - val_loss: -7.7591 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -7.75831 to -7.75915, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8677 - acc: 0.2383 - val_loss: -7.7560 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -7.75915\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8660 - acc: 0.2383 - val_loss: -7.7594 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss improved from -7.75915 to -7.75944, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8683 - acc: 0.2383 - val_loss: -7.7579 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75944\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8675 - acc: 0.2383 - val_loss: -7.7607 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss improved from -7.75944 to -7.76072, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.8691 - acc: 0.2383 - val_loss: -7.7598 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.76072\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8691 - acc: 0.2383 - val_loss: -7.7621 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss improved from -7.76072 to -7.76206, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.7976 - acc: 0.2383 - val_loss: -7.7586 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.76206\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -5.7727 - acc: 0.2376 - val_loss: -6.1518 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.15177, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -8.3287 - acc: 0.2383 - val_loss: -6.2994 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.15177 to -6.29940, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -8.4736 - acc: 0.2383 - val_loss: -6.4420 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.29940 to -6.44202, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -8.6160 - acc: 0.2383 - val_loss: -6.5848 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.44202 to -6.58482, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.7586 - acc: 0.2383 - val_loss: -6.7275 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.58482 to -6.72749, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -8.9014 - acc: 0.2383 - val_loss: -6.8715 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.72749 to -6.87146, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.0457 - acc: 0.2383 - val_loss: -7.0143 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -6.87146 to -7.01434, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1866 - acc: 0.2383 - val_loss: -7.1520 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.01434 to -7.15201, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.3204 - acc: 0.2383 - val_loss: -7.2796 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.15201 to -7.27962, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.4404 - acc: 0.2383 - val_loss: -7.3892 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.27962 to -7.38916, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.5453 - acc: 0.2383 - val_loss: -7.4897 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.38916 to -7.48967, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.6337 - acc: 0.2383 - val_loss: -7.5641 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.48967 to -7.56405, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.6997 - acc: 0.2383 - val_loss: -7.6188 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.56405 to -7.61882, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.7501 - acc: 0.2383 - val_loss: -7.6620 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.61882 to -7.66201, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.7879 - acc: 0.2383 - val_loss: -7.6971 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.66201 to -7.69709, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.7844 - acc: 0.2383 - val_loss: -7.6959 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -7.69709\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8057 - acc: 0.2383 - val_loss: -7.6994 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.69709 to -7.69943, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.8094 - acc: 0.2383 - val_loss: -7.7032 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.69943 to -7.70323, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.8134 - acc: 0.2383 - val_loss: -7.7075 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.70323 to -7.70751, saving model to model-5.h5\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.8180 - acc: 0.2383 - val_loss: -7.7125 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.70751 to -7.71252, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8234 - acc: 0.2383 - val_loss: -7.7184 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.71252 to -7.71842, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8297 - acc: 0.2383 - val_loss: -7.7252 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.71842 to -7.72525, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8369 - acc: 0.2383 - val_loss: -7.7328 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -7.72525 to -7.73283, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8434 - acc: 0.2383 - val_loss: -7.7385 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.73283 to -7.73854, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8476 - acc: 0.2383 - val_loss: -7.7420 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -7.73854 to -7.74198, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8536 - acc: 0.2383 - val_loss: -7.7490 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -7.74198 to -7.74904, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8587 - acc: 0.2383 - val_loss: -7.7503 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -7.74904 to -7.75030, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8614 - acc: 0.2383 - val_loss: -7.7511 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -7.75030 to -7.75106, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8619 - acc: 0.2383 - val_loss: -7.7564 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -7.75106 to -7.75641, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.8653 - acc: 0.2383 - val_loss: -7.7577 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -7.75641 to -7.75774, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8671 - acc: 0.2383 - val_loss: -7.7597 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -7.75774 to -7.75971, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8673 - acc: 0.2383 - val_loss: -7.7605 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -7.75971 to -7.76052, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8678 - acc: 0.2383 - val_loss: -7.7608 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -7.76052 to -7.76083, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8692 - acc: 0.2383 - val_loss: -7.7621 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss improved from -7.76083 to -7.76209, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8687 - acc: 0.2383 - val_loss: -7.7620 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -7.76209\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8672 - acc: 0.2383 - val_loss: -7.7584 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.76209\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8674 - acc: 0.2383 - val_loss: -7.7600 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -7.76209\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8690 - acc: 0.2383 - val_loss: -7.7615 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.76209\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8698 - acc: 0.2383 - val_loss: -7.7616 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.76209\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8700 - acc: 0.2383 - val_loss: -7.7618 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.76209\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -2.6644 - acc: 0.2448 - val_loss: -6.2614 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.26140, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -8.5486 - acc: 0.2383 - val_loss: -6.6304 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.26140 to -6.63038, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -8.8704 - acc: 0.2383 - val_loss: -6.9012 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.63038 to -6.90124, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.1078 - acc: 0.2383 - val_loss: -7.1014 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.90124 to -7.10145, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.2898 - acc: 0.2383 - val_loss: -7.2665 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.10145 to -7.26652, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4313 - acc: 0.2383 - val_loss: -7.3903 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.26652 to -7.39027, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.5455 - acc: 0.2383 - val_loss: -7.4892 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.39027 to -7.48916, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.6302 - acc: 0.2383 - val_loss: -7.5617 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.48916 to -7.56165, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.6977 - acc: 0.2383 - val_loss: -7.6193 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.56165 to -7.61930, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.7495 - acc: 0.2383 - val_loss: -7.6651 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.61930 to -7.66509, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.7821 - acc: 0.2383 - val_loss: -7.6937 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.66509 to -7.69365, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8061 - acc: 0.2383 - val_loss: -7.7036 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.69365 to -7.70365, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8212 - acc: 0.2383 - val_loss: -7.7217 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.70365 to -7.72170, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8309 - acc: 0.2383 - val_loss: -7.7228 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.72170 to -7.72283, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8353 - acc: 0.2383 - val_loss: -7.7317 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.72283 to -7.73171, saving model to model-1.h5\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 3s 901us/step - loss: -9.8436 - acc: 0.2383 - val_loss: -7.7395 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.73171 to -7.73949, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.8487 - acc: 0.2383 - val_loss: -7.7436 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.73949 to -7.74356, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8530 - acc: 0.2383 - val_loss: -7.7454 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.74356 to -7.74536, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8548 - acc: 0.2383 - val_loss: -7.7465 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.74536 to -7.74654, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8572 - acc: 0.2383 - val_loss: -7.7450 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -7.74654\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8542 - acc: 0.2383 - val_loss: -7.7472 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.74654 to -7.74715, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8564 - acc: 0.2383 - val_loss: -7.7494 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.74715 to -7.74936, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.8587 - acc: 0.2383 - val_loss: -7.7517 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -7.74936 to -7.75170, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8611 - acc: 0.2383 - val_loss: -7.7542 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.75170 to -7.75421, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8629 - acc: 0.2383 - val_loss: -7.7566 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -7.75421 to -7.75658, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8598 - acc: 0.2383 - val_loss: -7.7523 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -7.75658\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8616 - acc: 0.2383 - val_loss: -7.7546 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -7.75658\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8639 - acc: 0.2383 - val_loss: -7.7569 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -7.75658 to -7.75690, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8620 - acc: 0.2383 - val_loss: -7.7538 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -7.75690\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8632 - acc: 0.2383 - val_loss: -7.7562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -7.75690\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.8655 - acc: 0.2383 - val_loss: -7.7584 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -7.75690 to -7.75843, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8662 - acc: 0.2383 - val_loss: -7.7588 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -7.75843 to -7.75884, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8634 - acc: 0.2383 - val_loss: -7.7547 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -7.75884\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.8632 - acc: 0.2383 - val_loss: -7.7554 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -7.75884\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.8639 - acc: 0.2383 - val_loss: -7.7561 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -7.75884\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.8648 - acc: 0.2383 - val_loss: -7.7570 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75884\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.8653 - acc: 0.2383 - val_loss: -7.7572 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -7.75884\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8655 - acc: 0.2383 - val_loss: -7.7573 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.75884\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8657 - acc: 0.2383 - val_loss: -7.7575 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.75884\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.8659 - acc: 0.2383 - val_loss: -7.7578 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.75884\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -4.7626 - acc: 0.2401 - val_loss: -6.1972 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.19722, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -8.4381 - acc: 0.2383 - val_loss: -6.4747 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.19722 to -6.47475, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.6910 - acc: 0.2383 - val_loss: -6.7009 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.47475 to -6.70087, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.8998 - acc: 0.2383 - val_loss: -6.8908 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.70087 to -6.89081, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.0751 - acc: 0.2383 - val_loss: -7.0522 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.89081 to -7.05224, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.2275 - acc: 0.2383 - val_loss: -7.1914 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.05224 to -7.19144, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.3578 - acc: 0.2383 - val_loss: -7.3153 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.19144 to -7.31532, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.4708 - acc: 0.2383 - val_loss: -7.4184 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.31532 to -7.41839, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.5629 - acc: 0.2383 - val_loss: -7.4933 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.41839 to -7.49326, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.6365 - acc: 0.2383 - val_loss: -7.5659 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.49326 to -7.56592, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.6970 - acc: 0.2383 - val_loss: -7.6160 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.56592 to -7.61601, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.7416 - acc: 0.2383 - val_loss: -7.6567 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.61601 to -7.65665, saving model to model-2.h5\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.7750 - acc: 0.2383 - val_loss: -7.6720 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.65665 to -7.67197, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.7888 - acc: 0.2383 - val_loss: -7.6901 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.67197 to -7.69012, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8060 - acc: 0.2383 - val_loss: -7.7062 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.69012 to -7.70624, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8171 - acc: 0.2383 - val_loss: -7.7151 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.70624 to -7.71507, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.8292 - acc: 0.2383 - val_loss: -7.7270 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.71507 to -7.72697, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8353 - acc: 0.2383 - val_loss: -7.7270 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.72697 to -7.72703, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8390 - acc: 0.2383 - val_loss: -7.7351 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.72703 to -7.73505, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8466 - acc: 0.2383 - val_loss: -7.7407 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.73505 to -7.74072, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8498 - acc: 0.2383 - val_loss: -7.7417 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.74072 to -7.74171, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8529 - acc: 0.2383 - val_loss: -7.7463 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.74171 to -7.74629, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8547 - acc: 0.2383 - val_loss: -7.7437 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -7.74629\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8534 - acc: 0.2383 - val_loss: -7.7469 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.74629 to -7.74686, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8566 - acc: 0.2383 - val_loss: -7.7500 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -7.74686 to -7.75002, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.8597 - acc: 0.2383 - val_loss: -7.7532 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -7.75002 to -7.75324, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8605 - acc: 0.2383 - val_loss: -7.7502 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -7.75324\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8600 - acc: 0.2383 - val_loss: -7.7535 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -7.75324 to -7.75350, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.8631 - acc: 0.2383 - val_loss: -7.7557 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -7.75350 to -7.75567, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.8644 - acc: 0.2383 - val_loss: -7.7572 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -7.75567 to -7.75717, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 844us/step - loss: -9.8642 - acc: 0.2383 - val_loss: -7.7547 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -7.75717\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8649 - acc: 0.2383 - val_loss: -7.7587 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -7.75717 to -7.75872, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.8664 - acc: 0.2383 - val_loss: -7.7568 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -7.75872\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.7375 - acc: 0.2383 - val_loss: -7.7562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -7.75872\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8646 - acc: 0.2383 - val_loss: -7.7565 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -7.75872\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8648 - acc: 0.2383 - val_loss: -7.7568 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75872\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8650 - acc: 0.2383 - val_loss: -7.7568 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -7.75872\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8651 - acc: 0.2383 - val_loss: -7.7569 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.75872\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8651 - acc: 0.2383 - val_loss: -7.7569 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.75872\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8652 - acc: 0.2383 - val_loss: -7.7570 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.75872\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -5.2610 - acc: 0.2434 - val_loss: -6.2007 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.20072, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.4204 - acc: 0.2383 - val_loss: -6.4358 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.20072 to -6.43583, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -8.6349 - acc: 0.2383 - val_loss: -6.6317 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.43583 to -6.63172, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.8224 - acc: 0.2383 - val_loss: -6.8065 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.63172 to -6.80649, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -8.9883 - acc: 0.2383 - val_loss: -6.9607 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.80649 to -6.96071, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1365 - acc: 0.2383 - val_loss: -7.1051 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.96071 to -7.10514, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.2720 - acc: 0.2383 - val_loss: -7.2322 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.10514 to -7.23220, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.3886 - acc: 0.2383 - val_loss: -7.3379 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.23220 to -7.33788, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.4915 - acc: 0.2383 - val_loss: -7.4334 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.33788 to -7.43342, saving model to model-3.h5\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 843us/step - loss: -9.5795 - acc: 0.2383 - val_loss: -7.5136 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.43342 to -7.51362, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.6528 - acc: 0.2383 - val_loss: -7.5753 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.51362 to -7.57533, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.7110 - acc: 0.2383 - val_loss: -7.6302 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.57533 to -7.63024, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.7570 - acc: 0.2383 - val_loss: -7.6703 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.63024 to -7.67030, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.7926 - acc: 0.2383 - val_loss: -7.6989 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.67030 to -7.69891, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.8088 - acc: 0.2383 - val_loss: -7.7026 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.69891 to -7.70259, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8147 - acc: 0.2383 - val_loss: -7.7109 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.70259 to -7.71085, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.8229 - acc: 0.2383 - val_loss: -7.7190 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.71085 to -7.71899, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.8310 - acc: 0.2383 - val_loss: -7.7272 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.71899 to -7.72720, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8392 - acc: 0.2383 - val_loss: -7.7294 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.72720 to -7.72937, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8411 - acc: 0.2383 - val_loss: -7.7369 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.72937 to -7.73686, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8483 - acc: 0.2383 - val_loss: -7.7421 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.73686 to -7.74208, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8523 - acc: 0.2383 - val_loss: -7.7466 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.74208 to -7.74656, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8569 - acc: 0.2383 - val_loss: -7.7510 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -7.74656 to -7.75103, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8026 - acc: 0.2383 - val_loss: -7.7469 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -7.75103\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.8554 - acc: 0.2383 - val_loss: -7.7474 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -7.75103\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.8560 - acc: 0.2383 - val_loss: -7.7481 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -7.75103\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.8567 - acc: 0.2383 - val_loss: -7.7489 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -7.75103\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8572 - acc: 0.2383 - val_loss: -7.7490 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -7.75103\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.8574 - acc: 0.2383 - val_loss: -7.7492 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -7.75103\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.8575 - acc: 0.2383 - val_loss: -7.7494 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -7.75103\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8578 - acc: 0.2383 - val_loss: -7.7497 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -7.75103\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 840us/step - loss: -9.8580 - acc: 0.2383 - val_loss: -7.7497 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -7.75103\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.8580 - acc: 0.2383 - val_loss: -7.7498 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -7.75103\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8581 - acc: 0.2383 - val_loss: -7.7499 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -7.75103\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8582 - acc: 0.2383 - val_loss: -7.7500 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -7.75103\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8583 - acc: 0.2383 - val_loss: -7.7501 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75103\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8584 - acc: 0.2383 - val_loss: -7.7502 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -7.75103\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8585 - acc: 0.2383 - val_loss: -7.7504 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.75103\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.8587 - acc: 0.2383 - val_loss: -7.7506 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.75103\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8589 - acc: 0.2383 - val_loss: -7.7507 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.75103\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -5.6290 - acc: 0.2383 - val_loss: -6.1842 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.18417, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.3863 - acc: 0.2383 - val_loss: -6.3834 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.18417 to -6.38338, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -8.5740 - acc: 0.2383 - val_loss: -6.5587 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.38338 to -6.55872, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.7427 - acc: 0.2383 - val_loss: -6.7184 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.55872 to -6.71843, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.8977 - acc: 0.2383 - val_loss: -6.8713 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.71843 to -6.87126, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.0461 - acc: 0.2383 - val_loss: -7.0152 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.87126 to -7.01520, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.1839 - acc: 0.2383 - val_loss: -7.1481 - val_acc: 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss improved from -7.01520 to -7.14808, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.3146 - acc: 0.2383 - val_loss: -7.2705 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.14808 to -7.27048, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.4316 - acc: 0.2383 - val_loss: -7.3832 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.27048 to -7.38324, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.5325 - acc: 0.2383 - val_loss: -7.4752 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.38324 to -7.47521, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.6198 - acc: 0.2383 - val_loss: -7.5379 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.47521 to -7.53793, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.6717 - acc: 0.2383 - val_loss: -7.5914 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.53793 to -7.59137, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.7207 - acc: 0.2383 - val_loss: -7.6356 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.59137 to -7.63563, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.7562 - acc: 0.2383 - val_loss: -7.6665 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.63563 to -7.66651, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.7751 - acc: 0.2383 - val_loss: -7.6696 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.66651 to -7.66962, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 843us/step - loss: -9.7810 - acc: 0.2383 - val_loss: -7.6766 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.66962 to -7.67656, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.7882 - acc: 0.2383 - val_loss: -7.6840 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.67656 to -7.68399, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.7960 - acc: 0.2383 - val_loss: -7.6923 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.68399 to -7.69230, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8048 - acc: 0.2383 - val_loss: -7.7017 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.69230 to -7.70174, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.8148 - acc: 0.2383 - val_loss: -7.7122 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.70174 to -7.71221, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.8226 - acc: 0.2383 - val_loss: -7.7148 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.71221 to -7.71478, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8256 - acc: 0.2383 - val_loss: -7.7204 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.71478 to -7.72037, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.8313 - acc: 0.2383 - val_loss: -7.7263 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -7.72037 to -7.72628, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8374 - acc: 0.2383 - val_loss: -7.7327 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.72628 to -7.73266, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.8434 - acc: 0.2383 - val_loss: -7.7381 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -7.73266 to -7.73812, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8486 - acc: 0.2383 - val_loss: -7.7436 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -7.73812 to -7.74365, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8521 - acc: 0.2383 - val_loss: -7.7475 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -7.74365 to -7.74748, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8570 - acc: 0.2383 - val_loss: -7.7496 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -7.74748 to -7.74962, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.8601 - acc: 0.2383 - val_loss: -7.7536 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -7.74962 to -7.75358, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8627 - acc: 0.2383 - val_loss: -7.7568 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -7.75358 to -7.75681, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8640 - acc: 0.2383 - val_loss: -7.7576 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -7.75681 to -7.75759, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.7260 - acc: 0.2383 - val_loss: -7.7539 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -7.75759\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.8623 - acc: 0.2383 - val_loss: -7.7542 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -7.75759\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.8626 - acc: 0.2383 - val_loss: -7.7546 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -7.75759\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.8630 - acc: 0.2383 - val_loss: -7.7550 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -7.75759\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8632 - acc: 0.2383 - val_loss: -7.7550 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75759\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.8633 - acc: 0.2383 - val_loss: -7.7551 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -7.75759\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8634 - acc: 0.2383 - val_loss: -7.7552 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -7.75759\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8635 - acc: 0.2383 - val_loss: -7.7553 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -7.75759\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 841us/step - loss: -9.8636 - acc: 0.2383 - val_loss: -7.7554 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.75759\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 11s 4ms/step - loss: -5.1317 - acc: 0.2336 - val_loss: -6.1670 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.16697, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.3544 - acc: 0.2383 - val_loss: -6.3362 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.16697 to -6.33624, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -8.5181 - acc: 0.2383 - val_loss: -6.4941 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.33624 to -6.49411, saving model to model-5.h5\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 850us/step - loss: -8.6710 - acc: 0.2383 - val_loss: -6.6440 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.49411 to -6.64399, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -8.8206 - acc: 0.2383 - val_loss: -6.7911 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.64399 to -6.79110, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -8.9656 - acc: 0.2383 - val_loss: -6.9342 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.79110 to -6.93416, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.1049 - acc: 0.2383 - val_loss: -7.0692 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -6.93416 to -7.06922, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.2380 - acc: 0.2383 - val_loss: -7.1929 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.06922 to -7.19287, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.3576 - acc: 0.2383 - val_loss: -7.3069 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.19287 to -7.30686, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.4662 - acc: 0.2383 - val_loss: -7.4112 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.30686 to -7.41125, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.5592 - acc: 0.2383 - val_loss: -7.4973 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.41125 to -7.49731, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.6373 - acc: 0.2383 - val_loss: -7.5658 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.49731 to -7.56577, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.7025 - acc: 0.2383 - val_loss: -7.6254 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.56577 to -7.62542, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.7366 - acc: 0.2383 - val_loss: -7.6400 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.62542 to -7.64000, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.7586 - acc: 0.2383 - val_loss: -7.6621 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.64000 to -7.66212, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.7799 - acc: 0.2383 - val_loss: -7.6825 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.66212 to -7.68251, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 840us/step - loss: -9.8006 - acc: 0.2383 - val_loss: -7.6995 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.68251 to -7.69946, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8111 - acc: 0.2383 - val_loss: -7.7044 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -7.69946 to -7.70440, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.8169 - acc: 0.2383 - val_loss: -7.7135 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -7.70440 to -7.71347, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8258 - acc: 0.2383 - val_loss: -7.7223 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -7.71347 to -7.72225, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8345 - acc: 0.2383 - val_loss: -7.7287 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -7.72225 to -7.72871, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8402 - acc: 0.2383 - val_loss: -7.7368 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -7.72871 to -7.73685, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8461 - acc: 0.2383 - val_loss: -7.7365 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -7.73685\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.8470 - acc: 0.2383 - val_loss: -7.7413 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -7.73685 to -7.74127, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.8517 - acc: 0.2383 - val_loss: -7.7459 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -7.74127 to -7.74590, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.8471 - acc: 0.2383 - val_loss: -7.7443 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -7.74590\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 843us/step - loss: -9.8529 - acc: 0.2383 - val_loss: -7.7451 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -7.74590\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8538 - acc: 0.2383 - val_loss: -7.7460 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -7.74590 to -7.74604, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8548 - acc: 0.2383 - val_loss: -7.7471 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -7.74604 to -7.74713, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8560 - acc: 0.2383 - val_loss: -7.7485 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -7.74713 to -7.74847, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8575 - acc: 0.2383 - val_loss: -7.7504 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -7.74847 to -7.75042, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8584 - acc: 0.2383 - val_loss: -7.7516 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -7.75042 to -7.75155, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.8605 - acc: 0.2383 - val_loss: -7.7529 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -7.75155 to -7.75291, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.8628 - acc: 0.2383 - val_loss: -7.7545 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss improved from -7.75291 to -7.75448, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.8628 - acc: 0.2383 - val_loss: -7.7550 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss improved from -7.75448 to -7.75499, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.8637 - acc: 0.2383 - val_loss: -7.7542 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -7.75499\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.8638 - acc: 0.2383 - val_loss: -7.7570 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss improved from -7.75499 to -7.75700, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.8659 - acc: 0.2383 - val_loss: -7.7586 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss improved from -7.75700 to -7.75861, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8663 - acc: 0.2383 - val_loss: -7.7595 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss improved from -7.75861 to -7.75951, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.8631 - acc: 0.2383 - val_loss: -7.7549 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -7.75951\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 12s 5ms/step - loss: -1.9382 - acc: 0.2262 - val_loss: -7.7080 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.70799, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 886us/step - loss: -8.1104 - acc: 0.2321 - val_loss: -7.9201 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.70799 to -7.92013, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 881us/step - loss: -8.2786 - acc: 0.2321 - val_loss: -8.0815 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.92013 to -8.08145, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.4332 - acc: 0.2321 - val_loss: -8.2385 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.08145 to -8.23846, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.5846 - acc: 0.2321 - val_loss: -8.3823 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.23846 to -8.38235, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -8.7264 - acc: 0.2321 - val_loss: -8.5231 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.38235 to -8.52306, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -8.8666 - acc: 0.2321 - val_loss: -8.6587 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.52306 to -8.65870, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -8.9982 - acc: 0.2321 - val_loss: -8.7912 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.65870 to -8.79118, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.1205 - acc: 0.2321 - val_loss: -8.9111 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.79118 to -8.91108, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2355 - acc: 0.2321 - val_loss: -9.0108 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.91108 to -9.01079, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3343 - acc: 0.2321 - val_loss: -9.1098 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.01079 to -9.10980, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.4215 - acc: 0.2321 - val_loss: -9.1828 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.10980 to -9.18277, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.4917 - acc: 0.2321 - val_loss: -9.2527 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.18277 to -9.25273, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.5512 - acc: 0.2321 - val_loss: -9.3032 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.25273 to -9.30319, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.5971 - acc: 0.2321 - val_loss: -9.3454 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.30319 to -9.34535, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.6312 - acc: 0.2321 - val_loss: -9.3730 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.34535 to -9.37297, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.6415 - acc: 0.2321 - val_loss: -9.3817 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.37297 to -9.38168, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.6596 - acc: 0.2321 - val_loss: -9.3905 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.38168 to -9.39045, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 883us/step - loss: -9.6680 - acc: 0.2321 - val_loss: -9.3984 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.39045 to -9.39839, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 918us/step - loss: -9.6756 - acc: 0.2321 - val_loss: -9.4058 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.39839 to -9.40581, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.6829 - acc: 0.2321 - val_loss: -9.4129 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.40581 to -9.41293, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.6895 - acc: 0.2321 - val_loss: -9.4197 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.41293 to -9.41968, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.6944 - acc: 0.2321 - val_loss: -9.4240 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.41968 to -9.42395, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.6998 - acc: 0.2321 - val_loss: -9.4284 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.42395 to -9.42843, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.7051 - acc: 0.2321 - val_loss: -9.4321 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.42843 to -9.43208, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.7089 - acc: 0.2321 - val_loss: -9.4379 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.43208 to -9.43788, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.7120 - acc: 0.2321 - val_loss: -9.4404 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.43788 to -9.44044, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.7140 - acc: 0.2321 - val_loss: -9.4407 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.44044 to -9.44068, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.7165 - acc: 0.2321 - val_loss: -9.4448 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.44068 to -9.44483, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.7113 - acc: 0.2321 - val_loss: -9.4405 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -9.44483\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.7150 - acc: 0.2321 - val_loss: -9.4418 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -9.44483\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.7163 - acc: 0.2321 - val_loss: -9.4431 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.44483\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.7176 - acc: 0.2321 - val_loss: -9.4446 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.44483\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 880us/step - loss: -9.7185 - acc: 0.2321 - val_loss: -9.4447 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.44483\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.7187 - acc: 0.2321 - val_loss: -9.4449 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss improved from -9.44483 to -9.44494, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.7189 - acc: 0.2321 - val_loss: -9.4452 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.44494 to -9.44520, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.7192 - acc: 0.2321 - val_loss: -9.4455 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss improved from -9.44520 to -9.44554, saving model to model-1.h5\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7196 - acc: 0.2321 - val_loss: -9.4460 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.44554 to -9.44596, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.7200 - acc: 0.2321 - val_loss: -9.4465 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss improved from -9.44596 to -9.44645, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.7206 - acc: 0.2321 - val_loss: -9.4470 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss improved from -9.44645 to -9.44703, saving model to model-1.h5\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 11s 5ms/step - loss: -4.1530 - acc: 0.2317 - val_loss: -7.7818 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.78181, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.1402 - acc: 0.2321 - val_loss: -7.9313 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.78181 to -7.93130, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.2869 - acc: 0.2321 - val_loss: -8.0746 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.93130 to -8.07462, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.4266 - acc: 0.2321 - val_loss: -8.2151 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.07462 to -8.21506, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -8.5643 - acc: 0.2321 - val_loss: -8.3524 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.21506 to -8.35237, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -8.6963 - acc: 0.2321 - val_loss: -8.4941 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.35237 to -8.49411, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -8.8277 - acc: 0.2321 - val_loss: -8.6148 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.49411 to -8.61476, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -8.9548 - acc: 0.2321 - val_loss: -8.7346 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.61476 to -8.73459, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 880us/step - loss: -9.0774 - acc: 0.2321 - val_loss: -8.8578 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.73459 to -8.85781, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.1897 - acc: 0.2321 - val_loss: -8.9755 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.85781 to -8.97549, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2939 - acc: 0.2321 - val_loss: -8.8730 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss did not improve from -8.97549\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.3679 - acc: 0.2321 - val_loss: -9.1368 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.97549 to -9.13677, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.4394 - acc: 0.2321 - val_loss: -9.1998 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.13677 to -9.19982, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.4939 - acc: 0.2321 - val_loss: -9.2455 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.19982 to -9.24551, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.5415 - acc: 0.2321 - val_loss: -9.2930 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.24551 to -9.29303, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.5720 - acc: 0.2321 - val_loss: -9.3113 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.29303 to -9.31126, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.5969 - acc: 0.2321 - val_loss: -9.3368 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.31126 to -9.33676, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.6211 - acc: 0.2321 - val_loss: -9.3594 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.33676 to -9.35941, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.6404 - acc: 0.2321 - val_loss: -9.3756 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.35941 to -9.37555, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.6562 - acc: 0.2321 - val_loss: -9.3910 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.37555 to -9.39098, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.6713 - acc: 0.2321 - val_loss: -9.4051 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.39098 to -9.40513, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.6839 - acc: 0.2321 - val_loss: -9.4102 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.40513 to -9.41020, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.6896 - acc: 0.2321 - val_loss: -9.4220 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.41020 to -9.42202, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.6988 - acc: 0.2321 - val_loss: -9.4300 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.42202 to -9.43003, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.7057 - acc: 0.2321 - val_loss: -9.4350 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.43003 to -9.43500, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.6946 - acc: 0.2321 - val_loss: -9.4329 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -9.43500\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.7073 - acc: 0.2321 - val_loss: -9.4340 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -9.43500\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.7083 - acc: 0.2321 - val_loss: -9.4350 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.43500 to -9.43504, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7094 - acc: 0.2321 - val_loss: -9.4362 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.43504 to -9.43621, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.7107 - acc: 0.2321 - val_loss: -9.4375 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.43621 to -9.43753, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.7121 - acc: 0.2321 - val_loss: -9.4390 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.43753 to -9.43905, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.7137 - acc: 0.2321 - val_loss: -9.4408 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.43905 to -9.44081, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.7156 - acc: 0.2321 - val_loss: -9.4428 - val_acc: 0.2776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss improved from -9.44081 to -9.44282, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.7161 - acc: 0.2321 - val_loss: -9.4411 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.44282\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.7161 - acc: 0.2321 - val_loss: -9.4436 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss improved from -9.44282 to -9.44356, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.7185 - acc: 0.2321 - val_loss: -9.4460 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.44356 to -9.44600, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.7190 - acc: 0.2321 - val_loss: -9.4448 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.44600\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.7202 - acc: 0.2321 - val_loss: -9.4480 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.44600 to -9.44797, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.7150 - acc: 0.2321 - val_loss: -9.4436 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.44797\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.7179 - acc: 0.2321 - val_loss: -9.4445 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.44797\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 11s 5ms/step - loss: -4.7488 - acc: 0.2283 - val_loss: -7.7668 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.76679, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.1115 - acc: 0.2321 - val_loss: -7.9140 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.76679 to -7.91395, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.2499 - acc: 0.2321 - val_loss: -8.0504 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.91395 to -8.05042, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.3845 - acc: 0.2321 - val_loss: -8.1832 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.05042 to -8.18324, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.5162 - acc: 0.2321 - val_loss: -8.3147 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.18324 to -8.31469, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -8.6489 - acc: 0.2321 - val_loss: -8.4473 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.31469 to -8.44727, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.7805 - acc: 0.2321 - val_loss: -8.5789 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.44727 to -8.57887, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -8.9107 - acc: 0.2321 - val_loss: -8.7064 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.57887 to -8.70637, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.0358 - acc: 0.2321 - val_loss: -8.8287 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.70637 to -8.82874, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.1542 - acc: 0.2321 - val_loss: -8.9410 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.82874 to -8.94096, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2629 - acc: 0.2321 - val_loss: -9.0429 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.94096 to -9.04285, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.3580 - acc: 0.2321 - val_loss: -9.1266 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.04285 to -9.12657, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.4360 - acc: 0.2321 - val_loss: -9.2012 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.12657 to -9.20123, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.5040 - acc: 0.2321 - val_loss: -9.2635 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.20123 to -9.26352, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.5569 - acc: 0.2321 - val_loss: -9.3084 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.26352 to -9.30839, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.6024 - acc: 0.2321 - val_loss: -9.1744 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -9.30839\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.6134 - acc: 0.2321 - val_loss: -9.3517 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.30839 to -9.35175, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.6312 - acc: 0.2321 - val_loss: -9.3639 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.35175 to -9.36394, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 888us/step - loss: -9.6430 - acc: 0.2321 - val_loss: -9.3753 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.36394 to -9.37530, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.6541 - acc: 0.2321 - val_loss: -9.3862 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.37530 to -9.38625, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.6645 - acc: 0.2321 - val_loss: -9.3960 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.38625 to -9.39605, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.6747 - acc: 0.2321 - val_loss: -9.4036 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.39605 to -9.40355, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6825 - acc: 0.2321 - val_loss: -9.4146 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.40355 to -9.41463, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.6918 - acc: 0.2321 - val_loss: -9.4207 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.41463 to -9.42072, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.6982 - acc: 0.2321 - val_loss: -9.4230 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.42072 to -9.42298, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.6983 - acc: 0.2321 - val_loss: -9.4263 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.42298 to -9.42626, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.7016 - acc: 0.2321 - val_loss: -9.4295 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.42626 to -9.42952, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.7049 - acc: 0.2321 - val_loss: -9.4329 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.42952 to -9.43288, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.7083 - acc: 0.2321 - val_loss: -9.4364 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.43288 to -9.43640, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7119 - acc: 0.2321 - val_loss: -9.4363 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -9.43640\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.7121 - acc: 0.2321 - val_loss: -9.4406 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.43640 to -9.44059, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7157 - acc: 0.2321 - val_loss: -9.4411 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.44059 to -9.44114, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.7164 - acc: 0.2321 - val_loss: -9.4415 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.44114 to -9.44151, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.7175 - acc: 0.2321 - val_loss: -9.4461 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss improved from -9.44151 to -9.44612, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7196 - acc: 0.2321 - val_loss: -9.4430 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.44612\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.7179 - acc: 0.2321 - val_loss: -9.4453 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.44612\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7201 - acc: 0.2321 - val_loss: -9.4474 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss improved from -9.44612 to -9.44738, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7221 - acc: 0.2321 - val_loss: -9.4493 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.44738 to -9.44930, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.7166 - acc: 0.2321 - val_loss: -9.4453 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.44930\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7194 - acc: 0.2321 - val_loss: -9.4457 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.44930\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 11s 5ms/step - loss: -4.5355 - acc: 0.2338 - val_loss: -7.8179 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.81787, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -8.1526 - acc: 0.2321 - val_loss: -7.9495 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.81787 to -7.94952, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.2794 - acc: 0.2321 - val_loss: -8.0736 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.94952 to -8.07362, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -8.4034 - acc: 0.2321 - val_loss: -8.1975 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.07362 to -8.19751, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.5280 - acc: 0.2321 - val_loss: -8.3227 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.19751 to -8.32272, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.6543 - acc: 0.2321 - val_loss: -8.4498 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.32272 to -8.44977, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.7810 - acc: 0.2321 - val_loss: -8.5761 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.44977 to -8.57609, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.9078 - acc: 0.2321 - val_loss: -8.7019 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.57609 to -8.70186, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.0309 - acc: 0.2321 - val_loss: -8.8243 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.70186 to -8.82429, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.1483 - acc: 0.2321 - val_loss: -8.9361 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.82429 to -8.93605, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2571 - acc: 0.2321 - val_loss: -9.0366 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.93605 to -9.03664, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.3525 - acc: 0.2321 - val_loss: -9.1266 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.03664 to -9.12662, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.4360 - acc: 0.2321 - val_loss: -9.2029 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.12662 to -9.20286, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.5055 - acc: 0.2321 - val_loss: -9.2660 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.20286 to -9.26602, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.5628 - acc: 0.2321 - val_loss: -9.3165 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.26602 to -9.31655, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6081 - acc: 0.2321 - val_loss: -9.3557 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.31655 to -9.35566, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.6417 - acc: 0.2321 - val_loss: -9.3852 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.35566 to -9.38519, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 886us/step - loss: -9.6506 - acc: 0.2321 - val_loss: -9.3863 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.38519 to -9.38629, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6633 - acc: 0.2321 - val_loss: -9.3932 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.38629 to -9.39321, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6701 - acc: 0.2321 - val_loss: -9.3998 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.39321 to -9.39981, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.6766 - acc: 0.2321 - val_loss: -9.4063 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.39981 to -9.40632, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.6831 - acc: 0.2321 - val_loss: -9.4129 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.40632 to -9.41288, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.6898 - acc: 0.2321 - val_loss: -9.4196 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.41288 to -9.41956, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.6964 - acc: 0.2321 - val_loss: -9.4255 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.41956 to -9.42555, saving model to model-4.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7017 - acc: 0.2321 - val_loss: -9.4308 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.42555 to -9.43082, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.7025 - acc: 0.2321 - val_loss: -9.4290 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -9.43082\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7037 - acc: 0.2321 - val_loss: -9.4310 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.43082 to -9.43098, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7058 - acc: 0.2321 - val_loss: -9.4332 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.43098 to -9.43315, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.7081 - acc: 0.2321 - val_loss: -9.4355 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.43315 to -9.43553, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.7106 - acc: 0.2321 - val_loss: -9.4382 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.43553 to -9.43815, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.7133 - acc: 0.2321 - val_loss: -9.4410 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.43815 to -9.44100, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7143 - acc: 0.2321 - val_loss: -9.4416 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.44100 to -9.44163, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.7163 - acc: 0.2321 - val_loss: -9.4433 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.44163 to -9.44325, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.7187 - acc: 0.2321 - val_loss: -9.4455 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss improved from -9.44325 to -9.44550, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 843us/step - loss: -9.6805 - acc: 0.2321 - val_loss: -9.4430 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.44550\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.7170 - acc: 0.2321 - val_loss: -9.4434 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.44550\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7175 - acc: 0.2321 - val_loss: -9.4438 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.44550\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.7179 - acc: 0.2321 - val_loss: -9.4444 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.44550\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7183 - acc: 0.2321 - val_loss: -9.4444 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.44550\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.7183 - acc: 0.2321 - val_loss: -9.4445 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.44550\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 11s 5ms/step - loss: -4.8221 - acc: 0.2385 - val_loss: -7.7940 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.79403, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.1240 - acc: 0.2321 - val_loss: -7.9173 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.79403 to -7.91733, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.2449 - acc: 0.2321 - val_loss: -8.0386 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.91733 to -8.03859, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.3655 - acc: 0.2321 - val_loss: -8.1592 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.03859 to -8.15915, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -8.4872 - acc: 0.2321 - val_loss: -8.2800 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.15915 to -8.27998, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -8.6097 - acc: 0.2321 - val_loss: -8.4039 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.27998 to -8.40388, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.7326 - acc: 0.2321 - val_loss: -8.5286 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.40388 to -8.52861, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -8.8604 - acc: 0.2321 - val_loss: -8.6551 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.52861 to -8.65514, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.9827 - acc: 0.2321 - val_loss: -8.7747 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.65514 to -8.77473, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.1028 - acc: 0.2321 - val_loss: -8.7120 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss did not improve from -8.77473\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.1832 - acc: 0.2321 - val_loss: -8.9553 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.77473 to -8.95526, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.2617 - acc: 0.2321 - val_loss: -9.0265 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.95526 to -9.02654, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.3308 - acc: 0.2321 - val_loss: -9.0931 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.02654 to -9.09312, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.3936 - acc: 0.2321 - val_loss: -9.1519 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.09312 to -9.15188, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.4514 - acc: 0.2321 - val_loss: -8.9369 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -9.15188\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.4812 - acc: 0.2321 - val_loss: -9.2260 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.15188 to -9.22603, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.5124 - acc: 0.2321 - val_loss: -9.2534 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.22603 to -9.25343, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.5393 - acc: 0.2321 - val_loss: -9.2799 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.25343 to -9.27989, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.5651 - acc: 0.2321 - val_loss: -9.3048 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.27989 to -9.30485, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.5900 - acc: 0.2321 - val_loss: -9.3282 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.30485 to -9.32815, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.6130 - acc: 0.2321 - val_loss: -9.3513 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.32815 to -9.35130, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6346 - acc: 0.2321 - val_loss: -9.3731 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.35130 to -9.37311, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.6550 - acc: 0.2321 - val_loss: -9.3842 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.37311 to -9.38424, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.6647 - acc: 0.2321 - val_loss: -9.3984 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.38424 to -9.39845, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.6781 - acc: 0.2321 - val_loss: -9.4109 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.39845 to -9.41090, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.6867 - acc: 0.2321 - val_loss: -9.4179 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.41090 to -9.41787, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.6941 - acc: 0.2321 - val_loss: -9.4235 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.41787 to -9.42353, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7014 - acc: 0.2321 - val_loss: -9.4322 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.42353 to -9.43217, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.7074 - acc: 0.2321 - val_loss: -9.4375 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.43217 to -9.43755, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.7113 - acc: 0.2321 - val_loss: -9.4409 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.43755 to -9.44092, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7153 - acc: 0.2321 - val_loss: -9.4441 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.44092 to -9.44408, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.6410 - acc: 0.2321 - val_loss: -9.4390 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.44408\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7131 - acc: 0.2321 - val_loss: -9.4395 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.44408\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 879us/step - loss: -9.7137 - acc: 0.2321 - val_loss: -9.4401 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.44408\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.7142 - acc: 0.2321 - val_loss: -9.4407 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.44408\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.7146 - acc: 0.2321 - val_loss: -9.4408 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.44408\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.7147 - acc: 0.2321 - val_loss: -9.4409 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.44408\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.7148 - acc: 0.2321 - val_loss: -9.4410 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.44408\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.7149 - acc: 0.2321 - val_loss: -9.4412 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.44408\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.7150 - acc: 0.2321 - val_loss: -9.4412 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.44408\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 11s 5ms/step - loss: -1.7131 - acc: 0.2313 - val_loss: -7.9393 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.93927, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -8.3668 - acc: 0.2321 - val_loss: -8.2632 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.93927 to -8.26324, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.6559 - acc: 0.2321 - val_loss: -8.5171 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.26324 to -8.51713, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.8824 - acc: 0.2321 - val_loss: -8.7146 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.51713 to -8.71455, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.0621 - acc: 0.2321 - val_loss: -8.8715 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.71455 to -8.87147, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.2059 - acc: 0.2321 - val_loss: -9.0017 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.87147 to -9.00170, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3215 - acc: 0.2321 - val_loss: -9.1024 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.00170 to -9.10235, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.4102 - acc: 0.2321 - val_loss: -9.1819 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.10235 to -9.18189, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.4869 - acc: 0.2321 - val_loss: -9.2460 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -9.18189 to -9.24601, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.5397 - acc: 0.2321 - val_loss: -9.2930 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.24601 to -9.29296, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.5860 - acc: 0.2321 - val_loss: -9.3336 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.29296 to -9.33360, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.6216 - acc: 0.2321 - val_loss: -9.3623 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.33360 to -9.36229, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.6472 - acc: 0.2321 - val_loss: -9.3898 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.36229 to -9.38975, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.6616 - acc: 0.2321 - val_loss: -9.3986 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.38975 to -9.39857, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.6791 - acc: 0.2321 - val_loss: -9.4096 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.39857 to -9.40964, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6896 - acc: 0.2321 - val_loss: -9.4241 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.40964 to -9.42406, saving model to model-1.h5\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.6906 - acc: 0.2321 - val_loss: -9.4204 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -9.42406\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.6977 - acc: 0.2321 - val_loss: -9.4279 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.42406 to -9.42789, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.7043 - acc: 0.2321 - val_loss: -9.4313 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.42789 to -9.43130, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7078 - acc: 0.2321 - val_loss: -9.4360 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.43130 to -9.43601, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.7104 - acc: 0.2321 - val_loss: -9.4376 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.43601 to -9.43759, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7135 - acc: 0.2321 - val_loss: -9.4407 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.43759 to -9.44073, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7138 - acc: 0.2321 - val_loss: -9.4419 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.44073 to -9.44185, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.7174 - acc: 0.2321 - val_loss: -9.4440 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.44185 to -9.44398, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7142 - acc: 0.2321 - val_loss: -9.4402 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -9.44398\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.7148 - acc: 0.2321 - val_loss: -9.4419 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -9.44398\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7166 - acc: 0.2321 - val_loss: -9.4437 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -9.44398\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.7183 - acc: 0.2321 - val_loss: -9.4455 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.44398 to -9.44546, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7202 - acc: 0.2321 - val_loss: -9.4473 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.44546 to -9.44733, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.7211 - acc: 0.2321 - val_loss: -9.4483 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.44733 to -9.44829, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.7138 - acc: 0.2321 - val_loss: -9.4441 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -9.44829\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7182 - acc: 0.2321 - val_loss: -9.4446 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.44829\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7188 - acc: 0.2321 - val_loss: -9.4452 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.44829\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7194 - acc: 0.2321 - val_loss: -9.4460 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.44829\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7199 - acc: 0.2321 - val_loss: -9.4460 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.44829\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.7200 - acc: 0.2321 - val_loss: -9.4462 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.44829\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7201 - acc: 0.2321 - val_loss: -9.4463 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.44829\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.7203 - acc: 0.2321 - val_loss: -9.4465 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.44829\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7204 - acc: 0.2321 - val_loss: -9.4465 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.44829\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.7204 - acc: 0.2321 - val_loss: -9.4466 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.44829\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 12s 5ms/step - loss: -4.3608 - acc: 0.2330 - val_loss: -7.8638 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.86376, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -8.2411 - acc: 0.2321 - val_loss: -8.0816 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.86376 to -8.08156, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -8.4455 - acc: 0.2321 - val_loss: -8.2705 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.08156 to -8.27050, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.6181 - acc: 0.2321 - val_loss: -8.4332 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.27050 to -8.43323, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.7712 - acc: 0.2321 - val_loss: -8.5751 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.43323 to -8.57508, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -8.9089 - acc: 0.2321 - val_loss: -8.7048 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.57508 to -8.70480, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.0339 - acc: 0.2321 - val_loss: -8.8240 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.70480 to -8.82403, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.1479 - acc: 0.2321 - val_loss: -8.9332 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.82403 to -8.93317, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2513 - acc: 0.2321 - val_loss: -9.0283 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.93317 to -9.02833, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.3421 - acc: 0.2321 - val_loss: -9.1150 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -9.02833 to -9.11504, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 910us/step - loss: -9.4234 - acc: 0.2321 - val_loss: -9.1891 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.11504 to -9.18912, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.4928 - acc: 0.2321 - val_loss: -9.2506 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.18912 to -9.25062, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.5496 - acc: 0.2321 - val_loss: -9.3016 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.25062 to -9.30162, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.5895 - acc: 0.2321 - val_loss: -9.3356 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.30162 to -9.33561, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.6260 - acc: 0.2321 - val_loss: -9.3683 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.33561 to -9.36826, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.6537 - acc: 0.2321 - val_loss: -9.3921 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.36826 to -9.39209, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.6617 - acc: 0.2321 - val_loss: -9.3914 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -9.39209\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.6695 - acc: 0.2321 - val_loss: -9.4006 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.39209 to -9.40060, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.6784 - acc: 0.2321 - val_loss: -9.4094 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.40060 to -9.40936, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6871 - acc: 0.2321 - val_loss: -9.4178 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.40936 to -9.41783, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6942 - acc: 0.2321 - val_loss: -9.4238 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.41783 to -9.42381, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.7001 - acc: 0.2321 - val_loss: -9.4263 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.42381 to -9.42629, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.6981 - acc: 0.2321 - val_loss: -9.4248 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -9.42629\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.6995 - acc: 0.2321 - val_loss: -9.4267 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.42629 to -9.42672, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7015 - acc: 0.2321 - val_loss: -9.4289 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.42672 to -9.42887, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7038 - acc: 0.2321 - val_loss: -9.4313 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.42887 to -9.43134, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.7065 - acc: 0.2321 - val_loss: -9.4342 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.43134 to -9.43418, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7095 - acc: 0.2321 - val_loss: -9.4374 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.43418 to -9.43738, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.7116 - acc: 0.2321 - val_loss: -9.4352 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -9.43738\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.7110 - acc: 0.2321 - val_loss: -9.4394 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.43738 to -9.43944, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.7150 - acc: 0.2321 - val_loss: -9.4425 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.43944 to -9.44252, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.7146 - acc: 0.2321 - val_loss: -9.4424 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.44252\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.7178 - acc: 0.2321 - val_loss: -9.4422 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.44252\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.7182 - acc: 0.2321 - val_loss: -9.4467 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss improved from -9.44252 to -9.44669, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7197 - acc: 0.2321 - val_loss: -9.4464 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.44669\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7214 - acc: 0.2321 - val_loss: -9.4475 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.44669 to -9.44752, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.7212 - acc: 0.2321 - val_loss: -9.4454 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.44752\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7211 - acc: 0.2321 - val_loss: -9.4492 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.44752 to -9.44924, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6141 - acc: 0.2321 - val_loss: -9.4471 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.44924\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7210 - acc: 0.2321 - val_loss: -9.4473 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.44924\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 12s 5ms/step - loss: -4.4225 - acc: 0.2334 - val_loss: -7.8632 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.86318, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.2254 - acc: 0.2321 - val_loss: -8.0546 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.86318 to -8.05460, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -8.4054 - acc: 0.2321 - val_loss: -8.2217 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.05460 to -8.22166, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -8.5641 - acc: 0.2321 - val_loss: -8.3718 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.22166 to -8.37178, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.7090 - acc: 0.2321 - val_loss: -8.5092 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.37178 to -8.50919, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.8414 - acc: 0.2321 - val_loss: -8.6363 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.50919 to -8.63630, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.9662 - acc: 0.2321 - val_loss: -8.7566 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.63630 to -8.75655, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.0824 - acc: 0.2321 - val_loss: -8.8686 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.75655 to -8.86864, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.1891 - acc: 0.2321 - val_loss: -8.9727 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.86864 to -8.97274, saving model to model-3.h5\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.2884 - acc: 0.2321 - val_loss: -9.0645 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.97274 to -9.06450, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.3745 - acc: 0.2321 - val_loss: -9.1293 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.06450 to -9.12927, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.4285 - acc: 0.2321 - val_loss: -9.1844 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.12927 to -9.18437, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.4808 - acc: 0.2321 - val_loss: -9.2334 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.18437 to -9.23344, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.5269 - acc: 0.2321 - val_loss: -9.2713 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.23344 to -9.27128, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.5637 - acc: 0.2321 - val_loss: -9.3115 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.27128 to -9.31145, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.5964 - acc: 0.2321 - val_loss: -9.3385 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.31145 to -9.33849, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.6261 - acc: 0.2321 - val_loss: -9.3675 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.33849 to -9.36751, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.6407 - acc: 0.2321 - val_loss: -9.3701 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.36751 to -9.37008, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.6482 - acc: 0.2321 - val_loss: -9.3795 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.37008 to -9.37946, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.6575 - acc: 0.2321 - val_loss: -9.3888 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.37946 to -9.38876, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.6669 - acc: 0.2321 - val_loss: -9.3982 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.38876 to -9.39821, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.6758 - acc: 0.2321 - val_loss: -9.4067 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.39821 to -9.40672, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.6804 - acc: 0.2321 - val_loss: -9.4064 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -9.40672\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.6823 - acc: 0.2321 - val_loss: -9.4109 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.40672 to -9.41092, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.6869 - acc: 0.2321 - val_loss: -9.4157 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.41092 to -9.41566, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.6918 - acc: 0.2321 - val_loss: -9.4208 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.41566 to -9.42077, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.6970 - acc: 0.2321 - val_loss: -9.4256 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.42077 to -9.42564, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.7005 - acc: 0.2321 - val_loss: -9.4289 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.42564 to -9.42890, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7054 - acc: 0.2321 - val_loss: -9.4344 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.42890 to -9.43435, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 843us/step - loss: -9.7080 - acc: 0.2321 - val_loss: -9.4345 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.43435 to -9.43454, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7114 - acc: 0.2321 - val_loss: -9.4409 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.43454 to -9.44094, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.7136 - acc: 0.2321 - val_loss: -9.4365 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.44094\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.7109 - acc: 0.2321 - val_loss: -9.4376 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.44094\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7121 - acc: 0.2321 - val_loss: -9.4389 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.44094\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.7134 - acc: 0.2321 - val_loss: -9.4404 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.44094\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7143 - acc: 0.2321 - val_loss: -9.4405 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -9.44094\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.7145 - acc: 0.2321 - val_loss: -9.4408 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.44094\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7147 - acc: 0.2321 - val_loss: -9.4410 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.44094 to -9.44104, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7151 - acc: 0.2321 - val_loss: -9.4414 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss improved from -9.44104 to -9.44141, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.7155 - acc: 0.2321 - val_loss: -9.4419 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss improved from -9.44141 to -9.44188, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 12s 5ms/step - loss: -4.9984 - acc: 0.2321 - val_loss: -7.8393 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.83933, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.2012 - acc: 0.2321 - val_loss: -8.0305 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.83933 to -8.03049, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.3831 - acc: 0.2321 - val_loss: -8.2021 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.03049 to -8.20207, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.5477 - acc: 0.2321 - val_loss: -8.3583 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.20207 to -8.35833, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.6972 - acc: 0.2321 - val_loss: -8.5021 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.35833 to -8.50211, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -8.8350 - acc: 0.2321 - val_loss: -8.6323 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.50211 to -8.63234, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -8.9645 - acc: 0.2321 - val_loss: -8.7590 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.63234 to -8.75901, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.0859 - acc: 0.2321 - val_loss: -8.8690 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.75901 to -8.86901, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.1935 - acc: 0.2321 - val_loss: -8.9791 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.86901 to -8.97912, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 844us/step - loss: -9.2954 - acc: 0.2321 - val_loss: -9.0699 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.97912 to -9.06987, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.3817 - acc: 0.2321 - val_loss: -9.1474 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -9.06987 to -9.14743, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.4547 - acc: 0.2321 - val_loss: -9.2185 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.14743 to -9.21853, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.5175 - acc: 0.2321 - val_loss: -9.2729 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.21853 to -9.27286, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.5692 - acc: 0.2321 - val_loss: -9.3182 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.27286 to -9.31817, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6094 - acc: 0.2321 - val_loss: -9.3413 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.31817 to -9.34126, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6228 - acc: 0.2321 - val_loss: -9.3580 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.34126 to -9.35796, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 844us/step - loss: -9.6388 - acc: 0.2321 - val_loss: -9.3733 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.35796 to -9.37331, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.6537 - acc: 0.2321 - val_loss: -9.3877 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss improved from -9.37331 to -9.38767, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6669 - acc: 0.2321 - val_loss: -9.4000 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.38767 to -9.40003, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.6746 - acc: 0.2321 - val_loss: -9.4065 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.40003 to -9.40650, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.6856 - acc: 0.2321 - val_loss: -9.4179 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.40650 to -9.41788, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.6092 - acc: 0.2321 - val_loss: -9.4189 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.41788 to -9.41894, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6933 - acc: 0.2321 - val_loss: -9.4201 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.41894 to -9.42008, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.6945 - acc: 0.2321 - val_loss: -9.4213 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.42008 to -9.42129, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 844us/step - loss: -9.6958 - acc: 0.2321 - val_loss: -9.4226 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.42129 to -9.42265, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.6972 - acc: 0.2321 - val_loss: -9.4242 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.42265 to -9.42421, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.6989 - acc: 0.2321 - val_loss: -9.4261 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.42421 to -9.42608, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.7009 - acc: 0.2321 - val_loss: -9.4283 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.42608 to -9.42832, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.7034 - acc: 0.2321 - val_loss: -9.4310 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss improved from -9.42832 to -9.43100, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.7066 - acc: 0.2321 - val_loss: -9.4314 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.43100 to -9.43139, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.7070 - acc: 0.2321 - val_loss: -9.4352 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.43139 to -9.43525, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.7100 - acc: 0.2321 - val_loss: -9.4339 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -9.43525\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7095 - acc: 0.2321 - val_loss: -9.4376 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss improved from -9.43525 to -9.43762, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.7131 - acc: 0.2321 - val_loss: -9.4412 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss improved from -9.43762 to -9.44118, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.7152 - acc: 0.2321 - val_loss: -9.4401 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.44118\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.7156 - acc: 0.2321 - val_loss: -9.4436 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.44118 to -9.44359, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.6945 - acc: 0.2321 - val_loss: -9.4407 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -9.44359\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.7147 - acc: 0.2321 - val_loss: -9.4410 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -9.44359\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7150 - acc: 0.2321 - val_loss: -9.4413 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -9.44359\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.7154 - acc: 0.2321 - val_loss: -9.4417 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -9.44359\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 12s 5ms/step - loss: -5.3179 - acc: 0.2346 - val_loss: -7.8466 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.84659, saving model to model-5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -8.1971 - acc: 0.2321 - val_loss: -8.0132 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.84659 to -8.01322, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -8.3560 - acc: 0.2321 - val_loss: -8.1636 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00003: val_loss improved from -8.01322 to -8.16356, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -8.5011 - acc: 0.2321 - val_loss: -8.3022 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00004: val_loss improved from -8.16356 to -8.30219, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -8.6344 - acc: 0.2321 - val_loss: -8.4314 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00005: val_loss improved from -8.30219 to -8.43142, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -8.7636 - acc: 0.2321 - val_loss: -8.5516 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.43142 to -8.55157, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -8.8784 - acc: 0.2321 - val_loss: -8.6680 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.55157 to -8.66799, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -8.9932 - acc: 0.2321 - val_loss: -8.7796 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.66799 to -8.77961, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.1029 - acc: 0.2321 - val_loss: -8.8872 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.77961 to -8.88716, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.2051 - acc: 0.2321 - val_loss: -8.9834 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.88716 to -8.98338, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 881us/step - loss: -9.2993 - acc: 0.2321 - val_loss: -9.0746 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.98338 to -9.07465, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.3823 - acc: 0.2321 - val_loss: -9.1493 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss improved from -9.07465 to -9.14926, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.4561 - acc: 0.2321 - val_loss: -9.2151 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00013: val_loss improved from -9.14926 to -9.21514, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.5172 - acc: 0.2321 - val_loss: -9.2684 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00014: val_loss improved from -9.21514 to -9.26844, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.5641 - acc: 0.2321 - val_loss: -9.3134 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00015: val_loss improved from -9.26844 to -9.31341, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.6008 - acc: 0.2321 - val_loss: -9.3412 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00016: val_loss improved from -9.31341 to -9.34115, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.6289 - acc: 0.2321 - val_loss: -9.3715 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00017: val_loss improved from -9.34115 to -9.37153, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.6052 - acc: 0.2321 - val_loss: -9.3692 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -9.37153\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.6450 - acc: 0.2321 - val_loss: -9.3735 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00019: val_loss improved from -9.37153 to -9.37353, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6493 - acc: 0.2321 - val_loss: -9.3779 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00020: val_loss improved from -9.37353 to -9.37786, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.6537 - acc: 0.2321 - val_loss: -9.3824 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00021: val_loss improved from -9.37786 to -9.38239, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.6585 - acc: 0.2321 - val_loss: -9.3874 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00022: val_loss improved from -9.38239 to -9.38736, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.6637 - acc: 0.2321 - val_loss: -9.3930 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00023: val_loss improved from -9.38736 to -9.39297, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.6697 - acc: 0.2321 - val_loss: -9.3997 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00024: val_loss improved from -9.39297 to -9.39967, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.6760 - acc: 0.2321 - val_loss: -9.4059 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00025: val_loss improved from -9.39967 to -9.40588, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.6840 - acc: 0.2321 - val_loss: -9.4087 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00026: val_loss improved from -9.40588 to -9.40874, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.6860 - acc: 0.2321 - val_loss: -9.4165 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00027: val_loss improved from -9.40874 to -9.41647, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.6932 - acc: 0.2321 - val_loss: -9.4222 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00028: val_loss improved from -9.41647 to -9.42223, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.6958 - acc: 0.2321 - val_loss: -9.4216 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -9.42223\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.6983 - acc: 0.2321 - val_loss: -9.4278 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00030: val_loss improved from -9.42223 to -9.42776, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.7049 - acc: 0.2321 - val_loss: -9.4320 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00031: val_loss improved from -9.42776 to -9.43201, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.7083 - acc: 0.2321 - val_loss: -9.4355 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00032: val_loss improved from -9.43201 to -9.43551, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.7015 - acc: 0.2321 - val_loss: -9.4325 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -9.43551\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7069 - acc: 0.2321 - val_loss: -9.4336 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -9.43551\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.7080 - acc: 0.2321 - val_loss: -9.4347 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -9.43551\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.7091 - acc: 0.2321 - val_loss: -9.4360 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00036: val_loss improved from -9.43551 to -9.43597, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.7105 - acc: 0.2321 - val_loss: -9.4374 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00037: val_loss improved from -9.43597 to -9.43741, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.7120 - acc: 0.2321 - val_loss: -9.4391 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00038: val_loss improved from -9.43741 to -9.43910, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.7142 - acc: 0.2321 - val_loss: -9.4414 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00039: val_loss improved from -9.43910 to -9.44141, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.7153 - acc: 0.2321 - val_loss: -9.4436 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00040: val_loss improved from -9.44141 to -9.44358, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 13s 7ms/step - loss: -2.2688 - acc: 0.2493 - val_loss: -9.1481 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.14805, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -7.0023 - acc: 0.2473 - val_loss: -9.4419 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.14805 to -9.44185, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 901us/step - loss: -7.1620 - acc: 0.2473 - val_loss: -9.5846 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.44185 to -9.58457, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 909us/step - loss: -7.2994 - acc: 0.2473 - val_loss: -9.7174 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.58457 to -9.71743, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 902us/step - loss: -7.4320 - acc: 0.2473 - val_loss: -9.8423 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.71743 to -9.84233, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -7.5524 - acc: 0.2473 - val_loss: -9.9634 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.84233 to -9.96344, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -7.6732 - acc: 0.2473 - val_loss: -10.0823 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.96344 to -10.08233, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 890us/step - loss: -7.7905 - acc: 0.2473 - val_loss: -10.1940 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.08233 to -10.19404, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 889us/step - loss: -7.8959 - acc: 0.2473 - val_loss: -10.3004 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.19404 to -10.30036, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.9999 - acc: 0.2473 - val_loss: -10.4011 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.30036 to -10.40110, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.1000 - acc: 0.2473 - val_loss: -10.4948 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.40110 to -10.49484, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.1897 - acc: 0.2473 - val_loss: -10.5730 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.49484 to -10.57299, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -8.2653 - acc: 0.2473 - val_loss: -10.6492 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.57299 to -10.64917, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.3322 - acc: 0.2473 - val_loss: -10.7098 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.64917 to -10.70976, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 892us/step - loss: -8.3913 - acc: 0.2473 - val_loss: -10.7640 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.70976 to -10.76404, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.4438 - acc: 0.2473 - val_loss: -10.8073 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.76404 to -10.80733, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 893us/step - loss: -8.4838 - acc: 0.2473 - val_loss: -10.8517 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.80733 to -10.85175, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 888us/step - loss: -8.5213 - acc: 0.2473 - val_loss: -10.8849 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.85175 to -10.88488, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -8.5488 - acc: 0.2473 - val_loss: -10.9057 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.88488 to -10.90571, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.5715 - acc: 0.2473 - val_loss: -10.9277 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.90571 to -10.92770, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.5915 - acc: 0.2473 - val_loss: -10.9420 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.92770 to -10.94199, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.6040 - acc: 0.2473 - val_loss: -10.9548 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.94199 to -10.95477, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.6138 - acc: 0.2473 - val_loss: -10.9613 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.95477 to -10.96128, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -8.6229 - acc: 0.2473 - val_loss: -10.9698 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.96128 to -10.96977, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -8.6311 - acc: 0.2473 - val_loss: -10.9782 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.96977 to -10.97822, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -8.6354 - acc: 0.2473 - val_loss: -10.9791 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.97822 to -10.97907, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.6385 - acc: 0.2473 - val_loss: -10.8663 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -10.97907\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -8.6306 - acc: 0.2473 - val_loss: -10.9805 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.97907 to -10.98052, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6378 - acc: 0.2473 - val_loss: -10.9829 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.98052 to -10.98294, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 900us/step - loss: -8.6401 - acc: 0.2473 - val_loss: -10.9852 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.98294 to -10.98519, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 901us/step - loss: -8.6423 - acc: 0.2473 - val_loss: -10.9873 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.98519 to -10.98732, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 889us/step - loss: -8.6452 - acc: 0.2473 - val_loss: -10.9904 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.98732 to -10.99043, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.6455 - acc: 0.2473 - val_loss: -10.9899 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.99043\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.6477 - acc: 0.2473 - val_loss: -10.9906 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.99043 to -10.99064, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.6482 - acc: 0.2473 - val_loss: -10.9928 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.99064 to -10.99282, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -8.6476 - acc: 0.2473 - val_loss: -10.9933 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.99282 to -10.99334, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.6505 - acc: 0.2473 - val_loss: -10.9931 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.99334\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -8.6367 - acc: 0.2473 - val_loss: -10.9901 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.99334\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.6466 - acc: 0.2473 - val_loss: -10.9908 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.99334\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.6474 - acc: 0.2473 - val_loss: -10.9916 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.99334\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 11s 6ms/step - loss: -3.5351 - acc: 0.2457 - val_loss: -9.3415 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.34153, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -7.0595 - acc: 0.2473 - val_loss: -9.4769 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.34153 to -9.47695, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -7.1873 - acc: 0.2473 - val_loss: -9.6011 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.47695 to -9.60110, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -7.3123 - acc: 0.2473 - val_loss: -9.7262 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.60110 to -9.72621, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -7.4324 - acc: 0.2473 - val_loss: -9.8448 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.72621 to -9.84480, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -7.5513 - acc: 0.2473 - val_loss: -9.9584 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.84480 to -9.95845, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -7.6619 - acc: 0.2473 - val_loss: -10.0704 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.95845 to -10.07043, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -7.7742 - acc: 0.2473 - val_loss: -10.1808 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.07043 to -10.18081, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -7.8789 - acc: 0.2473 - val_loss: -10.2807 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.18081 to -10.28068, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -7.9783 - acc: 0.2473 - val_loss: -10.3778 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.28068 to -10.37785, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 891us/step - loss: -8.0749 - acc: 0.2473 - val_loss: -10.4708 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.37785 to -10.47085, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -8.1632 - acc: 0.2473 - val_loss: -10.5492 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.47085 to -10.54923, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -8.2409 - acc: 0.2473 - val_loss: -10.6268 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.54923 to -10.62680, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 888us/step - loss: -8.3090 - acc: 0.2473 - val_loss: -10.6902 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.62680 to -10.69016, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.3736 - acc: 0.2473 - val_loss: -10.7491 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.69016 to -10.74912, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 893us/step - loss: -8.4281 - acc: 0.2473 - val_loss: -10.7989 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.74912 to -10.79895, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 889us/step - loss: -8.4665 - acc: 0.2473 - val_loss: -10.8321 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.79895 to -10.83206, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.5003 - acc: 0.2473 - val_loss: -10.8626 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.83206 to -10.86256, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -8.5316 - acc: 0.2473 - val_loss: -10.8907 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.86256 to -10.89072, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 899us/step - loss: -8.5568 - acc: 0.2473 - val_loss: -10.9132 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.89072 to -10.91322, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.5747 - acc: 0.2473 - val_loss: -10.9268 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.91322 to -10.92682, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -8.5911 - acc: 0.2473 - val_loss: -10.9427 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.92682 to -10.94273, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 908us/step - loss: -8.6044 - acc: 0.2473 - val_loss: -10.9551 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.94273 to -10.95508, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.6146 - acc: 0.2473 - val_loss: -10.9627 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.95508 to -10.96268, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 894us/step - loss: -8.6242 - acc: 0.2473 - val_loss: -10.9671 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.96268 to -10.96711, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.6278 - acc: 0.2473 - val_loss: -10.9769 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.96711 to -10.97695, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 892us/step - loss: -8.6334 - acc: 0.2473 - val_loss: -10.9745 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -10.97695\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -8.6322 - acc: 0.2473 - val_loss: -10.9778 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.97695 to -10.97778, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -8.6353 - acc: 0.2473 - val_loss: -10.9808 - val_acc: 0.2207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_loss improved from -10.97778 to -10.98085, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6383 - acc: 0.2473 - val_loss: -10.9838 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.98085 to -10.98376, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 888us/step - loss: -8.6412 - acc: 0.2473 - val_loss: -10.9866 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.98376 to -10.98656, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -8.6436 - acc: 0.2473 - val_loss: -10.9883 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.98656 to -10.98835, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.6436 - acc: 0.2473 - val_loss: -10.9841 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.98835\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6414 - acc: 0.2473 - val_loss: -10.9865 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.98835\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.6437 - acc: 0.2473 - val_loss: -10.9888 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.98835 to -10.98882, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6460 - acc: 0.2473 - val_loss: -10.9910 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.98882 to -10.99103, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6478 - acc: 0.2473 - val_loss: -10.9922 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.99103 to -10.99218, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.6484 - acc: 0.2473 - val_loss: -10.9891 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.99218\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 891us/step - loss: -8.6462 - acc: 0.2473 - val_loss: -10.9910 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.99218\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -8.6479 - acc: 0.2473 - val_loss: -10.9927 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.99218 to -10.99269, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -2.9824 - acc: 0.2530 - val_loss: -9.3559 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.35590, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 898us/step - loss: -7.0673 - acc: 0.2473 - val_loss: -9.4828 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.35590 to -9.48276, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -7.1896 - acc: 0.2473 - val_loss: -9.6029 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.48276 to -9.60288, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 888us/step - loss: -7.3094 - acc: 0.2473 - val_loss: -9.7205 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.60288 to -9.72052, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.4255 - acc: 0.2473 - val_loss: -9.8357 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.72052 to -9.83575, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -7.5393 - acc: 0.2473 - val_loss: -9.9448 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.83575 to -9.94483, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -7.6482 - acc: 0.2473 - val_loss: -10.0557 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.94483 to -10.05569, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -7.7589 - acc: 0.2473 - val_loss: -10.1619 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.05569 to -10.16195, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -7.8639 - acc: 0.2473 - val_loss: -10.2672 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.16195 to -10.26724, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.9663 - acc: 0.2473 - val_loss: -10.3686 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.26724 to -10.36857, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.0644 - acc: 0.2473 - val_loss: -10.4555 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.36857 to -10.45555, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -8.1499 - acc: 0.2473 - val_loss: -10.5439 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.45555 to -10.54395, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.2335 - acc: 0.2473 - val_loss: -10.6193 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.54395 to -10.61932, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -8.3065 - acc: 0.2473 - val_loss: -10.6898 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.61932 to -10.68976, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.3713 - acc: 0.2473 - val_loss: -10.7453 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.68976 to -10.74526, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.4273 - acc: 0.2473 - val_loss: -10.7975 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.74526 to -10.79746, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.4735 - acc: 0.2473 - val_loss: -10.8423 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.79746 to -10.84227, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.5133 - acc: 0.2473 - val_loss: -10.8774 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.84227 to -10.87743, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.5436 - acc: 0.2473 - val_loss: -10.8986 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.87743 to -10.89865, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.5670 - acc: 0.2473 - val_loss: -10.9255 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.89865 to -10.92553, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5333 - acc: 0.2473 - val_loss: -10.9237 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -10.92553\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -8.5816 - acc: 0.2473 - val_loss: -10.9276 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.92553 to -10.92755, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.5854 - acc: 0.2473 - val_loss: -10.9313 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.92755 to -10.93131, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5892 - acc: 0.2473 - val_loss: -10.9351 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.93131 to -10.93509, saving model to model-3.h5\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.5930 - acc: 0.2473 - val_loss: -10.9390 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.93509 to -10.93901, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.5970 - acc: 0.2473 - val_loss: -10.9432 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.93901 to -10.94318, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6013 - acc: 0.2473 - val_loss: -10.9477 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.94318 to -10.94769, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6060 - acc: 0.2473 - val_loss: -10.9526 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.94769 to -10.95257, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6110 - acc: 0.2473 - val_loss: -10.9579 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.95257 to -10.95785, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6156 - acc: 0.2473 - val_loss: -10.9631 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.95785 to -10.96308, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.6202 - acc: 0.2473 - val_loss: -10.9668 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.96308 to -10.96680, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6254 - acc: 0.2473 - val_loss: -10.9725 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.96680 to -10.97245, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6242 - acc: 0.2473 - val_loss: -10.9710 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -10.97245\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6293 - acc: 0.2473 - val_loss: -10.9758 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.97245 to -10.97584, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.6341 - acc: 0.2473 - val_loss: -10.9804 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.97584 to -10.98038, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.6346 - acc: 0.2473 - val_loss: -10.9772 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.98038\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6345 - acc: 0.2473 - val_loss: -10.9796 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.98038\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6369 - acc: 0.2473 - val_loss: -10.9820 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.98038 to -10.98204, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.6393 - acc: 0.2473 - val_loss: -10.9845 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss improved from -10.98204 to -10.98451, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6418 - acc: 0.2473 - val_loss: -10.9870 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.98451 to -10.98702, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -2.9836 - acc: 0.2478 - val_loss: -9.3488 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.34875, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -7.0564 - acc: 0.2473 - val_loss: -9.4679 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.34875 to -9.46794, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -7.1745 - acc: 0.2473 - val_loss: -9.5820 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.46794 to -9.58197, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -7.2872 - acc: 0.2473 - val_loss: -9.6942 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.58197 to -9.69421, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -7.3975 - acc: 0.2473 - val_loss: -9.8028 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.69421 to -9.80276, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -7.5065 - acc: 0.2473 - val_loss: -9.9137 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.80276 to -9.91373, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.6158 - acc: 0.2473 - val_loss: -10.0209 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.91373 to -10.02091, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -7.7242 - acc: 0.2473 - val_loss: -10.1151 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.02091 to -10.11514, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.8306 - acc: 0.2473 - val_loss: -10.2325 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.11514 to -10.23255, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -7.9332 - acc: 0.2473 - val_loss: -10.3312 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.23255 to -10.33120, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.0298 - acc: 0.2473 - val_loss: -10.4281 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.33120 to -10.42806, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.1242 - acc: 0.2473 - val_loss: -10.5191 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.42806 to -10.51907, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.2104 - acc: 0.2473 - val_loss: -10.6000 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.51907 to -10.60002, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.2840 - acc: 0.2473 - val_loss: -10.6636 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.60002 to -10.66363, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.3477 - acc: 0.2473 - val_loss: -10.7267 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.66363 to -10.72674, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.4050 - acc: 0.2473 - val_loss: -10.7752 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.72674 to -10.77522, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.4519 - acc: 0.2473 - val_loss: -10.8221 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.77522 to -10.82206, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.4931 - acc: 0.2473 - val_loss: -10.8591 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.82206 to -10.85911, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -8.5251 - acc: 0.2473 - val_loss: -10.8805 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.85911 to -10.88051, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.5480 - acc: 0.2473 - val_loss: -10.9058 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.88051 to -10.90579, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.5714 - acc: 0.2473 - val_loss: -10.9269 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.90579 to -10.92692, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.5895 - acc: 0.2473 - val_loss: -10.9381 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.92692 to -10.93807, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6010 - acc: 0.2473 - val_loss: -10.9530 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.93807 to -10.95297, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6128 - acc: 0.2473 - val_loss: -10.9585 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.95297 to -10.95852, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.6198 - acc: 0.2473 - val_loss: -10.9698 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.95852 to -10.96979, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6285 - acc: 0.2473 - val_loss: -10.9764 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.96979 to -10.97642, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6354 - acc: 0.2473 - val_loss: -10.6789 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -10.97642\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6226 - acc: 0.2473 - val_loss: -10.9771 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.97642 to -10.97712, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6339 - acc: 0.2473 - val_loss: -10.9785 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.97712 to -10.97846, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.6353 - acc: 0.2473 - val_loss: -10.9798 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.97846 to -10.97982, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6367 - acc: 0.2473 - val_loss: -10.9812 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.97982 to -10.98124, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.6381 - acc: 0.2473 - val_loss: -10.9828 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.98124 to -10.98277, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6397 - acc: 0.2473 - val_loss: -10.9844 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.98277 to -10.98444, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.6414 - acc: 0.2473 - val_loss: -10.9863 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.98444 to -10.98625, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6433 - acc: 0.2473 - val_loss: -10.9882 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.98625 to -10.98822, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.6446 - acc: 0.2473 - val_loss: -10.9891 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.98822 to -10.98907, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6455 - acc: 0.2473 - val_loss: -10.9888 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.98907\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -8.6461 - acc: 0.2473 - val_loss: -10.9913 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.98907 to -10.99131, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6473 - acc: 0.2473 - val_loss: -10.9920 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss improved from -10.99131 to -10.99204, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.6490 - acc: 0.2473 - val_loss: -10.9924 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.99204 to -10.99238, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -3.8579 - acc: 0.2436 - val_loss: -9.3194 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.31942, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.0231 - acc: 0.2473 - val_loss: -9.4292 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.31942 to -9.42918, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.1311 - acc: 0.2473 - val_loss: -9.5355 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.42918 to -9.53551, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -7.2374 - acc: 0.2473 - val_loss: -9.6421 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.53551 to -9.64210, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.3443 - acc: 0.2473 - val_loss: -9.7492 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.64210 to -9.74922, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -7.4510 - acc: 0.2473 - val_loss: -9.8552 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.74922 to -9.85517, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.5581 - acc: 0.2473 - val_loss: -9.9626 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -9.85517 to -9.96259, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -7.6650 - acc: 0.2473 - val_loss: -10.0707 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -9.96259 to -10.07070, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.7712 - acc: 0.2473 - val_loss: -10.1775 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.07070 to -10.17753, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -7.8766 - acc: 0.2473 - val_loss: -10.2875 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.17753 to -10.28749, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -7.9775 - acc: 0.2473 - val_loss: -10.3771 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.28749 to -10.37711, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.0727 - acc: 0.2473 - val_loss: -10.4677 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.37711 to -10.46774, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.1614 - acc: 0.2473 - val_loss: -10.5526 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.46774 to -10.55264, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.2423 - acc: 0.2473 - val_loss: -10.6284 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.55264 to -10.62843, saving model to model-5.h5\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.3161 - acc: 0.2473 - val_loss: -10.6992 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.62843 to -10.69922, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.3790 - acc: 0.2473 - val_loss: -10.7557 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.69922 to -10.75570, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.4346 - acc: 0.2473 - val_loss: -10.8064 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.75570 to -10.80644, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.4810 - acc: 0.2473 - val_loss: -10.8472 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.80644 to -10.84718, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.5132 - acc: 0.2473 - val_loss: -10.8660 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.84718 to -10.86598, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.5320 - acc: 0.2473 - val_loss: -10.8882 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.86598 to -10.88820, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.5530 - acc: 0.2473 - val_loss: -10.9077 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.88820 to -10.90772, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.5715 - acc: 0.2473 - val_loss: -10.9250 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.90772 to -10.92499, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -8.5874 - acc: 0.2473 - val_loss: -10.9388 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.92499 to -10.93880, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5960 - acc: 0.2473 - val_loss: -10.9450 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.93880 to -10.94502, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -8.6061 - acc: 0.2473 - val_loss: -10.9560 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.94502 to -10.95598, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -8.6155 - acc: 0.2473 - val_loss: -10.9637 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.95598 to -10.96368, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.6218 - acc: 0.2473 - val_loss: -10.9638 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.96368 to -10.96382, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.6219 - acc: 0.2473 - val_loss: -10.9680 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.96382 to -10.96802, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6260 - acc: 0.2473 - val_loss: -10.9721 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.96802 to -10.97206, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6300 - acc: 0.2473 - val_loss: -10.9760 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.97206 to -10.97601, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6339 - acc: 0.2473 - val_loss: -10.9799 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.97601 to -10.97991, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.6378 - acc: 0.2473 - val_loss: -10.9837 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.97991 to -10.98374, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6402 - acc: 0.2473 - val_loss: -10.9859 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.98374 to -10.98588, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.6432 - acc: 0.2473 - val_loss: -10.9887 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.98588 to -10.98866, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6430 - acc: 0.2473 - val_loss: -10.9880 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.98866\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6458 - acc: 0.2473 - val_loss: -10.9916 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.98866 to -10.99161, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6488 - acc: 0.2473 - val_loss: -10.9932 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.99161 to -10.99320, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.6397 - acc: 0.2473 - val_loss: -10.9893 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.99320\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6458 - acc: 0.2473 - val_loss: -10.9900 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.99320\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6465 - acc: 0.2473 - val_loss: -10.9907 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.99320\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -0.0935 - acc: 0.2441 - val_loss: -9.3550 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.35501, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -7.1322 - acc: 0.2473 - val_loss: -9.6263 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.35501 to -9.62632, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -7.3814 - acc: 0.2473 - val_loss: -9.8477 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.62632 to -9.84770, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -7.5872 - acc: 0.2473 - val_loss: -10.0307 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.84770 to -10.03065, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -7.7589 - acc: 0.2473 - val_loss: -10.1884 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -10.03065 to -10.18838, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -7.9045 - acc: 0.2473 - val_loss: -10.3225 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -10.18838 to -10.32246, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.0239 - acc: 0.2473 - val_loss: -10.4323 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -10.32246 to -10.43227, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.1306 - acc: 0.2473 - val_loss: -10.5230 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.43227 to -10.52295, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.2185 - acc: 0.2473 - val_loss: -10.6094 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.52295 to -10.60939, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 909us/step - loss: -8.2973 - acc: 0.2473 - val_loss: -10.6740 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.60939 to -10.67401, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.3593 - acc: 0.2473 - val_loss: -10.7379 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.67401 to -10.73793, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.4158 - acc: 0.2473 - val_loss: -10.7826 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.73793 to -10.78259, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.4598 - acc: 0.2473 - val_loss: -10.8306 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.78259 to -10.83056, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.4972 - acc: 0.2473 - val_loss: -10.8601 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.83056 to -10.86014, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.5291 - acc: 0.2473 - val_loss: -10.8888 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.86014 to -10.88884, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.5569 - acc: 0.2473 - val_loss: -10.9151 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.88884 to -10.91510, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -8.5712 - acc: 0.2473 - val_loss: -10.9262 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.91510 to -10.92624, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.5905 - acc: 0.2473 - val_loss: -10.9434 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.92624 to -10.94344, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.6034 - acc: 0.2473 - val_loss: -10.9544 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.94344 to -10.95441, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6125 - acc: 0.2473 - val_loss: -10.9655 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.95441 to -10.96550, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6182 - acc: 0.2473 - val_loss: -10.9673 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.96550 to -10.96729, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.6270 - acc: 0.2473 - val_loss: -10.9748 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.96729 to -10.97478, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.6294 - acc: 0.2473 - val_loss: -10.9743 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -10.97478\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -8.6335 - acc: 0.2473 - val_loss: -10.9810 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.97478 to -10.98103, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6383 - acc: 0.2473 - val_loss: -10.9828 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.98103 to -10.98279, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.6400 - acc: 0.2473 - val_loss: -10.9855 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.98279 to -10.98548, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.6427 - acc: 0.2473 - val_loss: -10.9874 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.98548 to -10.98745, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.6446 - acc: 0.2473 - val_loss: -10.9905 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.98745 to -10.99050, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6452 - acc: 0.2473 - val_loss: -10.9912 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.99050 to -10.99122, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -8.6467 - acc: 0.2473 - val_loss: -10.9870 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -10.99122\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6444 - acc: 0.2473 - val_loss: -10.9897 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -10.99122\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6470 - acc: 0.2473 - val_loss: -10.9920 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.99122 to -10.99205, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.6492 - acc: 0.2473 - val_loss: -10.9942 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.99205 to -10.99416, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.6506 - acc: 0.2473 - val_loss: -10.9921 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.99416\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6494 - acc: 0.2473 - val_loss: -10.9945 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.99416 to -10.99452, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.6510 - acc: 0.2473 - val_loss: -10.9948 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.99452 to -10.99484, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6513 - acc: 0.2473 - val_loss: -10.9952 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.99484 to -10.99522, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6521 - acc: 0.2473 - val_loss: -10.9966 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.99522 to -10.99660, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -8.5788 - acc: 0.2473 - val_loss: -10.9934 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.99660\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.6497 - acc: 0.2473 - val_loss: -10.9937 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.99660\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -2.6746 - acc: 0.2478 - val_loss: -9.3697 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.36972, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -7.1111 - acc: 0.2473 - val_loss: -9.5633 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.36972 to -9.56330, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.2952 - acc: 0.2473 - val_loss: -9.7355 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.56330 to -9.73554, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.4595 - acc: 0.2473 - val_loss: -9.8899 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.73554 to -9.88993, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -7.6070 - acc: 0.2473 - val_loss: -10.0269 - val_acc: 0.2207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss improved from -9.88993 to -10.02688, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -7.7381 - acc: 0.2473 - val_loss: -10.1491 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -10.02688 to -10.14912, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -7.8560 - acc: 0.2473 - val_loss: -10.2612 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -10.14912 to -10.26119, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -7.9623 - acc: 0.2473 - val_loss: -10.3665 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.26119 to -10.36647, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.0639 - acc: 0.2473 - val_loss: -10.4588 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.36647 to -10.45879, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.1531 - acc: 0.2473 - val_loss: -10.5460 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.45879 to -10.54600, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.2358 - acc: 0.2473 - val_loss: -10.6237 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.54600 to -10.62366, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.3089 - acc: 0.2473 - val_loss: -10.6903 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.62366 to -10.69029, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.3615 - acc: 0.2473 - val_loss: -10.7203 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.69029 to -10.72027, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.3899 - acc: 0.2473 - val_loss: -10.7509 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.72027 to -10.75092, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.4196 - acc: 0.2473 - val_loss: -10.7796 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.75092 to -10.77963, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.4478 - acc: 0.2473 - val_loss: -10.8078 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.77963 to -10.80784, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.4735 - acc: 0.2473 - val_loss: -10.8202 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.80784 to -10.82019, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.4931 - acc: 0.2473 - val_loss: -10.8514 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.82019 to -10.85137, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.5151 - acc: 0.2473 - val_loss: -10.8685 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.85137 to -10.86854, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.5349 - acc: 0.2473 - val_loss: -10.8917 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.86854 to -10.89169, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.5536 - acc: 0.2473 - val_loss: -10.9085 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.89169 to -10.90846, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.5664 - acc: 0.2473 - val_loss: -10.9167 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.90846 to -10.91667, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.5797 - acc: 0.2473 - val_loss: -10.9321 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.91667 to -10.93207, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.5937 - acc: 0.2473 - val_loss: -10.9405 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.93207 to -10.94054, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6027 - acc: 0.2473 - val_loss: -10.9520 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.94054 to -10.95198, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6125 - acc: 0.2473 - val_loss: -10.9619 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.95198 to -10.96194, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6184 - acc: 0.2473 - val_loss: -10.9677 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.96194 to -10.96770, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.6268 - acc: 0.2473 - val_loss: -10.9700 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.96770 to -10.96997, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6308 - acc: 0.2473 - val_loss: -10.9802 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.96997 to -10.98015, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.6341 - acc: 0.2473 - val_loss: -10.9813 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.98015 to -10.98128, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6402 - acc: 0.2473 - val_loss: -10.9867 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.98128 to -10.98665, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.6433 - acc: 0.2473 - val_loss: -10.9842 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -10.98665\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6435 - acc: 0.2473 - val_loss: -10.9909 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.98665 to -10.99091, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.6418 - acc: 0.2473 - val_loss: -10.9860 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.99091\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.6439 - acc: 0.2473 - val_loss: -10.9897 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.99091\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6473 - acc: 0.2473 - val_loss: -10.9927 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.99091 to -10.99271, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6451 - acc: 0.2473 - val_loss: -10.9876 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.99271\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6442 - acc: 0.2473 - val_loss: -10.9884 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.99271\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6450 - acc: 0.2473 - val_loss: -10.9893 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.99271\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6460 - acc: 0.2473 - val_loss: -10.9903 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.99271\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -3.6679 - acc: 0.2467 - val_loss: -9.3467 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.34669, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -7.0942 - acc: 0.2473 - val_loss: -9.5522 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.34669 to -9.55221, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -7.2882 - acc: 0.2473 - val_loss: -9.7319 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.55221 to -9.73185, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -7.4566 - acc: 0.2473 - val_loss: -9.8882 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.73185 to -9.88817, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -7.6039 - acc: 0.2473 - val_loss: -10.0269 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.88817 to -10.02692, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -7.7388 - acc: 0.2473 - val_loss: -10.1493 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -10.02692 to -10.14930, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.8567 - acc: 0.2473 - val_loss: -10.2668 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -10.14930 to -10.26678, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -7.9688 - acc: 0.2473 - val_loss: -10.3711 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.26678 to -10.37110, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.0702 - acc: 0.2473 - val_loss: -10.4667 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.37110 to -10.46665, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.1593 - acc: 0.2473 - val_loss: -10.5498 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.46665 to -10.54979, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.2416 - acc: 0.2473 - val_loss: -10.6298 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.54979 to -10.62985, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.3154 - acc: 0.2473 - val_loss: -10.6983 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.62985 to -10.69831, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.3691 - acc: 0.2473 - val_loss: -10.7370 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.69831 to -10.73701, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.4018 - acc: 0.2473 - val_loss: -10.7567 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.73701 to -10.75675, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.4212 - acc: 0.2473 - val_loss: -10.7759 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.75675 to -10.77591, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.4403 - acc: 0.2473 - val_loss: -10.7949 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.77591 to -10.79492, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.4594 - acc: 0.2473 - val_loss: -10.8141 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.79492 to -10.81412, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.4787 - acc: 0.2473 - val_loss: -10.8338 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.81412 to -10.83377, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.4970 - acc: 0.2473 - val_loss: -10.8517 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.83377 to -10.85172, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.5165 - acc: 0.2473 - val_loss: -10.8705 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.85172 to -10.87050, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.5341 - acc: 0.2473 - val_loss: -10.8869 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.87050 to -10.88689, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.5510 - acc: 0.2473 - val_loss: -10.9060 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.88689 to -10.90600, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5707 - acc: 0.2473 - val_loss: -10.9231 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.90600 to -10.92310, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5850 - acc: 0.2473 - val_loss: -10.9371 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.92310 to -10.93706, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6002 - acc: 0.2473 - val_loss: -10.9470 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.93706 to -10.94698, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6102 - acc: 0.2473 - val_loss: -9.8033 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -10.94698\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.5471 - acc: 0.2473 - val_loss: -10.9568 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.94698 to -10.95680, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6139 - acc: 0.2473 - val_loss: -10.9588 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.95680 to -10.95880, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.6159 - acc: 0.2473 - val_loss: -10.9609 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.95880 to -10.96092, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 891us/step - loss: -8.6181 - acc: 0.2473 - val_loss: -10.9632 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.96092 to -10.96321, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6205 - acc: 0.2473 - val_loss: -10.9657 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.96321 to -10.96574, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6232 - acc: 0.2473 - val_loss: -10.9686 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.96574 to -10.96857, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6261 - acc: 0.2473 - val_loss: -10.9717 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.96857 to -10.97175, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6291 - acc: 0.2473 - val_loss: -10.9743 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.97175 to -10.97426, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6319 - acc: 0.2473 - val_loss: -10.9761 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.97426 to -10.97606, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.6337 - acc: 0.2473 - val_loss: -10.9734 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.97606\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 878us/step - loss: -8.6307 - acc: 0.2473 - val_loss: -10.9758 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.97606\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6330 - acc: 0.2473 - val_loss: -10.9782 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.97606 to -10.97818, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.6355 - acc: 0.2473 - val_loss: -10.9807 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss improved from -10.97818 to -10.98072, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6381 - acc: 0.2473 - val_loss: -10.9834 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.98072 to -10.98341, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -3.1119 - acc: 0.2483 - val_loss: -9.3414 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.34141, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.0672 - acc: 0.2473 - val_loss: -9.5002 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.34141 to -9.50023, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -7.2196 - acc: 0.2473 - val_loss: -9.6446 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.50023 to -9.64460, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -7.3587 - acc: 0.2473 - val_loss: -9.7774 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.64460 to -9.77735, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -7.4874 - acc: 0.2473 - val_loss: -9.9009 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.77735 to -9.90093, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.6068 - acc: 0.2473 - val_loss: -10.0155 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.90093 to -10.01550, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -7.7196 - acc: 0.2473 - val_loss: -10.1256 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -10.01550 to -10.12559, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -7.8282 - acc: 0.2473 - val_loss: -10.1803 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.12559 to -10.18025, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.9206 - acc: 0.2473 - val_loss: -10.3203 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.18025 to -10.32027, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.0158 - acc: 0.2473 - val_loss: -10.4093 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.32027 to -10.40931, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.1023 - acc: 0.2473 - val_loss: -10.4935 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.40931 to -10.49351, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.1848 - acc: 0.2473 - val_loss: -10.5719 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.49351 to -10.57189, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -8.2577 - acc: 0.2473 - val_loss: -10.6424 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.57189 to -10.64241, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.3263 - acc: 0.2473 - val_loss: -10.7050 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.64241 to -10.70497, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 893us/step - loss: -8.3861 - acc: 0.2473 - val_loss: -10.7609 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.70497 to -10.76085, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -8.4399 - acc: 0.2473 - val_loss: -10.7992 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.76085 to -10.79919, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.4610 - acc: 0.2473 - val_loss: -10.8222 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.79919 to -10.82224, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.4880 - acc: 0.2473 - val_loss: -10.8441 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.82224 to -10.84410, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.5092 - acc: 0.2473 - val_loss: -10.8645 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.84410 to -10.86449, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.5289 - acc: 0.2473 - val_loss: -10.8826 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.86449 to -10.88260, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.5468 - acc: 0.2473 - val_loss: -10.9004 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.88260 to -10.90043, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5629 - acc: 0.2473 - val_loss: -10.9152 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.90043 to -10.91515, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.5784 - acc: 0.2473 - val_loss: -10.9276 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.91515 to -10.92758, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.5911 - acc: 0.2473 - val_loss: -10.9389 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.92758 to -10.93891, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -8.6017 - acc: 0.2473 - val_loss: -10.9537 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss improved from -10.93891 to -10.95371, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6128 - acc: 0.2473 - val_loss: -10.9619 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss improved from -10.95371 to -10.96195, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.5320 - acc: 0.2473 - val_loss: -10.9661 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.96195 to -10.96613, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.6229 - acc: 0.2473 - val_loss: -10.9674 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.96613 to -10.96744, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6242 - acc: 0.2473 - val_loss: -10.9688 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.96744 to -10.96877, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.6256 - acc: 0.2473 - val_loss: -10.9701 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.96877 to -10.97015, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6270 - acc: 0.2473 - val_loss: -10.9716 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.97015 to -10.97163, saving model to model-4.h5\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.6285 - acc: 0.2473 - val_loss: -10.9733 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.97163 to -10.97326, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6303 - acc: 0.2473 - val_loss: -10.9751 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.97326 to -10.97509, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.6321 - acc: 0.2473 - val_loss: -10.9759 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss improved from -10.97509 to -10.97590, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 902us/step - loss: -8.6329 - acc: 0.2473 - val_loss: -10.9775 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss improved from -10.97590 to -10.97751, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6349 - acc: 0.2473 - val_loss: -10.9804 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss improved from -10.97751 to -10.98036, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6366 - acc: 0.2473 - val_loss: -10.9811 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss improved from -10.98036 to -10.98115, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.6389 - acc: 0.2473 - val_loss: -10.9831 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss improved from -10.98115 to -10.98311, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6410 - acc: 0.2473 - val_loss: -10.9836 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss improved from -10.98311 to -10.98360, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.6416 - acc: 0.2473 - val_loss: -10.9877 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss improved from -10.98360 to -10.98773, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2200\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 12s 6ms/step - loss: -3.5490 - acc: 0.2499 - val_loss: -9.3896 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -9.38961, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.1069 - acc: 0.2473 - val_loss: -9.5356 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00002: val_loss improved from -9.38961 to -9.53561, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.2528 - acc: 0.2473 - val_loss: -9.6729 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00003: val_loss improved from -9.53561 to -9.67286, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -7.3837 - acc: 0.2473 - val_loss: -9.7973 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00004: val_loss improved from -9.67286 to -9.79729, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -7.5045 - acc: 0.2473 - val_loss: -9.9147 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00005: val_loss improved from -9.79729 to -9.91472, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -7.6193 - acc: 0.2473 - val_loss: -10.0268 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00006: val_loss improved from -9.91472 to -10.02675, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -7.7288 - acc: 0.2473 - val_loss: -10.1318 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00007: val_loss improved from -10.02675 to -10.13180, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -7.8320 - acc: 0.2473 - val_loss: -10.2313 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00008: val_loss improved from -10.13180 to -10.23131, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -7.9296 - acc: 0.2473 - val_loss: -10.3276 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00009: val_loss improved from -10.23131 to -10.32765, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.0250 - acc: 0.2473 - val_loss: -10.4226 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00010: val_loss improved from -10.32765 to -10.42257, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.1136 - acc: 0.2473 - val_loss: -10.5037 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00011: val_loss improved from -10.42257 to -10.50367, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.1944 - acc: 0.2473 - val_loss: -10.5820 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00012: val_loss improved from -10.50367 to -10.58199, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.2698 - acc: 0.2473 - val_loss: -10.6525 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00013: val_loss improved from -10.58199 to -10.65250, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.3378 - acc: 0.2473 - val_loss: -10.7152 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00014: val_loss improved from -10.65250 to -10.71522, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -8.3969 - acc: 0.2473 - val_loss: -10.7731 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00015: val_loss improved from -10.71522 to -10.77308, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.4476 - acc: 0.2473 - val_loss: -10.8165 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00016: val_loss improved from -10.77308 to -10.81648, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.4904 - acc: 0.2473 - val_loss: -10.8588 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from -10.81648 to -10.85875, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5148 - acc: 0.2473 - val_loss: -10.8693 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00018: val_loss improved from -10.85875 to -10.86926, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -8.5341 - acc: 0.2473 - val_loss: -10.8889 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from -10.86926 to -10.88886, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.5528 - acc: 0.2473 - val_loss: -10.9066 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00020: val_loss improved from -10.88886 to -10.90657, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.5696 - acc: 0.2473 - val_loss: -10.9211 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00021: val_loss improved from -10.90657 to -10.92114, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.5837 - acc: 0.2473 - val_loss: -10.9300 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00022: val_loss improved from -10.92114 to -10.92998, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -8.5921 - acc: 0.2473 - val_loss: -10.9434 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00023: val_loss improved from -10.92998 to -10.94336, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.6048 - acc: 0.2473 - val_loss: -10.9552 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00024: val_loss improved from -10.94336 to -10.95523, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.5839 - acc: 0.2473 - val_loss: -10.9522 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -10.95523\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6093 - acc: 0.2473 - val_loss: -10.9541 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -10.95523\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.6112 - acc: 0.2473 - val_loss: -10.9561 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00027: val_loss improved from -10.95523 to -10.95613, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6133 - acc: 0.2473 - val_loss: -10.9583 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00028: val_loss improved from -10.95613 to -10.95829, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -8.6155 - acc: 0.2473 - val_loss: -10.9607 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00029: val_loss improved from -10.95829 to -10.96069, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6181 - acc: 0.2473 - val_loss: -10.9634 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00030: val_loss improved from -10.96069 to -10.96340, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.6209 - acc: 0.2473 - val_loss: -10.9665 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00031: val_loss improved from -10.96340 to -10.96646, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6241 - acc: 0.2473 - val_loss: -10.9699 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00032: val_loss improved from -10.96646 to -10.96992, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.6279 - acc: 0.2473 - val_loss: -10.9740 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00033: val_loss improved from -10.96992 to -10.97403, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.6104 - acc: 0.2473 - val_loss: -10.9701 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -10.97403\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 906us/step - loss: -8.6267 - acc: 0.2473 - val_loss: -10.9710 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -10.97403\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -8.6276 - acc: 0.2473 - val_loss: -10.9720 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -10.97403\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.6287 - acc: 0.2473 - val_loss: -10.9731 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -10.97403\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.6294 - acc: 0.2473 - val_loss: -10.9733 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -10.97403\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -8.6296 - acc: 0.2473 - val_loss: -10.9735 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -10.97403\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 882us/step - loss: -8.6298 - acc: 0.2473 - val_loss: -10.9737 - val_acc: 0.2207\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -10.97403\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -2.5832 - acc: 0.2423 - val_loss: -6.8184 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.81843, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -7.8802 - acc: 0.2426 - val_loss: -7.0527 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.81843 to -7.05273, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 888us/step - loss: -8.0751 - acc: 0.2426 - val_loss: -7.2388 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.05273 to -7.23876, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 3s 906us/step - loss: -8.2542 - acc: 0.2426 - val_loss: -7.4118 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.23876 to -7.41178, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 898us/step - loss: -8.4243 - acc: 0.2426 - val_loss: -7.5775 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.41178 to -7.57747, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -8.5853 - acc: 0.2426 - val_loss: -7.7330 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.57747 to -7.73296, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -8.7357 - acc: 0.2426 - val_loss: -7.8778 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.73296 to -7.87779, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -8.8741 - acc: 0.2426 - val_loss: -8.0063 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.87779 to -8.00629, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.9953 - acc: 0.2426 - val_loss: -8.1194 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.00629 to -8.11940, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.0994 - acc: 0.2426 - val_loss: -8.2075 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.11940 to -8.20750, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.1811 - acc: 0.2426 - val_loss: -8.2864 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.20750 to -8.28644, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.2497 - acc: 0.2426 - val_loss: -8.3394 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.28644 to -8.33945, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.2975 - acc: 0.2426 - val_loss: -8.3764 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.33945 to -8.37643, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.3291 - acc: 0.2426 - val_loss: -8.4114 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.37643 to -8.41139, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.3565 - acc: 0.2426 - val_loss: -8.4324 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.41139 to -8.43238, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.3747 - acc: 0.2426 - val_loss: -8.4466 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.43238 to -8.44662, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.3863 - acc: 0.2426 - val_loss: -8.4556 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.44662 to -8.45565, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.3967 - acc: 0.2426 - val_loss: -8.4655 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.45565 to -8.46550, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.4005 - acc: 0.2426 - val_loss: -8.4695 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.46550 to -8.46955, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.4043 - acc: 0.2426 - val_loss: -8.4720 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.46955 to -8.47199, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.4093 - acc: 0.2426 - val_loss: -8.4759 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.47199 to -8.47591, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4119 - acc: 0.2426 - val_loss: -8.4758 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -8.47591\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.4130 - acc: 0.2426 - val_loss: -8.4785 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.47591 to -8.47847, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.4128 - acc: 0.2426 - val_loss: -8.4772 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -8.47847\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 882us/step - loss: -9.4145 - acc: 0.2426 - val_loss: -8.4807 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.47847 to -8.48066, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.4156 - acc: 0.2426 - val_loss: -8.4799 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.48066\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4157 - acc: 0.2426 - val_loss: -8.4798 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.48066\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.3994 - acc: 0.2426 - val_loss: -8.4779 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.48066\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4137 - acc: 0.2426 - val_loss: -8.4783 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.48066\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.4139 - acc: 0.2426 - val_loss: -8.4783 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.48066\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4139 - acc: 0.2426 - val_loss: -8.4784 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.48066\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.4139 - acc: 0.2426 - val_loss: -8.4784 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.48066\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4140 - acc: 0.2426 - val_loss: -8.4785 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.48066\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.4141 - acc: 0.2426 - val_loss: -8.4785 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.48066\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4141 - acc: 0.2426 - val_loss: -8.4785 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.48066\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.4141 - acc: 0.2426 - val_loss: -8.4786 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.48066\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.4141 - acc: 0.2426 - val_loss: -8.4786 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.48066\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.4142 - acc: 0.2426 - val_loss: -8.4786 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.48066\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4142 - acc: 0.2426 - val_loss: -8.4787 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.48066\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4143 - acc: 0.2426 - val_loss: -8.4787 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.48066\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -4.4087 - acc: 0.2419 - val_loss: -6.8713 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.87125, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -7.8934 - acc: 0.2426 - val_loss: -7.0568 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.87125 to -7.05685, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.0726 - acc: 0.2426 - val_loss: -7.2283 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.05685 to -7.22828, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -8.2406 - acc: 0.2426 - val_loss: -7.3931 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.22828 to -7.39312, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -8.4027 - acc: 0.2426 - val_loss: -7.5442 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.39312 to -7.54423, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -8.5542 - acc: 0.2426 - val_loss: -7.7004 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.54423 to -7.70045, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -8.7023 - acc: 0.2426 - val_loss: -7.8432 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.70045 to -7.84322, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -8.8404 - acc: 0.2426 - val_loss: -7.9671 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.84322 to -7.96714, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -8.9622 - acc: 0.2426 - val_loss: -8.0872 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.96714 to -8.08718, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.0696 - acc: 0.2426 - val_loss: -8.1857 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.08718 to -8.18569, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.1580 - acc: 0.2426 - val_loss: -8.2649 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.18569 to -8.26486, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.2300 - acc: 0.2426 - val_loss: -8.3271 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.26486 to -8.32711, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.2847 - acc: 0.2426 - val_loss: -8.3683 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.32711 to -8.36828, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3234 - acc: 0.2426 - val_loss: -8.4067 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.36828 to -8.40672, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -9.3535 - acc: 0.2426 - val_loss: -8.4317 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.40672 to -8.43171, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 882us/step - loss: -9.3675 - acc: 0.2426 - val_loss: -8.4370 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.43171 to -8.43702, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 3s 906us/step - loss: -9.3780 - acc: 0.2426 - val_loss: -8.4483 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.43702 to -8.44827, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.3881 - acc: 0.2426 - val_loss: -8.4567 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.44827 to -8.45668, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.3944 - acc: 0.2426 - val_loss: -8.4636 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.45668 to -8.46357, saving model to model-2.h5\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.3934 - acc: 0.2426 - val_loss: -8.4594 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -8.46357\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.3968 - acc: 0.2426 - val_loss: -8.4633 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -8.46357\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.4007 - acc: 0.2426 - val_loss: -8.4673 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.46357 to -8.46727, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.4047 - acc: 0.2426 - val_loss: -8.4687 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.46727 to -8.46871, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.4064 - acc: 0.2426 - val_loss: -8.4710 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.46871 to -8.47104, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4086 - acc: 0.2426 - val_loss: -8.4746 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.47104 to -8.47463, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 887us/step - loss: -9.4054 - acc: 0.2426 - val_loss: -8.4706 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.47463\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.4069 - acc: 0.2426 - val_loss: -8.4723 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.47463\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4087 - acc: 0.2426 - val_loss: -8.4741 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.47463\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.4106 - acc: 0.2426 - val_loss: -8.4761 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.47463 to -8.47613, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.4107 - acc: 0.2426 - val_loss: -8.4730 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.47613\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.4090 - acc: 0.2426 - val_loss: -8.4740 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.47613\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.4101 - acc: 0.2426 - val_loss: -8.4751 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.47613\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4112 - acc: 0.2426 - val_loss: -8.4764 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.47613 to -8.47637, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4126 - acc: 0.2426 - val_loss: -8.4778 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.47637 to -8.47781, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.4134 - acc: 0.2426 - val_loss: -8.4759 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.47781\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.4123 - acc: 0.2426 - val_loss: -8.4779 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.47781 to -8.47786, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4143 - acc: 0.2426 - val_loss: -8.4798 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.47786 to -8.47979, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 880us/step - loss: -9.4153 - acc: 0.2426 - val_loss: -8.4798 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.47979 to -8.47983, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4144 - acc: 0.2426 - val_loss: -8.4788 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.47983\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4155 - acc: 0.2426 - val_loss: -8.4801 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.47983 to -8.48006, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -4.6839 - acc: 0.2430 - val_loss: -6.8544 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.85437, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -7.8626 - acc: 0.2426 - val_loss: -7.0114 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.85437 to -7.01144, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -8.0168 - acc: 0.2426 - val_loss: -7.1620 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.01144 to -7.16201, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -8.1666 - acc: 0.2426 - val_loss: -7.3102 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.16201 to -7.31018, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.3142 - acc: 0.2426 - val_loss: -7.4589 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.31018 to -7.45886, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -8.4620 - acc: 0.2426 - val_loss: -7.6053 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.45886 to -7.60535, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -8.6080 - acc: 0.2426 - val_loss: -7.7516 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.60535 to -7.75161, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.7502 - acc: 0.2426 - val_loss: -7.8879 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.75161 to -7.88794, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -8.8796 - acc: 0.2426 - val_loss: -8.0102 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.88794 to -8.01021, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -8.9981 - acc: 0.2426 - val_loss: -8.1205 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.01021 to -8.12054, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.0991 - acc: 0.2426 - val_loss: -8.1538 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.12054 to -8.15383, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.1773 - acc: 0.2426 - val_loss: -8.2742 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.15383 to -8.27420, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.2391 - acc: 0.2426 - val_loss: -8.3344 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.27420 to -8.33438, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.2808 - acc: 0.2426 - val_loss: -8.3582 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.33438 to -8.35817, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.3057 - acc: 0.2426 - val_loss: -8.3834 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.35817 to -8.38341, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.3293 - acc: 0.2426 - val_loss: -8.4053 - val_acc: 0.2710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from -8.38341 to -8.40526, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.3476 - acc: 0.2426 - val_loss: -8.4195 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.40526 to -8.41954, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.3626 - acc: 0.2426 - val_loss: -8.4358 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.41954 to -8.43584, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.3771 - acc: 0.2426 - val_loss: -8.4483 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.43584 to -8.44834, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3867 - acc: 0.2426 - val_loss: -8.4577 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.44834 to -8.45766, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.3869 - acc: 0.2426 - val_loss: -8.4548 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -8.45766\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.3915 - acc: 0.2426 - val_loss: -8.4573 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -8.45766\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.3940 - acc: 0.2426 - val_loss: -8.4599 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.45766 to -8.45990, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3968 - acc: 0.2426 - val_loss: -8.4628 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.45990 to -8.46284, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.3999 - acc: 0.2426 - val_loss: -8.4662 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.46284 to -8.46616, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3996 - acc: 0.2426 - val_loss: -8.4643 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.46616\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4003 - acc: 0.2426 - val_loss: -8.4653 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.46616\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 880us/step - loss: -9.4013 - acc: 0.2426 - val_loss: -8.4664 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.46616 to -8.46638, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 879us/step - loss: -9.4025 - acc: 0.2426 - val_loss: -8.4677 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.46638 to -8.46769, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.4040 - acc: 0.2426 - val_loss: -8.4693 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.46769 to -8.46932, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.4058 - acc: 0.2426 - val_loss: -8.4713 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.46932 to -8.47128, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4078 - acc: 0.2426 - val_loss: -8.4730 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.47128 to -8.47302, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.4085 - acc: 0.2426 - val_loss: -8.4739 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.47302 to -8.47393, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4105 - acc: 0.2426 - val_loss: -8.4731 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.47393\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4106 - acc: 0.2426 - val_loss: -8.4772 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.47393 to -8.47716, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.4005 - acc: 0.2426 - val_loss: -8.4733 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.47716\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4091 - acc: 0.2426 - val_loss: -8.4738 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47716\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4096 - acc: 0.2426 - val_loss: -8.4743 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.47716\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.4102 - acc: 0.2426 - val_loss: -8.4750 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.47716\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.4106 - acc: 0.2426 - val_loss: -8.4750 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.47716\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -5.1920 - acc: 0.2462 - val_loss: -6.8678 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.86778, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -7.8780 - acc: 0.2426 - val_loss: -7.0271 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.86778 to -7.02706, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -8.0322 - acc: 0.2426 - val_loss: -7.1791 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.02706 to -7.17914, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.1838 - acc: 0.2426 - val_loss: -7.3289 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.17914 to -7.32892, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.3326 - acc: 0.2426 - val_loss: -7.4771 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.32892 to -7.47714, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.4811 - acc: 0.2426 - val_loss: -7.6236 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.47714 to -7.62361, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -8.6254 - acc: 0.2426 - val_loss: -7.7673 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.62361 to -7.76726, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.7660 - acc: 0.2426 - val_loss: -7.9027 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.76726 to -7.90266, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -8.8948 - acc: 0.2426 - val_loss: -8.0224 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.90266 to -8.02238, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.0055 - acc: 0.2426 - val_loss: -8.1229 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.02238 to -8.12288, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.1015 - acc: 0.2426 - val_loss: -8.2122 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.12288 to -8.21224, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.1824 - acc: 0.2426 - val_loss: -8.2839 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.21224 to -8.28393, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.2463 - acc: 0.2426 - val_loss: -8.3397 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.28393 to -8.33965, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.2967 - acc: 0.2426 - val_loss: -8.3842 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.33965 to -8.38423, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.3352 - acc: 0.2426 - val_loss: -8.4152 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.38423 to -8.41524, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.3560 - acc: 0.2426 - val_loss: -8.4238 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.41524 to -8.42377, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.3631 - acc: 0.2426 - val_loss: -8.4319 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.42377 to -8.43187, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.3709 - acc: 0.2426 - val_loss: -8.4394 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.43187 to -8.43943, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.3784 - acc: 0.2426 - val_loss: -8.4468 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.43943 to -8.44678, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.3857 - acc: 0.2426 - val_loss: -8.4541 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.44678 to -8.45409, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.3913 - acc: 0.2426 - val_loss: -8.4587 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.45409 to -8.45866, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.3965 - acc: 0.2426 - val_loss: -8.4610 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.45866 to -8.46099, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.3998 - acc: 0.2426 - val_loss: -8.4678 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.46099 to -8.46784, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4046 - acc: 0.2426 - val_loss: -8.4720 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.46784 to -8.47199, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.3817 - acc: 0.2426 - val_loss: -8.4686 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -8.47199\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.4044 - acc: 0.2426 - val_loss: -8.4692 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.47199\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.4050 - acc: 0.2426 - val_loss: -8.4699 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.47199\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.4058 - acc: 0.2426 - val_loss: -8.4706 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.47199\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -9.4062 - acc: 0.2426 - val_loss: -8.4707 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.47199\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.4064 - acc: 0.2426 - val_loss: -8.4709 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.47199\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4065 - acc: 0.2426 - val_loss: -8.4711 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.47199\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.4068 - acc: 0.2426 - val_loss: -8.4713 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.47199\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4069 - acc: 0.2426 - val_loss: -8.4714 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.47199\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.4070 - acc: 0.2426 - val_loss: -8.4714 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.47199\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.4070 - acc: 0.2426 - val_loss: -8.4715 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.47199\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.4071 - acc: 0.2426 - val_loss: -8.4716 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.47199\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.4072 - acc: 0.2426 - val_loss: -8.4717 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47199\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.4073 - acc: 0.2426 - val_loss: -8.4718 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.47199\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.4074 - acc: 0.2426 - val_loss: -8.4720 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.47199\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.4076 - acc: 0.2426 - val_loss: -8.4721 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.47199 to -8.47211, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -5.0707 - acc: 0.2434 - val_loss: -6.8872 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.88721, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -7.9026 - acc: 0.2426 - val_loss: -7.0580 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.88721 to -7.05804, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -8.0667 - acc: 0.2426 - val_loss: -7.2166 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.05804 to -7.21658, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.2244 - acc: 0.2426 - val_loss: -7.3724 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.21658 to -7.37241, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.3768 - acc: 0.2426 - val_loss: -7.5201 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.37241 to -7.52009, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.5233 - acc: 0.2426 - val_loss: -7.6652 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.52009 to -7.66518, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -8.6652 - acc: 0.2426 - val_loss: -7.8040 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.66518 to -7.80401, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.8003 - acc: 0.2426 - val_loss: -7.9337 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.80401 to -7.93374, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.9249 - acc: 0.2426 - val_loss: -8.0521 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.93374 to -8.05214, saving model to model-5.h5\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.0312 - acc: 0.2426 - val_loss: -8.1485 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.05214 to -8.14854, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.1216 - acc: 0.2426 - val_loss: -8.2270 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.14854 to -8.22703, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.1938 - acc: 0.2426 - val_loss: -8.2930 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.22703 to -8.29295, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.2531 - acc: 0.2426 - val_loss: -8.3441 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.29295 to -8.34412, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.2996 - acc: 0.2426 - val_loss: -8.3776 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.34412 to -8.37765, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.3283 - acc: 0.2426 - val_loss: -8.4089 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.37765 to -8.40885, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.3479 - acc: 0.2426 - val_loss: -8.4156 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.40885 to -8.41559, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.3548 - acc: 0.2426 - val_loss: -8.4235 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.41559 to -8.42347, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.3625 - acc: 0.2426 - val_loss: -8.4310 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.42347 to -8.43104, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.3701 - acc: 0.2426 - val_loss: -8.4387 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.43104 to -8.43866, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.3778 - acc: 0.2426 - val_loss: -8.4465 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.43866 to -8.44650, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.3848 - acc: 0.2426 - val_loss: -8.4525 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.44650 to -8.45250, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.3911 - acc: 0.2426 - val_loss: -8.4590 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.45250 to -8.45903, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.3970 - acc: 0.2426 - val_loss: -8.4652 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.45903 to -8.46518, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 838us/step - loss: -9.4021 - acc: 0.2426 - val_loss: -8.4693 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.46518 to -8.46931, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 835us/step - loss: -9.4060 - acc: 0.2426 - val_loss: -8.4733 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.46931 to -8.47331, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.4079 - acc: 0.2426 - val_loss: -8.4744 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.47331 to -8.47444, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 881us/step - loss: -9.4111 - acc: 0.2426 - val_loss: -8.4765 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.47444 to -8.47651, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4124 - acc: 0.2426 - val_loss: -8.4781 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.47651 to -8.47809, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.4137 - acc: 0.2426 - val_loss: -8.4791 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.47809 to -8.47909, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.3427 - acc: 0.2426 - val_loss: -8.4759 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.47909\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.4115 - acc: 0.2426 - val_loss: -8.4761 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.47909\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.4117 - acc: 0.2426 - val_loss: -8.4763 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.47909\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.4120 - acc: 0.2426 - val_loss: -8.4766 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.47909\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.4122 - acc: 0.2426 - val_loss: -8.4766 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.47909\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.4122 - acc: 0.2426 - val_loss: -8.4767 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.47909\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4123 - acc: 0.2426 - val_loss: -8.4768 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.47909\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4124 - acc: 0.2426 - val_loss: -8.4769 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47909\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.4124 - acc: 0.2426 - val_loss: -8.4769 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.47909\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.4124 - acc: 0.2426 - val_loss: -8.4769 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.47909\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.4125 - acc: 0.2426 - val_loss: -8.4769 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.47909\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -2.6545 - acc: 0.2462 - val_loss: -6.9881 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.98807, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -8.1044 - acc: 0.2426 - val_loss: -7.3603 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.98807 to -7.36026, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -8.4301 - acc: 0.2426 - val_loss: -7.6358 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.36026 to -7.63580, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -8.6731 - acc: 0.2426 - val_loss: -7.8465 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.63580 to -7.84650, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -8.8607 - acc: 0.2426 - val_loss: -8.0051 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.84650 to -8.00515, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.0025 - acc: 0.2426 - val_loss: -8.1334 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.00515 to -8.13345, saving model to model-1.h5\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.1091 - acc: 0.2426 - val_loss: -8.2259 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.13345 to -8.22593, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -9.1894 - acc: 0.2426 - val_loss: -8.2901 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.22593 to -8.29014, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 872us/step - loss: -9.2527 - acc: 0.2426 - val_loss: -8.3450 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.29014 to -8.34503, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 3s 918us/step - loss: -9.3000 - acc: 0.2426 - val_loss: -8.3850 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.34503 to -8.38504, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 3s 912us/step - loss: -9.3334 - acc: 0.2426 - val_loss: -8.4114 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.38504 to -8.41140, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.3551 - acc: 0.2426 - val_loss: -8.4272 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.41140 to -8.42719, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.3723 - acc: 0.2426 - val_loss: -8.4438 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.42719 to -8.44383, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3843 - acc: 0.2426 - val_loss: -8.4555 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.44383 to -8.45548, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.3920 - acc: 0.2426 - val_loss: -8.4615 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.45548 to -8.46146, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.3991 - acc: 0.2426 - val_loss: -8.4668 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.46146 to -8.46679, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4029 - acc: 0.2426 - val_loss: -8.4624 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -8.46679\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4004 - acc: 0.2426 - val_loss: -8.4676 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.46679 to -8.46759, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.4052 - acc: 0.2426 - val_loss: -8.4720 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.46759 to -8.47201, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4088 - acc: 0.2426 - val_loss: -8.4744 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.47201 to -8.47442, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.4103 - acc: 0.2426 - val_loss: -8.4760 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.47442 to -8.47599, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4070 - acc: 0.2426 - val_loss: -8.4717 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -8.47599\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4080 - acc: 0.2426 - val_loss: -8.4733 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -8.47599\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.4096 - acc: 0.2426 - val_loss: -8.4750 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -8.47599\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 873us/step - loss: -9.4114 - acc: 0.2426 - val_loss: -8.4769 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.47599 to -8.47689, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4128 - acc: 0.2426 - val_loss: -8.4779 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.47689 to -8.47786, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.4130 - acc: 0.2426 - val_loss: -8.4784 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.47786 to -8.47844, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4127 - acc: 0.2426 - val_loss: -8.4744 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.47844\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.4102 - acc: 0.2426 - val_loss: -8.4750 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.47844\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.4109 - acc: 0.2426 - val_loss: -8.4757 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.47844\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -9.4116 - acc: 0.2426 - val_loss: -8.4765 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.47844\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.4121 - acc: 0.2426 - val_loss: -8.4766 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.47844\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 836us/step - loss: -9.4122 - acc: 0.2426 - val_loss: -8.4767 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.47844\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4123 - acc: 0.2426 - val_loss: -8.4769 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.47844\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4126 - acc: 0.2426 - val_loss: -8.4772 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.47844\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4127 - acc: 0.2426 - val_loss: -8.4772 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.47844\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4128 - acc: 0.2426 - val_loss: -8.4772 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47844\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -9.4128 - acc: 0.2426 - val_loss: -8.4773 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.47844\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 869us/step - loss: -9.4129 - acc: 0.2426 - val_loss: -8.4774 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.47844\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.4130 - acc: 0.2426 - val_loss: -8.4775 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.47844\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -3.9715 - acc: 0.2505 - val_loss: -6.9549 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.95491, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.0098 - acc: 0.2426 - val_loss: -7.2054 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.95491 to -7.20542, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -8.2399 - acc: 0.2426 - val_loss: -7.4132 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.20542 to -7.41322, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.4343 - acc: 0.2426 - val_loss: -7.5946 - val_acc: 0.2710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from -7.41322 to -7.59458, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.6041 - acc: 0.2426 - val_loss: -7.7539 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.59458 to -7.75387, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -8.7540 - acc: 0.2426 - val_loss: -7.8921 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.75387 to -7.89207, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -8.8874 - acc: 0.2426 - val_loss: -8.0162 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.89207 to -8.01625, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.0015 - acc: 0.2426 - val_loss: -8.1211 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.01625 to -8.12114, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 844us/step - loss: -9.1003 - acc: 0.2426 - val_loss: -8.2110 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.12114 to -8.21096, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.1832 - acc: 0.2426 - val_loss: -8.2870 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.21096 to -8.28699, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.2468 - acc: 0.2426 - val_loss: -8.3360 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.28699 to -8.33599, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.2930 - acc: 0.2426 - val_loss: -8.3771 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.33599 to -8.37713, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.3273 - acc: 0.2426 - val_loss: -8.4087 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.37713 to -8.40871, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.3457 - acc: 0.2426 - val_loss: -8.4143 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.40871 to -8.41427, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.3560 - acc: 0.2426 - val_loss: -8.4275 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.41427 to -8.42747, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 842us/step - loss: -9.3686 - acc: 0.2426 - val_loss: -8.4394 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.42747 to -8.43936, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.3791 - acc: 0.2426 - val_loss: -8.4481 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.43936 to -8.44806, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.3860 - acc: 0.2426 - val_loss: -8.4549 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.44806 to -8.45486, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 843us/step - loss: -9.3926 - acc: 0.2426 - val_loss: -8.4613 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.45486 to -8.46131, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.3951 - acc: 0.2426 - val_loss: -8.4589 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -8.46131\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.3952 - acc: 0.2426 - val_loss: -8.4606 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -8.46131\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 845us/step - loss: -9.3969 - acc: 0.2426 - val_loss: -8.4624 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.46131 to -8.46236, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 846us/step - loss: -9.3989 - acc: 0.2426 - val_loss: -8.4645 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.46236 to -8.46446, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.4011 - acc: 0.2426 - val_loss: -8.4669 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.46446 to -8.46693, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 3s 906us/step - loss: -9.4038 - acc: 0.2426 - val_loss: -8.4698 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.46693 to -8.46982, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 879us/step - loss: -9.4052 - acc: 0.2426 - val_loss: -8.4711 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.46982 to -8.47106, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.4073 - acc: 0.2426 - val_loss: -8.4715 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.47106 to -8.47152, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.4053 - acc: 0.2426 - val_loss: -8.4683 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.47152\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.4049 - acc: 0.2426 - val_loss: -8.4705 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.47152\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.4072 - acc: 0.2426 - val_loss: -8.4729 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.47152 to -8.47292, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 843us/step - loss: -9.4096 - acc: 0.2426 - val_loss: -8.4754 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.47292 to -8.47544, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4111 - acc: 0.2426 - val_loss: -8.4778 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.47544 to -8.47778, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.4083 - acc: 0.2426 - val_loss: -8.4734 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.47778\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.4099 - acc: 0.2426 - val_loss: -8.4755 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.47778\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.4120 - acc: 0.2426 - val_loss: -8.4776 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.47778\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.4131 - acc: 0.2426 - val_loss: -8.4786 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.47778 to -8.47855, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4137 - acc: 0.2426 - val_loss: -8.4771 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47855\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4140 - acc: 0.2426 - val_loss: -8.4779 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.47855\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 843us/step - loss: -9.4147 - acc: 0.2426 - val_loss: -8.4790 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.47855 to -8.47897, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4098 - acc: 0.2426 - val_loss: -8.4748 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.47897\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 13s 5ms/step - loss: -4.4411 - acc: 0.2459 - val_loss: -6.9013 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.90135, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -7.9337 - acc: 0.2426 - val_loss: -7.1057 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.90135 to -7.10572, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -8.1255 - acc: 0.2426 - val_loss: -7.2845 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.10572 to -7.28453, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.2954 - acc: 0.2426 - val_loss: -7.4440 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.28453 to -7.44404, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.4485 - acc: 0.2426 - val_loss: -7.5913 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.44404 to -7.59129, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -8.5925 - acc: 0.2426 - val_loss: -7.7305 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.59129 to -7.73048, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 3s 899us/step - loss: -8.7284 - acc: 0.2426 - val_loss: -7.8635 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.73048 to -7.86351, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -8.8568 - acc: 0.2426 - val_loss: -7.9758 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.86351 to -7.97575, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -8.9639 - acc: 0.2426 - val_loss: -8.0870 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.97575 to -8.08704, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 874us/step - loss: -9.0646 - acc: 0.2426 - val_loss: -8.1781 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.08704 to -8.17808, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.1463 - acc: 0.2426 - val_loss: -8.2516 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.17808 to -8.25155, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.2160 - acc: 0.2426 - val_loss: -8.3105 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.25155 to -8.31051, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 879us/step - loss: -9.2687 - acc: 0.2426 - val_loss: -8.3463 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.31051 to -8.34632, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 3s 983us/step - loss: -9.2964 - acc: 0.2426 - val_loss: -8.3770 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.34632 to -8.37697, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 3s 918us/step - loss: -9.3250 - acc: 0.2426 - val_loss: -8.4047 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.37697 to -8.40475, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 864us/step - loss: -9.3419 - acc: 0.2426 - val_loss: -8.4172 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.40475 to -8.41719, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 888us/step - loss: -9.3608 - acc: 0.2426 - val_loss: -8.4339 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.41719 to -8.43387, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.3739 - acc: 0.2426 - val_loss: -8.4451 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.43387 to -8.44511, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 868us/step - loss: -9.3815 - acc: 0.2426 - val_loss: -8.4451 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -8.44511\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.3835 - acc: 0.2426 - val_loss: -8.4513 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.44511 to -8.45126, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 842us/step - loss: -9.3896 - acc: 0.2426 - val_loss: -8.4573 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.45126 to -8.45730, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.3956 - acc: 0.2426 - val_loss: -8.4633 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.45730 to -8.46331, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.3967 - acc: 0.2426 - val_loss: -8.4619 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -8.46331\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.4000 - acc: 0.2426 - val_loss: -8.4673 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.46331 to -8.46725, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -9.4021 - acc: 0.2426 - val_loss: -8.4642 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -8.46725\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 882us/step - loss: -9.4009 - acc: 0.2426 - val_loss: -8.4667 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.46725\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.4035 - acc: 0.2426 - val_loss: -8.4694 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.46725 to -8.46941, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.4063 - acc: 0.2426 - val_loss: -8.4723 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.46941 to -8.47228, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.4094 - acc: 0.2426 - val_loss: -8.4741 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.47228 to -8.47410, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 859us/step - loss: -9.4099 - acc: 0.2426 - val_loss: -8.4760 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.47410 to -8.47597, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.4111 - acc: 0.2426 - val_loss: -8.4710 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.47597\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.4069 - acc: 0.2426 - val_loss: -8.4717 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.47597\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.4076 - acc: 0.2426 - val_loss: -8.4725 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.47597\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.4085 - acc: 0.2426 - val_loss: -8.4735 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.47597\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.4091 - acc: 0.2426 - val_loss: -8.4736 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.47597\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.4093 - acc: 0.2426 - val_loss: -8.4738 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.47597\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -9.4094 - acc: 0.2426 - val_loss: -8.4740 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47597\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 3s 915us/step - loss: -9.4097 - acc: 0.2426 - val_loss: -8.4743 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.47597\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.4099 - acc: 0.2426 - val_loss: -8.4744 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.47597\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 3s 1ms/step - loss: -9.4100 - acc: 0.2426 - val_loss: -8.4744 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.47597\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 14s 5ms/step - loss: -4.6763 - acc: 0.2434 - val_loss: -6.9225 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.92250, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -7.9460 - acc: 0.2426 - val_loss: -7.1086 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.92250 to -7.10860, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 860us/step - loss: -8.1223 - acc: 0.2426 - val_loss: -7.2760 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.10860 to -7.27603, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 865us/step - loss: -8.2835 - acc: 0.2426 - val_loss: -7.4294 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.27603 to -7.42941, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -8.4326 - acc: 0.2426 - val_loss: -7.5763 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.42941 to -7.57632, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.5774 - acc: 0.2426 - val_loss: -7.7172 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.57632 to -7.71717, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.7149 - acc: 0.2426 - val_loss: -7.8524 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.71717 to -7.85240, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 858us/step - loss: -8.8428 - acc: 0.2426 - val_loss: -7.9749 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.85240 to -7.97489, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -8.9619 - acc: 0.2426 - val_loss: -8.0841 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.97489 to -8.08412, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.0655 - acc: 0.2426 - val_loss: -8.1814 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.08412 to -8.18140, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.1538 - acc: 0.2426 - val_loss: -8.2573 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.18140 to -8.25734, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.2258 - acc: 0.2426 - val_loss: -8.3248 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.25734 to -8.32482, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 878us/step - loss: -9.2782 - acc: 0.2426 - val_loss: -8.3619 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.32482 to -8.36192, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.3170 - acc: 0.2426 - val_loss: -8.4020 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.36192 to -8.40200, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 862us/step - loss: -9.3440 - acc: 0.2426 - val_loss: -8.4119 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.40200 to -8.41186, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 863us/step - loss: -9.3545 - acc: 0.2426 - val_loss: -8.4267 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.41186 to -8.42671, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 871us/step - loss: -9.3683 - acc: 0.2426 - val_loss: -8.4393 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.42671 to -8.43934, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.3101 - acc: 0.2426 - val_loss: -8.4445 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.43934 to -8.44446, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.3807 - acc: 0.2426 - val_loss: -8.4460 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.44446 to -8.44600, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 887us/step - loss: -9.3823 - acc: 0.2426 - val_loss: -8.4476 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.44600 to -8.44756, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.3839 - acc: 0.2426 - val_loss: -8.4493 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.44756 to -8.44928, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.3858 - acc: 0.2426 - val_loss: -8.4513 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.44928 to -8.45133, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 875us/step - loss: -9.3880 - acc: 0.2426 - val_loss: -8.4538 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.45133 to -8.45384, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 3s 926us/step - loss: -9.3915 - acc: 0.2426 - val_loss: -8.4552 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.45384 to -8.45524, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 896us/step - loss: -9.3926 - acc: 0.2426 - val_loss: -8.4591 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.45524 to -8.45913, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 3s 958us/step - loss: -9.3962 - acc: 0.2426 - val_loss: -8.4584 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.45913\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 3s 959us/step - loss: -9.3962 - acc: 0.2426 - val_loss: -8.4633 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.45913 to -8.46333, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 3s 915us/step - loss: -9.4018 - acc: 0.2426 - val_loss: -8.4677 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.46333 to -8.46769, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 3s 968us/step - loss: -9.4041 - acc: 0.2426 - val_loss: -8.4703 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.46769 to -8.47025, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 883us/step - loss: -9.4001 - acc: 0.2426 - val_loss: -8.4668 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.47025\n",
      "Epoch 31/40\n",
      "2782/2782 [==============================] - 2s 838us/step - loss: -9.4029 - acc: 0.2426 - val_loss: -8.4680 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.47025\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 837us/step - loss: -9.4042 - acc: 0.2426 - val_loss: -8.4693 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.47025\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.4056 - acc: 0.2426 - val_loss: -8.4709 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.47025 to -8.47087, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 831us/step - loss: -9.4072 - acc: 0.2426 - val_loss: -8.4727 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.47087 to -8.47270, saving model to model-4.h5\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 843us/step - loss: -9.4106 - acc: 0.2426 - val_loss: -8.4748 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.47270 to -8.47480, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 857us/step - loss: -9.4088 - acc: 0.2426 - val_loss: -8.4741 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.47480\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 836us/step - loss: -9.4089 - acc: 0.2426 - val_loss: -8.4727 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47480\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 876us/step - loss: -9.4098 - acc: 0.2426 - val_loss: -8.4760 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.47480 to -8.47595, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 3s 925us/step - loss: -9.4120 - acc: 0.2426 - val_loss: -8.4768 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.47595 to -8.47679, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 3s 948us/step - loss: -9.4117 - acc: 0.2426 - val_loss: -8.4743 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.47679\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2782 samples, validate on 310 samples\n",
      "Epoch 1/40\n",
      "2782/2782 [==============================] - 13s 5ms/step - loss: -5.5518 - acc: 0.2477 - val_loss: -6.8349 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.83492, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -7.8421 - acc: 0.2426 - val_loss: -6.9886 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.83492 to -6.98863, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -7.9925 - acc: 0.2426 - val_loss: -7.1359 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.98863 to -7.13594, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -8.1385 - acc: 0.2426 - val_loss: -7.2812 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.13594 to -7.28125, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2782/2782 [==============================] - 2s 847us/step - loss: -8.2842 - acc: 0.2426 - val_loss: -7.4276 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.28125 to -7.42760, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.4305 - acc: 0.2426 - val_loss: -7.5749 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.42760 to -7.57486, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -8.5767 - acc: 0.2426 - val_loss: -7.7200 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.57486 to -7.71999, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -8.7196 - acc: 0.2426 - val_loss: -7.8557 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.71999 to -7.85568, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2782/2782 [==============================] - 2s 867us/step - loss: -8.8523 - acc: 0.2426 - val_loss: -7.9853 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.85568 to -7.98531, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2782/2782 [==============================] - 2s 870us/step - loss: -8.9749 - acc: 0.2426 - val_loss: -8.1004 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.98531 to -8.10042, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.0825 - acc: 0.2426 - val_loss: -8.1969 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.10042 to -8.19691, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.1686 - acc: 0.2426 - val_loss: -8.2743 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.19691 to -8.27428, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.2382 - acc: 0.2426 - val_loss: -8.3269 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.27428 to -8.32688, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.2853 - acc: 0.2426 - val_loss: -8.3741 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.32688 to -8.37412, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.3212 - acc: 0.2426 - val_loss: -8.4028 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.37412 to -8.40284, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.3438 - acc: 0.2426 - val_loss: -8.4146 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.40284 to -8.41463, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.3571 - acc: 0.2426 - val_loss: -8.4292 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.41463 to -8.42921, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2782/2782 [==============================] - 2s 861us/step - loss: -9.3707 - acc: 0.2426 - val_loss: -8.4426 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.42921 to -8.44262, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.3831 - acc: 0.2426 - val_loss: -8.4498 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.44262 to -8.44976, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.3902 - acc: 0.2426 - val_loss: -8.4571 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.44976 to -8.45713, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.3959 - acc: 0.2426 - val_loss: -8.4641 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.45713 to -8.46407, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.4019 - acc: 0.2426 - val_loss: -8.4394 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -8.46407\n",
      "Epoch 23/40\n",
      "2782/2782 [==============================] - 2s 877us/step - loss: -9.3998 - acc: 0.2426 - val_loss: -8.4647 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.46407 to -8.46475, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2782/2782 [==============================] - 2s 866us/step - loss: -9.4009 - acc: 0.2426 - val_loss: -8.4660 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.46475 to -8.46599, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.4022 - acc: 0.2426 - val_loss: -8.4674 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.46599 to -8.46743, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.4038 - acc: 0.2426 - val_loss: -8.4692 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.46743 to -8.46915, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4056 - acc: 0.2426 - val_loss: -8.4712 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.46915 to -8.47121, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2782/2782 [==============================] - 2s 856us/step - loss: -9.4079 - acc: 0.2426 - val_loss: -8.4736 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.47121 to -8.47363, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2782/2782 [==============================] - 2s 854us/step - loss: -9.4084 - acc: 0.2426 - val_loss: -8.4732 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.47363\n",
      "Epoch 30/40\n",
      "2782/2782 [==============================] - 2s 855us/step - loss: -9.4102 - acc: 0.2426 - val_loss: -8.4763 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.47363 to -8.47627, saving model to model-5.h5\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.4093 - acc: 0.2426 - val_loss: -8.4746 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.47627\n",
      "Epoch 32/40\n",
      "2782/2782 [==============================] - 2s 849us/step - loss: -9.4114 - acc: 0.2426 - val_loss: -8.4774 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.47627 to -8.47736, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2782/2782 [==============================] - 2s 851us/step - loss: -9.4085 - acc: 0.2426 - val_loss: -8.4738 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.47736\n",
      "Epoch 34/40\n",
      "2782/2782 [==============================] - 2s 850us/step - loss: -9.4097 - acc: 0.2426 - val_loss: -8.4746 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.47736\n",
      "Epoch 35/40\n",
      "2782/2782 [==============================] - 2s 879us/step - loss: -9.4105 - acc: 0.2426 - val_loss: -8.4754 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.47736\n",
      "Epoch 36/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4115 - acc: 0.2426 - val_loss: -8.4765 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.47736\n",
      "Epoch 37/40\n",
      "2782/2782 [==============================] - 2s 853us/step - loss: -9.4121 - acc: 0.2426 - val_loss: -8.4766 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.47736\n",
      "Epoch 38/40\n",
      "2782/2782 [==============================] - 2s 848us/step - loss: -9.4122 - acc: 0.2426 - val_loss: -8.4768 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.47736\n",
      "Epoch 39/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4124 - acc: 0.2426 - val_loss: -8.4770 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.47736\n",
      "Epoch 40/40\n",
      "2782/2782 [==============================] - 2s 852us/step - loss: -9.4127 - acc: 0.2426 - val_loss: -8.4773 - val_acc: 0.2710\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.47736\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 19s 8ms/step - loss: -2.2507 - acc: 0.2474 - val_loss: -6.8444 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.84444, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 1ms/step - loss: -7.6655 - acc: 0.2440 - val_loss: -7.1123 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.84444 to -7.11226, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 939us/step - loss: -7.8301 - acc: 0.2440 - val_loss: -7.2770 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.11226 to -7.27696, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -7.9825 - acc: 0.2440 - val_loss: -7.4172 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.27696 to -7.41720, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -8.1296 - acc: 0.2440 - val_loss: -7.5702 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.41720 to -7.57017, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -8.2702 - acc: 0.2440 - val_loss: -7.7092 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.57017 to -7.70918, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.4074 - acc: 0.2440 - val_loss: -7.8527 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.70918 to -7.85267, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -8.5378 - acc: 0.2440 - val_loss: -7.9707 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.85267 to -7.97070, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -8.6620 - acc: 0.2440 - val_loss: -8.0892 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.97070 to -8.08919, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.7735 - acc: 0.2440 - val_loss: -8.2144 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.08919 to -8.21442, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.8745 - acc: 0.2440 - val_loss: -8.3089 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.21442 to -8.30888, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 1ms/step - loss: -8.9628 - acc: 0.2440 - val_loss: -8.3881 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.30888 to -8.38808, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.0380 - acc: 0.2440 - val_loss: -8.4517 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.38808 to -8.45171, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 960us/step - loss: -9.0914 - acc: 0.2440 - val_loss: -8.5031 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.45171 to -8.50305, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 912us/step - loss: -9.1381 - acc: 0.2440 - val_loss: -8.5435 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.50305 to -8.54350, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 999us/step - loss: -9.1746 - acc: 0.2440 - val_loss: -8.5731 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.54350 to -8.57309, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.1994 - acc: 0.2440 - val_loss: -8.5899 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.57309 to -8.58987, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.2145 - acc: 0.2440 - val_loss: -8.6078 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.58987 to -8.60777, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2308 - acc: 0.2440 - val_loss: -8.6203 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.60777 to -8.62035, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2416 - acc: 0.2440 - val_loss: -8.6303 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.62035 to -8.63026, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2500 - acc: 0.2440 - val_loss: -8.6387 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.63026 to -8.63873, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.2577 - acc: 0.2440 - val_loss: -8.6437 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.63873 to -8.64373, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2628 - acc: 0.2440 - val_loss: -8.6504 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.64373 to -8.65038, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 887us/step - loss: -9.2669 - acc: 0.2440 - val_loss: -8.6498 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -8.65038\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2684 - acc: 0.2440 - val_loss: -8.6505 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.65038 to -8.65046, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2691 - acc: 0.2440 - val_loss: -8.6554 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.65046 to -8.65544, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2735 - acc: 0.2440 - val_loss: -8.6592 - val_acc: 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_loss improved from -8.65544 to -8.65921, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 1000us/step - loss: -9.2620 - acc: 0.2440 - val_loss: -8.6552 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.65921\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2720 - acc: 0.2440 - val_loss: -8.6563 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.65921\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.2730 - acc: 0.2440 - val_loss: -8.6574 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.65921\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2741 - acc: 0.2440 - val_loss: -8.6585 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.65921\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2748 - acc: 0.2440 - val_loss: -8.6587 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.65921\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 883us/step - loss: -9.2750 - acc: 0.2440 - val_loss: -8.6588 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.65921\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 887us/step - loss: -9.2751 - acc: 0.2440 - val_loss: -8.6590 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.65921\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.2754 - acc: 0.2440 - val_loss: -8.6593 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.65921 to -8.65928, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2755 - acc: 0.2440 - val_loss: -8.6593 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.65928 to -8.65931, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2756 - acc: 0.2440 - val_loss: -8.6594 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.65931 to -8.65936, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -9.2756 - acc: 0.2440 - val_loss: -8.6594 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.65936 to -8.65941, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2757 - acc: 0.2440 - val_loss: -8.6595 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.65941 to -8.65947, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 881us/step - loss: -9.2757 - acc: 0.2440 - val_loss: -8.6595 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.65947 to -8.65954, saving model to model-1.h5\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 13s 6ms/step - loss: -3.2319 - acc: 0.2465 - val_loss: -6.9946 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.99461, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -7.6904 - acc: 0.2440 - val_loss: -7.1575 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.99461 to -7.15752, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -7.8401 - acc: 0.2440 - val_loss: -7.3022 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.15752 to -7.30218, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -7.9813 - acc: 0.2440 - val_loss: -7.4412 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.30218 to -7.44119, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.1194 - acc: 0.2440 - val_loss: -7.5760 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.44119 to -7.57596, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -8.2532 - acc: 0.2440 - val_loss: -7.6998 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.57596 to -7.69983, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.3837 - acc: 0.2440 - val_loss: -7.8371 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.69983 to -7.83707, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.5106 - acc: 0.2440 - val_loss: -7.9522 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.83707 to -7.95220, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -8.6314 - acc: 0.2440 - val_loss: -8.0676 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.95220 to -8.06760, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -8.7420 - acc: 0.2440 - val_loss: -8.1823 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.06760 to -8.18230, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.8421 - acc: 0.2440 - val_loss: -8.2773 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.18230 to -8.27731, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 883us/step - loss: -8.9288 - acc: 0.2440 - val_loss: -8.3537 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.27731 to -8.35370, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.0023 - acc: 0.2440 - val_loss: -8.4229 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.35370 to -8.42293, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.0617 - acc: 0.2440 - val_loss: -8.4723 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.42293 to -8.47233, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.1110 - acc: 0.2440 - val_loss: -8.5160 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.47233 to -8.51604, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.1500 - acc: 0.2440 - val_loss: -8.5535 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.51604 to -8.55349, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.1816 - acc: 0.2440 - val_loss: -8.5825 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.55349 to -8.58252, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2032 - acc: 0.2440 - val_loss: -8.5995 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.58252 to -8.59948, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.1845 - acc: 0.2440 - val_loss: -8.6037 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.59948 to -8.60367, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2218 - acc: 0.2440 - val_loss: -8.6079 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.60367 to -8.60792, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2260 - acc: 0.2440 - val_loss: -8.6120 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.60792 to -8.61204, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2302 - acc: 0.2440 - val_loss: -8.6162 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.61204 to -8.61622, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 896us/step - loss: -9.2344 - acc: 0.2440 - val_loss: -8.6206 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.61622 to -8.62062, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2390 - acc: 0.2440 - val_loss: -8.6254 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.62062 to -8.62535, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2439 - acc: 0.2440 - val_loss: -8.6305 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.62535 to -8.63051, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2482 - acc: 0.2440 - val_loss: -8.6348 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.63051 to -8.63478, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - ETA: 0s - loss: -9.2032 - acc: 0.24 - 2s 862us/step - loss: -9.2486 - acc: 0.2440 - val_loss: -8.6355 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.63478 to -8.63552, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.2542 - acc: 0.2440 - val_loss: -8.6408 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.63552 to -8.64082, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2588 - acc: 0.2440 - val_loss: -8.6417 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.64082 to -8.64170, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - ETA: 0s - loss: -9.2152 - acc: 0.24 - 2s 860us/step - loss: -9.2606 - acc: 0.2440 - val_loss: -8.6474 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.64170 to -8.64744, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2650 - acc: 0.2440 - val_loss: -8.6510 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.64744 to -8.65098, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.2672 - acc: 0.2440 - val_loss: -8.6521 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.65098 to -8.65211, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2694 - acc: 0.2440 - val_loss: -8.6550 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.65211 to -8.65501, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2700 - acc: 0.2440 - val_loss: -8.6551 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.65501 to -8.65507, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2727 - acc: 0.2440 - val_loss: -8.6567 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.65507 to -8.65666, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2491 - acc: 0.2440 - val_loss: -8.6547 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.65666\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2713 - acc: 0.2440 - val_loss: -8.6554 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.65666\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2719 - acc: 0.2440 - val_loss: -8.6560 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.65666\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.2725 - acc: 0.2440 - val_loss: -8.6567 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.65666 to -8.65667, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.2729 - acc: 0.2440 - val_loss: -8.6567 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.65667 to -8.65675, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 13s 6ms/step - loss: -4.6121 - acc: 0.2507 - val_loss: -7.0167 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.01667, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -7.6958 - acc: 0.2440 - val_loss: -7.1560 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.01667 to -7.15598, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -7.8335 - acc: 0.2440 - val_loss: -7.2868 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.15598 to -7.28678, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -7.9671 - acc: 0.2440 - val_loss: -7.4226 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.28678 to -7.42257, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -8.0975 - acc: 0.2440 - val_loss: -7.5434 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.42257 to -7.54342, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.2262 - acc: 0.2440 - val_loss: -7.6801 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.54342 to -7.68009, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -8.3549 - acc: 0.2440 - val_loss: -7.8084 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.68009 to -7.80840, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.4810 - acc: 0.2440 - val_loss: -7.9316 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.80840 to -7.93163, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.6011 - acc: 0.2440 - val_loss: -8.0336 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.93163 to -8.03358, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.7134 - acc: 0.2440 - val_loss: -8.1575 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.03358 to -8.15750, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.8177 - acc: 0.2440 - val_loss: -8.2538 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.15750 to -8.25376, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.9095 - acc: 0.2440 - val_loss: -8.3404 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.25376 to -8.34035, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -8.9884 - acc: 0.2440 - val_loss: -8.4079 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.34035 to -8.40794, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.0543 - acc: 0.2440 - val_loss: -8.4643 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.40794 to -8.46428, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.1041 - acc: 0.2440 - val_loss: -8.5133 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.46428 to -8.51333, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.1471 - acc: 0.2440 - val_loss: -8.5432 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.51333 to -8.54324, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.1752 - acc: 0.2440 - val_loss: -8.5765 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.54324 to -8.57655, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2032 - acc: 0.2440 - val_loss: -8.5948 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.57655 to -8.59481, saving model to model-3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 889us/step - loss: -9.2209 - acc: 0.2440 - val_loss: -8.6135 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.59481 to -8.61347, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2367 - acc: 0.2440 - val_loss: -8.6296 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.61347 to -8.62960, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2460 - acc: 0.2440 - val_loss: -8.6365 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.62960 to -8.63647, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2555 - acc: 0.2440 - val_loss: -8.6357 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -8.63647\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2542 - acc: 0.2440 - val_loss: -8.6406 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.63647 to -8.64058, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2588 - acc: 0.2440 - val_loss: -8.6450 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.64058 to -8.64499, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2631 - acc: 0.2440 - val_loss: -8.6491 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.64499 to -8.64911, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2669 - acc: 0.2440 - val_loss: -8.6522 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.64911 to -8.65223, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2692 - acc: 0.2440 - val_loss: -8.6545 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.65223 to -8.65453, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2713 - acc: 0.2440 - val_loss: -8.6567 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.65453 to -8.65671, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2728 - acc: 0.2440 - val_loss: -8.6555 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.65671\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2736 - acc: 0.2440 - val_loss: -8.6588 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.65671 to -8.65883, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.2751 - acc: 0.2440 - val_loss: -8.6571 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.65883\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.2748 - acc: 0.2440 - val_loss: -8.6603 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.65883 to -8.66028, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2688 - acc: 0.2440 - val_loss: -8.6578 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.66028\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2742 - acc: 0.2440 - val_loss: -8.6582 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.66028\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2746 - acc: 0.2440 - val_loss: -8.6586 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.66028\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - ETA: 0s - loss: -9.2443 - acc: 0.24 - 2s 906us/step - loss: -9.2750 - acc: 0.2440 - val_loss: -8.6590 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.66028\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2753 - acc: 0.2440 - val_loss: -8.6591 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.66028\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2754 - acc: 0.2440 - val_loss: -8.6592 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.66028\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2754 - acc: 0.2440 - val_loss: -8.6593 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.66028\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2756 - acc: 0.2440 - val_loss: -8.6594 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.66028\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 13s 6ms/step - loss: -4.3247 - acc: 0.2402 - val_loss: -7.0134 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.01336, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -7.6943 - acc: 0.2440 - val_loss: -7.1519 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.01336 to -7.15192, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -7.8281 - acc: 0.2440 - val_loss: -7.2828 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.15192 to -7.28282, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -7.9576 - acc: 0.2440 - val_loss: -7.4131 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.28282 to -7.41311, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -8.0877 - acc: 0.2440 - val_loss: -7.5421 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.41311 to -7.54209, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 883us/step - loss: -8.2150 - acc: 0.2440 - val_loss: -7.6700 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.54209 to -7.67000, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 884us/step - loss: -8.3448 - acc: 0.2440 - val_loss: -7.7988 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.67000 to -7.79881, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -8.4712 - acc: 0.2440 - val_loss: -7.9246 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.79881 to -7.92459, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 882us/step - loss: -8.5954 - acc: 0.2440 - val_loss: -8.0452 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.92459 to -8.04525, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -8.7084 - acc: 0.2440 - val_loss: -8.1551 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.04525 to -8.15509, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 886us/step - loss: -8.8165 - acc: 0.2440 - val_loss: -8.2554 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.15509 to -8.25537, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 879us/step - loss: -8.9111 - acc: 0.2440 - val_loss: -8.3402 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.25537 to -8.34022, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.9921 - acc: 0.2440 - val_loss: -8.4157 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.34022 to -8.41568, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 879us/step - loss: -9.0605 - acc: 0.2440 - val_loss: -8.4781 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.41568 to -8.47806, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.1037 - acc: 0.2440 - val_loss: -8.5060 - val_acc: 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss improved from -8.47806 to -8.50605, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.1374 - acc: 0.2440 - val_loss: -8.5385 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.50605 to -8.53853, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.1677 - acc: 0.2440 - val_loss: -8.5593 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.53853 to -8.55928, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 912us/step - loss: -9.1862 - acc: 0.2440 - val_loss: -8.5822 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.55928 to -8.58224, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2074 - acc: 0.2440 - val_loss: -8.6009 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.58224 to -8.60092, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2239 - acc: 0.2440 - val_loss: -8.6162 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.60092 to -8.61616, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.2373 - acc: 0.2440 - val_loss: -8.6290 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.61616 to -8.62896, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2478 - acc: 0.2440 - val_loss: -8.6382 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.62896 to -8.63816, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.2539 - acc: 0.2440 - val_loss: -8.6421 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.63816 to -8.64212, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2337 - acc: 0.2440 - val_loss: -8.6439 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.64212 to -8.64393, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 892us/step - loss: -9.2605 - acc: 0.2440 - val_loss: -8.6447 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.64393 to -8.64467, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 898us/step - loss: -9.2612 - acc: 0.2440 - val_loss: -8.6454 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.64467 to -8.64544, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.2621 - acc: 0.2440 - val_loss: -8.6463 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.64544 to -8.64630, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.2630 - acc: 0.2440 - val_loss: -8.6473 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.64630 to -8.64729, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.2640 - acc: 0.2440 - val_loss: -8.6484 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.64729 to -8.64845, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -9.2653 - acc: 0.2440 - val_loss: -8.6498 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.64845 to -8.64984, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.2668 - acc: 0.2440 - val_loss: -8.6515 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.64984 to -8.65149, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2686 - acc: 0.2440 - val_loss: -8.6534 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.65149 to -8.65342, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.2705 - acc: 0.2440 - val_loss: -8.6518 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.65342\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 880us/step - loss: -9.2691 - acc: 0.2440 - val_loss: -8.6541 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.65342 to -8.65413, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2714 - acc: 0.2440 - val_loss: -8.6565 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.65413 to -8.65654, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2739 - acc: 0.2440 - val_loss: -8.5304 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.65654\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.2652 - acc: 0.2440 - val_loss: -8.6547 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.65654\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 882us/step - loss: -9.2711 - acc: 0.2440 - val_loss: -8.6551 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.65654\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 880us/step - loss: -9.2715 - acc: 0.2440 - val_loss: -8.6555 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.65654\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2718 - acc: 0.2440 - val_loss: -8.6556 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.65654\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 13s 6ms/step - loss: -4.8000 - acc: 0.2448 - val_loss: -7.0288 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.02880, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 880us/step - loss: -7.7027 - acc: 0.2440 - val_loss: -7.1578 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.02880 to -7.15781, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -7.8307 - acc: 0.2440 - val_loss: -7.2840 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.15781 to -7.28398, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 883us/step - loss: -7.9556 - acc: 0.2440 - val_loss: -7.4089 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.28398 to -7.40886, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -8.0806 - acc: 0.2440 - val_loss: -7.5317 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.40886 to -7.53172, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -8.2059 - acc: 0.2440 - val_loss: -7.6591 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.53172 to -7.65907, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 888us/step - loss: -8.3316 - acc: 0.2440 - val_loss: -7.7849 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.65907 to -7.78492, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -8.4563 - acc: 0.2440 - val_loss: -7.9067 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.78492 to -7.90668, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -8.5780 - acc: 0.2440 - val_loss: -8.0276 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.90668 to -8.02756, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -8.6938 - acc: 0.2440 - val_loss: -8.1388 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.02756 to -8.13880, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -8.8037 - acc: 0.2440 - val_loss: -8.2440 - val_acc: 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss improved from -8.13880 to -8.24402, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -8.8962 - acc: 0.2440 - val_loss: -8.3264 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.24402 to -8.32637, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -8.9783 - acc: 0.2440 - val_loss: -8.4032 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.32637 to -8.40317, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.0465 - acc: 0.2440 - val_loss: -8.4647 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.40317 to -8.46471, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.1057 - acc: 0.2440 - val_loss: -8.5075 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.46471 to -8.50748, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.1441 - acc: 0.2440 - val_loss: -8.5508 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.50748 to -8.55084, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.1804 - acc: 0.2440 - val_loss: -8.5765 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.55084 to -8.57654, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.2046 - acc: 0.2440 - val_loss: -8.6016 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.57654 to -8.60160, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2200 - acc: 0.2440 - val_loss: -8.6045 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.60160 to -8.60454, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2239 - acc: 0.2440 - val_loss: -8.6114 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.60454 to -8.61136, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.2306 - acc: 0.2440 - val_loss: -8.6180 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.61136 to -8.61799, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -9.2372 - acc: 0.2440 - val_loss: -8.6246 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.61799 to -8.62462, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2439 - acc: 0.2440 - val_loss: -8.6313 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.62462 to -8.63134, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2506 - acc: 0.2440 - val_loss: -8.6372 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.63134 to -8.63717, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2565 - acc: 0.2440 - val_loss: -8.6428 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.63717 to -8.64279, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2612 - acc: 0.2440 - val_loss: -8.6457 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.64279 to -8.64566, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.2649 - acc: 0.2440 - val_loss: -8.6520 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.64566 to -8.65203, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.2633 - acc: 0.2440 - val_loss: -8.6474 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.65203\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 881us/step - loss: -9.2640 - acc: 0.2440 - val_loss: -8.6483 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.65203\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2650 - acc: 0.2440 - val_loss: -8.6494 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.65203\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2662 - acc: 0.2440 - val_loss: -8.6506 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.65203\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.2669 - acc: 0.2440 - val_loss: -8.6508 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.65203\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2671 - acc: 0.2440 - val_loss: -8.6510 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.65203\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2673 - acc: 0.2440 - val_loss: -8.6512 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.65203\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2676 - acc: 0.2440 - val_loss: -8.6516 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.65203\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2678 - acc: 0.2440 - val_loss: -8.6516 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.65203\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 878us/step - loss: -9.2679 - acc: 0.2440 - val_loss: -8.6517 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.65203\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2679 - acc: 0.2440 - val_loss: -8.6517 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.65203\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2680 - acc: 0.2440 - val_loss: -8.6518 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.65203\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2681 - acc: 0.2440 - val_loss: -8.6519 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.65203\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 14s 6ms/step - loss: -1.8156 - acc: 0.2389 - val_loss: -7.0914 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.09140, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -7.8697 - acc: 0.2440 - val_loss: -7.4349 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.09140 to -7.43492, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -8.1775 - acc: 0.2440 - val_loss: -7.7032 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.43492 to -7.70322, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -8.4165 - acc: 0.2440 - val_loss: -7.9086 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.70322 to -7.90861, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -8.5999 - acc: 0.2440 - val_loss: -8.0697 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.90861 to -8.06969, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.7449 - acc: 0.2440 - val_loss: -8.1984 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -8.06969 to -8.19842, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -8.8626 - acc: 0.2440 - val_loss: -8.3021 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -8.19842 to -8.30213, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 876us/step - loss: -8.9575 - acc: 0.2440 - val_loss: -8.3808 - val_acc: 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss improved from -8.30213 to -8.38083, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.0301 - acc: 0.2440 - val_loss: -8.4458 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.38083 to -8.44583, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.0906 - acc: 0.2440 - val_loss: -8.4911 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.44583 to -8.49109, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.1303 - acc: 0.2440 - val_loss: -8.5391 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.49109 to -8.53915, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.1697 - acc: 0.2440 - val_loss: -8.5668 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.53915 to -8.56677, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.1959 - acc: 0.2440 - val_loss: -8.5894 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.56677 to -8.58941, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2173 - acc: 0.2440 - val_loss: -8.6133 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.58941 to -8.61331, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2344 - acc: 0.2440 - val_loss: -8.6265 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.61331 to -8.62648, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.2408 - acc: 0.2440 - val_loss: -8.6271 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.62648 to -8.62709, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2477 - acc: 0.2440 - val_loss: -8.6365 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.62709 to -8.63651, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2558 - acc: 0.2440 - val_loss: -8.6430 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.63651 to -8.64299, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2598 - acc: 0.2440 - val_loss: -8.6464 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.64299 to -8.64640, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 894us/step - loss: -9.2627 - acc: 0.2440 - val_loss: -8.6452 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -8.64640\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2650 - acc: 0.2440 - val_loss: -8.6528 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.64640 to -8.65276, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2642 - acc: 0.2440 - val_loss: -8.6476 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -8.65276\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2649 - acc: 0.2440 - val_loss: -8.6501 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -8.65276\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2675 - acc: 0.2440 - val_loss: -8.6526 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -8.65276\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2700 - acc: 0.2440 - val_loss: -8.6552 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.65276 to -8.65521, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.2719 - acc: 0.2440 - val_loss: -8.6561 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.65521 to -8.65613, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2731 - acc: 0.2440 - val_loss: -8.6578 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.65613 to -8.65777, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.2741 - acc: 0.2440 - val_loss: -8.6585 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.65777 to -8.65848, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.2733 - acc: 0.2440 - val_loss: -8.6572 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.65848\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2752 - acc: 0.2440 - val_loss: -8.6581 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.65848\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 880us/step - loss: -9.2762 - acc: 0.2440 - val_loss: -8.6621 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.65848 to -8.66210, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2732 - acc: 0.2440 - val_loss: -8.6579 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.66210\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2752 - acc: 0.2440 - val_loss: -8.6603 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.66210\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2775 - acc: 0.2440 - val_loss: -8.6624 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.66210 to -8.66243, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -9.2775 - acc: 0.2440 - val_loss: -8.6584 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.66243\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2749 - acc: 0.2440 - val_loss: -8.6590 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.66243\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2755 - acc: 0.2440 - val_loss: -8.6597 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.66243\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 875us/step - loss: -9.2763 - acc: 0.2440 - val_loss: -8.6605 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.66243\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.2767 - acc: 0.2440 - val_loss: -8.6606 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.66243\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 860us/step - loss: -9.2768 - acc: 0.2440 - val_loss: -8.6607 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.66243\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 13s 6ms/step - loss: -4.0629 - acc: 0.2452 - val_loss: -7.0586 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.05858, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 877us/step - loss: -7.7819 - acc: 0.2440 - val_loss: -7.2890 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.05858 to -7.28904, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -7.9963 - acc: 0.2440 - val_loss: -7.4847 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.28904 to -7.48471, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -8.1781 - acc: 0.2440 - val_loss: -7.6519 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.48471 to -7.65194, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -8.3367 - acc: 0.2440 - val_loss: -7.7995 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.65194 to -7.79949, saving model to model-2.h5\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 865us/step - loss: -8.4764 - acc: 0.2440 - val_loss: -7.9335 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.79949 to -7.93346, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.6010 - acc: 0.2440 - val_loss: -8.0501 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.93346 to -8.05012, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 869us/step - loss: -8.7113 - acc: 0.2440 - val_loss: -8.1517 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.05012 to -8.15168, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -8.8125 - acc: 0.2440 - val_loss: -8.2443 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.15168 to -8.24434, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -8.9002 - acc: 0.2440 - val_loss: -8.3290 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.24434 to -8.32897, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -8.9776 - acc: 0.2440 - val_loss: -8.3963 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.32897 to -8.39635, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.0433 - acc: 0.2440 - val_loss: -8.4592 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.39635 to -8.45923, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - ETA: 0s - loss: -9.1687 - acc: 0.24 - 2s 862us/step - loss: -9.0997 - acc: 0.2440 - val_loss: -8.5092 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.45923 to -8.50922, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.1395 - acc: 0.2440 - val_loss: -8.5294 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.50922 to -8.52942, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 868us/step - loss: -9.1522 - acc: 0.2440 - val_loss: -8.5439 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.52942 to -8.54387, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.1664 - acc: 0.2440 - val_loss: -8.5577 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.54387 to -8.55773, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.1801 - acc: 0.2440 - val_loss: -8.5714 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.55773 to -8.57142, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.1937 - acc: 0.2440 - val_loss: -8.5842 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.57142 to -8.58421, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2062 - acc: 0.2440 - val_loss: -8.5973 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.58421 to -8.59726, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 871us/step - loss: -9.2148 - acc: 0.2440 - val_loss: -8.6021 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.59726 to -8.60207, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 864us/step - loss: -9.2236 - acc: 0.2440 - val_loss: -8.6137 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.60207 to -8.61375, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2347 - acc: 0.2440 - val_loss: -8.6239 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.61375 to -8.62394, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.2418 - acc: 0.2440 - val_loss: -8.6310 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.62394 to -8.63104, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2498 - acc: 0.2440 - val_loss: -8.6363 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.63104 to -8.63633, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2561 - acc: 0.2440 - val_loss: -8.6443 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.63633 to -8.64435, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2617 - acc: 0.2440 - val_loss: -8.6482 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.64435 to -8.64823, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2652 - acc: 0.2440 - val_loss: -8.6517 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.64823 to -8.65166, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2696 - acc: 0.2440 - val_loss: -8.6562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.65166 to -8.65623, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 865us/step - loss: -9.2719 - acc: 0.2440 - val_loss: -8.6562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.65623 to -8.65624, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2735 - acc: 0.2440 - val_loss: -8.6580 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.65624 to -8.65795, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2473 - acc: 0.2440 - val_loss: -8.6546 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.65795\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 867us/step - loss: -9.2711 - acc: 0.2440 - val_loss: -8.6551 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.65795\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 863us/step - loss: -9.2715 - acc: 0.2440 - val_loss: -8.6555 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.65795\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2720 - acc: 0.2440 - val_loss: -8.6560 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.65795\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2723 - acc: 0.2440 - val_loss: -8.6561 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.65795\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 893us/step - loss: -9.2724 - acc: 0.2440 - val_loss: -8.6562 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.65795\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 872us/step - loss: -9.2725 - acc: 0.2440 - val_loss: -8.6563 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.65795\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2726 - acc: 0.2440 - val_loss: -8.6564 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.65795\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2727 - acc: 0.2440 - val_loss: -8.6564 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.65795\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2727 - acc: 0.2440 - val_loss: -8.6565 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.65795\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 14s 6ms/step - loss: -4.4364 - acc: 0.2457 - val_loss: -7.0788 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.07878, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -7.7935 - acc: 0.2440 - val_loss: -7.2910 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.07878 to -7.29096, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -7.9928 - acc: 0.2440 - val_loss: -7.4760 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.29096 to -7.47596, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -8.1655 - acc: 0.2440 - val_loss: -7.6364 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.47596 to -7.63639, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -8.3180 - acc: 0.2440 - val_loss: -7.7788 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.63639 to -7.77881, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 895us/step - loss: -8.4556 - acc: 0.2440 - val_loss: -7.9075 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.77881 to -7.90754, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 913us/step - loss: -8.5799 - acc: 0.2440 - val_loss: -8.0314 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.90754 to -8.03136, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 887us/step - loss: -8.6962 - acc: 0.2440 - val_loss: -8.1406 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -8.03136 to -8.14056, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -8.7993 - acc: 0.2440 - val_loss: -8.2376 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.14056 to -8.23758, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -8.8936 - acc: 0.2440 - val_loss: -8.3234 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.23758 to -8.32343, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -8.9701 - acc: 0.2440 - val_loss: -8.3926 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.32343 to -8.39262, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 882us/step - loss: -9.0391 - acc: 0.2440 - val_loss: -8.4559 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.39262 to -8.45591, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 881us/step - loss: -9.0744 - acc: 0.2440 - val_loss: -8.4684 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.45591 to -8.46844, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 906us/step - loss: -9.0935 - acc: 0.2440 - val_loss: -8.4877 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.46844 to -8.48775, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.1124 - acc: 0.2440 - val_loss: -8.5064 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.48775 to -8.50644, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.1311 - acc: 0.2440 - val_loss: -8.5251 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.50644 to -8.52514, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.1499 - acc: 0.2440 - val_loss: -8.5442 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.52514 to -8.54424, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 856us/step - loss: -9.1685 - acc: 0.2440 - val_loss: -8.5612 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.54424 to -8.56120, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 882us/step - loss: -9.1857 - acc: 0.2440 - val_loss: -8.5792 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.56120 to -8.57915, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 939us/step - loss: -9.2029 - acc: 0.2440 - val_loss: -8.5924 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.57915 to -8.59241, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 950us/step - loss: -9.2174 - acc: 0.2440 - val_loss: -8.6017 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.59241 to -8.60174, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 879us/step - loss: -9.2208 - acc: 0.2440 - val_loss: -8.6080 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.60174 to -8.60804, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.2271 - acc: 0.2440 - val_loss: -8.6143 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.60804 to -8.61435, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 920us/step - loss: -9.2335 - acc: 0.2440 - val_loss: -8.6208 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.61435 to -8.62084, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 903us/step - loss: -9.2401 - acc: 0.2440 - val_loss: -8.6276 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.62084 to -8.62764, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 879us/step - loss: -9.2463 - acc: 0.2440 - val_loss: -8.6349 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.62764 to -8.63486, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 888us/step - loss: -9.2455 - acc: 0.2440 - val_loss: -8.6307 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.63486\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 921us/step - loss: -9.2487 - acc: 0.2440 - val_loss: -8.6347 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.63486\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 928us/step - loss: -9.2528 - acc: 0.2440 - val_loss: -8.6389 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.63486 to -8.63893, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 936us/step - loss: -9.2571 - acc: 0.2440 - val_loss: -8.6421 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.63893 to -8.64209, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 997us/step - loss: -9.2602 - acc: 0.2440 - val_loss: -8.6409 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.64209\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 989us/step - loss: -9.2590 - acc: 0.2440 - val_loss: -8.6450 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.64209 to -8.64499, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 958us/step - loss: -9.2630 - acc: 0.2440 - val_loss: -8.6490 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.64499 to -8.64900, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 903us/step - loss: -9.2665 - acc: 0.2440 - val_loss: -8.6514 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.64900 to -8.65143, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 862us/step - loss: -9.2682 - acc: 0.2440 - val_loss: -8.6489 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.65143\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 909us/step - loss: -9.2660 - acc: 0.2440 - val_loss: -8.6508 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.65143\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.2679 - acc: 0.2440 - val_loss: -8.6527 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.65143 to -8.65274, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 915us/step - loss: -9.2699 - acc: 0.2440 - val_loss: -8.6548 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.65274 to -8.65482, saving model to model-3.h5\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 877us/step - loss: -9.2720 - acc: 0.2440 - val_loss: -8.6570 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.65482 to -8.65703, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 857us/step - loss: -9.2711 - acc: 0.2440 - val_loss: -8.6551 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.65703\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 14s 6ms/step - loss: -4.6918 - acc: 0.2435 - val_loss: -7.0597 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.05974, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 832us/step - loss: -7.7622 - acc: 0.2440 - val_loss: -7.2467 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.05974 to -7.24672, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 824us/step - loss: -7.9396 - acc: 0.2440 - val_loss: -7.4135 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.24672 to -7.41351, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 827us/step - loss: -8.0992 - acc: 0.2440 - val_loss: -7.5651 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.41351 to -7.56509, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 825us/step - loss: -8.2435 - acc: 0.2440 - val_loss: -7.7026 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.56509 to -7.70261, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 842us/step - loss: -8.3779 - acc: 0.2440 - val_loss: -7.8301 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.70261 to -7.83006, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 830us/step - loss: -8.5028 - acc: 0.2440 - val_loss: -7.9528 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.83006 to -7.95281, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 837us/step - loss: -8.6207 - acc: 0.2440 - val_loss: -8.0643 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.95281 to -8.06433, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 827us/step - loss: -8.7305 - acc: 0.2440 - val_loss: -8.1694 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -8.06433 to -8.16938, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 831us/step - loss: -8.8302 - acc: 0.2440 - val_loss: -8.2599 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.16938 to -8.25987, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 882us/step - loss: -8.9122 - acc: 0.2440 - val_loss: -8.3258 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.25987 to -8.32584, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -8.9545 - acc: 0.2440 - val_loss: -8.3531 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.32584 to -8.35312, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 948us/step - loss: -8.9813 - acc: 0.2440 - val_loss: -8.3795 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.35312 to -8.37955, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 1ms/step - loss: -9.0077 - acc: 0.2440 - val_loss: -8.4060 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.37955 to -8.40601, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 950us/step - loss: -9.0342 - acc: 0.2440 - val_loss: -8.4325 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.40601 to -8.43253, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 980us/step - loss: -9.0613 - acc: 0.2440 - val_loss: -8.4611 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.43253 to -8.46109, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 975us/step - loss: -9.0907 - acc: 0.2440 - val_loss: -8.4884 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.46109 to -8.48839, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 930us/step - loss: -9.1171 - acc: 0.2440 - val_loss: -8.5165 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.48839 to -8.51646, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 885us/step - loss: -9.1437 - acc: 0.2440 - val_loss: -8.5434 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.51646 to -8.54345, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.1703 - acc: 0.2440 - val_loss: -8.5714 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.54345 to -8.57136, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -9.1911 - acc: 0.2440 - val_loss: -8.5880 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.57136 to -8.58804, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 861us/step - loss: -9.2047 - acc: 0.2440 - val_loss: -8.5899 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.58804 to -8.58987, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 854us/step - loss: -9.2104 - acc: 0.2440 - val_loss: -8.5993 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.58987 to -8.59935, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 866us/step - loss: -9.2199 - acc: 0.2440 - val_loss: -8.6089 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.59935 to -8.60894, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.2304 - acc: 0.2440 - val_loss: -8.6171 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.60894 to -8.61711, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.2247 - acc: 0.2440 - val_loss: -8.6142 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.61711\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.2317 - acc: 0.2440 - val_loss: -8.6171 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.61711\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 873us/step - loss: -9.2347 - acc: 0.2440 - val_loss: -8.6204 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.61711 to -8.62038, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 870us/step - loss: -9.2386 - acc: 0.2440 - val_loss: -8.6243 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.62038 to -8.62428, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.2441 - acc: 0.2440 - val_loss: -8.6278 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.62428 to -8.62782, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.2481 - acc: 0.2440 - val_loss: -8.6320 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.62782 to -8.63204, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.2512 - acc: 0.2440 - val_loss: -8.6342 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.63204 to -8.63424, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.2549 - acc: 0.2440 - val_loss: -8.6375 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.63424 to -8.63746, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.2567 - acc: 0.2440 - val_loss: -8.6425 - val_acc: 0.2548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from -8.63746 to -8.64250, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.2553 - acc: 0.2440 - val_loss: -8.6390 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.64250\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 841us/step - loss: -9.2578 - acc: 0.2440 - val_loss: -8.6448 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.64250 to -8.64476, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 850us/step - loss: -9.2660 - acc: 0.2440 - val_loss: -8.6469 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.64476 to -8.64689, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.2656 - acc: 0.2440 - val_loss: -8.6506 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.64689 to -8.65056, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.2624 - acc: 0.2440 - val_loss: -8.6470 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.65056\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 858us/step - loss: -9.2650 - acc: 0.2440 - val_loss: -8.6508 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.65056 to -8.65078, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2361 samples, validate on 263 samples\n",
      "Epoch 1/40\n",
      "2361/2361 [==============================] - 14s 6ms/step - loss: -5.0625 - acc: 0.2444 - val_loss: -7.0415 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -7.04148, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2361/2361 [==============================] - 2s 874us/step - loss: -7.7317 - acc: 0.2440 - val_loss: -7.2026 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00002: val_loss improved from -7.04148 to -7.20263, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -7.8868 - acc: 0.2440 - val_loss: -7.3508 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00003: val_loss improved from -7.20263 to -7.35075, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -8.0297 - acc: 0.2440 - val_loss: -7.4868 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.35075 to -7.48680, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2361/2361 [==============================] - 2s 842us/step - loss: -8.1630 - acc: 0.2440 - val_loss: -7.6181 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.48680 to -7.61813, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -8.2891 - acc: 0.2440 - val_loss: -7.7412 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.61813 to -7.74124, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.4121 - acc: 0.2440 - val_loss: -7.8616 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.74124 to -7.86159, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -8.5290 - acc: 0.2440 - val_loss: -7.9752 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.86159 to -7.97518, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -8.6443 - acc: 0.2440 - val_loss: -8.0864 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.97518 to -8.08639, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2361/2361 [==============================] - 2s 840us/step - loss: -8.7456 - acc: 0.2440 - val_loss: -8.1846 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00010: val_loss improved from -8.08639 to -8.18458, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2361/2361 [==============================] - 2s 844us/step - loss: -8.8422 - acc: 0.2440 - val_loss: -8.2748 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00011: val_loss improved from -8.18458 to -8.27481, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2361/2361 [==============================] - 2s 847us/step - loss: -8.9148 - acc: 0.2440 - val_loss: -8.3307 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00012: val_loss improved from -8.27481 to -8.33067, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -8.9727 - acc: 0.2440 - val_loss: -8.3868 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.33067 to -8.38681, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2361/2361 [==============================] - 2s 843us/step - loss: -9.0274 - acc: 0.2440 - val_loss: -8.4353 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.38681 to -8.43532, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.0714 - acc: 0.2440 - val_loss: -8.4770 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.43532 to -8.47699, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.1115 - acc: 0.2440 - val_loss: -8.5124 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.47699 to -8.51242, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.1437 - acc: 0.2440 - val_loss: -8.5438 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.51242 to -8.54379, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2361/2361 [==============================] - 2s 843us/step - loss: -9.1495 - acc: 0.2440 - val_loss: -8.5613 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.54379 to -8.56135, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2361/2361 [==============================] - 2s 839us/step - loss: -9.1792 - acc: 0.2440 - val_loss: -8.5649 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.56135 to -8.56489, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.1828 - acc: 0.2440 - val_loss: -8.5686 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.56489 to -8.56859, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2361/2361 [==============================] - 2s 848us/step - loss: -9.1866 - acc: 0.2440 - val_loss: -8.5726 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.56859 to -8.57262, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.1909 - acc: 0.2440 - val_loss: -8.5772 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.57262 to -8.57717, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2361/2361 [==============================] - 2s 851us/step - loss: -9.1959 - acc: 0.2440 - val_loss: -8.5828 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.57717 to -8.58280, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2361/2361 [==============================] - 2s 845us/step - loss: -9.2028 - acc: 0.2440 - val_loss: -8.5897 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.58280 to -8.58971, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2361/2361 [==============================] - 2s 852us/step - loss: -9.2111 - acc: 0.2440 - val_loss: -8.5946 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.58971 to -8.59458, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2361/2361 [==============================] - 2s 855us/step - loss: -9.2160 - acc: 0.2440 - val_loss: -8.6019 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.59458 to -8.60188, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2361/2361 [==============================] - 2s 846us/step - loss: -9.2238 - acc: 0.2440 - val_loss: -8.6111 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.60188 to -8.61106, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2361/2361 [==============================] - 2s 853us/step - loss: -9.2334 - acc: 0.2440 - val_loss: -8.6200 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.61106 to -8.61996, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2361/2361 [==============================] - 2s 844us/step - loss: -9.2358 - acc: 0.2440 - val_loss: -8.6207 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.61996 to -8.62069, saving model to model-5.h5\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 2s 847us/step - loss: -9.2412 - acc: 0.2440 - val_loss: -8.6283 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.62069 to -8.62835, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2361/2361 [==============================] - 2s 849us/step - loss: -9.2435 - acc: 0.2440 - val_loss: -8.6281 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.62835\n",
      "Epoch 32/40\n",
      "2361/2361 [==============================] - 2s 917us/step - loss: -9.2481 - acc: 0.2440 - val_loss: -8.6342 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.62835 to -8.63416, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2361/2361 [==============================] - 2s 908us/step - loss: -9.2546 - acc: 0.2440 - val_loss: -8.6396 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.63416 to -8.63962, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2361/2361 [==============================] - 2s 971us/step - loss: -9.2553 - acc: 0.2440 - val_loss: -8.6371 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.63962\n",
      "Epoch 35/40\n",
      "2361/2361 [==============================] - 2s 941us/step - loss: -9.2551 - acc: 0.2440 - val_loss: -8.6385 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.63962\n",
      "Epoch 36/40\n",
      "2361/2361 [==============================] - 2s 973us/step - loss: -9.2562 - acc: 0.2440 - val_loss: -8.6400 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.63962 to -8.63997, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2361/2361 [==============================] - 2s 894us/step - loss: -9.2584 - acc: 0.2440 - val_loss: -8.6416 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.63997 to -8.64160, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2361/2361 [==============================] - 2s 859us/step - loss: -9.2617 - acc: 0.2440 - val_loss: -8.6437 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.64160 to -8.64366, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2361/2361 [==============================] - 2s 1ms/step - loss: -9.2644 - acc: 0.2440 - val_loss: -8.6446 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.64366 to -8.64460, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2361/2361 [==============================] - 2s 987us/step - loss: -9.2638 - acc: 0.2440 - val_loss: -8.6460 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.64460 to -8.64599, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 15s 8ms/step - loss: -0.8933 - acc: 0.2436 - val_loss: -5.9039 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -5.90392, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -7.6713 - acc: 0.2368 - val_loss: -6.6396 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -5.90392 to -6.63964, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 930us/step - loss: -7.8449 - acc: 0.2368 - val_loss: -6.7629 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.63964 to -6.76290, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -7.9663 - acc: 0.2368 - val_loss: -6.8826 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.76290 to -6.88262, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.0856 - acc: 0.2368 - val_loss: -6.9974 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.88262 to -6.99737, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -8.1985 - acc: 0.2368 - val_loss: -7.1136 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.99737 to -7.11357, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -8.3142 - acc: 0.2368 - val_loss: -7.2267 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.11357 to -7.22672, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.4256 - acc: 0.2368 - val_loss: -7.3345 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.22672 to -7.33447, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 846us/step - loss: -8.5357 - acc: 0.2368 - val_loss: -7.4419 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.33447 to -7.44186, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.6391 - acc: 0.2368 - val_loss: -7.5461 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.44186 to -7.54608, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.7399 - acc: 0.2368 - val_loss: -7.6425 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.54608 to -7.64250, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -8.8324 - acc: 0.2368 - val_loss: -7.7315 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.64250 to -7.73150, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.9169 - acc: 0.2368 - val_loss: -7.8123 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.73150 to -7.81230, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -8.9920 - acc: 0.2368 - val_loss: -7.8777 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.81230 to -7.87768, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.0606 - acc: 0.2368 - val_loss: -7.9454 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.87768 to -7.94541, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.1124 - acc: 0.2368 - val_loss: -7.9939 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.94541 to -7.99389, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.1625 - acc: 0.2368 - val_loss: -8.0368 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.99389 to -8.03678, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -9.2054 - acc: 0.2368 - val_loss: -8.0739 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.03678 to -8.07393, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.2384 - acc: 0.2368 - val_loss: -8.1086 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.07393 to -8.10861, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.2668 - acc: 0.2368 - val_loss: -8.1302 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.10861 to -8.13018, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2911 - acc: 0.2368 - val_loss: -8.1517 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.13018 to -8.15173, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.3100 - acc: 0.2368 - val_loss: -8.1651 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.15173 to -8.16505, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3226 - acc: 0.2368 - val_loss: -8.1805 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.16505 to -8.18053, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3337 - acc: 0.2368 - val_loss: -8.2049 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.18053 to -8.20492, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3404 - acc: 0.2368 - val_loss: -8.1942 - val_acc: 0.2582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_loss did not improve from -8.20492\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.3487 - acc: 0.2368 - val_loss: -8.2029 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.20492\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3562 - acc: 0.2368 - val_loss: -8.2040 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -8.20492\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3576 - acc: 0.2368 - val_loss: -8.2095 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.20492 to -8.20946, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3614 - acc: 0.2368 - val_loss: -8.2104 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.20946 to -8.21038, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3643 - acc: 0.2368 - val_loss: -8.2167 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.21038 to -8.21670, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 893us/step - loss: -9.3598 - acc: 0.2368 - val_loss: -8.2116 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.21670\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.3635 - acc: 0.2368 - val_loss: -8.2146 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.21670\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3663 - acc: 0.2368 - val_loss: -8.2172 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.21670 to -8.21725, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.3689 - acc: 0.2368 - val_loss: -8.2197 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.21725 to -8.21971, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.3724 - acc: 0.2368 - val_loss: -8.2201 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.21971 to -8.22010, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -9.3698 - acc: 0.2368 - val_loss: -8.2199 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.22010\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3717 - acc: 0.2368 - val_loss: -8.2231 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.22010 to -8.22305, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3733 - acc: 0.2368 - val_loss: -8.2209 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.22305\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -9.3727 - acc: 0.2368 - val_loss: -8.2235 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.22305 to -8.22348, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3753 - acc: 0.2368 - val_loss: -8.2237 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.22348 to -8.22367, saving model to model-1.h5\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -4.0827 - acc: 0.2358 - val_loss: -6.5459 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.54589, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -7.7480 - acc: 0.2368 - val_loss: -6.6792 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.54589 to -6.67925, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -7.8829 - acc: 0.2368 - val_loss: -6.8039 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.67925 to -6.80393, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -8.0077 - acc: 0.2368 - val_loss: -6.9329 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.80393 to -6.93289, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.1314 - acc: 0.2368 - val_loss: -7.0483 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.93289 to -7.04828, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -8.2504 - acc: 0.2368 - val_loss: -7.1633 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.04828 to -7.16325, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.3665 - acc: 0.2368 - val_loss: -7.2748 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.16325 to -7.27477, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.4728 - acc: 0.2368 - val_loss: -7.3871 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.27477 to -7.38714, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -8.5847 - acc: 0.2368 - val_loss: -7.4908 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.38714 to -7.49081, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -8.6876 - acc: 0.2368 - val_loss: -7.5919 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.49081 to -7.59190, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.7842 - acc: 0.2368 - val_loss: -7.6856 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.59190 to -7.68561, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.8734 - acc: 0.2368 - val_loss: -7.7697 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.68561 to -7.76974, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.9516 - acc: 0.2368 - val_loss: -7.8406 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.76974 to -7.84064, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.0230 - acc: 0.2368 - val_loss: -7.9122 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.84064 to -7.91220, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.0891 - acc: 0.2368 - val_loss: -7.9763 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.91220 to -7.97627, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -9.1397 - acc: 0.2368 - val_loss: -8.0137 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.97627 to -8.01371, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.1850 - acc: 0.2368 - val_loss: -8.0602 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.01371 to -8.06018, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.2257 - acc: 0.2368 - val_loss: -8.0909 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.06018 to -8.09091, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 889us/step - loss: -9.2554 - acc: 0.2368 - val_loss: -8.1222 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.09091 to -8.12216, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.2826 - acc: 0.2368 - val_loss: -8.1443 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.12216 to -8.14429, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.2904 - acc: 0.2368 - val_loss: -8.1496 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.14429 to -8.14958, saving model to model-2.h5\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.3059 - acc: 0.2368 - val_loss: -8.1626 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.14958 to -8.16258, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3182 - acc: 0.2368 - val_loss: -8.1750 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.16258 to -8.17500, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.3304 - acc: 0.2368 - val_loss: -8.1792 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.17500 to -8.17925, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.3337 - acc: 0.2368 - val_loss: -8.1873 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.17925 to -8.18730, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3409 - acc: 0.2368 - val_loss: -8.1938 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.18730 to -8.19382, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3473 - acc: 0.2368 - val_loss: -8.2005 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.19382 to -8.20052, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.3413 - acc: 0.2368 - val_loss: -8.1961 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -8.20052\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.3479 - acc: 0.2368 - val_loss: -8.1989 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -8.20052\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3507 - acc: 0.2368 - val_loss: -8.2017 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.20052 to -8.20173, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.3536 - acc: 0.2368 - val_loss: -8.2046 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.20173 to -8.20461, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3565 - acc: 0.2368 - val_loss: -8.2076 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.20461 to -8.20762, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.3586 - acc: 0.2368 - val_loss: -8.2077 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.20762 to -8.20773, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -9.3598 - acc: 0.2368 - val_loss: -8.2112 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.20773 to -8.21121, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3631 - acc: 0.2368 - val_loss: -8.2114 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.21121 to -8.21142, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3637 - acc: 0.2368 - val_loss: -8.2153 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.21142 to -8.21533, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -9.3658 - acc: 0.2368 - val_loss: -8.2150 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.21533\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.3672 - acc: 0.2368 - val_loss: -8.2187 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.21533 to -8.21870, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -9.3703 - acc: 0.2368 - val_loss: -8.2200 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.21870 to -8.22002, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3695 - acc: 0.2368 - val_loss: -8.2196 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.22002\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -3.9724 - acc: 0.2389 - val_loss: -6.5628 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.56277, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -7.7638 - acc: 0.2368 - val_loss: -6.6788 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.56277 to -6.67884, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -7.8776 - acc: 0.2368 - val_loss: -6.7910 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.67884 to -6.79097, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -7.9893 - acc: 0.2368 - val_loss: -6.9021 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.79097 to -6.90209, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -8.0979 - acc: 0.2368 - val_loss: -7.0094 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.90209 to -7.00939, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -8.2062 - acc: 0.2368 - val_loss: -7.1162 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.00939 to -7.11618, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.3134 - acc: 0.2368 - val_loss: -7.2242 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.11618 to -7.22420, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.4229 - acc: 0.2368 - val_loss: -7.3330 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.22420 to -7.33297, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -8.5290 - acc: 0.2368 - val_loss: -7.4358 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.33297 to -7.43577, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -8.6261 - acc: 0.2368 - val_loss: -7.5354 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.43577 to -7.53542, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -8.7255 - acc: 0.2368 - val_loss: -7.6296 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.53542 to -7.62957, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.8191 - acc: 0.2368 - val_loss: -7.7177 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.62957 to -7.71771, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -8.9060 - acc: 0.2368 - val_loss: -7.8010 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.71771 to -7.80100, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 847us/step - loss: -8.9843 - acc: 0.2368 - val_loss: -7.8759 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.80100 to -7.87589, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.0558 - acc: 0.2368 - val_loss: -7.9429 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.87589 to -7.94288, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.1184 - acc: 0.2368 - val_loss: -7.9995 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.94288 to -7.99946, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -9.1664 - acc: 0.2368 - val_loss: -8.0391 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.99946 to -8.03908, saving model to model-3.h5\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2080 - acc: 0.2368 - val_loss: -8.0812 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.03908 to -8.08116, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.2438 - acc: 0.2368 - val_loss: -8.1045 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.08116 to -8.10447, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.2671 - acc: 0.2368 - val_loss: -8.1315 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.10447 to -8.13152, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.2908 - acc: 0.2368 - val_loss: -8.1507 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.13152 to -8.15069, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.3020 - acc: 0.2368 - val_loss: -8.1561 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.15069 to -8.15613, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.3110 - acc: 0.2368 - val_loss: -8.1658 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.15613 to -8.16582, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3203 - acc: 0.2368 - val_loss: -8.1747 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.16582 to -8.17466, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.3288 - acc: 0.2368 - val_loss: -8.1829 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.17466 to -8.18286, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.3368 - acc: 0.2368 - val_loss: -8.1906 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.18286 to -8.19056, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -9.3437 - acc: 0.2368 - val_loss: -8.1956 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.19056 to -8.19560, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.3484 - acc: 0.2368 - val_loss: -8.2002 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.19560 to -8.20022, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3538 - acc: 0.2368 - val_loss: -8.2051 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.20022 to -8.20513, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.3573 - acc: 0.2368 - val_loss: -8.2088 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.20513 to -8.20880, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -9.3609 - acc: 0.2368 - val_loss: -8.2086 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -8.20880\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.3613 - acc: 0.2368 - val_loss: -8.2133 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.20880 to -8.21333, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3658 - acc: 0.2368 - val_loss: -8.2175 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.21333 to -8.21745, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3700 - acc: 0.2368 - val_loss: -8.2142 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.21745\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.3656 - acc: 0.2368 - val_loss: -8.2160 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.21745\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3673 - acc: 0.2368 - val_loss: -8.2177 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.21745 to -8.21768, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.3690 - acc: 0.2368 - val_loss: -8.2194 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.21768 to -8.21940, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3707 - acc: 0.2368 - val_loss: -8.2211 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.21940 to -8.22115, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3725 - acc: 0.2368 - val_loss: -8.2305 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.22115 to -8.23051, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.3684 - acc: 0.2368 - val_loss: -8.2193 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.23051\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -3.6946 - acc: 0.2290 - val_loss: -6.5769 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.57695, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -7.7704 - acc: 0.2368 - val_loss: -6.6835 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.57695 to -6.68346, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -7.8800 - acc: 0.2368 - val_loss: -6.7905 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.68346 to -6.79053, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -7.9865 - acc: 0.2368 - val_loss: -6.8968 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.79053 to -6.89680, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -8.0928 - acc: 0.2368 - val_loss: -7.0045 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.89680 to -7.00447, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -8.2004 - acc: 0.2368 - val_loss: -7.1100 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.00447 to -7.10996, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -8.3062 - acc: 0.2368 - val_loss: -7.2198 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.10996 to -7.21979, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -8.4107 - acc: 0.2368 - val_loss: -7.3197 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.21979 to -7.31966, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -8.5155 - acc: 0.2368 - val_loss: -7.4249 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.31966 to -7.42491, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -8.6201 - acc: 0.2368 - val_loss: -7.5278 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.42491 to -7.52779, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.7204 - acc: 0.2368 - val_loss: -7.6253 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.52779 to -7.62526, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -8.8145 - acc: 0.2368 - val_loss: -7.7165 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.62526 to -7.71650, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -8.9013 - acc: 0.2368 - val_loss: -7.7969 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.71650 to -7.79687, saving model to model-4.h5\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 863us/step - loss: -8.9805 - acc: 0.2368 - val_loss: -7.8667 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.79687 to -7.86666, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.0473 - acc: 0.2368 - val_loss: -7.9419 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.86666 to -7.94185, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.1067 - acc: 0.2368 - val_loss: -7.9844 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.94185 to -7.98436, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.1562 - acc: 0.2368 - val_loss: -8.0268 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.98436 to -8.02677, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -9.1950 - acc: 0.2368 - val_loss: -8.0666 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.02677 to -8.06665, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.2318 - acc: 0.2368 - val_loss: -8.0977 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.06665 to -8.09767, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 846us/step - loss: -9.2607 - acc: 0.2368 - val_loss: -8.1199 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.09767 to -8.11985, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.2809 - acc: 0.2368 - val_loss: -8.1434 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.11985 to -8.14336, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 846us/step - loss: -9.3016 - acc: 0.2368 - val_loss: -8.1600 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.14336 to -8.16001, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 846us/step - loss: -9.3174 - acc: 0.2368 - val_loss: -8.1751 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.16001 to -8.17513, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.3307 - acc: 0.2368 - val_loss: -8.1868 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.17513 to -8.18683, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3271 - acc: 0.2368 - val_loss: -8.1857 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -8.18683\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -9.3375 - acc: 0.2368 - val_loss: -8.1886 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.18683 to -8.18856, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -9.3404 - acc: 0.2368 - val_loss: -8.1914 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.18856 to -8.19137, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -9.3432 - acc: 0.2368 - val_loss: -8.1942 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.19137 to -8.19422, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.3461 - acc: 0.2368 - val_loss: -8.1972 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.19422 to -8.19718, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 844us/step - loss: -9.3491 - acc: 0.2368 - val_loss: -8.2003 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.19718 to -8.20031, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3523 - acc: 0.2368 - val_loss: -8.2036 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.20031 to -8.20364, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.3557 - acc: 0.2368 - val_loss: -8.2072 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.20364 to -8.20717, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3592 - acc: 0.2368 - val_loss: -8.2171 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.20717 to -8.21712, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -9.3616 - acc: 0.2368 - val_loss: -8.2099 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.21712\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.3622 - acc: 0.2368 - val_loss: -8.2139 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.21712\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 844us/step - loss: -9.3652 - acc: 0.2368 - val_loss: -8.2159 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.21712\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3649 - acc: 0.2368 - val_loss: -8.2133 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.21712\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 840us/step - loss: -9.3641 - acc: 0.2368 - val_loss: -8.2136 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.21712\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.3643 - acc: 0.2368 - val_loss: -8.2139 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.21712\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 844us/step - loss: -9.3646 - acc: 0.2368 - val_loss: -8.2142 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.21712\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -4.0763 - acc: 0.2420 - val_loss: -6.5596 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.55958, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 847us/step - loss: -7.7538 - acc: 0.2368 - val_loss: -6.6589 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.55958 to -6.65891, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 845us/step - loss: -7.8491 - acc: 0.2368 - val_loss: -6.7562 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.65891 to -6.75621, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 839us/step - loss: -7.9482 - acc: 0.2368 - val_loss: -6.8524 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.75621 to -6.85244, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 835us/step - loss: -8.0437 - acc: 0.2368 - val_loss: -6.9488 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.85244 to -6.94884, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 843us/step - loss: -8.1403 - acc: 0.2368 - val_loss: -7.0442 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -6.94884 to -7.04420, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 845us/step - loss: -8.2380 - acc: 0.2368 - val_loss: -7.1451 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.04420 to -7.14512, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 841us/step - loss: -8.3399 - acc: 0.2368 - val_loss: -7.2481 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.14512 to -7.24813, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 842us/step - loss: -8.4419 - acc: 0.2368 - val_loss: -7.3506 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.24813 to -7.35057, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -8.5456 - acc: 0.2368 - val_loss: -7.4534 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.35057 to -7.45337, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 836us/step - loss: -8.6487 - acc: 0.2368 - val_loss: -7.5523 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.45337 to -7.55226, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 840us/step - loss: -8.7453 - acc: 0.2368 - val_loss: -7.6483 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.55226 to -7.64833, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 912us/step - loss: -8.8389 - acc: 0.2368 - val_loss: -7.7377 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.64833 to -7.73769, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 920us/step - loss: -8.9249 - acc: 0.2368 - val_loss: -7.8208 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.73769 to -7.82082, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 938us/step - loss: -9.0042 - acc: 0.2368 - val_loss: -7.8941 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.82082 to -7.89413, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.0741 - acc: 0.2368 - val_loss: -7.9598 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.89413 to -7.95976, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 899us/step - loss: -9.1337 - acc: 0.2368 - val_loss: -8.0121 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -7.95976 to -8.01214, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.1848 - acc: 0.2368 - val_loss: -8.0617 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.01214 to -8.06173, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.2281 - acc: 0.2368 - val_loss: -8.0918 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.06173 to -8.09178, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2559 - acc: 0.2368 - val_loss: -8.1222 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.09178 to -8.12221, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 994us/step - loss: -9.2831 - acc: 0.2368 - val_loss: -8.1452 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.12221 to -8.14518, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3045 - acc: 0.2368 - val_loss: -8.1639 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.14518 to -8.16388, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -9.3222 - acc: 0.2368 - val_loss: -8.1776 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.16388 to -8.17764, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.3347 - acc: 0.2368 - val_loss: -8.1882 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.17764 to -8.18824, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.3445 - acc: 0.2368 - val_loss: -8.2008 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.18824 to -8.20075, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3537 - acc: 0.2368 - val_loss: -8.2066 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.20075 to -8.20658, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3600 - acc: 0.2368 - val_loss: -8.2118 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.20658 to -8.21180, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.3654 - acc: 0.2368 - val_loss: -8.2156 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.21180 to -8.21558, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.3690 - acc: 0.2368 - val_loss: -8.2217 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.21558 to -8.22167, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3696 - acc: 0.2368 - val_loss: -8.2214 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.22167\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3738 - acc: 0.2368 - val_loss: -8.2253 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.22167 to -8.22534, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 931us/step - loss: -9.3737 - acc: 0.2368 - val_loss: -8.2249 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.22534\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 928us/step - loss: -9.3759 - acc: 0.2368 - val_loss: -8.2248 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -8.22534\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 971us/step - loss: -9.3768 - acc: 0.2368 - val_loss: -8.2279 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.22534 to -8.22785, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 920us/step - loss: -9.3780 - acc: 0.2368 - val_loss: -8.2253 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.22785\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3773 - acc: 0.2368 - val_loss: -8.2283 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.22785 to -8.22835, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 919us/step - loss: -9.3788 - acc: 0.2368 - val_loss: -8.2288 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.22835 to -8.22883, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 996us/step - loss: -9.3791 - acc: 0.2368 - val_loss: -8.2291 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.22883 to -8.22907, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3782 - acc: 0.2368 - val_loss: -8.2281 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.22907\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.2709 - acc: 0.2368 - val_loss: -8.2261 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.22907\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -0.6130 - acc: 0.2378 - val_loss: -6.6071 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.60712, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -7.8851 - acc: 0.2368 - val_loss: -6.8845 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.60712 to -6.88453, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -8.1431 - acc: 0.2368 - val_loss: -7.1162 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.88453 to -7.11617, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -8.3504 - acc: 0.2368 - val_loss: -7.2998 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -7.11617 to -7.29981, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.5206 - acc: 0.2368 - val_loss: -7.4539 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.29981 to -7.45390, saving model to model-1.h5\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 920us/step - loss: -8.6641 - acc: 0.2368 - val_loss: -7.5821 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.45390 to -7.58206, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 888us/step - loss: -8.7857 - acc: 0.2368 - val_loss: -7.6978 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.58206 to -7.69776, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -8.8888 - acc: 0.2368 - val_loss: -7.7862 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.69776 to -7.78617, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 842us/step - loss: -8.9747 - acc: 0.2368 - val_loss: -7.8681 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.78617 to -7.86806, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 835us/step - loss: -9.0484 - acc: 0.2368 - val_loss: -7.9360 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.86806 to -7.93603, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.1121 - acc: 0.2368 - val_loss: -7.9837 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.93603 to -7.98372, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 847us/step - loss: -9.1588 - acc: 0.2368 - val_loss: -8.0387 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.98372 to -8.03869, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 839us/step - loss: -9.1968 - acc: 0.2368 - val_loss: -8.0632 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -8.03869 to -8.06319, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 841us/step - loss: -9.2289 - acc: 0.2368 - val_loss: -8.0972 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -8.06319 to -8.09724, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 844us/step - loss: -9.2589 - acc: 0.2368 - val_loss: -8.1223 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.09724 to -8.12231, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 843us/step - loss: -9.2806 - acc: 0.2368 - val_loss: -8.1400 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.12231 to -8.13996, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -9.2989 - acc: 0.2368 - val_loss: -8.1419 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.13996 to -8.14188, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 844us/step - loss: -9.3056 - acc: 0.2368 - val_loss: -8.1618 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.14188 to -8.16183, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3181 - acc: 0.2368 - val_loss: -8.1748 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.16183 to -8.17476, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 844us/step - loss: -9.3301 - acc: 0.2368 - val_loss: -8.1816 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.17476 to -8.18157, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.3370 - acc: 0.2368 - val_loss: -8.1839 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.18157 to -8.18385, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 855us/step - loss: -9.3387 - acc: 0.2368 - val_loss: -8.1935 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.18385 to -8.19355, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 842us/step - loss: -9.3479 - acc: 0.2368 - val_loss: -8.1982 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.19355 to -8.19821, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.3523 - acc: 0.2368 - val_loss: -8.2025 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.19821 to -8.20251, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -9.3565 - acc: 0.2368 - val_loss: -8.2091 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.20251 to -8.20914, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 845us/step - loss: -9.3598 - acc: 0.2368 - val_loss: -8.2053 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.20914\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 839us/step - loss: -9.3581 - acc: 0.2368 - val_loss: -8.2104 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.20914 to -8.21039, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 842us/step - loss: -9.3630 - acc: 0.2368 - val_loss: -8.2149 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.21039 to -8.21490, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 842us/step - loss: -9.3666 - acc: 0.2368 - val_loss: -8.2173 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.21490 to -8.21734, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 843us/step - loss: -9.3683 - acc: 0.2368 - val_loss: -8.2148 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.21734\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 844us/step - loss: -9.3675 - acc: 0.2368 - val_loss: -8.2194 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.21734 to -8.21945, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 843us/step - loss: -9.3712 - acc: 0.2368 - val_loss: -8.2212 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.21945 to -8.22123, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3716 - acc: 0.2368 - val_loss: -8.2222 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.22123 to -8.22218, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.3736 - acc: 0.2368 - val_loss: -8.2201 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.22218\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3729 - acc: 0.2368 - val_loss: -8.2248 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.22218 to -8.22483, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3725 - acc: 0.2368 - val_loss: -8.2223 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -8.22483\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 854us/step - loss: -9.3744 - acc: 0.2368 - val_loss: -8.2257 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.22483 to -8.22573, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.3740 - acc: 0.2368 - val_loss: -8.2210 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -8.22573\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -9.3719 - acc: 0.2368 - val_loss: -8.2217 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.22573\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 843us/step - loss: -9.3727 - acc: 0.2368 - val_loss: -8.2225 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.22573\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -3.2197 - acc: 0.2358 - val_loss: -6.6006 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.60061, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 838us/step - loss: -7.8413 - acc: 0.2368 - val_loss: -6.8049 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.60061 to -6.80491, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 846us/step - loss: -8.0338 - acc: 0.2368 - val_loss: -6.9835 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.80491 to -6.98347, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -8.2028 - acc: 0.2368 - val_loss: -7.1358 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.98347 to -7.13582, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 852us/step - loss: -8.3483 - acc: 0.2368 - val_loss: -7.2764 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.13582 to -7.27645, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 853us/step - loss: -8.4814 - acc: 0.2368 - val_loss: -7.4009 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.27645 to -7.40089, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 849us/step - loss: -8.6013 - acc: 0.2368 - val_loss: -7.5137 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.40089 to -7.51369, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -8.7088 - acc: 0.2368 - val_loss: -7.6137 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.51369 to -7.61367, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -8.8062 - acc: 0.2368 - val_loss: -7.7100 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.61367 to -7.71005, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 858us/step - loss: -8.8966 - acc: 0.2368 - val_loss: -7.7893 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.71005 to -7.78931, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -8.9751 - acc: 0.2368 - val_loss: -7.8650 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.78931 to -7.86502, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 934us/step - loss: -9.0439 - acc: 0.2368 - val_loss: -7.9205 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.86502 to -7.92054, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 920us/step - loss: -9.0968 - acc: 0.2368 - val_loss: -7.9785 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.92054 to -7.97849, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 922us/step - loss: -9.1423 - acc: 0.2368 - val_loss: -8.0093 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.97849 to -8.00933, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 943us/step - loss: -9.1766 - acc: 0.2368 - val_loss: -8.0471 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -8.00933 to -8.04707, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 880us/step - loss: -9.2116 - acc: 0.2368 - val_loss: -8.0786 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -8.04707 to -8.07864, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -9.2366 - acc: 0.2368 - val_loss: -8.0986 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.07864 to -8.09859, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -9.2607 - acc: 0.2368 - val_loss: -8.1230 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.09859 to -8.12301, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.2813 - acc: 0.2368 - val_loss: -8.1394 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.12301 to -8.13943, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -9.2987 - acc: 0.2368 - val_loss: -8.1583 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.13943 to -8.15833, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -9.3159 - acc: 0.2368 - val_loss: -8.1731 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.15833 to -8.17310, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 923us/step - loss: -9.3266 - acc: 0.2368 - val_loss: -8.1801 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.17310 to -8.18006, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -9.3376 - acc: 0.2368 - val_loss: -8.1955 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.18006 to -8.19553, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - ETA: 0s - loss: -9.2100 - acc: 0.23 - 2s 937us/step - loss: -9.3300 - acc: 0.2368 - val_loss: -8.1895 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -8.19553\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3410 - acc: 0.2368 - val_loss: -8.1915 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -8.19553\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3430 - acc: 0.2368 - val_loss: -8.1936 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -8.19553\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3451 - acc: 0.2368 - val_loss: -8.1958 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.19553 to -8.19584, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3475 - acc: 0.2368 - val_loss: -8.1983 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.19584 to -8.19832, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3501 - acc: 0.2368 - val_loss: -8.2011 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.19832 to -8.20108, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3530 - acc: 0.2368 - val_loss: -8.2042 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.20108 to -8.20416, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 897us/step - loss: -9.3559 - acc: 0.2368 - val_loss: -8.2059 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.20416 to -8.20588, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -9.3582 - acc: 0.2368 - val_loss: -8.2073 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.20588 to -8.20734, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3599 - acc: 0.2368 - val_loss: -8.2119 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.20734 to -8.21188, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -9.3587 - acc: 0.2368 - val_loss: -8.2084 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -8.21188\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -9.3604 - acc: 0.2368 - val_loss: -8.2117 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -8.21188\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -9.3636 - acc: 0.2368 - val_loss: -8.2149 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.21188 to -8.21487, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3667 - acc: 0.2368 - val_loss: -8.2172 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.21487 to -8.21722, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.3673 - acc: 0.2368 - val_loss: -8.2174 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.21722 to -8.21741, saving model to model-2.h5\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3684 - acc: 0.2368 - val_loss: -8.2164 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.21741\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3687 - acc: 0.2368 - val_loss: -8.2203 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.21741 to -8.22029, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -3.0497 - acc: 0.2347 - val_loss: -6.5673 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.56734, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -7.7926 - acc: 0.2368 - val_loss: -6.7377 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.56734 to -6.73766, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -7.9546 - acc: 0.2368 - val_loss: -6.8897 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.73766 to -6.88972, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.0985 - acc: 0.2368 - val_loss: -7.0247 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.88972 to -7.02471, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.2309 - acc: 0.2368 - val_loss: -7.1497 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.02471 to -7.14972, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.3512 - acc: 0.2368 - val_loss: -7.2660 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.14972 to -7.26597, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 886us/step - loss: -8.4649 - acc: 0.2368 - val_loss: -7.3766 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.26597 to -7.37660, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -8.5725 - acc: 0.2368 - val_loss: -7.4806 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.37660 to -7.48063, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 881us/step - loss: -8.6743 - acc: 0.2368 - val_loss: -7.5815 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.48063 to -7.58153, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -8.7623 - acc: 0.2368 - val_loss: -7.6599 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.58153 to -7.65994, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.8472 - acc: 0.2368 - val_loss: -7.7440 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.65994 to -7.74400, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.9254 - acc: 0.2368 - val_loss: -7.8155 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.74400 to -7.81553, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.9960 - acc: 0.2368 - val_loss: -7.8837 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.81553 to -7.88370, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.0615 - acc: 0.2368 - val_loss: -7.9437 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.88370 to -7.94368, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 913us/step - loss: -9.1191 - acc: 0.2368 - val_loss: -7.9936 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.94368 to -7.99361, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.1665 - acc: 0.2368 - val_loss: -8.0424 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.99361 to -8.04244, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.2114 - acc: 0.2368 - val_loss: -8.0890 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.04244 to -8.08900, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -9.2335 - acc: 0.2368 - val_loss: -8.0925 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.08900 to -8.09249, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -9.2517 - acc: 0.2368 - val_loss: -8.1122 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.09249 to -8.11220, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.2707 - acc: 0.2368 - val_loss: -8.1302 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.11220 to -8.13019, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.2881 - acc: 0.2368 - val_loss: -8.1459 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.13019 to -8.14594, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3015 - acc: 0.2368 - val_loss: -8.1586 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.14594 to -8.15862, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.3140 - acc: 0.2368 - val_loss: -8.1682 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.15862 to -8.16816, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 883us/step - loss: -9.3241 - acc: 0.2368 - val_loss: -8.1737 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.16816 to -8.17368, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 863us/step - loss: -9.3257 - acc: 0.2368 - val_loss: -8.1769 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.17368 to -8.17691, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3289 - acc: 0.2368 - val_loss: -8.1802 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.17691 to -8.18017, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3322 - acc: 0.2368 - val_loss: -8.1835 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.18017 to -8.18354, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.3357 - acc: 0.2368 - val_loss: -8.1871 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.18354 to -8.18713, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -9.3394 - acc: 0.2368 - val_loss: -8.1910 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.18713 to -8.19102, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -9.3434 - acc: 0.2368 - val_loss: -8.1953 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.19102 to -8.19527, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.3470 - acc: 0.2368 - val_loss: -8.1990 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.19527 to -8.19897, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 879us/step - loss: -9.3506 - acc: 0.2368 - val_loss: -8.2029 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.19897 to -8.20290, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.3528 - acc: 0.2368 - val_loss: -8.2043 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.20290 to -8.20434, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -9.3573 - acc: 0.2368 - val_loss: -8.2098 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.20434 to -8.20976, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3591 - acc: 0.2368 - val_loss: -8.2101 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.20976 to -8.21006, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3629 - acc: 0.2368 - val_loss: -8.2142 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.21006 to -8.21421, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.3649 - acc: 0.2368 - val_loss: -8.2146 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.21421 to -8.21459, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.3672 - acc: 0.2368 - val_loss: -8.2192 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.21459 to -8.21915, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3684 - acc: 0.2368 - val_loss: -8.2190 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.21915\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3712 - acc: 0.2368 - val_loss: -8.2217 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.21915 to -8.22172, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -3.6691 - acc: 0.2394 - val_loss: -6.6040 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.60397, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -7.8297 - acc: 0.2368 - val_loss: -6.7747 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.60397 to -6.77475, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -7.9920 - acc: 0.2368 - val_loss: -6.9265 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.77475 to -6.92651, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -8.1372 - acc: 0.2368 - val_loss: -7.0650 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.92651 to -7.06505, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 943us/step - loss: -8.2669 - acc: 0.2368 - val_loss: -7.1842 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -7.06505 to -7.18421, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -8.3843 - acc: 0.2368 - val_loss: -7.2983 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.18421 to -7.29835, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -8.4938 - acc: 0.2368 - val_loss: -7.4025 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.29835 to -7.40253, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -8.5970 - acc: 0.2368 - val_loss: -7.5040 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.40253 to -7.50398, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 872us/step - loss: -8.6934 - acc: 0.2368 - val_loss: -7.5877 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.50398 to -7.58768, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -8.7760 - acc: 0.2368 - val_loss: -7.6730 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.58768 to -7.67303, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.8584 - acc: 0.2368 - val_loss: -7.7526 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.67303 to -7.75255, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -8.9342 - acc: 0.2368 - val_loss: -7.8192 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.75255 to -7.81923, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.9992 - acc: 0.2368 - val_loss: -7.8852 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.81923 to -7.88519, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.0595 - acc: 0.2368 - val_loss: -7.9433 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.88519 to -7.94329, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -9.1163 - acc: 0.2368 - val_loss: -7.9942 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.94329 to -7.99416, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.1617 - acc: 0.2368 - val_loss: -8.0364 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.99416 to -8.03644, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 875us/step - loss: -9.2025 - acc: 0.2368 - val_loss: -8.0720 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.03644 to -8.07204, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -9.2388 - acc: 0.2368 - val_loss: -8.0996 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.07204 to -8.09963, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -9.2642 - acc: 0.2368 - val_loss: -8.1310 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.09963 to -8.13099, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 887us/step - loss: -9.2881 - acc: 0.2368 - val_loss: -8.1472 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.13099 to -8.14719, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 897us/step - loss: -9.3073 - acc: 0.2368 - val_loss: -8.1683 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.14719 to -8.16831, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 884us/step - loss: -9.1560 - acc: 0.2368 - val_loss: -8.1719 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.16831 to -8.17191, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 893us/step - loss: -9.3236 - acc: 0.2368 - val_loss: -8.1745 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.17191 to -8.17454, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -9.3263 - acc: 0.2368 - val_loss: -8.1771 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00024: val_loss improved from -8.17454 to -8.17714, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.3289 - acc: 0.2368 - val_loss: -8.1799 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.17714 to -8.17991, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 878us/step - loss: -9.3317 - acc: 0.2368 - val_loss: -8.1826 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.17991 to -8.18265, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 873us/step - loss: -9.3345 - acc: 0.2368 - val_loss: -8.1860 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.18265 to -8.18598, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 870us/step - loss: -9.3392 - acc: 0.2368 - val_loss: -8.1897 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.18598 to -8.18972, saving model to model-4.h5\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 2s 878us/step - loss: -9.3404 - acc: 0.2368 - val_loss: -8.1918 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.18972 to -8.19177, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 864us/step - loss: -9.3435 - acc: 0.2368 - val_loss: -8.1920 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss improved from -8.19177 to -8.19201, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 869us/step - loss: -9.3446 - acc: 0.2368 - val_loss: -8.1965 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.19201 to -8.19651, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3506 - acc: 0.2368 - val_loss: -8.1951 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -8.19651\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.3476 - acc: 0.2368 - val_loss: -8.1996 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.19651 to -8.19962, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.3525 - acc: 0.2368 - val_loss: -8.2034 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.19962 to -8.20342, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 862us/step - loss: -9.3571 - acc: 0.2368 - val_loss: -8.2039 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.20342 to -8.20393, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 868us/step - loss: -9.3575 - acc: 0.2368 - val_loss: -8.2086 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.20393 to -8.20862, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -9.3631 - acc: 0.2368 - val_loss: -8.2105 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss improved from -8.20862 to -8.21053, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 877us/step - loss: -9.3633 - acc: 0.2368 - val_loss: -8.2137 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.21053 to -8.21368, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.3616 - acc: 0.2368 - val_loss: -8.2082 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -8.21368\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 867us/step - loss: -9.3595 - acc: 0.2368 - val_loss: -8.2098 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -8.21368\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 1800\n",
      "Embedding dim: 200\n",
      "Filter sizes: [2, 3, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 1913 samples, validate on 213 samples\n",
      "Epoch 1/40\n",
      "1913/1913 [==============================] - 14s 7ms/step - loss: -3.8485 - acc: 0.2431 - val_loss: -6.5777 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -6.57771, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -7.7867 - acc: 0.2368 - val_loss: -6.7125 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00002: val_loss improved from -6.57771 to -6.71255, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -7.9189 - acc: 0.2368 - val_loss: -6.8390 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00003: val_loss improved from -6.71255 to -6.83903, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "1913/1913 [==============================] - 2s 885us/step - loss: -8.0408 - acc: 0.2368 - val_loss: -6.9577 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00004: val_loss improved from -6.83903 to -6.95770, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.1565 - acc: 0.2368 - val_loss: -7.0710 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00005: val_loss improved from -6.95770 to -7.07101, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "1913/1913 [==============================] - 2s 871us/step - loss: -8.2686 - acc: 0.2368 - val_loss: -7.1814 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00006: val_loss improved from -7.07101 to -7.18143, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "1913/1913 [==============================] - 2s 866us/step - loss: -8.3781 - acc: 0.2368 - val_loss: -7.2895 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00007: val_loss improved from -7.18143 to -7.28952, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "1913/1913 [==============================] - 2s 952us/step - loss: -8.4856 - acc: 0.2368 - val_loss: -7.3954 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00008: val_loss improved from -7.28952 to -7.39541, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "1913/1913 [==============================] - 2s 898us/step - loss: -8.5867 - acc: 0.2368 - val_loss: -7.4948 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00009: val_loss improved from -7.39541 to -7.49480, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "1913/1913 [==============================] - 2s 974us/step - loss: -8.6872 - acc: 0.2368 - val_loss: -7.5900 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00010: val_loss improved from -7.49480 to -7.59001, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "1913/1913 [==============================] - 2s 904us/step - loss: -8.7799 - acc: 0.2368 - val_loss: -7.6803 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00011: val_loss improved from -7.59001 to -7.68032, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "1913/1913 [==============================] - 2s 861us/step - loss: -8.8688 - acc: 0.2368 - val_loss: -7.7656 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00012: val_loss improved from -7.68032 to -7.76564, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -8.9423 - acc: 0.2368 - val_loss: -7.8298 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00013: val_loss improved from -7.76564 to -7.82976, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.0097 - acc: 0.2368 - val_loss: -7.8965 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00014: val_loss improved from -7.82976 to -7.89651, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "1913/1913 [==============================] - 2s 874us/step - loss: -9.0710 - acc: 0.2368 - val_loss: -7.9522 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00015: val_loss improved from -7.89651 to -7.95223, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "1913/1913 [==============================] - 2s 876us/step - loss: -9.1248 - acc: 0.2368 - val_loss: -8.0027 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00016: val_loss improved from -7.95223 to -8.00267, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.1722 - acc: 0.2368 - val_loss: -8.0455 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from -8.00267 to -8.04554, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "1913/1913 [==============================] - 2s 859us/step - loss: -9.2124 - acc: 0.2368 - val_loss: -8.0538 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00018: val_loss improved from -8.04554 to -8.05375, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.2326 - acc: 0.2368 - val_loss: -8.0945 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00019: val_loss improved from -8.05375 to -8.09450, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.2538 - acc: 0.2368 - val_loss: -8.1144 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00020: val_loss improved from -8.09450 to -8.11440, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "1913/1913 [==============================] - 2s 932us/step - loss: -9.2729 - acc: 0.2368 - val_loss: -8.1326 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00021: val_loss improved from -8.11440 to -8.13255, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.2869 - acc: 0.2368 - val_loss: -8.1430 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00022: val_loss improved from -8.13255 to -8.14304, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "1913/1913 [==============================] - 2s 980us/step - loss: -9.3028 - acc: 0.2368 - val_loss: -8.1494 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00023: val_loss improved from -8.14304 to -8.14936, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3103 - acc: 0.2368 - val_loss: -8.1672 - val_acc: 0.2582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_loss improved from -8.14936 to -8.16719, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3199 - acc: 0.2368 - val_loss: -8.1684 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00025: val_loss improved from -8.16719 to -8.16835, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "1913/1913 [==============================] - 2s 989us/step - loss: -9.3214 - acc: 0.2368 - val_loss: -8.1741 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00026: val_loss improved from -8.16835 to -8.17409, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3271 - acc: 0.2368 - val_loss: -8.1796 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00027: val_loss improved from -8.17409 to -8.17965, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "1913/1913 [==============================] - 2s 1ms/step - loss: -9.3327 - acc: 0.2368 - val_loss: -8.1858 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00028: val_loss improved from -8.17965 to -8.18575, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "1913/1913 [==============================] - 2s 947us/step - loss: -9.3402 - acc: 0.2368 - val_loss: -8.1910 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00029: val_loss improved from -8.18575 to -8.19102, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3415 - acc: 0.2368 - val_loss: -8.1909 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -8.19102\n",
      "Epoch 31/40\n",
      "1913/1913 [==============================] - 2s 865us/step - loss: -9.3443 - acc: 0.2368 - val_loss: -8.1960 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00031: val_loss improved from -8.19102 to -8.19604, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.3520 - acc: 0.2368 - val_loss: -8.1996 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00032: val_loss improved from -8.19604 to -8.19959, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.3531 - acc: 0.2368 - val_loss: -8.2028 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00033: val_loss improved from -8.19959 to -8.20279, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3561 - acc: 0.2368 - val_loss: -8.2050 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00034: val_loss improved from -8.20279 to -8.20500, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "1913/1913 [==============================] - 2s 856us/step - loss: -9.3577 - acc: 0.2368 - val_loss: -8.2073 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00035: val_loss improved from -8.20500 to -8.20730, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "1913/1913 [==============================] - 2s 857us/step - loss: -9.3623 - acc: 0.2368 - val_loss: -8.2116 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00036: val_loss improved from -8.20730 to -8.21156, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "1913/1913 [==============================] - 2s 848us/step - loss: -9.3658 - acc: 0.2368 - val_loss: -8.2088 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -8.21156\n",
      "Epoch 38/40\n",
      "1913/1913 [==============================] - 2s 860us/step - loss: -9.3622 - acc: 0.2368 - val_loss: -8.2144 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00038: val_loss improved from -8.21156 to -8.21444, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "1913/1913 [==============================] - 2s 851us/step - loss: -9.3663 - acc: 0.2368 - val_loss: -8.2173 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00039: val_loss improved from -8.21444 to -8.21735, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "1913/1913 [==============================] - 2s 850us/step - loss: -9.3688 - acc: 0.2368 - val_loss: -8.2191 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00040: val_loss improved from -8.21735 to -8.21912, saving model to model-5.h5\n"
     ]
    }
   ],
   "source": [
    "# BALANCED DATA\n",
    "printing = {}\n",
    "MAX_NUM_WORDS_AR = [ 2000, 2200, 1800 ]\n",
    "WORD_FILTERING = [3,5,7]\n",
    "emb_layers_names = ['word2vectext8','glovetext8']\n",
    "for num in MAX_NUM_WORDS_AR:\n",
    "    for filtering_count in WORD_FILTERING:\n",
    "        MAX_NUM_WORDS = num\n",
    "        emotional_mapping = {'ang': 0, 'sad': 1, 'hap': 2, 'neu': 3,'fru': 4,'exc': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "        data = load_data(filtering_count, emotional_mapping)\n",
    "        df = data[['text','emotion_code']]\n",
    "        df.head()\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data.text, data.emotion_code, test_size=TEST_SIZE)\n",
    "        tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(x_train)\n",
    "        sequences = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "        length = max_length(x_train)\n",
    "        word_index = tokenizer.word_index\n",
    "\n",
    "        result = [len(x.split()) for x in x_train]\n",
    "        data   = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
    "\n",
    "        embedding_data = [x.split() for x in x_train]\n",
    "        emb_layers = [create_word2vec_embeddings(use_text8=True),\n",
    "    #                   create_word2vec_embeddings(embedding_data),\n",
    "                      create_glove_embeddings(use_text8=True),\n",
    "    #                   create_glove_embeddings(embedding_data)\n",
    "                     ]\n",
    "\n",
    "    #     ######################################################\n",
    "        for index,lay in enumerate(emb_layers):\n",
    "\n",
    "            histories = []\n",
    "\n",
    "            for i in range(RUNS):\n",
    "                print('Running iteration %i/%i' % (i+1, RUNS))\n",
    "\n",
    "                X_train, X_val, labels, y_val = train_test_split(data, y_train, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "                emb_layer = None\n",
    "                if USE_GLOVE:\n",
    "                    emb_layer = lay#emb_layers[2] #create_word2vec_embeddings(result)\n",
    "\n",
    "                model = cnn_model.build_cnn(\n",
    "                    embedding_layer=emb_layer,\n",
    "                    num_words=MAX_NUM_WORDS,\n",
    "                    embedding_dim=EMBEDDING_DIM,\n",
    "                    filter_sizes=FILTER_SIZES,\n",
    "                    feature_maps=FEATURE_MAPS,\n",
    "                    max_seq_length=MAX_SEQ_LENGTH,\n",
    "                    dropout_rate=DROPOUT_RATE\n",
    "                )\n",
    "\n",
    "                model.compile(\n",
    "                    loss='binary_crossentropy',\n",
    "                    optimizer=Adadelta(clipvalue=3),\n",
    "                    metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "                history = model.fit(\n",
    "                    X_train, labels,\n",
    "                    epochs=NB_EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n",
    "                                               verbose=1, save_best_only=True, mode='min'),\n",
    "                               ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.01)\n",
    "                              ]\n",
    "                )\n",
    "                histories.append(history.history)\n",
    "\n",
    "            with open('history/unbalanced_'+emb_layers_names[index]+'_MAX'+str(MAX_NUM_WORDS)+'_WFILT_'+str(filtering_count)+'.pkl', 'wb') as f:\n",
    "                pickle.dump(histories, f)\n",
    "            printing['unbalanced_'+emb_layers_names[index]+'_MAX'+str(MAX_NUM_WORDS)+'_WFILT_'+str(filtering_count)+'.pkl'] = [get_avg(histories, 'loss'),get_avg(histories, 'acc'),get_avg(histories, 'val_loss'),get_avg(histories, 'val_acc')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unbalanced_glovetext8_MAX2000_WFILT_5.pkl': [-9.379054949759226, 0.24354087114839018, -9.686146862334624, 0.231939160041936], 'unbalanced_glovetext8_MAX1800_WFILT_7.pkl': [-9.369296975641806, 0.2368008341081343, -8.220108535480051, 0.2582159586635554], 'unbalanced_glovetext8_MAX2200_WFILT_3.pkl': [-9.863662485387323, 0.23831775586953013, -7.757138815233785, 0.2548387060242315], 'unbalanced_glovetext8_MAX2200_WFILT_5.pkl': [-9.717693644244507, 0.23210503843339608, -9.445315311707471, 0.27756655091568544], 'unbalanced_word2vectext8_MAX2200_WFILT_3.pkl': [-9.866766514356492, 0.23831775618662174, -7.759937753985005, 0.2548387060242315], 'unbalanced_word2vectext8_MAX2000_WFILT_7.pkl': [-9.22876589989949, 0.23680083402089283, -8.373327045709313, 0.2676056210703693], 'unbalanced_word2vectext8_MAX2000_WFILT_5.pkl': [-9.38152556748574, 0.24354087210771952, -9.688828022307769, 0.231939160041936], 'unbalanced_glovetext8_MAX1800_WFILT_5.pkl': [-9.270355138613075, 0.2439644209046527, -8.654833746500342, 0.25475285159770983], 'unbalanced_glovetext8_MAX2000_WFILT_7.pkl': [-9.221932783889573, 0.23680083420160739, -8.36417629797134, 0.2676056210703693], 'unbalanced_word2vectext8_MAX1800_WFILT_7.pkl': [-9.371292719763732, 0.23680083538871505, -8.224077295921218, 0.2582159586635554], 'unbalanced_word2vectext8_MAX2000_WFILT_3.pkl': [-9.118777526633334, 0.23723939441460487, -10.37913716839206, 0.25161290264898734], 'unbalanced_glovetext8_MAX2200_WFILT_7.pkl': [-8.641394580077328, 0.24725561831798842, -10.986896152451564, 0.22065728105289834], 'unbalanced_word2vectext8_MAX1800_WFILT_5.pkl': [-9.271967844173394, 0.2439644207291965, -8.657028341837258, 0.25475285159770983], 'unbalanced_glovetext8_MAX2000_WFILT_3.pkl': [-9.1194454228081, 0.23723939550728526, -10.380696468968546, 0.25161290264898734], 'unbalanced_word2vectext8_MAX1800_WFILT_3.pkl': [-9.412387682669973, 0.24263120041872255, -8.47781338230256, 0.27096773251410455], 'unbalanced_word2vectext8_MAX2200_WFILT_7.pkl': [-8.647020680656373, 0.2472556178833388, -10.991725544638477, 0.22065728105289834], 'unbalanced_word2vectext8_MAX2200_WFILT_5.pkl': [-9.719369364006951, 0.23210503782750389, -9.446777630214909, 0.27756655091568544], 'unbalanced_glovetext8_MAX1800_WFILT_3.pkl': [-9.412214061290047, 0.24263119797411795, -8.477503438149729, 0.27096773251410455]}\n"
     ]
    }
   ],
   "source": [
    "print(printing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('history/unbalanced_glovetext8_2954.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories = pickle.load(open('history/unbalanced_glovetext8_2500.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \t2.1239 loss / 0.2452 acc\n",
      "Validation: \t2.1951 loss / 0.2411 acc\n"
     ]
    }
   ],
   "source": [
    "def get_avg(histories, his_key):\n",
    "    tmp = []\n",
    "    for history in histories:\n",
    "        tmp.append(history[his_key][np.argmin(history['val_loss'])])\n",
    "    return np.mean(tmp)\n",
    "    \n",
    "print('Training: \\t%0.4f loss / %0.4f acc' % (get_avg(histories, 'loss'),\n",
    "                                              get_avg(histories, 'acc')))\n",
    "print('Validation: \\t%0.4f loss / %0.4f acc' % (get_avg(histories, 'val_loss'),\n",
    "                                                get_avg(histories, 'val_acc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def  plot_acc_loss(title, histories, key_acc, key_loss):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # Accuracy\n",
    "    ax1.set_title('Model accuracy (%s)' % title)\n",
    "    names = []\n",
    "    for i, model in enumerate(histories):\n",
    "        ax1.plot(model[key_acc])\n",
    "        ax1.set_xlabel('epoch')\n",
    "        names.append('Model %i' % (i+1))\n",
    "        ax1.set_ylabel('accuracy')\n",
    "    ax1.legend(names, loc='lower right')\n",
    "    # Loss\n",
    "    ax2.set_title('Model loss (%s)' % title)\n",
    "    for model in histories:\n",
    "        ax2.plot(model[key_loss])\n",
    "        ax2.set_xlabel('epoch')\n",
    "        ax2.set_ylabel('loss')\n",
    "    ax2.legend(names, loc='upper right')\n",
    "    fig.set_size_inches(20, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJkAAAFNCAYAAACjXb61AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcQddpAg5bXUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJkAAAFNCAYAAACjXb61AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIVpiaTiIiIiIiIiIhU2P8DbPCFTrddUocAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_loss('training', histories, 'acc', 'loss')\n",
    "plot_acc_loss('validation', histories, 'val_acc', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
