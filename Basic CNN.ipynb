{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Pickling\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Input, Dense, Flatten, Dropout, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_word2vec_text8(saveTo = 'models/text8.model'):\n",
    "    sentences = word2vec.Text8Corpus('data/text8')\n",
    "    model = word2vec.Word2Vec(sentences, size=EMBEDDING_DIM)\n",
    "    model.save(saveTo)\n",
    "    model.wv.save_word2vec_format(saveTo + '.bin', binary=True)\n",
    "    print('DONE! Saved to', saveTo)\n",
    "\n",
    "def generate_glove_text8(saveTo = 'models/glovetext8.model'):\n",
    "    import itertools\n",
    "    sentences = list(itertools.islice(word2vec.Text8Corpus('data/text8'),None))\n",
    "    corpus = Corpus()\n",
    "    corpus.fit(sentences, window=10)\n",
    "    glove = Glove(no_components=EMBEDDING_DIM,learning_rate=0.05)\n",
    "    glove.fit(corpus.matrix, epochs=30,no_threads=4,verbose=True)\n",
    "    glove.add_dictionary(corpus.dictionary)\n",
    "    glove.save(saveTo)\n",
    "    print('DONE! Saved to', saveTo)\n",
    "    \n",
    "def load_data(word_count, emotional_mapping):\n",
    "    # full = generate_IEMOCAP_df()\n",
    "    data = pd.read_csv('data/IEMOCAP_sentences.csv',index_col=0)\n",
    "    data['emotion_code'] = data['emotion'].map( emotional_mapping ).astype(int)\n",
    "    # Take away fear, surprise,disgust, xxx and others. Not enough data\n",
    "    data = data[data.emotion_code < 6]\n",
    "    # Clean Transcripts\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    # Filter Word Count\n",
    "    data = filter_word_count(data, word_count)\n",
    "#     data,patterns = remove_empty_patterns(data,patterns)\n",
    "    return data\n",
    "\n",
    "def clean_text(text):\n",
    "    punct_str = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~«»“…‘”\\t'\n",
    "    for p in punct_str:\n",
    "        text = text.replace(p,' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = re.sub(\".*?\\[(.*?)\\]\",\"\",text) # Take out any [action] text in the transcript\n",
    "    return text.lower().strip()\n",
    "\n",
    "def filter_word_count(data, n_count):\n",
    "    return data[list(map(lambda x: len(x.split(' ')) >= n_count,data['text']))]\n",
    "\n",
    "def balance_data(data):\n",
    "    min_sample = min(data.groupby('emotion').count()['emotion_code'])\n",
    "    emotions_list = list(data['emotion'].unique())\n",
    "    samples = []\n",
    "    for emotion in emotions_list:\n",
    "        samples.append(data[data.emotion == emotion].sample(n=min_sample))\n",
    "    result = pd.concat(samples).sample(frac=1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro01_F002</th>\n",
       "      <td>is there a problem</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro01_F005</th>\n",
       "      <td>well what's the problem let me change it</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro01_F006</th>\n",
       "      <td>what i'm getting an id this is why i'm here my...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro01_F007</th>\n",
       "      <td>how am i supposed to get an id without an id h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ses01F_impro01_F008</th>\n",
       "      <td>i'm here to get an id</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "Ses01F_impro01_F002                                 is there a problem   \n",
       "Ses01F_impro01_F005           well what's the problem let me change it   \n",
       "Ses01F_impro01_F006  what i'm getting an id this is why i'm here my...   \n",
       "Ses01F_impro01_F007  how am i supposed to get an id without an id h...   \n",
       "Ses01F_impro01_F008                              i'm here to get an id   \n",
       "\n",
       "                     emotion_code  \n",
       "Ses01F_impro01_F002             3  \n",
       "Ses01F_impro01_F005             3  \n",
       "Ses01F_impro01_F006             4  \n",
       "Ses01F_impro01_F007             4  \n",
       "Ses01F_impro01_F008             4  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotional_mapping = {'ang': 0, 'sad': 1, 'exc': 2, 'neu': 3,'fru': 4,'hap': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "data = load_data(3, emotional_mapping)\n",
    "# data = balance_data(data)\n",
    "df = data[['text','emotion_code']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>text</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>emotion_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ang</th>\n",
       "      <td>15.887412</td>\n",
       "      <td>15.887412</td>\n",
       "      <td>15.887412</td>\n",
       "      <td>15.887412</td>\n",
       "      <td>15.887412</td>\n",
       "      <td>15.887412</td>\n",
       "      <td>15.887412</td>\n",
       "      <td>15.887412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exc</th>\n",
       "      <td>13.760751</td>\n",
       "      <td>13.760751</td>\n",
       "      <td>13.760751</td>\n",
       "      <td>13.760751</td>\n",
       "      <td>13.760751</td>\n",
       "      <td>13.760751</td>\n",
       "      <td>13.760751</td>\n",
       "      <td>13.760751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fru</th>\n",
       "      <td>25.801407</td>\n",
       "      <td>25.801407</td>\n",
       "      <td>25.801407</td>\n",
       "      <td>25.801407</td>\n",
       "      <td>25.801407</td>\n",
       "      <td>25.801407</td>\n",
       "      <td>25.801407</td>\n",
       "      <td>25.801407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hap</th>\n",
       "      <td>7.849883</td>\n",
       "      <td>7.849883</td>\n",
       "      <td>7.849883</td>\n",
       "      <td>7.849883</td>\n",
       "      <td>7.849883</td>\n",
       "      <td>7.849883</td>\n",
       "      <td>7.849883</td>\n",
       "      <td>7.849883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>22.095387</td>\n",
       "      <td>22.095387</td>\n",
       "      <td>22.095387</td>\n",
       "      <td>22.095387</td>\n",
       "      <td>22.095387</td>\n",
       "      <td>22.095387</td>\n",
       "      <td>22.095387</td>\n",
       "      <td>22.095387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>14.605160</td>\n",
       "      <td>14.605160</td>\n",
       "      <td>14.605160</td>\n",
       "      <td>14.605160</td>\n",
       "      <td>14.605160</td>\n",
       "      <td>14.605160</td>\n",
       "      <td>14.605160</td>\n",
       "      <td>14.605160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time   end_time       text   wav_path    valence    arousal  \\\n",
       "emotion                                                                      \n",
       "ang       15.887412  15.887412  15.887412  15.887412  15.887412  15.887412   \n",
       "exc       13.760751  13.760751  13.760751  13.760751  13.760751  13.760751   \n",
       "fru       25.801407  25.801407  25.801407  25.801407  25.801407  25.801407   \n",
       "hap        7.849883   7.849883   7.849883   7.849883   7.849883   7.849883   \n",
       "neu       22.095387  22.095387  22.095387  22.095387  22.095387  22.095387   \n",
       "sad       14.605160  14.605160  14.605160  14.605160  14.605160  14.605160   \n",
       "\n",
       "         dominance  emotion_code  \n",
       "emotion                           \n",
       "ang      15.887412     15.887412  \n",
       "exc      13.760751     13.760751  \n",
       "fru      25.801407     25.801407  \n",
       "hap       7.849883      7.849883  \n",
       "neu      22.095387     22.095387  \n",
       "sad      14.605160     14.605160  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(data.groupby('emotion').count()['emotion_code'])\n",
    "(data.groupby('emotion').count() / total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>text</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>emotion_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ang</th>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exc</th>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fru</th>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hap</th>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time  end_time  text  wav_path  valence  arousal  dominance  \\\n",
       "emotion                                                                      \n",
       "ang             502       502   502       502      502      502        502   \n",
       "exc             502       502   502       502      502      502        502   \n",
       "fru             502       502   502       502      502      502        502   \n",
       "hap             502       502   502       502      502      502        502   \n",
       "neu             502       502   502       502      502      502        502   \n",
       "sad             502       502   502       502      502      502        502   \n",
       "\n",
       "         emotion_code  \n",
       "emotion                \n",
       "ang               502  \n",
       "exc               502  \n",
       "fru               502  \n",
       "hap               502  \n",
       "neu               502  \n",
       "sad               502  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced = balance_data(data)\n",
    "df_balanced = data_balanced[['text','emotion_code']]\n",
    "df_balanced.head()\n",
    "data_balanced.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "TEST_SIZE      = 0.2\n",
    "\n",
    "# EMBEDDING\n",
    "MAX_NUM_WORDS  = 2954 # 2500, 2000, 2700\n",
    "# MAX_NUM_WORDS  = # 1800, 2000, 2201\n",
    "EMBEDDING_DIM  = 200\n",
    "MAX_SEQ_LENGTH = 100\n",
    "USE_GLOVE      = True\n",
    "\n",
    "# MODEL\n",
    "FILTER_SIZES   = [3,4,5]\n",
    "FEATURE_MAPS   = [10,10,10]\n",
    "DROPOUT_RATE   = 0.5\n",
    "\n",
    "# LEARNING\n",
    "BATCH_SIZE     = 200\n",
    "NB_EPOCHS      = 40\n",
    "RUNS           = 5\n",
    "VAL_SIZE       = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.text, data.emotion_code, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text informations:\n",
      "max length: 100 / min length: 3 / mean length: 13 / limit length: 100\n",
      "vocabulary size: 2943 / limit: 2954\n"
     ]
    }
   ],
   "source": [
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])\n",
    "\n",
    "tokenizer = Tokenizer()#num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "length = max_length(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "result = [len(x.split()) for x in x_train]\n",
    "print('Text informations:')\n",
    "print('max length: %i / min length: %i / mean length: %i / limit length: %i' % (np.max(result),\n",
    "                                                                                np.min(result),\n",
    "                                                                                np.mean(result),\n",
    "                                                                                MAX_SEQ_LENGTH))\n",
    "\n",
    "print('vocabulary size: %i / limit: %i' % (len(word_index), MAX_NUM_WORDS))\n",
    "\n",
    "# Padding all sequences to same length of `MAX_SEQ_LENGTH`\n",
    "data   = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5116, 5116)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_glove_embeddings(data = None, use_text8 = False, LEARNING_RATE=0.05, EPOCHS=30, NO_THREADS=4):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = Glove.load('models/glovetext8.model')\n",
    "    else:\n",
    "        if(data != None):\n",
    "            corpus = Corpus()\n",
    "            corpus.fit(data, window=10)\n",
    "            model = Glove(no_components=EMBEDDING_DIM,learning_rate=LEARNING_RATE)\n",
    "            model.fit(corpus.matrix, epochs=EPOCHS,no_threads=NO_THREADS,verbose=True)\n",
    "            model.add_dictionary(corpus.dictionary)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = Glove.load('models/glovetext8.model')\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word,index in model.dictionary.items():\n",
    "        embeddings_index[word] = model.word_vectors[index]\n",
    "    \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM,\n",
    "                     weights=[embedding_matrix], trainable=True)\n",
    "    \n",
    "def create_word2vec_embeddings(data = None, use_text8 = False):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    else:\n",
    "        if(data != None):  \n",
    "            model = word2vec.Word2Vec(data, size=EMBEDDING_DIM)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word in model.wv.index2word:\n",
    "        embeddings_index[word] = model[word]\n",
    "        \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length = MAX_SEQ_LENGTH,\n",
    "                    weights= [embedding_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "embedding_data = [x.split() for x in x_train]\n",
    "emb_layers = [create_word2vec_embeddings(use_text8=True),\n",
    "              create_word2vec_embeddings(embedding_data),\n",
    "              create_glove_embeddings(use_text8=True),\n",
    "              create_glove_embeddings(embedding_data)\n",
    "             ]\n",
    "\n",
    "emb_layers_names = ['word2vectext8','word2veciemocap','glovetext8','gloveiemocap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5116, 5116)\n"
     ]
    }
   ],
   "source": [
    "print(len(data),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cnn_model\n",
    "\n",
    "for index,lay in enumerate(emb_layers):\n",
    "    \n",
    "    histories = []\n",
    "    \n",
    "    for i in range(RUNS):\n",
    "        print('Running iteration %i/%i' % (i+1, RUNS))\n",
    "\n",
    "        X_train, X_val, labels, y_val = train_test_split(data, y_train, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "        emb_layer = None\n",
    "        if USE_GLOVE:\n",
    "            emb_layer = lay#emb_layers[2] #create_word2vec_embeddings(result)\n",
    "\n",
    "        model = cnn_model.build_cnn(\n",
    "            embedding_layer=emb_layer,\n",
    "            num_words=MAX_NUM_WORDS,\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            filter_sizes=FILTER_SIZES,\n",
    "            feature_maps=FEATURE_MAPS,\n",
    "            max_seq_length=MAX_SEQ_LENGTH,\n",
    "            dropout_rate=DROPOUT_RATE\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=Adadelta(clipvalue=3),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, labels,\n",
    "            epochs=NB_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=1,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n",
    "                                       verbose=1, save_best_only=True, mode='min'),\n",
    "                       ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.01)\n",
    "                      ]\n",
    "        )\n",
    "        histories.append(history.history)\n",
    "        \n",
    "    with open('history/unbalanced_'+emb_layers_names[index]+'_'+str(MAX_NUM_WORDS)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(histories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text informations:\n",
      "max length: 91 / min length: 3 / mean length: 13 / limit length: 100\n",
      "vocabulary size: 2212 / limit: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -10.2215 - acc: 0.1582 - val_loss: -21.6044 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.60436, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.7153 - acc: 0.1619 - val_loss: -21.7037 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.60436 to -21.70373, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.8203 - acc: 0.1619 - val_loss: -21.8083 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.70373 to -21.80827, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -22.9237 - acc: 0.1619 - val_loss: -21.9113 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.80827 to -21.91130, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -23.0275 - acc: 0.1619 - val_loss: -22.0143 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.91130 to -22.01434, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.1320 - acc: 0.1619 - val_loss: -22.1231 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.01434 to -22.12309, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.2429 - acc: 0.1619 - val_loss: -22.2365 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.12309 to -22.23646, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.3577 - acc: 0.1619 - val_loss: -22.3514 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.23646 to -22.35141, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 999us/step - loss: -23.4744 - acc: 0.1619 - val_loss: -22.4688 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.35141 to -22.46878, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.5911 - acc: 0.1619 - val_loss: -22.5856 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.46878 to -22.58565, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.7084 - acc: 0.1619 - val_loss: -22.7004 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.58565 to -22.70042, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8191 - acc: 0.1619 - val_loss: -22.8112 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.70042 to -22.81125, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 1000us/step - loss: -23.9257 - acc: 0.1619 - val_loss: -22.9103 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.81125 to -22.91026, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -24.0183 - acc: 0.1619 - val_loss: -22.9971 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.91026 to -22.99713, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.1028 - acc: 0.1619 - val_loss: -23.0726 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.99713 to -23.07259, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -24.1734 - acc: 0.1619 - val_loss: -23.1387 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.07259 to -23.13869, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -24.2306 - acc: 0.1619 - val_loss: -23.1884 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.13869 to -23.18845, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -24.2782 - acc: 0.1619 - val_loss: -23.2323 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.18845 to -23.23234, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 996us/step - loss: -24.3128 - acc: 0.1619 - val_loss: -23.2603 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.23234 to -23.26034, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -24.3376 - acc: 0.1619 - val_loss: -23.2755 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.26034 to -23.27553, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -24.3556 - acc: 0.1619 - val_loss: -23.2977 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.27553 to -23.29770, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 999us/step - loss: -24.3722 - acc: 0.1619 - val_loss: -23.3083 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.29770 to -23.30828, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -24.3829 - acc: 0.1619 - val_loss: -23.3121 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.30828 to -23.31208, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -24.3873 - acc: 0.1619 - val_loss: -23.3239 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31208 to -23.32390, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 995us/step - loss: -24.3971 - acc: 0.1619 - val_loss: -23.3304 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.32390 to -23.33042, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -24.3930 - acc: 0.1619 - val_loss: -23.3250 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -23.33042\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -24.3958 - acc: 0.1619 - val_loss: -23.3275 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -23.33042\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -24.3983 - acc: 0.1619 - val_loss: -23.3300 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -23.33042\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 995us/step - loss: -24.4008 - acc: 0.1619 - val_loss: -23.3326 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.33042 to -23.33256, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -24.4034 - acc: 0.1619 - val_loss: -23.3352 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33256 to -23.33519, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -24.4061 - acc: 0.1619 - val_loss: -23.3379 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.33519 to -23.33789, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 999us/step - loss: -24.4077 - acc: 0.1619 - val_loss: -23.3388 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -23.33789 to -23.33882, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 1000us/step - loss: -24.4081 - acc: 0.1619 - val_loss: -23.3347 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33882\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 998us/step - loss: -24.4053 - acc: 0.1619 - val_loss: -23.3367 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33882\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 989us/step - loss: -24.4073 - acc: 0.1619 - val_loss: -23.3388 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.33882\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -24.4094 - acc: 0.1619 - val_loss: -23.3408 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -23.33882 to -23.34081, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.4114 - acc: 0.1619 - val_loss: -23.3436 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.34081 to -23.34358, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -24.4082 - acc: 0.1619 - val_loss: -23.3389 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34358\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.4095 - acc: 0.1619 - val_loss: -23.3408 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34358\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.4113 - acc: 0.1619 - val_loss: -23.3427 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34358\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -12.7253 - acc: 0.1684 - val_loss: -21.6255 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.62548, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.7316 - acc: 0.1619 - val_loss: -21.7070 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.62548 to -21.70700, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.8130 - acc: 0.1619 - val_loss: -21.7886 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.70700 to -21.78859, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.8955 - acc: 0.1619 - val_loss: -21.8729 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.78859 to -21.87287, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.9820 - acc: 0.1619 - val_loss: -21.9614 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.87287 to -21.96137, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.0729 - acc: 0.1619 - val_loss: -22.0553 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -21.96137 to -22.05526, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.1692 - acc: 0.1619 - val_loss: -22.1546 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.05526 to -22.15459, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.2716 - acc: 0.1619 - val_loss: -22.2595 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.15459 to -22.25953, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.3796 - acc: 0.1619 - val_loss: -22.3729 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.25953 to -22.37286, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4943 - acc: 0.1619 - val_loss: -22.4882 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.37286 to -22.48824, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.6097 - acc: 0.1619 - val_loss: -22.6040 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.48824 to -22.60401, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.7224 - acc: 0.1619 - val_loss: -22.7158 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.60401 to -22.71578, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.8328 - acc: 0.1619 - val_loss: -22.8219 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.71578 to -22.82194, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.9356 - acc: 0.1619 - val_loss: -22.9183 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.82194 to -22.91831, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -24.0273 - acc: 0.1619 - val_loss: -23.0050 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.91831 to -23.00498, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -24.1058 - acc: 0.1619 - val_loss: -23.0760 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.00498 to -23.07596, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.1764 - acc: 0.1619 - val_loss: -23.1394 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.07596 to -23.13940, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -24.2246 - acc: 0.1619 - val_loss: -23.1710 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.13940 to -23.17099, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.2567 - acc: 0.1619 - val_loss: -23.2057 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.17099 to -23.20574, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -24.2891 - acc: 0.1619 - val_loss: -23.2347 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.20574 to -23.23472, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.3133 - acc: 0.1619 - val_loss: -23.2528 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.23472 to -23.25281, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -24.3333 - acc: 0.1619 - val_loss: -23.2742 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.25281 to -23.27419, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.3492 - acc: 0.1619 - val_loss: -23.2857 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.27419 to -23.28569, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -24.3635 - acc: 0.1619 - val_loss: -23.3031 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.28569 to -23.30312, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -24.3755 - acc: 0.1619 - val_loss: -23.3131 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.30312 to -23.31309, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.3852 - acc: 0.1619 - val_loss: -23.3206 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.31309 to -23.32063, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -24.3923 - acc: 0.1619 - val_loss: -23.3277 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.32063 to -23.32766, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -24.3964 - acc: 0.1619 - val_loss: -23.3245 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -23.32766\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.3972 - acc: 0.1619 - val_loss: -23.3310 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.32766 to -23.33104, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.4032 - acc: 0.1619 - val_loss: -23.3364 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33104 to -23.33640, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.3972 - acc: 0.1619 - val_loss: -23.3299 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33640\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4003 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.33640\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.4020 - acc: 0.1619 - val_loss: -23.3333 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33640\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4038 - acc: 0.1619 - val_loss: -23.3351 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33640\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.4049 - acc: 0.1619 - val_loss: -23.3353 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.33640\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.4051 - acc: 0.1619 - val_loss: -23.3356 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.33640\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -24.4054 - acc: 0.1619 - val_loss: -23.3359 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.33640\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.4058 - acc: 0.1619 - val_loss: -23.3363 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.33640\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.4060 - acc: 0.1619 - val_loss: -23.3364 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.33640\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.4061 - acc: 0.1619 - val_loss: -23.3365 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -23.33640 to -23.33645, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -13.8003 - acc: 0.1610 - val_loss: -21.6312 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.63119, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.7362 - acc: 0.1619 - val_loss: -21.7101 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.63119 to -21.71008, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.8146 - acc: 0.1619 - val_loss: -21.7887 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.71008 to -21.78865, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.8945 - acc: 0.1619 - val_loss: -21.8702 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.78865 to -21.87016, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.9778 - acc: 0.1619 - val_loss: -21.9549 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.87016 to -21.95494, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.0657 - acc: 0.1619 - val_loss: -22.0475 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -21.95494 to -22.04751, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.1608 - acc: 0.1619 - val_loss: -22.1471 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.04751 to -22.14711, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.2632 - acc: 0.1619 - val_loss: -22.2540 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.14711 to -22.25397, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.3730 - acc: 0.1619 - val_loss: -22.3657 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.25397 to -22.36567, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.4873 - acc: 0.1619 - val_loss: -22.4823 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.36567 to -22.48234, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.6030 - acc: 0.1619 - val_loss: -22.5977 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.48234 to -22.59775, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.7192 - acc: 0.1619 - val_loss: -22.7114 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.59775 to -22.71137, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8298 - acc: 0.1619 - val_loss: -22.8157 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.71137 to -22.81569, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.9319 - acc: 0.1619 - val_loss: -22.9178 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.81569 to -22.91775, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.0267 - acc: 0.1619 - val_loss: -23.0035 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.91775 to -23.00347, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.1009 - acc: 0.1619 - val_loss: -23.0635 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.00347 to -23.06348, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.1610 - acc: 0.1619 - val_loss: -23.1238 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.06348 to -23.12377, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.2167 - acc: 0.1619 - val_loss: -23.1703 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.12377 to -23.17035, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.2591 - acc: 0.1619 - val_loss: -23.2098 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.17035 to -23.20977, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.2965 - acc: 0.1619 - val_loss: -23.2370 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.20977 to -23.23699, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3209 - acc: 0.1619 - val_loss: -23.2675 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.23699 to -23.26753, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.3470 - acc: 0.1619 - val_loss: -23.2891 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.26753 to -23.28914, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -24.3648 - acc: 0.1619 - val_loss: -23.3018 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.28914 to -23.30179, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.3783 - acc: 0.1619 - val_loss: -23.3150 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.30179 to -23.31500, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -24.3857 - acc: 0.1619 - val_loss: -23.3187 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.31500 to -23.31867, saving model to model-3.h5\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.3931 - acc: 0.1619 - val_loss: -23.3288 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.31867 to -23.32876, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3987 - acc: 0.1619 - val_loss: -23.3317 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.32876 to -23.33175, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.4031 - acc: 0.1619 - val_loss: -23.3330 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.33175 to -23.33303, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.4058 - acc: 0.1619 - val_loss: -23.3396 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.33303 to -23.33960, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.4082 - acc: 0.1619 - val_loss: -23.3408 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33960 to -23.34084, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.4104 - acc: 0.1619 - val_loss: -23.3426 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.34084 to -23.34264, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.4090 - acc: 0.1619 - val_loss: -23.3387 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.34264\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.4102 - acc: 0.1619 - val_loss: -23.3425 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.34264\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.4135 - acc: 0.1619 - val_loss: -23.3435 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.34264 to -23.34349, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -24.4131 - acc: 0.1619 - val_loss: -23.3427 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.34349\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -24.4139 - acc: 0.1619 - val_loss: -23.3438 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -23.34349 to -23.34377, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -24.4150 - acc: 0.1619 - val_loss: -23.3469 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.34377 to -23.34689, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.4135 - acc: 0.1619 - val_loss: -23.3451 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34689\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.4153 - acc: 0.1619 - val_loss: -23.3444 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34689\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.4154 - acc: 0.1619 - val_loss: -23.3472 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -23.34689 to -23.34719, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -15.9159 - acc: 0.1619 - val_loss: -21.6439 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.64390, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.7463 - acc: 0.1619 - val_loss: -21.7173 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.64390 to -21.71731, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.8201 - acc: 0.1619 - val_loss: -21.7924 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.71731 to -21.79244, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.8964 - acc: 0.1619 - val_loss: -21.8702 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.79244 to -21.87020, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.9762 - acc: 0.1619 - val_loss: -21.9523 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.87020 to -21.95230, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.0609 - acc: 0.1619 - val_loss: -22.0408 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -21.95230 to -22.04083, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.1529 - acc: 0.1619 - val_loss: -22.1368 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.04083 to -22.13678, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.2516 - acc: 0.1619 - val_loss: -22.2405 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.13678 to -22.24053, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.3581 - acc: 0.1619 - val_loss: -22.3502 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.24053 to -22.35019, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4708 - acc: 0.1619 - val_loss: -22.4657 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.35019 to -22.46571, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.5863 - acc: 0.1619 - val_loss: -22.5811 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.46571 to -22.58111, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.6996 - acc: 0.1619 - val_loss: -22.6930 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.58111 to -22.69296, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8078 - acc: 0.1619 - val_loss: -22.7979 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.69296 to -22.79785, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.9141 - acc: 0.1619 - val_loss: -22.8997 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.79785 to -22.89972, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.0095 - acc: 0.1619 - val_loss: -22.9860 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.89972 to -22.98598, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.0924 - acc: 0.1619 - val_loss: -23.0645 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -22.98598 to -23.06448, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1652 - acc: 0.1619 - val_loss: -23.1293 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.06448 to -23.12930, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.2244 - acc: 0.1619 - val_loss: -23.1768 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.12930 to -23.17680, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.2681 - acc: 0.1619 - val_loss: -23.2231 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.17680 to -23.22308, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.3092 - acc: 0.1619 - val_loss: -23.2497 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.22308 to -23.24967, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.3334 - acc: 0.1619 - val_loss: -23.2795 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.24967 to -23.27950, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3577 - acc: 0.1619 - val_loss: -23.2963 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.27950 to -23.29630, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3695 - acc: 0.1619 - val_loss: -23.3008 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.29630 to -23.30077, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3718 - acc: 0.1619 - val_loss: -23.3038 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.30077 to -23.30379, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3748 - acc: 0.1619 - val_loss: -23.3068 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.30379 to -23.30678, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.3778 - acc: 0.1619 - val_loss: -23.3099 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.30678 to -23.30986, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3810 - acc: 0.1619 - val_loss: -23.3131 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.30986 to -23.31314, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.3844 - acc: 0.1619 - val_loss: -23.3167 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.31314 to -23.31673, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3881 - acc: 0.1619 - val_loss: -23.3207 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.31673 to -23.32067, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3922 - acc: 0.1619 - val_loss: -23.3250 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.32067 to -23.32496, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3967 - acc: 0.1619 - val_loss: -23.3295 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.32496 to -23.32951, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.3992 - acc: 0.1619 - val_loss: -23.3320 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -23.32951 to -23.33198, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.4006 - acc: 0.1619 - val_loss: -23.3320 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33198\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4039 - acc: 0.1619 - val_loss: -23.3368 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.33198 to -23.33680, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4060 - acc: 0.1619 - val_loss: -23.3374 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -23.33680 to -23.33744, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.4081 - acc: 0.1619 - val_loss: -23.3360 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.33744\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.4076 - acc: 0.1619 - val_loss: -23.3401 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.33744 to -23.34009, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.4113 - acc: 0.1619 - val_loss: -23.3434 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -23.34009 to -23.34337, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.4071 - acc: 0.1619 - val_loss: -23.3378 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34337\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4083 - acc: 0.1619 - val_loss: -23.3396 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34337\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -15.9962 - acc: 0.1628 - val_loss: -21.6358 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.63576, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.7345 - acc: 0.1619 - val_loss: -21.7007 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.63576 to -21.70071, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.8003 - acc: 0.1619 - val_loss: -21.7679 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.70071 to -21.76792, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.8696 - acc: 0.1619 - val_loss: -21.8373 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.76792 to -21.83729, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.9400 - acc: 0.1619 - val_loss: -21.9127 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.83729 to -21.91269, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.0186 - acc: 0.1619 - val_loss: -21.9950 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -21.91269 to -21.99497, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.1044 - acc: 0.1619 - val_loss: -22.0853 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -21.99497 to -22.08533, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.1962 - acc: 0.1619 - val_loss: -22.1811 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.08533 to -22.18106, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.2965 - acc: 0.1619 - val_loss: -22.2854 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.18106 to -22.28540, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4038 - acc: 0.1619 - val_loss: -22.3948 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.28540 to -22.39481, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.5156 - acc: 0.1619 - val_loss: -22.5077 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.39481 to -22.50770, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.6281 - acc: 0.1619 - val_loss: -22.6212 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.50770 to -22.62115, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.7415 - acc: 0.1619 - val_loss: -22.7331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.62115 to -22.73306, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8502 - acc: 0.1619 - val_loss: -22.8368 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.73306 to -22.83678, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.9498 - acc: 0.1619 - val_loss: -22.9319 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.83678 to -22.93186, saving model to model-5.h5\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.0403 - acc: 0.1619 - val_loss: -23.0155 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -22.93186 to -23.01552, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1192 - acc: 0.1619 - val_loss: -23.0842 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.01552 to -23.08421, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1838 - acc: 0.1619 - val_loss: -23.1487 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.08421 to -23.14868, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.2410 - acc: 0.1619 - val_loss: -23.1991 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.14868 to -23.19912, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.2738 - acc: 0.1619 - val_loss: -23.2081 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.19912 to -23.20809, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.2830 - acc: 0.1619 - val_loss: -23.2197 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.20809 to -23.21969, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.2944 - acc: 0.1619 - val_loss: -23.2309 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.21969 to -23.23093, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3056 - acc: 0.1619 - val_loss: -23.2422 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.23093 to -23.24215, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3169 - acc: 0.1619 - val_loss: -23.2537 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.24215 to -23.25366, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3287 - acc: 0.1619 - val_loss: -23.2656 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.25366 to -23.26563, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3408 - acc: 0.1619 - val_loss: -23.2781 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.26563 to -23.27806, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3520 - acc: 0.1619 - val_loss: -23.2878 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.27806 to -23.28777, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3629 - acc: 0.1619 - val_loss: -23.2967 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.28777 to -23.29668, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.3720 - acc: 0.1619 - val_loss: -23.3091 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.29668 to -23.30908, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3819 - acc: 0.1619 - val_loss: -23.3168 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.30908 to -23.31681, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.3840 - acc: 0.1619 - val_loss: -23.3163 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.31681\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3866 - acc: 0.1619 - val_loss: -23.3178 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -23.31681 to -23.31778, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3881 - acc: 0.1619 - val_loss: -23.3193 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.31778 to -23.31930, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.3897 - acc: 0.1619 - val_loss: -23.3210 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.31930 to -23.32099, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.3915 - acc: 0.1619 - val_loss: -23.3229 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -23.32099 to -23.32290, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3935 - acc: 0.1619 - val_loss: -23.3251 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -23.32290 to -23.32511, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.3959 - acc: 0.1619 - val_loss: -23.3277 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.32511 to -23.32765, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3986 - acc: 0.1619 - val_loss: -23.3305 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -23.32765 to -23.33054, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.4016 - acc: 0.1619 - val_loss: -23.3337 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -23.33054 to -23.33373, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4026 - acc: 0.1619 - val_loss: -23.3340 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -23.33373 to -23.33403, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -8.1014 - acc: 0.1610 - val_loss: -21.7283 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.72826, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.9036 - acc: 0.1619 - val_loss: -21.9581 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.72826 to -21.95814, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.1162 - acc: 0.1619 - val_loss: -22.1507 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.95814 to -22.15068, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.2921 - acc: 0.1619 - val_loss: -22.3085 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -22.15068 to -22.30849, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4416 - acc: 0.1619 - val_loss: -22.4476 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -22.30849 to -22.44760, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.5705 - acc: 0.1619 - val_loss: -22.5642 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.44760 to -22.56417, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.6844 - acc: 0.1619 - val_loss: -22.6725 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.56417 to -22.67252, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.7876 - acc: 0.1619 - val_loss: -22.7699 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.67252 to -22.76988, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.8798 - acc: 0.1619 - val_loss: -22.8597 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.76988 to -22.85969, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.9633 - acc: 0.1619 - val_loss: -22.9397 - val_acc: 0.1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss improved from -22.85969 to -22.93972, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.0394 - acc: 0.1619 - val_loss: -23.0086 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.93972 to -23.00859, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -24.1088 - acc: 0.1619 - val_loss: -23.0731 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.00859 to -23.07308, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1626 - acc: 0.1619 - val_loss: -23.1255 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -23.07308 to -23.12553, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.2143 - acc: 0.1619 - val_loss: -23.1696 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -23.12553 to -23.16961, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.2572 - acc: 0.1619 - val_loss: -23.2113 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -23.16961 to -23.21130, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.2888 - acc: 0.1619 - val_loss: -23.2375 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.21130 to -23.23755, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3207 - acc: 0.1619 - val_loss: -23.2491 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.23755 to -23.24910, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3288 - acc: 0.1619 - val_loss: -23.2708 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.24910 to -23.27081, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.3488 - acc: 0.1619 - val_loss: -23.2880 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.27081 to -23.28798, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.3620 - acc: 0.1619 - val_loss: -23.2926 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.28798 to -23.29264, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3695 - acc: 0.1619 - val_loss: -23.3081 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.29264 to -23.30806, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.3742 - acc: 0.1619 - val_loss: -23.3072 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -23.30806\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.3814 - acc: 0.1619 - val_loss: -23.3170 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.30806 to -23.31696, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3878 - acc: 0.1619 - val_loss: -23.3225 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31696 to -23.32249, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.3933 - acc: 0.1619 - val_loss: -23.3272 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.32249 to -23.32717, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3962 - acc: 0.1619 - val_loss: -23.3303 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32717 to -23.33030, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.4009 - acc: 0.1619 - val_loss: -23.3347 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.33030 to -23.33467, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.4003 - acc: 0.1619 - val_loss: -23.3343 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -23.33467\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.4024 - acc: 0.1619 - val_loss: -23.3329 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33467\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4056 - acc: 0.1619 - val_loss: -23.3392 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33467 to -23.33924, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.4042 - acc: 0.1619 - val_loss: -23.3348 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33924\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.4067 - acc: 0.1619 - val_loss: -23.3394 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -23.33924 to -23.33941, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.4108 - acc: 0.1619 - val_loss: -22.4615 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33941\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.2838 - acc: 0.1619 - val_loss: -23.3368 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33941\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4065 - acc: 0.1619 - val_loss: -23.3370 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.33941\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4068 - acc: 0.1619 - val_loss: -23.3373 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.33941\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4069 - acc: 0.1619 - val_loss: -23.3373 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.33941\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4070 - acc: 0.1619 - val_loss: -23.3373 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.33941\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4070 - acc: 0.1619 - val_loss: -23.3374 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.33941\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.4071 - acc: 0.1619 - val_loss: -23.3374 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.33941\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -13.2889 - acc: 0.1637 - val_loss: -21.6348 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.63484, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.7626 - acc: 0.1619 - val_loss: -21.7622 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.63484 to -21.76218, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.8849 - acc: 0.1619 - val_loss: -21.8791 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.76218 to -21.87909, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.9986 - acc: 0.1619 - val_loss: -21.9893 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.87909 to -21.98932, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.1069 - acc: 0.1619 - val_loss: -22.0959 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.98932 to -22.09594, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2129 - acc: 0.1619 - val_loss: -22.2014 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.09594 to -22.20144, saving model to model-2.h5\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.3186 - acc: 0.1619 - val_loss: -22.3077 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.20144 to -22.30766, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4246 - acc: 0.1619 - val_loss: -22.4143 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.30766 to -22.41431, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.5321 - acc: 0.1619 - val_loss: -22.5210 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.41431 to -22.52100, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.6384 - acc: 0.1619 - val_loss: -22.6264 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.52100 to -22.62637, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.7434 - acc: 0.1619 - val_loss: -22.7329 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.62637 to -22.73289, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8462 - acc: 0.1619 - val_loss: -22.8312 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.73289 to -22.83124, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.9441 - acc: 0.1619 - val_loss: -22.9249 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.83124 to -22.92492, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.0335 - acc: 0.1619 - val_loss: -23.0101 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.92492 to -23.01011, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1133 - acc: 0.1619 - val_loss: -23.0855 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -23.01011 to -23.08547, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1557 - acc: 0.1619 - val_loss: -23.1085 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.08547 to -23.10852, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1950 - acc: 0.1619 - val_loss: -23.1455 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.10852 to -23.14553, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.2305 - acc: 0.1619 - val_loss: -23.1768 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.14553 to -23.17676, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.2608 - acc: 0.1619 - val_loss: -23.2057 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.17676 to -23.20575, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.2886 - acc: 0.1619 - val_loss: -23.2342 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.20575 to -23.23423, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -24.3084 - acc: 0.1619 - val_loss: -23.2534 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.23423 to -23.25339, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.3329 - acc: 0.1619 - val_loss: -23.2740 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.25339 to -23.27404, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -24.3502 - acc: 0.1619 - val_loss: -23.2892 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.27404 to -23.28918, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.3636 - acc: 0.1619 - val_loss: -23.3008 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.28918 to -23.30085, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3764 - acc: 0.1619 - val_loss: -23.3107 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.30085 to -23.31072, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3861 - acc: 0.1619 - val_loss: -23.3189 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.31072 to -23.31895, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3914 - acc: 0.1619 - val_loss: -23.3199 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.31895 to -23.31986, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3944 - acc: 0.1619 - val_loss: -23.3301 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.31986 to -23.33007, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.4021 - acc: 0.1619 - val_loss: -23.3304 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.33007 to -23.33042, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.4039 - acc: 0.1619 - val_loss: -23.3383 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33042 to -23.33828, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.3997 - acc: 0.1619 - val_loss: -23.3314 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33828\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4029 - acc: 0.1619 - val_loss: -23.3354 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.33828\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4067 - acc: 0.1619 - val_loss: -23.3389 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.33828 to -23.33891, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4090 - acc: 0.1619 - val_loss: -23.3382 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33891\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4097 - acc: 0.1619 - val_loss: -23.3421 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -23.33891 to -23.34207, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.4080 - acc: 0.1619 - val_loss: -23.3395 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.34207\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4110 - acc: 0.1619 - val_loss: -23.3433 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.34207 to -23.34328, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4106 - acc: 0.1619 - val_loss: -23.3423 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34328\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4090 - acc: 0.1619 - val_loss: -23.3369 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34328\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4068 - acc: 0.1619 - val_loss: -23.3374 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34328\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -13.9345 - acc: 0.1614 - val_loss: -21.6768 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.67680, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.7949 - acc: 0.1619 - val_loss: -21.7833 - val_acc: 0.1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from -21.67680 to -21.78332, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.8981 - acc: 0.1619 - val_loss: -21.8835 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.78332 to -21.88349, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.9970 - acc: 0.1619 - val_loss: -21.9810 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.88349 to -21.98100, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.0941 - acc: 0.1619 - val_loss: -22.0781 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.98100 to -22.07812, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.1914 - acc: 0.1619 - val_loss: -22.1753 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.07812 to -22.17530, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.2895 - acc: 0.1619 - val_loss: -22.2753 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.17530 to -22.27526, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.3918 - acc: 0.1619 - val_loss: -22.3797 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.27526 to -22.37968, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4973 - acc: 0.1619 - val_loss: -22.4850 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.37968 to -22.48505, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.6030 - acc: 0.1619 - val_loss: -22.5926 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.48505 to -22.59263, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.7092 - acc: 0.1619 - val_loss: -22.6977 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.59263 to -22.69765, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8099 - acc: 0.1619 - val_loss: -22.7935 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.69765 to -22.79354, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.9078 - acc: 0.1619 - val_loss: -22.8916 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.79354 to -22.89162, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.0003 - acc: 0.1619 - val_loss: -22.9743 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.89162 to -22.97429, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.0806 - acc: 0.1619 - val_loss: -23.0504 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.97429 to -23.05044, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1510 - acc: 0.1619 - val_loss: -23.1165 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.05044 to -23.11653, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.2125 - acc: 0.1619 - val_loss: -23.1699 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.11653 to -23.16986, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.2608 - acc: 0.1619 - val_loss: -23.2120 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.16986 to -23.21199, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3010 - acc: 0.1619 - val_loss: -23.2490 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.21199 to -23.24905, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3069 - acc: 0.1619 - val_loss: -23.2563 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.24905 to -23.25626, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3271 - acc: 0.1619 - val_loss: -23.2588 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.25626 to -23.25882, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.3297 - acc: 0.1619 - val_loss: -23.2615 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.25882 to -23.26153, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3325 - acc: 0.1619 - val_loss: -23.2645 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.26153 to -23.26451, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3357 - acc: 0.1619 - val_loss: -23.2679 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.26451 to -23.26790, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3393 - acc: 0.1619 - val_loss: -23.2718 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.26790 to -23.27184, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3435 - acc: 0.1619 - val_loss: -23.2765 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.27184 to -23.27650, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.3486 - acc: 0.1619 - val_loss: -23.2820 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.27650 to -23.28201, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.3545 - acc: 0.1619 - val_loss: -23.2885 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.28201 to -23.28846, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3614 - acc: 0.1619 - val_loss: -23.2958 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.28846 to -23.29583, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3682 - acc: 0.1619 - val_loss: -23.3015 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.29583 to -23.30154, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3750 - acc: 0.1619 - val_loss: -23.3071 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.30154 to -23.30706, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3811 - acc: 0.1619 - val_loss: -23.3167 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -23.30706 to -23.31669, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3880 - acc: 0.1619 - val_loss: -23.3230 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.31669 to -23.32303, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.3940 - acc: 0.1619 - val_loss: -23.3284 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.32303 to -23.32844, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -24.3878 - acc: 0.1619 - val_loss: -23.3246 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.32844\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -24.3944 - acc: 0.1619 - val_loss: -23.3250 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.32844\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.3949 - acc: 0.1619 - val_loss: -23.3255 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.32844\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3954 - acc: 0.1619 - val_loss: -23.3260 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.32844\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 981us/step - loss: -24.3957 - acc: 0.1619 - val_loss: -23.3261 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.32844\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.3958 - acc: 0.1619 - val_loss: -23.3262 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.32844\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -12.5751 - acc: 0.1601 - val_loss: -21.6627 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.66273, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.7780 - acc: 0.1619 - val_loss: -21.7633 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.66273 to -21.76325, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.8761 - acc: 0.1619 - val_loss: -21.8590 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.76325 to -21.85903, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.9708 - acc: 0.1619 - val_loss: -21.9530 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.85903 to -21.95301, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.0649 - acc: 0.1619 - val_loss: -22.0475 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.95301 to -22.04751, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.1603 - acc: 0.1619 - val_loss: -22.1443 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.04751 to -22.14430, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.2585 - acc: 0.1619 - val_loss: -22.2445 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.14430 to -22.24448, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.3604 - acc: 0.1619 - val_loss: -22.3484 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.24448 to -22.34837, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4658 - acc: 0.1619 - val_loss: -22.4554 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.34837 to -22.45544, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.5733 - acc: 0.1619 - val_loss: -22.5632 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.45544 to -22.56323, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.6817 - acc: 0.1619 - val_loss: -22.6718 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.56323 to -22.67179, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.7879 - acc: 0.1619 - val_loss: -22.7729 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.67179 to -22.77295, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8867 - acc: 0.1619 - val_loss: -22.8679 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.77295 to -22.86790, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.9797 - acc: 0.1619 - val_loss: -22.9603 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.86790 to -22.96032, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.0665 - acc: 0.1619 - val_loss: -23.0404 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.96032 to -23.04039, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1344 - acc: 0.1619 - val_loss: -23.0954 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.04039 to -23.09545, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1913 - acc: 0.1619 - val_loss: -23.1522 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.09545 to -23.15217, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.2398 - acc: 0.1619 - val_loss: -23.1939 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.15217 to -23.19387, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.2803 - acc: 0.1619 - val_loss: -23.2310 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.19387 to -23.23095, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3035 - acc: 0.1619 - val_loss: -23.2392 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.23095 to -23.23918, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.3165 - acc: 0.1619 - val_loss: -23.2560 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.23918 to -23.25602, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3327 - acc: 0.1619 - val_loss: -23.2715 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.25602 to -23.27153, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3477 - acc: 0.1619 - val_loss: -23.2859 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.27153 to -23.28595, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3587 - acc: 0.1619 - val_loss: -23.2933 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.28595 to -23.29330, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3692 - acc: 0.1619 - val_loss: -23.3069 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.29330 to -23.30690, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3788 - acc: 0.1619 - val_loss: -23.3148 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.30690 to -23.31480, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3864 - acc: 0.1619 - val_loss: -23.3212 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.31480 to -23.32124, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3933 - acc: 0.1619 - val_loss: -23.3274 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.32124 to -23.32742, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.3971 - acc: 0.1619 - val_loss: -23.3290 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.32742 to -23.32902, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4024 - acc: 0.1619 - val_loss: -23.2522 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -23.32902\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.3820 - acc: 0.1619 - val_loss: -23.3286 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.32902\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3984 - acc: 0.1619 - val_loss: -23.3289 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.32902\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.3987 - acc: 0.1619 - val_loss: -23.3293 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.32902 to -23.32927, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3991 - acc: 0.1619 - val_loss: -23.3297 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.32927 to -23.32969, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3996 - acc: 0.1619 - val_loss: -23.3302 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -23.32969 to -23.33020, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.4001 - acc: 0.1619 - val_loss: -23.3308 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -23.33020 to -23.33082, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4008 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.33082 to -23.33158, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4017 - acc: 0.1619 - val_loss: -23.3325 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -23.33158 to -23.33254, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4027 - acc: 0.1619 - val_loss: -23.3337 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -23.33254 to -23.33371, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.4040 - acc: 0.1619 - val_loss: -23.3351 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -23.33371 to -23.33512, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -15.0761 - acc: 0.1642 - val_loss: -21.7089 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.70887, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.8236 - acc: 0.1619 - val_loss: -21.8066 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.70887 to -21.80660, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -22.9153 - acc: 0.1619 - val_loss: -21.8921 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.80660 to -21.89209, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -22.9974 - acc: 0.1619 - val_loss: -21.9708 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.89209 to -21.97079, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.0746 - acc: 0.1619 - val_loss: -22.0467 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.97079 to -22.04670, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.1503 - acc: 0.1619 - val_loss: -22.1228 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.04670 to -22.12283, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.2274 - acc: 0.1619 - val_loss: -22.2015 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.12283 to -22.20149, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.3079 - acc: 0.1619 - val_loss: -22.2843 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.20149 to -22.28429, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.3929 - acc: 0.1619 - val_loss: -22.3721 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.28429 to -22.37209, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4830 - acc: 0.1619 - val_loss: -22.4649 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.37209 to -22.46495, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.5778 - acc: 0.1619 - val_loss: -22.5620 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.46495 to -22.56198, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.6761 - acc: 0.1619 - val_loss: -22.6614 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.56198 to -22.66143, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.7751 - acc: 0.1619 - val_loss: -22.7572 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.66143 to -22.75717, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8705 - acc: 0.1619 - val_loss: -22.8538 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.75717 to -22.85382, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.9635 - acc: 0.1619 - val_loss: -22.9397 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.85382 to -22.93974, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.0472 - acc: 0.1619 - val_loss: -23.0219 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -22.93974 to -23.02188, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1243 - acc: 0.1619 - val_loss: -23.0931 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.02188 to -23.09314, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1876 - acc: 0.1619 - val_loss: -23.1516 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.09314 to -23.15156, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.2428 - acc: 0.1619 - val_loss: -23.1991 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.15156 to -23.19908, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.2854 - acc: 0.1619 - val_loss: -23.2324 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.19908 to -23.23242, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3180 - acc: 0.1619 - val_loss: -23.2663 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.23242 to -23.26630, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.3411 - acc: 0.1619 - val_loss: -23.2850 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.26630 to -23.28498, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3629 - acc: 0.1619 - val_loss: -23.2999 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.28498 to -23.29993, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.3775 - acc: 0.1619 - val_loss: -23.3137 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.29993 to -23.31371, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3890 - acc: 0.1619 - val_loss: -23.3221 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.31371 to -23.32214, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3969 - acc: 0.1619 - val_loss: -23.3295 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32214 to -23.32953, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4026 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.32953 to -23.33161, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4050 - acc: 0.1619 - val_loss: -23.3393 - val_acc: 0.1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss improved from -23.33161 to -23.33934, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.3784 - acc: 0.1619 - val_loss: -23.3317 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33934\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -24.4015 - acc: 0.1619 - val_loss: -23.3320 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -23.33934\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4018 - acc: 0.1619 - val_loss: -23.3324 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33934\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4022 - acc: 0.1619 - val_loss: -23.3328 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.33934\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4025 - acc: 0.1619 - val_loss: -23.3328 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33934\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4025 - acc: 0.1619 - val_loss: -23.3329 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33934\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.4026 - acc: 0.1619 - val_loss: -23.3330 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.33934\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4027 - acc: 0.1619 - val_loss: -23.3331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.33934\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4027 - acc: 0.1619 - val_loss: -23.3331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.33934\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.4027 - acc: 0.1619 - val_loss: -23.3331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.33934\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4028 - acc: 0.1619 - val_loss: -23.3331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.33934\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4028 - acc: 0.1619 - val_loss: -23.3331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.33934\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -8.1643 - acc: 0.1577 - val_loss: -21.6224 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.62235, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.7866 - acc: 0.1619 - val_loss: -21.8287 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.62235 to -21.82874, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.9821 - acc: 0.1619 - val_loss: -22.0116 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.82874 to -22.01160, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.1562 - acc: 0.1619 - val_loss: -22.1759 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -22.01160 to -22.17587, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.3121 - acc: 0.1619 - val_loss: -22.3213 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -22.17587 to -22.32130, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4512 - acc: 0.1619 - val_loss: -22.4529 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.32130 to -22.45291, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.5777 - acc: 0.1619 - val_loss: -22.5765 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.45291 to -22.57647, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.6952 - acc: 0.1619 - val_loss: -22.6864 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.57647 to -22.68638, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8033 - acc: 0.1619 - val_loss: -22.7887 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.68638 to -22.78867, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.9029 - acc: 0.1619 - val_loss: -22.8856 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.78867 to -22.88557, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.9926 - acc: 0.1619 - val_loss: -22.9675 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.88557 to -22.96749, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -24.0737 - acc: 0.1619 - val_loss: -23.0444 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.96749 to -23.04438, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1450 - acc: 0.1619 - val_loss: -23.1048 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -23.04438 to -23.10479, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.2006 - acc: 0.1619 - val_loss: -23.1600 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -23.10479 to -23.16003, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.2521 - acc: 0.1619 - val_loss: -23.2015 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -23.16003 to -23.20151, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.2904 - acc: 0.1619 - val_loss: -23.2397 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.20151 to -23.23967, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3222 - acc: 0.1619 - val_loss: -23.2723 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.23967 to -23.27231, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3333 - acc: 0.1619 - val_loss: -23.2709 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -23.27231\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3475 - acc: 0.1619 - val_loss: -23.2859 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.27231 to -23.28592, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.3616 - acc: 0.1619 - val_loss: -23.2991 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.28592 to -23.29906, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3716 - acc: 0.1619 - val_loss: -23.3063 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.29906 to -23.30634, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3751 - acc: 0.1619 - val_loss: -23.3057 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -23.30634\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3794 - acc: 0.1619 - val_loss: -23.3146 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.30634 to -23.31458, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.3873 - acc: 0.1619 - val_loss: -23.3193 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31458 to -23.31928, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3919 - acc: 0.1619 - val_loss: -23.3235 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.31928 to -23.32346, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3946 - acc: 0.1619 - val_loss: -23.3278 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32346 to -23.32782, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.3998 - acc: 0.1619 - val_loss: -23.3309 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.32782 to -23.33094, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4021 - acc: 0.1619 - val_loss: -23.3352 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.33094 to -23.33519, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4060 - acc: 0.1619 - val_loss: -23.3290 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33519\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3999 - acc: 0.1619 - val_loss: -23.3317 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -23.33519\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.4026 - acc: 0.1619 - val_loss: -23.3344 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33519\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4053 - acc: 0.1619 - val_loss: -23.3370 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -23.33519 to -23.33705, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.4079 - acc: 0.1619 - val_loss: -23.3397 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.33705 to -23.33967, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.4090 - acc: 0.1619 - val_loss: -23.3396 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33967\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.4104 - acc: 0.1619 - val_loss: -23.3409 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -23.33967 to -23.34088, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.4076 - acc: 0.1619 - val_loss: -23.3361 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.34088\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.4060 - acc: 0.1619 - val_loss: -23.3366 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.34088\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4065 - acc: 0.1619 - val_loss: -23.3371 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34088\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.4071 - acc: 0.1619 - val_loss: -23.3377 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34088\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.4074 - acc: 0.1619 - val_loss: -23.3378 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34088\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -12.2809 - acc: 0.1614 - val_loss: -21.6531 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.65315, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.7880 - acc: 0.1619 - val_loss: -21.7959 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.65315 to -21.79585, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.9262 - acc: 0.1619 - val_loss: -21.9287 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.79585 to -21.92866, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.0555 - acc: 0.1619 - val_loss: -22.0546 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.92866 to -22.05456, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.1796 - acc: 0.1619 - val_loss: -22.1737 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -22.05456 to -22.17365, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.2948 - acc: 0.1619 - val_loss: -22.2886 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.17365 to -22.28863, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4099 - acc: 0.1619 - val_loss: -22.4032 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.28863 to -22.40316, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.5224 - acc: 0.1619 - val_loss: -22.5137 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.40316 to -22.51370, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.6310 - acc: 0.1619 - val_loss: -22.6211 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.51370 to -22.62105, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.7377 - acc: 0.1619 - val_loss: -22.7256 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.62105 to -22.72559, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8398 - acc: 0.1619 - val_loss: -22.8244 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.72559 to -22.82444, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.9364 - acc: 0.1619 - val_loss: -22.9163 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.82444 to -22.91633, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -24.0228 - acc: 0.1619 - val_loss: -22.9943 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.91633 to -22.99427, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1006 - acc: 0.1619 - val_loss: -23.0696 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.99427 to -23.06962, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -24.1693 - acc: 0.1619 - val_loss: -23.1332 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -23.06962 to -23.13324, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.2260 - acc: 0.1619 - val_loss: -23.1863 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.13324 to -23.18627, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.2650 - acc: 0.1619 - val_loss: -23.2193 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.18627 to -23.21934, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -24.3055 - acc: 0.1619 - val_loss: -23.2422 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.21934 to -23.24219, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.3268 - acc: 0.1619 - val_loss: -23.2739 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.24219 to -23.27394, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.3522 - acc: 0.1619 - val_loss: -23.2811 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.27394 to -23.28109, saving model to model-2.h5\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.3595 - acc: 0.1619 - val_loss: -23.2998 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.28109 to -23.29983, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -24.3761 - acc: 0.1619 - val_loss: -23.3106 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.29983 to -23.31057, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3839 - acc: 0.1619 - val_loss: -23.3172 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.31057 to -23.31719, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.3917 - acc: 0.1619 - val_loss: -23.3257 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31719 to -23.32572, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.3980 - acc: 0.1619 - val_loss: -23.3306 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.32572 to -23.33057, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.4012 - acc: 0.1619 - val_loss: -23.3304 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -23.33057\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4042 - acc: 0.1619 - val_loss: -23.3286 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -23.33057\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.4015 - acc: 0.1619 - val_loss: -23.3355 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.33057 to -23.33549, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4076 - acc: 0.1619 - val_loss: -23.3406 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.33549 to -23.34061, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4061 - acc: 0.1619 - val_loss: -23.3342 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -23.34061\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4040 - acc: 0.1619 - val_loss: -23.3345 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.34061\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4043 - acc: 0.1619 - val_loss: -23.3348 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.34061\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.4046 - acc: 0.1619 - val_loss: -23.3352 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.34061\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.4049 - acc: 0.1619 - val_loss: -23.3352 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.34061\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.4049 - acc: 0.1619 - val_loss: -23.3353 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.34061\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.4050 - acc: 0.1619 - val_loss: -23.3353 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.34061\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.4051 - acc: 0.1619 - val_loss: -23.3354 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.34061\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.4051 - acc: 0.1619 - val_loss: -23.3354 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34061\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4051 - acc: 0.1619 - val_loss: -23.3355 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34061\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.4051 - acc: 0.1619 - val_loss: -23.3355 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34061\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -14.5278 - acc: 0.1628 - val_loss: -21.6657 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.66567, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.7828 - acc: 0.1619 - val_loss: -21.7707 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.66567 to -21.77066, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.8840 - acc: 0.1619 - val_loss: -21.8677 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.77066 to -21.86774, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.9815 - acc: 0.1619 - val_loss: -21.9657 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.86774 to -21.96565, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.0787 - acc: 0.1619 - val_loss: -22.0626 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.96565 to -22.06261, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.1758 - acc: 0.1619 - val_loss: -22.1589 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.06261 to -22.15888, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.2744 - acc: 0.1619 - val_loss: -22.2621 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.15888 to -22.26209, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3781 - acc: 0.1619 - val_loss: -22.3664 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.26209 to -22.36636, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4820 - acc: 0.1619 - val_loss: -22.4720 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.36636 to -22.47200, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.5906 - acc: 0.1619 - val_loss: -22.5814 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.47200 to -22.58145, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.6992 - acc: 0.1619 - val_loss: -22.6895 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.58145 to -22.68946, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8053 - acc: 0.1619 - val_loss: -22.7920 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.68946 to -22.79198, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.9066 - acc: 0.1619 - val_loss: -22.8853 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.79198 to -22.88529, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.9970 - acc: 0.1619 - val_loss: -22.9754 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.88529 to -22.97545, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.0794 - acc: 0.1619 - val_loss: -23.0478 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.97545 to -23.04779, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -24.1503 - acc: 0.1619 - val_loss: -23.1188 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.04779 to -23.11883, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.2118 - acc: 0.1619 - val_loss: -23.1713 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.11883 to -23.17128, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.2485 - acc: 0.1619 - val_loss: -23.1836 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.17128 to -23.18359, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.2601 - acc: 0.1619 - val_loss: -23.1988 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.18359 to -23.19878, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.2752 - acc: 0.1619 - val_loss: -23.2138 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.19878 to -23.21377, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.2902 - acc: 0.1619 - val_loss: -23.2289 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.21377 to -23.22893, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3055 - acc: 0.1619 - val_loss: -23.2445 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.22893 to -23.24449, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3213 - acc: 0.1619 - val_loss: -23.2612 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.24449 to -23.26120, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3323 - acc: 0.1619 - val_loss: -23.2710 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.26120 to -23.27103, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3469 - acc: 0.1619 - val_loss: -23.2812 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.27103 to -23.28119, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3575 - acc: 0.1619 - val_loss: -23.2956 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.28119 to -23.29556, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.3690 - acc: 0.1619 - val_loss: -23.3058 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.29556 to -23.30578, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3798 - acc: 0.1619 - val_loss: -23.3062 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.30578 to -23.30617, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.3767 - acc: 0.1619 - val_loss: -23.3082 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.30617 to -23.30820, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3788 - acc: 0.1619 - val_loss: -23.3104 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.30820 to -23.31038, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -24.3811 - acc: 0.1619 - val_loss: -23.3128 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.31038 to -23.31280, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -24.3837 - acc: 0.1619 - val_loss: -23.3155 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -23.31280 to -23.31553, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.3866 - acc: 0.1619 - val_loss: -23.3187 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.31553 to -23.31867, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.3899 - acc: 0.1619 - val_loss: -23.3222 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.31867 to -23.32224, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.3937 - acc: 0.1619 - val_loss: -23.3262 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -23.32224 to -23.32624, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.3964 - acc: 0.1619 - val_loss: -23.3266 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -23.32624 to -23.32663, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.3986 - acc: 0.1619 - val_loss: -23.3317 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.32663 to -23.33172, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.3981 - acc: 0.1619 - val_loss: -23.3266 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.33172\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.3972 - acc: 0.1619 - val_loss: -23.3285 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.33172\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3991 - acc: 0.1619 - val_loss: -23.3306 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.33172\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -14.7003 - acc: 0.1619 - val_loss: -21.6730 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.67296, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.7835 - acc: 0.1619 - val_loss: -21.7638 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.67296 to -21.76385, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.8737 - acc: 0.1619 - val_loss: -21.8534 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.76385 to -21.85335, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.9631 - acc: 0.1619 - val_loss: -21.9430 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.85335 to -21.94302, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.0531 - acc: 0.1619 - val_loss: -22.0338 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.94302 to -22.03385, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.1454 - acc: 0.1619 - val_loss: -22.1279 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.03385 to -22.12787, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.2409 - acc: 0.1619 - val_loss: -22.2254 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.12787 to -22.22542, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.3397 - acc: 0.1619 - val_loss: -22.3263 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.22542 to -22.32632, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4420 - acc: 0.1619 - val_loss: -22.4276 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.32632 to -22.42758, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.5450 - acc: 0.1619 - val_loss: -22.5338 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.42758 to -22.53381, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.6504 - acc: 0.1619 - val_loss: -22.6388 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.53381 to -22.63878, saving model to model-4.h5\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.7531 - acc: 0.1619 - val_loss: -22.7414 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.63878 to -22.74138, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8560 - acc: 0.1619 - val_loss: -22.8392 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.74138 to -22.83917, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.9517 - acc: 0.1619 - val_loss: -22.9320 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.83917 to -22.93200, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.0388 - acc: 0.1619 - val_loss: -23.0132 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.93200 to -23.01315, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1145 - acc: 0.1619 - val_loss: -23.0835 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.01315 to -23.08349, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1824 - acc: 0.1619 - val_loss: -23.1461 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.08349 to -23.14613, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.2365 - acc: 0.1619 - val_loss: -23.1895 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.14613 to -23.18955, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.2805 - acc: 0.1619 - val_loss: -23.2349 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.18955 to -23.23493, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3144 - acc: 0.1619 - val_loss: -23.2636 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.23493 to -23.26358, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3439 - acc: 0.1619 - val_loss: -23.2840 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.26358 to -23.28403, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3636 - acc: 0.1619 - val_loss: -23.3016 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.28403 to -23.30158, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.3786 - acc: 0.1619 - val_loss: -23.3163 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.30158 to -23.31634, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3882 - acc: 0.1619 - val_loss: -23.3242 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31634 to -23.32416, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.3962 - acc: 0.1619 - val_loss: -23.3306 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.32416 to -23.33064, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4029 - acc: 0.1619 - val_loss: -23.3362 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.33064 to -23.33621, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4067 - acc: 0.1619 - val_loss: -23.3400 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.33621 to -23.33996, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.4079 - acc: 0.1619 - val_loss: -23.3413 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.33996 to -23.34134, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.4074 - acc: 0.1619 - val_loss: -23.3372 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.34134\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.4090 - acc: 0.1619 - val_loss: -23.3416 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.34134 to -23.34164, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.4129 - acc: 0.1619 - val_loss: -23.3449 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.34164 to -23.34490, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4138 - acc: 0.1619 - val_loss: -23.3420 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.34490\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4134 - acc: 0.1619 - val_loss: -23.3456 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.34490 to -23.34556, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4142 - acc: 0.1619 - val_loss: -23.3456 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.34556 to -23.34557, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.4134 - acc: 0.1619 - val_loss: -23.3413 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.34557\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.4122 - acc: 0.1619 - val_loss: -23.3439 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.34557\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4145 - acc: 0.1619 - val_loss: -23.3460 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -23.34557 to -23.34597, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.4164 - acc: 0.1619 - val_loss: -23.3427 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34597\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4135 - acc: 0.1619 - val_loss: -23.3452 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34597\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.4158 - acc: 0.1619 - val_loss: -23.3471 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -23.34597 to -23.34713, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -14.4603 - acc: 0.1642 - val_loss: -21.6948 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.69484, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 999us/step - loss: -22.8101 - acc: 0.1619 - val_loss: -21.7954 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.69484 to -21.79542, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.9082 - acc: 0.1619 - val_loss: -21.8909 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.79542 to -21.89094, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.0023 - acc: 0.1619 - val_loss: -21.9836 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.89094 to -21.98360, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0943 - acc: 0.1619 - val_loss: -22.0753 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.98360 to -22.07527, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.1857 - acc: 0.1619 - val_loss: -22.1670 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.07527 to -22.16697, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.2782 - acc: 0.1619 - val_loss: -22.2602 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.16697 to -22.26025, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.3726 - acc: 0.1619 - val_loss: -22.3546 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.26025 to -22.35464, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4679 - acc: 0.1619 - val_loss: -22.4523 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.35464 to -22.45233, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.5654 - acc: 0.1619 - val_loss: -22.5502 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.45233 to -22.55024, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.6634 - acc: 0.1619 - val_loss: -22.6486 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.55024 to -22.64860, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.7619 - acc: 0.1619 - val_loss: -22.7449 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.64860 to -22.74485, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8571 - acc: 0.1619 - val_loss: -22.8394 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.74485 to -22.83940, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.9446 - acc: 0.1619 - val_loss: -22.9228 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.83940 to -22.92277, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.0256 - acc: 0.1619 - val_loss: -22.9977 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.92277 to -22.99770, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1003 - acc: 0.1619 - val_loss: -23.0671 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -22.99770 to -23.06707, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1636 - acc: 0.1619 - val_loss: -23.1244 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.06707 to -23.12437, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.2188 - acc: 0.1619 - val_loss: -23.1758 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.12437 to -23.17576, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.2648 - acc: 0.1619 - val_loss: -23.2186 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.17576 to -23.21860, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.3037 - acc: 0.1619 - val_loss: -23.2518 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.21860 to -23.25185, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.3311 - acc: 0.1619 - val_loss: -23.2752 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.25185 to -23.27517, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3539 - acc: 0.1619 - val_loss: -23.2910 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.27517 to -23.29098, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.3695 - acc: 0.1619 - val_loss: -23.3097 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.29098 to -23.30968, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.3830 - acc: 0.1619 - val_loss: -23.3193 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.30968 to -23.31932, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.3914 - acc: 0.1619 - val_loss: -23.3231 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.31932 to -23.32314, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.3975 - acc: 0.1619 - val_loss: -23.3330 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32314 to -23.33300, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.4037 - acc: 0.1619 - val_loss: -23.3373 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.33300 to -23.33730, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.3745 - acc: 0.1619 - val_loss: -23.3304 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -23.33730\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.4002 - acc: 0.1619 - val_loss: -23.3307 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33730\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4005 - acc: 0.1619 - val_loss: -23.3310 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -23.33730\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4008 - acc: 0.1619 - val_loss: -23.3313 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33730\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.4010 - acc: 0.1619 - val_loss: -23.3313 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.33730\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4010 - acc: 0.1619 - val_loss: -23.3314 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33730\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4011 - acc: 0.1619 - val_loss: -23.3315 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33730\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.4012 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.33730\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.4012 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.33730\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.4012 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.33730\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.4013 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.33730\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.4013 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.33730\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4013 - acc: 0.1619 - val_loss: -23.3316 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.33730\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -7.2500 - acc: 0.1647 - val_loss: -21.7492 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.74921, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.9288 - acc: 0.1619 - val_loss: -21.9834 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.74921 to -21.98339, saving model to model-1.h5\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.1439 - acc: 0.1619 - val_loss: -22.1801 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.98339 to -22.18011, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3266 - acc: 0.1619 - val_loss: -22.3444 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -22.18011 to -22.34444, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4821 - acc: 0.1619 - val_loss: -22.4896 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -22.34444 to -22.48963, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.6161 - acc: 0.1619 - val_loss: -22.6136 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.48963 to -22.61358, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.7374 - acc: 0.1619 - val_loss: -22.7294 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.61358 to -22.72936, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.8464 - acc: 0.1619 - val_loss: -22.8287 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.72936 to -22.82866, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.9402 - acc: 0.1619 - val_loss: -22.9185 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.82866 to -22.91850, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.0253 - acc: 0.1619 - val_loss: -23.0027 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.91850 to -23.00269, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.0705 - acc: 0.1619 - val_loss: -23.0259 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.00269 to -23.02588, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.1166 - acc: 0.1619 - val_loss: -23.0722 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.02588 to -23.07220, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1607 - acc: 0.1619 - val_loss: -23.1146 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -23.07220 to -23.11460, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1974 - acc: 0.1619 - val_loss: -23.1428 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -23.11460 to -23.14282, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.2294 - acc: 0.1619 - val_loss: -23.1796 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -23.14282 to -23.17959, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.2606 - acc: 0.1619 - val_loss: -23.2090 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.17959 to -23.20898, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.2901 - acc: 0.1619 - val_loss: -23.2360 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.20898 to -23.23597, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.3120 - acc: 0.1619 - val_loss: -23.2581 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.23597 to -23.25805, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.3341 - acc: 0.1619 - val_loss: -23.2788 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.25805 to -23.27880, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.3488 - acc: 0.1619 - val_loss: -23.2915 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.27880 to -23.29155, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.3646 - acc: 0.1619 - val_loss: -23.3008 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.29155 to -23.30083, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.3691 - acc: 0.1619 - val_loss: -23.2990 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -23.30083\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.3739 - acc: 0.1619 - val_loss: -23.3103 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.30083 to -23.31026, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3843 - acc: 0.1619 - val_loss: -23.3198 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31026 to -23.31980, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3902 - acc: 0.1619 - val_loss: -23.3242 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.31980 to -23.32424, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.3940 - acc: 0.1619 - val_loss: -23.3266 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32424 to -23.32660, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.3957 - acc: 0.1619 - val_loss: -23.3283 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.32660 to -23.32825, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.4002 - acc: 0.1619 - val_loss: -23.3332 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.32825 to -23.33322, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.4020 - acc: 0.1619 - val_loss: -23.3253 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33322\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.3956 - acc: 0.1619 - val_loss: -23.3266 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -23.33322\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.3969 - acc: 0.1619 - val_loss: -23.3280 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33322\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3984 - acc: 0.1619 - val_loss: -23.3295 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.33322\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.3993 - acc: 0.1619 - val_loss: -23.3297 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33322\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.3995 - acc: 0.1619 - val_loss: -23.3299 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33322\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -24.3997 - acc: 0.1619 - val_loss: -23.3302 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.33322\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.4000 - acc: 0.1619 - val_loss: -23.3305 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.33322\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4002 - acc: 0.1619 - val_loss: -23.3306 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.33322\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.4003 - acc: 0.1619 - val_loss: -23.3306 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.33322\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4003 - acc: 0.1619 - val_loss: -23.3307 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.33322\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4004 - acc: 0.1619 - val_loss: -23.3308 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.33322\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 7s 3ms/step - loss: -11.7778 - acc: 0.1661 - val_loss: -21.6568 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.65677, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.7868 - acc: 0.1619 - val_loss: -21.7902 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.65677 to -21.79022, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.9161 - acc: 0.1619 - val_loss: -21.9170 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.79022 to -21.91703, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.0412 - acc: 0.1619 - val_loss: -22.0396 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.91703 to -22.03959, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.1612 - acc: 0.1619 - val_loss: -22.1568 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -22.03959 to -22.15677, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.2780 - acc: 0.1619 - val_loss: -22.2707 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.15677 to -22.27070, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3931 - acc: 0.1619 - val_loss: -22.3871 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.27070 to -22.38705, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.5072 - acc: 0.1619 - val_loss: -22.4985 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.38705 to -22.49846, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.6195 - acc: 0.1619 - val_loss: -22.6086 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.49846 to -22.60862, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.7290 - acc: 0.1619 - val_loss: -22.7200 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.60862 to -22.71998, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8367 - acc: 0.1619 - val_loss: -22.8229 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.71998 to -22.82291, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.9359 - acc: 0.1619 - val_loss: -22.9168 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.82291 to -22.91679, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.0235 - acc: 0.1619 - val_loss: -23.0029 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.91679 to -23.00294, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1059 - acc: 0.1619 - val_loss: -23.0756 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -23.00294 to -23.07556, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1719 - acc: 0.1619 - val_loss: -23.1318 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -23.07556 to -23.13178, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.2262 - acc: 0.1619 - val_loss: -23.1837 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.13178 to -23.18373, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.2612 - acc: 0.1619 - val_loss: -23.2105 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.18373 to -23.21053, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.2955 - acc: 0.1619 - val_loss: -23.2449 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.21053 to -23.24494, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.3220 - acc: 0.1619 - val_loss: -23.2630 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.24494 to -23.26303, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.3427 - acc: 0.1619 - val_loss: -23.2845 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.26303 to -23.28454, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -24.3600 - acc: 0.1619 - val_loss: -23.2980 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.28454 to -23.29802, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3714 - acc: 0.1619 - val_loss: -23.3100 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.29802 to -23.31004, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.3801 - acc: 0.1619 - val_loss: -23.3187 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.31004 to -23.31870, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.3880 - acc: 0.1619 - val_loss: -23.3202 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31870 to -23.32017, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.3920 - acc: 0.1619 - val_loss: -23.3246 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.32017 to -23.32462, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.3979 - acc: 0.1619 - val_loss: -23.3222 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -23.32462\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.3950 - acc: 0.1619 - val_loss: -23.3289 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.32462 to -23.32888, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.4008 - acc: 0.1619 - val_loss: -23.3340 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.32888 to -23.33396, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4048 - acc: 0.1619 - val_loss: -23.3299 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33396\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.4020 - acc: 0.1619 - val_loss: -23.3352 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33396 to -23.33522, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4065 - acc: 0.1619 - val_loss: -23.3356 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.33522 to -23.33558, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4072 - acc: 0.1619 - val_loss: -23.3323 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.33558\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4043 - acc: 0.1619 - val_loss: -23.3379 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.33558 to -23.33788, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4095 - acc: 0.1619 - val_loss: -23.3414 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -23.33788 to -23.34144, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.4108 - acc: 0.1619 - val_loss: -23.3416 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -23.34144 to -23.34158, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4101 - acc: 0.1619 - val_loss: -23.3369 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.34158\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.4079 - acc: 0.1619 - val_loss: -23.3399 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.34158\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.4111 - acc: 0.1619 - val_loss: -23.3430 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -23.34158 to -23.34298, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4112 - acc: 0.1619 - val_loss: -23.3423 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34298\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4130 - acc: 0.1619 - val_loss: -23.3427 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34298\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 3ms/step - loss: -13.2536 - acc: 0.1596 - val_loss: -21.6802 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.68018, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.8080 - acc: 0.1619 - val_loss: -21.8077 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.68018 to -21.80765, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -22.9281 - acc: 0.1619 - val_loss: -21.9200 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.80765 to -21.91995, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.0368 - acc: 0.1619 - val_loss: -22.0221 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.91995 to -22.02213, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.1362 - acc: 0.1619 - val_loss: -22.1174 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -22.02213 to -22.11741, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.2294 - acc: 0.1619 - val_loss: -22.2105 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.11741 to -22.21046, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.3209 - acc: 0.1619 - val_loss: -22.3022 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.21046 to -22.30220, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4130 - acc: 0.1619 - val_loss: -22.3944 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.30220 to -22.39443, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.5060 - acc: 0.1619 - val_loss: -22.4897 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.39443 to -22.48966, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.6033 - acc: 0.1619 - val_loss: -22.5861 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.48966 to -22.58609, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.6983 - acc: 0.1619 - val_loss: -22.6837 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.58609 to -22.68368, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.7965 - acc: 0.1619 - val_loss: -22.7780 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.68368 to -22.77796, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8905 - acc: 0.1619 - val_loss: -22.8711 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.77796 to -22.87114, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.9793 - acc: 0.1619 - val_loss: -22.9573 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.87114 to -22.95728, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.0623 - acc: 0.1619 - val_loss: -23.0337 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.95728 to -23.03373, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1336 - acc: 0.1619 - val_loss: -23.0986 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.03373 to -23.09857, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1967 - acc: 0.1619 - val_loss: -23.1546 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.09857 to -23.15460, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.2477 - acc: 0.1619 - val_loss: -23.2018 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.15460 to -23.20178, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.2882 - acc: 0.1619 - val_loss: -23.2314 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.20178 to -23.23138, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.3173 - acc: 0.1619 - val_loss: -23.2651 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.23138 to -23.26514, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.3452 - acc: 0.1619 - val_loss: -23.2887 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.26514 to -23.28866, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.3627 - acc: 0.1619 - val_loss: -23.2981 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.28866 to -23.29808, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.3745 - acc: 0.1619 - val_loss: -23.3113 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.29808 to -23.31128, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.3861 - acc: 0.1619 - val_loss: -23.3128 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.31128 to -23.31283, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.3877 - acc: 0.1619 - val_loss: -23.3231 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.31283 to -23.32307, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.3958 - acc: 0.1619 - val_loss: -23.3305 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32307 to -23.33046, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.3999 - acc: 0.1619 - val_loss: -23.3328 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.33046 to -23.33284, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.4035 - acc: 0.1619 - val_loss: -23.3338 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.33284 to -23.33376, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.4050 - acc: 0.1619 - val_loss: -23.3324 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33376\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.4054 - acc: 0.1619 - val_loss: -23.3387 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33376 to -23.33865, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4104 - acc: 0.1619 - val_loss: -23.3367 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.33865\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.3818 - acc: 0.1619 - val_loss: -23.3353 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.33865\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.4051 - acc: 0.1619 - val_loss: -23.3355 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.33865\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -24.4053 - acc: 0.1619 - val_loss: -23.3357 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.33865\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.4054 - acc: 0.1619 - val_loss: -23.3357 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.33865\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4054 - acc: 0.1619 - val_loss: -23.3358 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.33865\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.4054 - acc: 0.1619 - val_loss: -23.3358 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.33865\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.4055 - acc: 0.1619 - val_loss: -23.3358 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.33865\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4055 - acc: 0.1619 - val_loss: -23.3358 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.33865\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4055 - acc: 0.1619 - val_loss: -23.3358 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.33865\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 3ms/step - loss: -14.1236 - acc: 0.1610 - val_loss: -21.6749 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.67491, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.7979 - acc: 0.1619 - val_loss: -21.7818 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.67491 to -21.78182, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -22.8949 - acc: 0.1619 - val_loss: -21.8771 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.78182 to -21.87713, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.9896 - acc: 0.1619 - val_loss: -21.9725 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.87713 to -21.97245, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.0837 - acc: 0.1619 - val_loss: -22.0685 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.97245 to -22.06849, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.1841 - acc: 0.1619 - val_loss: -22.1660 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -22.06849 to -22.16599, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.2783 - acc: 0.1619 - val_loss: -22.2644 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.16599 to -22.26438, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.3793 - acc: 0.1619 - val_loss: -22.3660 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.26438 to -22.36596, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4840 - acc: 0.1619 - val_loss: -22.4713 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.36596 to -22.47132, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.5882 - acc: 0.1619 - val_loss: -22.5743 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.47132 to -22.57429, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.6918 - acc: 0.1619 - val_loss: -22.6788 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.57429 to -22.67876, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.7924 - acc: 0.1619 - val_loss: -22.7770 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.67876 to -22.77696, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8895 - acc: 0.1619 - val_loss: -22.8722 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.77696 to -22.87218, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -23.9797 - acc: 0.1619 - val_loss: -22.9579 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.87218 to -22.95788, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.0653 - acc: 0.1619 - val_loss: -23.0337 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.95788 to -23.03369, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1366 - acc: 0.1619 - val_loss: -23.1028 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -23.03369 to -23.10284, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.2012 - acc: 0.1619 - val_loss: -23.1603 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.10284 to -23.16029, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.2526 - acc: 0.1619 - val_loss: -23.2076 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.16029 to -23.20757, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.2939 - acc: 0.1619 - val_loss: -23.2437 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.20757 to -23.24371, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.3269 - acc: 0.1619 - val_loss: -23.2716 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.24371 to -23.27165, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.3526 - acc: 0.1619 - val_loss: -23.2952 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.27165 to -23.29523, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.3675 - acc: 0.1619 - val_loss: -23.3077 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.29523 to -23.30774, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.3843 - acc: 0.1619 - val_loss: -23.2989 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -23.30774\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.3870 - acc: 0.1619 - val_loss: -23.3214 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.30774 to -23.32140, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.3959 - acc: 0.1619 - val_loss: -23.3299 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.32140 to -23.32986, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.4007 - acc: 0.1619 - val_loss: -23.3334 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32986 to -23.33344, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.4067 - acc: 0.1619 - val_loss: -23.3364 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.33344 to -23.33641, saving model to model-4.h5\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4081 - acc: 0.1619 - val_loss: -23.3369 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.33641 to -23.33688, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.4093 - acc: 0.1619 - val_loss: -23.3375 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -23.33688 to -23.33749, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -24.4104 - acc: 0.1619 - val_loss: -23.3398 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33749 to -23.33981, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.4123 - acc: 0.1619 - val_loss: -23.3443 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -23.33981 to -23.34427, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4131 - acc: 0.1619 - val_loss: -23.3402 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.34427\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -24.4124 - acc: 0.1619 - val_loss: -23.3446 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -23.34427 to -23.34459, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.4090 - acc: 0.1619 - val_loss: -23.3382 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.34459\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4081 - acc: 0.1619 - val_loss: -23.3388 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.34459\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.4088 - acc: 0.1619 - val_loss: -23.3394 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.34459\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 943us/step - loss: -24.4098 - acc: 0.1619 - val_loss: -23.3402 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.34459\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4106 - acc: 0.1619 - val_loss: -23.3402 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34459\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.4107 - acc: 0.1619 - val_loss: -23.3404 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34459\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -24.4112 - acc: 0.1619 - val_loss: -23.3405 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34459\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2500\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -15.6415 - acc: 0.1624 - val_loss: -21.6606 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -21.66063, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -22.7977 - acc: 0.1619 - val_loss: -21.7580 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -21.66063 to -21.75797, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -22.8711 - acc: 0.1619 - val_loss: -21.8423 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -21.75797 to -21.84229, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.9445 - acc: 0.1619 - val_loss: -21.9127 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -21.84229 to -21.91269, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.0150 - acc: 0.1619 - val_loss: -21.9853 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -21.91269 to -21.98531, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.0906 - acc: 0.1619 - val_loss: -22.0626 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -21.98531 to -22.06257, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.1681 - acc: 0.1619 - val_loss: -22.1436 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -22.06257 to -22.14363, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.2529 - acc: 0.1619 - val_loss: -22.2321 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -22.14363 to -22.23210, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.3460 - acc: 0.1619 - val_loss: -22.3287 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -22.23210 to -22.32870, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4445 - acc: 0.1619 - val_loss: -22.4324 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -22.32870 to -22.43242, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.5520 - acc: 0.1619 - val_loss: -22.5404 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -22.43242 to -22.54038, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.6579 - acc: 0.1619 - val_loss: -22.6477 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -22.54038 to -22.64766, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.7661 - acc: 0.1619 - val_loss: -22.7544 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -22.64766 to -22.75444, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8724 - acc: 0.1619 - val_loss: -22.8593 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -22.75444 to -22.85929, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.9712 - acc: 0.1619 - val_loss: -22.9520 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -22.85929 to -22.95197, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.0592 - acc: 0.1619 - val_loss: -23.0353 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -22.95197 to -23.03527, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1370 - acc: 0.1619 - val_loss: -23.1066 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -23.03527 to -23.10664, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.2020 - acc: 0.1619 - val_loss: -23.1651 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -23.10664 to -23.16508, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.2543 - acc: 0.1619 - val_loss: -23.2104 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -23.16508 to -23.21044, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.2996 - acc: 0.1619 - val_loss: -23.2424 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -23.21044 to -23.24238, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.3290 - acc: 0.1619 - val_loss: -23.2761 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -23.24238 to -23.27609, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.3525 - acc: 0.1619 - val_loss: -23.2947 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -23.27609 to -23.29471, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.3755 - acc: 0.1619 - val_loss: -23.3072 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -23.29471 to -23.30724, saving model to model-5.h5\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.3859 - acc: 0.1619 - val_loss: -23.3232 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -23.30724 to -23.32319, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.3930 - acc: 0.1619 - val_loss: -23.3288 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -23.32319 to -23.32878, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.4023 - acc: 0.1619 - val_loss: -23.3304 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -23.32878 to -23.33040, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 945us/step - loss: -24.4050 - acc: 0.1619 - val_loss: -23.3383 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -23.33040 to -23.33834, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.4082 - acc: 0.1619 - val_loss: -23.3397 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -23.33834 to -23.33973, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.4090 - acc: 0.1619 - val_loss: -23.3390 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -23.33973\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4115 - acc: 0.1619 - val_loss: -23.3435 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -23.33973 to -23.34355, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.3970 - acc: 0.1619 - val_loss: -23.3372 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -23.34355\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4078 - acc: 0.1619 - val_loss: -23.3383 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -23.34355\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.4095 - acc: 0.1619 - val_loss: -23.3393 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -23.34355\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -24.4108 - acc: 0.1619 - val_loss: -23.3405 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -23.34355\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -24.4120 - acc: 0.1619 - val_loss: -23.3406 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -23.34355\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.4118 - acc: 0.1619 - val_loss: -23.3407 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -23.34355\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.4120 - acc: 0.1619 - val_loss: -23.3409 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -23.34355\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.4123 - acc: 0.1619 - val_loss: -23.3411 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -23.34355\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.4127 - acc: 0.1619 - val_loss: -23.3411 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -23.34355\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -24.4124 - acc: 0.1619 - val_loss: -23.3412 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -23.34355\n",
      "Text informations:\n",
      "max length: 87 / min length: 3 / mean length: 13 / limit length: 100\n",
      "vocabulary size: 2166 / limit: 2000\n",
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -7.7334 - acc: 0.1633 - val_loss: -22.8776 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.87763, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -21.7540 - acc: 0.1720 - val_loss: -23.0224 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.87763 to -23.02242, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -21.8592 - acc: 0.1720 - val_loss: -23.1250 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.02242 to -23.12496, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -21.9608 - acc: 0.1720 - val_loss: -23.2268 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.12496 to -23.22677, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.0639 - acc: 0.1720 - val_loss: -23.3313 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.22677 to -23.33133, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.1689 - acc: 0.1720 - val_loss: -23.4383 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.33133 to -23.43827, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.2786 - acc: 0.1720 - val_loss: -23.5503 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.43827 to -23.55030, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.3905 - acc: 0.1720 - val_loss: -23.6645 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.55030 to -23.66450, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.5090 - acc: 0.1720 - val_loss: -23.7836 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.66450 to -23.78362, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.6276 - acc: 0.1720 - val_loss: -23.8995 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.78362 to -23.89949, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.7438 - acc: 0.1720 - val_loss: -24.0184 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.89949 to -24.01837, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.8566 - acc: 0.1720 - val_loss: -24.1260 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.01837 to -24.12603, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -22.9613 - acc: 0.1720 - val_loss: -24.2235 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.12603 to -24.22348, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.0551 - acc: 0.1720 - val_loss: -24.3143 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.22348 to -24.31425, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.1410 - acc: 0.1720 - val_loss: -24.3888 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.31425 to -24.38875, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.2096 - acc: 0.1720 - val_loss: -24.4555 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.38875 to -24.45554, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.2663 - acc: 0.1720 - val_loss: -24.5045 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.45554 to -24.50451, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.3147 - acc: 0.1720 - val_loss: -24.5447 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.50451 to -24.54470, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.3521 - acc: 0.1720 - val_loss: -24.5774 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.54470 to -24.57736, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.3788 - acc: 0.1720 - val_loss: -24.6004 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.57736 to -24.60037, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 998us/step - loss: -23.3993 - acc: 0.1720 - val_loss: -24.6161 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.60037 to -24.61606, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4158 - acc: 0.1720 - val_loss: -24.6316 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.61606 to -24.63164, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4282 - acc: 0.1720 - val_loss: -24.6441 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.63164 to -24.64406, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4338 - acc: 0.1720 - val_loss: -24.6495 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.64406 to -24.64952, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4430 - acc: 0.1720 - val_loss: -24.6566 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.64952 to -24.65665, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.4439 - acc: 0.1720 - val_loss: -24.6573 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.65665 to -24.65728, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.4492 - acc: 0.1720 - val_loss: -24.6590 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.65728 to -24.65898, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4520 - acc: 0.1720 - val_loss: -24.6622 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.65898 to -24.66217, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4530 - acc: 0.1720 - val_loss: -24.6626 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.66217 to -24.66261, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4548 - acc: 0.1720 - val_loss: -24.6625 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.66261\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4555 - acc: 0.1720 - val_loss: -24.6673 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.66261 to -24.66733, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.4557 - acc: 0.1720 - val_loss: -24.6667 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.66733\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4564 - acc: 0.1720 - val_loss: -24.6632 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.66733\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4556 - acc: 0.1720 - val_loss: -24.6668 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.66733\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4587 - acc: 0.1720 - val_loss: -24.6694 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.66733 to -24.66942, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.4598 - acc: 0.1720 - val_loss: -24.6656 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.66942\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4577 - acc: 0.1720 - val_loss: -24.6686 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.66942\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.4604 - acc: 0.1720 - val_loss: -24.6657 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.66942\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4574 - acc: 0.1720 - val_loss: -24.6680 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.66942\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4588 - acc: 0.1720 - val_loss: -24.6682 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66942\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -12.1184 - acc: 0.1757 - val_loss: -22.9578 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.95777, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 1000us/step - loss: -21.7823 - acc: 0.1720 - val_loss: -23.0373 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.95777 to -23.03734, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -21.8642 - acc: 0.1720 - val_loss: -23.1185 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.03734 to -23.11845, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -21.9461 - acc: 0.1720 - val_loss: -23.2013 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.11845 to -23.20135, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.0304 - acc: 0.1720 - val_loss: -23.2874 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.20135 to -23.28736, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.1191 - acc: 0.1720 - val_loss: -23.3803 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.28736 to -23.38035, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.2141 - acc: 0.1720 - val_loss: -23.4785 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.38035 to -23.47851, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.3160 - acc: 0.1720 - val_loss: -23.5840 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.47851 to -23.58402, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.4234 - acc: 0.1720 - val_loss: -23.6933 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.58402 to -23.69328, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.5342 - acc: 0.1720 - val_loss: -23.8054 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.69328 to -23.80537, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.6467 - acc: 0.1720 - val_loss: -23.9190 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.80537 to -23.91905, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.7605 - acc: 0.1720 - val_loss: -24.0312 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.91905 to -24.03122, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.8688 - acc: 0.1720 - val_loss: -24.1368 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.03122 to -24.13676, saving model to model-2.h5\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.9696 - acc: 0.1720 - val_loss: -24.2316 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.13676 to -24.23157, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.0623 - acc: 0.1720 - val_loss: -24.3173 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.23157 to -24.31734, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.1439 - acc: 0.1720 - val_loss: -24.3936 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.31734 to -24.39362, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.2138 - acc: 0.1720 - val_loss: -24.4572 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.39362 to -24.45723, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.2713 - acc: 0.1720 - val_loss: -24.5096 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.45723 to -24.50958, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.3173 - acc: 0.1720 - val_loss: -24.5499 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.50958 to -24.54994, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.3479 - acc: 0.1720 - val_loss: -24.5719 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.54994 to -24.57189, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.3749 - acc: 0.1720 - val_loss: -24.5982 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.57189 to -24.59816, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.3946 - acc: 0.1720 - val_loss: -24.6140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.59816 to -24.61405, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -23.4107 - acc: 0.1720 - val_loss: -24.6269 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.61405 to -24.62687, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4235 - acc: 0.1720 - val_loss: -24.6391 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.62687 to -24.63915, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4241 - acc: 0.1720 - val_loss: -24.6366 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.63915\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4301 - acc: 0.1720 - val_loss: -24.6428 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.63915 to -24.64284, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4361 - acc: 0.1720 - val_loss: -24.6485 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.64284 to -24.64847, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4411 - acc: 0.1720 - val_loss: -24.6520 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.64847 to -24.65200, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4435 - acc: 0.1720 - val_loss: -24.6539 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.65200 to -24.65387, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4468 - acc: 0.1720 - val_loss: -24.6560 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.65387 to -24.65598, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4492 - acc: 0.1720 - val_loss: -24.6554 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65598\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4486 - acc: 0.1720 - val_loss: -24.6609 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.65598 to -24.66088, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4485 - acc: 0.1720 - val_loss: -24.6568 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.66088\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4478 - acc: 0.1720 - val_loss: -24.6575 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.66088\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4485 - acc: 0.1720 - val_loss: -24.6581 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.66088\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4491 - acc: 0.1720 - val_loss: -24.6588 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.66088\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4496 - acc: 0.1720 - val_loss: -24.6589 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.66088\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4497 - acc: 0.1720 - val_loss: -24.6590 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.66088\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4498 - acc: 0.1720 - val_loss: -24.6591 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.66088\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4499 - acc: 0.1720 - val_loss: -24.6593 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66088\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -14.7952 - acc: 0.1725 - val_loss: -22.9637 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.96367, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -21.7887 - acc: 0.1720 - val_loss: -23.0397 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.96367 to -23.03973, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -21.8653 - acc: 0.1720 - val_loss: -23.1193 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.03973 to -23.11935, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -21.9467 - acc: 0.1720 - val_loss: -23.2016 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.11935 to -23.20156, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -22.0306 - acc: 0.1720 - val_loss: -23.2883 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.20156 to -23.28833, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -22.1200 - acc: 0.1720 - val_loss: -23.3806 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.28833 to -23.38063, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.2149 - acc: 0.1720 - val_loss: -23.4795 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.38063 to -23.47948, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 999us/step - loss: -22.3162 - acc: 0.1720 - val_loss: -23.5846 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.47948 to -23.58460, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.4247 - acc: 0.1720 - val_loss: -23.6962 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.58460 to -23.69622, saving model to model-3.h5\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.5387 - acc: 0.1720 - val_loss: -23.8111 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.69622 to -23.81106, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.6544 - acc: 0.1720 - val_loss: -23.9253 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.81106 to -23.92529, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.7673 - acc: 0.1720 - val_loss: -24.0378 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.92529 to -24.03785, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.8778 - acc: 0.1720 - val_loss: -24.1462 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.03785 to -24.14621, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.9806 - acc: 0.1720 - val_loss: -24.2425 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.14621 to -24.24251, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.0739 - acc: 0.1720 - val_loss: -24.3259 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.24251 to -24.32586, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.1530 - acc: 0.1720 - val_loss: -24.4046 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.32586 to -24.40456, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.2232 - acc: 0.1720 - val_loss: -24.4520 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.40456 to -24.45198, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2636 - acc: 0.1720 - val_loss: -24.4972 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.45198 to -24.49723, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.3056 - acc: 0.1720 - val_loss: -24.5355 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.49723 to -24.53549, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.3387 - acc: 0.1720 - val_loss: -24.5610 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.53549 to -24.56096, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.3644 - acc: 0.1720 - val_loss: -24.5837 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.56096 to -24.58369, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.3739 - acc: 0.1720 - val_loss: -24.5905 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.58369 to -24.59048, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.3872 - acc: 0.1720 - val_loss: -24.6037 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.59048 to -24.60365, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.3998 - acc: 0.1720 - val_loss: -24.6157 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.60365 to -24.61575, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4115 - acc: 0.1720 - val_loss: -24.6269 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.61575 to -24.62695, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4199 - acc: 0.1720 - val_loss: -24.6330 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.62695 to -24.63303, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4273 - acc: 0.1720 - val_loss: -24.6367 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.63303 to -24.63669, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4318 - acc: 0.1720 - val_loss: -24.6463 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.63669 to -24.64632, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4401 - acc: 0.1720 - val_loss: -24.6531 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.64632 to -24.65315, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4444 - acc: 0.1720 - val_loss: -24.6530 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.65315\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4470 - acc: 0.1720 - val_loss: -24.6600 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.65315 to -24.66002, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4501 - acc: 0.1720 - val_loss: -24.6616 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.66002 to -24.66158, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4518 - acc: 0.1720 - val_loss: -24.6625 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.66158 to -24.66255, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4539 - acc: 0.1720 - val_loss: -24.6632 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.66255 to -24.66317, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4545 - acc: 0.1720 - val_loss: -24.6598 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.66317\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4525 - acc: 0.1720 - val_loss: -24.6640 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.66317 to -24.66401, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4562 - acc: 0.1720 - val_loss: -24.6672 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.66401 to -24.66721, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4582 - acc: 0.1720 - val_loss: -24.6685 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.66721 to -24.66851, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4561 - acc: 0.1720 - val_loss: -24.6663 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.66851\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4582 - acc: 0.1720 - val_loss: -24.6690 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.66851 to -24.66895, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -14.3924 - acc: 0.1780 - val_loss: -22.9884 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.98837, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -21.8098 - acc: 0.1720 - val_loss: -23.0575 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.98837 to -23.05753, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -21.8800 - acc: 0.1720 - val_loss: -23.1289 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.05753 to -23.12893, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -21.9521 - acc: 0.1720 - val_loss: -23.2026 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.12893 to -23.20257, saving model to model-4.h5\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.0274 - acc: 0.1720 - val_loss: -23.2805 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.20257 to -23.28051, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.1089 - acc: 0.1720 - val_loss: -23.3660 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.28051 to -23.36605, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.1981 - acc: 0.1720 - val_loss: -23.4597 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.36605 to -23.45969, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.2952 - acc: 0.1720 - val_loss: -23.5608 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.45969 to -23.56076, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.3984 - acc: 0.1720 - val_loss: -23.6672 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.56076 to -23.66725, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.5069 - acc: 0.1720 - val_loss: -23.7782 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.66725 to -23.77819, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.6193 - acc: 0.1720 - val_loss: -23.8918 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.77819 to -23.89177, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.7334 - acc: 0.1720 - val_loss: -23.9998 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.89177 to -23.99976, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.8399 - acc: 0.1720 - val_loss: -24.1090 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -23.99976 to -24.10903, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.9437 - acc: 0.1720 - val_loss: -24.2078 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.10903 to -24.20779, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.0398 - acc: 0.1720 - val_loss: -24.2982 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.20779 to -24.29821, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.1231 - acc: 0.1720 - val_loss: -24.3768 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.29821 to -24.37683, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 996us/step - loss: -23.1933 - acc: 0.1720 - val_loss: -24.4333 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.37683 to -24.43327, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.2499 - acc: 0.1720 - val_loss: -24.4892 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.43327 to -24.48923, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.2980 - acc: 0.1720 - val_loss: -24.5300 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.48923 to -24.52996, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.3366 - acc: 0.1720 - val_loss: -24.5637 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.52996 to -24.56371, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.3692 - acc: 0.1720 - val_loss: -24.5939 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.56371 to -24.59395, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.3902 - acc: 0.1720 - val_loss: -24.6107 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.59395 to -24.61073, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4104 - acc: 0.1720 - val_loss: -24.6257 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.61073 to -24.62568, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4240 - acc: 0.1720 - val_loss: -24.6415 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.62568 to -24.64154, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4272 - acc: 0.1720 - val_loss: -24.6410 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.64154\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4356 - acc: 0.1720 - val_loss: -24.6493 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.64154 to -24.64932, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4432 - acc: 0.1720 - val_loss: -24.6544 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.64932 to -24.65443, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4472 - acc: 0.1720 - val_loss: -24.6577 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.65443 to -24.65770, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4308 - acc: 0.1720 - val_loss: -24.6545 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.65770\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4454 - acc: 0.1720 - val_loss: -24.6549 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.65770\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4457 - acc: 0.1720 - val_loss: -24.6552 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65770\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4461 - acc: 0.1720 - val_loss: -24.6556 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.65770\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4464 - acc: 0.1720 - val_loss: -24.6557 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.65770\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4464 - acc: 0.1720 - val_loss: -24.6557 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.65770\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4465 - acc: 0.1720 - val_loss: -24.6558 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.65770\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4466 - acc: 0.1720 - val_loss: -24.6559 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.65770\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4466 - acc: 0.1720 - val_loss: -24.6559 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.65770\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4467 - acc: 0.1720 - val_loss: -24.6560 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.65770\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4467 - acc: 0.1720 - val_loss: -24.6560 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.65770\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4467 - acc: 0.1720 - val_loss: -24.6560 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.65770\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -14.9172 - acc: 0.1684 - val_loss: -22.9609 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.96095, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -21.7790 - acc: 0.1720 - val_loss: -23.0223 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.96095 to -23.02228, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -21.8410 - acc: 0.1720 - val_loss: -23.0854 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.02228 to -23.08542, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -21.9056 - acc: 0.1720 - val_loss: -23.1520 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.08542 to -23.15203, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -21.9744 - acc: 0.1720 - val_loss: -23.2239 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.15203 to -23.22391, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.0493 - acc: 0.1720 - val_loss: -23.3027 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.22391 to -23.30273, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.1317 - acc: 0.1720 - val_loss: -23.3898 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.30273 to -23.38977, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.2218 - acc: 0.1720 - val_loss: -23.4841 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.38977 to -23.48405, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.3206 - acc: 0.1720 - val_loss: -23.5879 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.48405 to -23.58794, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.4269 - acc: 0.1720 - val_loss: -23.6970 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.58794 to -23.69695, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.5387 - acc: 0.1720 - val_loss: -23.8120 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.69695 to -23.81202, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.6538 - acc: 0.1720 - val_loss: -23.9264 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.81202 to -23.92644, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.7685 - acc: 0.1720 - val_loss: -24.0406 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -23.92644 to -24.04063, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.8778 - acc: 0.1720 - val_loss: -24.1455 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.04063 to -24.14553, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.9804 - acc: 0.1720 - val_loss: -24.2424 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.14553 to -24.24240, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.0726 - acc: 0.1720 - val_loss: -24.3293 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.24240 to -24.32934, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.1549 - acc: 0.1720 - val_loss: -24.4019 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.32934 to -24.40187, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.2235 - acc: 0.1720 - val_loss: -24.4652 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.40187 to -24.46523, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.2816 - acc: 0.1720 - val_loss: -24.5174 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.46523 to -24.51737, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3285 - acc: 0.1720 - val_loss: -24.5550 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.51737 to -24.55496, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3621 - acc: 0.1720 - val_loss: -24.5899 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.55496 to -24.58993, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.3882 - acc: 0.1720 - val_loss: -24.6108 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.58993 to -24.61075, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4100 - acc: 0.1720 - val_loss: -24.6229 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.61075 to -24.62294, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4215 - acc: 0.1720 - val_loss: -24.6394 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.62294 to -24.63943, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4333 - acc: 0.1720 - val_loss: -24.6472 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.63943 to -24.64719, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4407 - acc: 0.1720 - val_loss: -24.6461 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -24.64719\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4388 - acc: 0.1720 - val_loss: -24.6505 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.64719 to -24.65045, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4429 - acc: 0.1720 - val_loss: -24.6543 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.65045 to -24.65432, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4466 - acc: 0.1720 - val_loss: -24.6579 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.65432 to -24.65788, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4501 - acc: 0.1720 - val_loss: -24.6612 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.65788 to -24.66119, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4529 - acc: 0.1720 - val_loss: -24.6632 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.66119 to -24.66323, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4329 - acc: 0.1720 - val_loss: -24.6585 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.66323\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4493 - acc: 0.1720 - val_loss: -24.6588 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.66323\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4496 - acc: 0.1720 - val_loss: -24.6591 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.66323\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4500 - acc: 0.1720 - val_loss: -24.6595 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.66323\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4502 - acc: 0.1720 - val_loss: -24.6595 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.66323\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.4502 - acc: 0.1720 - val_loss: -24.6596 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.66323\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4503 - acc: 0.1720 - val_loss: -24.6596 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.66323\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4504 - acc: 0.1720 - val_loss: -24.6597 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.66323\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4504 - acc: 0.1720 - val_loss: -24.6598 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66323\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -9.1410 - acc: 0.1711 - val_loss: -22.9990 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.99902, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -21.8983 - acc: 0.1720 - val_loss: -23.2326 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.99902 to -23.23260, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.1158 - acc: 0.1720 - val_loss: -23.4312 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.23260 to -23.43117, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.2971 - acc: 0.1720 - val_loss: -23.5951 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.43117 to -23.59511, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.4499 - acc: 0.1720 - val_loss: -23.7362 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.59511 to -23.73618, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.5830 - acc: 0.1720 - val_loss: -23.8611 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.73618 to -23.86115, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.7010 - acc: 0.1720 - val_loss: -23.9730 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.86115 to -23.97296, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.8077 - acc: 0.1720 - val_loss: -24.0725 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.97296 to -24.07246, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.9049 - acc: 0.1720 - val_loss: -24.1655 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.07246 to -24.16548, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.9899 - acc: 0.1720 - val_loss: -24.2487 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.16548 to -24.24871, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0720 - acc: 0.1720 - val_loss: -24.3213 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.24871 to -24.32127, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.1423 - acc: 0.1720 - val_loss: -24.3874 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.32127 to -24.38740, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.2057 - acc: 0.1720 - val_loss: -24.4430 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.38740 to -24.44300, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.2578 - acc: 0.1720 - val_loss: -24.4905 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.44300 to -24.49053, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.3024 - acc: 0.1720 - val_loss: -24.5377 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.49053 to -24.53771, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.3325 - acc: 0.1720 - val_loss: -24.5625 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.53771 to -24.56247, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.3649 - acc: 0.1720 - val_loss: -24.5814 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.56247 to -24.58135, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.3852 - acc: 0.1720 - val_loss: -24.6055 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.58135 to -24.60551, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4032 - acc: 0.1720 - val_loss: -24.6222 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.60551 to -24.62222, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4185 - acc: 0.1720 - val_loss: -24.6356 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.62222 to -24.63558, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4277 - acc: 0.1720 - val_loss: -24.6428 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.63558 to -24.64279, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4315 - acc: 0.1720 - val_loss: -24.6434 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.64279 to -24.64338, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4391 - acc: 0.1720 - val_loss: -24.6539 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.64338 to -24.65385, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4419 - acc: 0.1720 - val_loss: -24.6559 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.65385 to -24.65586, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4460 - acc: 0.1720 - val_loss: -24.6577 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.65586 to -24.65775, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4487 - acc: 0.1720 - val_loss: -24.6598 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.65775 to -24.65979, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4496 - acc: 0.1720 - val_loss: -24.6550 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -24.65979\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4480 - acc: 0.1720 - val_loss: -24.6599 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.65979 to -24.65993, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4525 - acc: 0.1720 - val_loss: -24.6640 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.65993 to -24.66395, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4548 - acc: 0.1720 - val_loss: -24.6645 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.66395 to -24.66449, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4564 - acc: 0.1720 - val_loss: -24.6669 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.66449 to -24.66694, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4561 - acc: 0.1720 - val_loss: -24.6674 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.66694 to -24.66743, saving model to model-1.h5\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4543 - acc: 0.1720 - val_loss: -24.6648 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.66743\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4573 - acc: 0.1720 - val_loss: -24.6684 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.66743 to -24.66843, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -23.4575 - acc: 0.1720 - val_loss: -24.6682 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.66843\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4584 - acc: 0.1720 - val_loss: -24.6689 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.66843 to -24.66895, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.3788 - acc: 0.1720 - val_loss: -24.6645 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.66895\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4553 - acc: 0.1720 - val_loss: -24.6646 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.66895\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4554 - acc: 0.1720 - val_loss: -24.6648 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.66895\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4556 - acc: 0.1720 - val_loss: -24.6650 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66895\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -12.5182 - acc: 0.1716 - val_loss: -22.9845 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.98449, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -21.8291 - acc: 0.1720 - val_loss: -23.1029 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.98449 to -23.10293, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -21.9433 - acc: 0.1720 - val_loss: -23.2126 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.10293 to -23.21259, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.0504 - acc: 0.1720 - val_loss: -23.3170 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.21259 to -23.31700, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.1535 - acc: 0.1720 - val_loss: -23.4190 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.31700 to -23.41903, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.2553 - acc: 0.1720 - val_loss: -23.5210 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.41903 to -23.52098, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.3579 - acc: 0.1720 - val_loss: -23.6245 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.52098 to -23.62448, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -22.4624 - acc: 0.1720 - val_loss: -23.7303 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.62448 to -23.73029, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.5676 - acc: 0.1720 - val_loss: -23.8344 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.73029 to -23.83444, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.6728 - acc: 0.1720 - val_loss: -23.9413 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.83444 to -23.94134, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.7775 - acc: 0.1720 - val_loss: -24.0443 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.94134 to -24.04435, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.8807 - acc: 0.1720 - val_loss: -24.1463 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.04435 to -24.14631, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.9768 - acc: 0.1720 - val_loss: -24.2338 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.14631 to -24.23384, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.0657 - acc: 0.1720 - val_loss: -24.3188 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.23384 to -24.31883, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.1445 - acc: 0.1720 - val_loss: -24.3945 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.31883 to -24.39448, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.2116 - acc: 0.1720 - val_loss: -24.4538 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.39448 to -24.45378, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.2691 - acc: 0.1720 - val_loss: -24.5077 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.45378 to -24.50772, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3154 - acc: 0.1720 - val_loss: -24.5405 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.50772 to -24.54047, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3495 - acc: 0.1720 - val_loss: -24.5785 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.54047 to -24.57849, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.3807 - acc: 0.1720 - val_loss: -24.5904 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.57849 to -24.59039, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3921 - acc: 0.1720 - val_loss: -24.6137 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.59039 to -24.61372, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4119 - acc: 0.1720 - val_loss: -24.6201 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.61372 to -24.62009, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4181 - acc: 0.1720 - val_loss: -24.6356 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.62009 to -24.63563, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4300 - acc: 0.1720 - val_loss: -24.6426 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.63563 to -24.64257, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4354 - acc: 0.1720 - val_loss: -24.6485 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.64257 to -24.64852, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4395 - acc: 0.1720 - val_loss: -24.6440 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -24.64852\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4353 - acc: 0.1720 - val_loss: -24.6453 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -24.64852\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4366 - acc: 0.1720 - val_loss: -24.6467 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -24.64852\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4380 - acc: 0.1720 - val_loss: -24.6482 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.64852\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4389 - acc: 0.1720 - val_loss: -24.6483 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.64852\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4391 - acc: 0.1720 - val_loss: -24.6486 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.64852 to -24.64857, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4394 - acc: 0.1720 - val_loss: -24.6488 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.64857 to -24.64884, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4397 - acc: 0.1720 - val_loss: -24.6492 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.64884 to -24.64919, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4401 - acc: 0.1720 - val_loss: -24.6496 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.64919 to -24.64964, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4406 - acc: 0.1720 - val_loss: -24.6502 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.64964 to -24.65020, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4412 - acc: 0.1720 - val_loss: -24.6509 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.65020 to -24.65090, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4420 - acc: 0.1720 - val_loss: -24.6517 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.65090 to -24.65175, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4429 - acc: 0.1720 - val_loss: -24.6528 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.65175 to -24.65275, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.4440 - acc: 0.1720 - val_loss: -24.6539 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.65275 to -24.65390, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4452 - acc: 0.1720 - val_loss: -24.6552 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.65390 to -24.65517, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -12.4533 - acc: 0.1757 - val_loss: -22.9988 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.99878, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -21.8486 - acc: 0.1720 - val_loss: -23.1284 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.99878 to -23.12837, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -21.9727 - acc: 0.1720 - val_loss: -23.2464 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.12837 to -23.24643, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.0870 - acc: 0.1720 - val_loss: -23.3566 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.24643 to -23.35660, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.1947 - acc: 0.1720 - val_loss: -23.4618 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.35660 to -23.46181, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.2986 - acc: 0.1720 - val_loss: -23.5643 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.46181 to -23.56432, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.4005 - acc: 0.1720 - val_loss: -23.6658 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.56432 to -23.66578, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.5015 - acc: 0.1720 - val_loss: -23.7664 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.66578 to -23.76636, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -22.6010 - acc: 0.1720 - val_loss: -23.8648 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.76636 to -23.86485, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.7009 - acc: 0.1720 - val_loss: -23.9653 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.86485 to -23.96533, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.7987 - acc: 0.1720 - val_loss: -24.0613 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.96533 to -24.06127, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.8943 - acc: 0.1720 - val_loss: -24.1531 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.06127 to -24.15307, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.9837 - acc: 0.1720 - val_loss: -24.2390 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.15307 to -24.23902, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.0673 - acc: 0.1720 - val_loss: -24.3191 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.23902 to -24.31911, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -23.1438 - acc: 0.1720 - val_loss: -24.3897 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.31911 to -24.38975, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.2092 - acc: 0.1720 - val_loss: -24.4487 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.38975 to -24.44874, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.2655 - acc: 0.1720 - val_loss: -24.5001 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.44874 to -24.50015, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.3116 - acc: 0.1720 - val_loss: -24.5394 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.50015 to -24.53941, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.3475 - acc: 0.1720 - val_loss: -24.5651 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.53941 to -24.56510, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.3694 - acc: 0.1720 - val_loss: -24.5942 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.56510 to -24.59417, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.3918 - acc: 0.1720 - val_loss: -24.5981 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.59417 to -24.59807, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.3909 - acc: 0.1720 - val_loss: -24.6027 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.59807 to -24.60270, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.3955 - acc: 0.1720 - val_loss: -24.6073 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.60270 to -24.60729, saving model to model-3.h5\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4001 - acc: 0.1720 - val_loss: -24.6120 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.60729 to -24.61202, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4050 - acc: 0.1720 - val_loss: -24.6171 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.61202 to -24.61707, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4102 - acc: 0.1720 - val_loss: -24.6226 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.61707 to -24.62258, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4159 - acc: 0.1720 - val_loss: -24.6286 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.62258 to -24.62861, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4222 - acc: 0.1720 - val_loss: -24.6352 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.62861 to -24.63515, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4263 - acc: 0.1720 - val_loss: -24.6382 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.63515 to -24.63823, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4320 - acc: 0.1720 - val_loss: -24.6419 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.63823 to -24.64192, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4363 - acc: 0.1720 - val_loss: -24.6499 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.64192 to -24.64988, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.3127 - acc: 0.1720 - val_loss: -24.6451 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.64988\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4360 - acc: 0.1720 - val_loss: -24.6455 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.64988\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4363 - acc: 0.1720 - val_loss: -24.6458 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.64988\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4367 - acc: 0.1720 - val_loss: -24.6463 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.64988\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4370 - acc: 0.1720 - val_loss: -24.6463 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.64988\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4371 - acc: 0.1720 - val_loss: -24.6464 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.64988\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4372 - acc: 0.1720 - val_loss: -24.6465 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.64988\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4373 - acc: 0.1720 - val_loss: -24.6466 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.64988\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4373 - acc: 0.1720 - val_loss: -24.6466 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.64988\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -13.9276 - acc: 0.1776 - val_loss: -23.0312 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.03121, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -21.8660 - acc: 0.1720 - val_loss: -23.1269 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.03121 to -23.12689, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -21.9561 - acc: 0.1720 - val_loss: -23.2113 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.12689 to -23.21132, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.0374 - acc: 0.1720 - val_loss: -23.2896 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.21132 to -23.28964, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.1144 - acc: 0.1720 - val_loss: -23.3657 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.28964 to -23.36566, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.1905 - acc: 0.1720 - val_loss: -23.4423 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.36566 to -23.44234, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.2684 - acc: 0.1720 - val_loss: -23.5220 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.44234 to -23.52196, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.3499 - acc: 0.1720 - val_loss: -23.6062 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.52196 to -23.60616, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -22.4365 - acc: 0.1720 - val_loss: -23.6958 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.60616 to -23.69582, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.5287 - acc: 0.1720 - val_loss: -23.7909 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.69582 to -23.79088, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.6258 - acc: 0.1720 - val_loss: -23.8881 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.79088 to -23.88810, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.7244 - acc: 0.1720 - val_loss: -23.9900 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.88810 to -23.99000, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.8258 - acc: 0.1720 - val_loss: -24.0895 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -23.99000 to -24.08952, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.9237 - acc: 0.1720 - val_loss: -24.1858 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.08952 to -24.18580, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.0162 - acc: 0.1720 - val_loss: -24.2745 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.18580 to -24.27455, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.1018 - acc: 0.1720 - val_loss: -24.3533 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.27455 to -24.35325, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.1770 - acc: 0.1720 - val_loss: -24.4247 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.35325 to -24.42469, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.2424 - acc: 0.1720 - val_loss: -24.4824 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.42469 to -24.48244, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.2906 - acc: 0.1720 - val_loss: -24.5102 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.48244 to -24.51024, saving model to model-4.h5\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.3131 - acc: 0.1720 - val_loss: -24.5368 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.51024 to -24.53684, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.3385 - acc: 0.1720 - val_loss: -24.5609 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.53684 to -24.56089, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3606 - acc: 0.1720 - val_loss: -24.5794 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.56089 to -24.57935, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.3794 - acc: 0.1720 - val_loss: -24.5999 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.57935 to -24.59987, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3853 - acc: 0.1720 - val_loss: -24.5940 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -24.59987\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.3861 - acc: 0.1720 - val_loss: -24.5972 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.59987\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.3895 - acc: 0.1720 - val_loss: -24.6007 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.59987 to -24.60075, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.3932 - acc: 0.1720 - val_loss: -24.6047 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.60075 to -24.60473, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.3974 - acc: 0.1720 - val_loss: -24.6093 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.60473 to -24.60933, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4024 - acc: 0.1720 - val_loss: -24.6147 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.60933 to -24.61466, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4080 - acc: 0.1720 - val_loss: -24.6208 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.61466 to -24.62080, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4145 - acc: 0.1720 - val_loss: -24.6277 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.62080 to -24.62772, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4203 - acc: 0.1720 - val_loss: -24.6328 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.62772 to -24.63279, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4267 - acc: 0.1720 - val_loss: -24.6346 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.63279 to -24.63462, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4292 - acc: 0.1720 - val_loss: -24.6431 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.63462 to -24.64306, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4373 - acc: 0.1720 - val_loss: -24.6465 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.64306 to -24.64653, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4408 - acc: 0.1720 - val_loss: -24.6543 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.64653 to -24.65430, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4358 - acc: 0.1720 - val_loss: -24.6488 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.65430\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4397 - acc: 0.1720 - val_loss: -24.6492 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.65430\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4401 - acc: 0.1720 - val_loss: -24.6497 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.65430\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4406 - acc: 0.1720 - val_loss: -24.6502 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.65430\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -13.6268 - acc: 0.1744 - val_loss: -22.9796 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.97960, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -21.8099 - acc: 0.1720 - val_loss: -23.0675 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.97960 to -23.06754, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -21.8966 - acc: 0.1720 - val_loss: -23.1528 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.06754 to -23.15278, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -21.9821 - acc: 0.1720 - val_loss: -23.2393 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.15278 to -23.23926, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.0694 - acc: 0.1720 - val_loss: -23.3277 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.23926 to -23.32772, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.1588 - acc: 0.1720 - val_loss: -23.4177 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.32772 to -23.41765, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.2510 - acc: 0.1720 - val_loss: -23.5134 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.41765 to -23.51335, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.3483 - acc: 0.1720 - val_loss: -23.6128 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.51335 to -23.61284, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.4472 - acc: 0.1720 - val_loss: -23.7149 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.61284 to -23.71492, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.5525 - acc: 0.1720 - val_loss: -23.8205 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.71492 to -23.82047, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.6573 - acc: 0.1720 - val_loss: -23.9250 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.82047 to -23.92502, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.7634 - acc: 0.1720 - val_loss: -24.0309 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.92502 to -24.03092, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.8662 - acc: 0.1720 - val_loss: -24.1299 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.03092 to -24.12987, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.9630 - acc: 0.1720 - val_loss: -24.2222 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.12987 to -24.22222, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.0532 - acc: 0.1720 - val_loss: -24.3105 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.22222 to -24.31054, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.1339 - acc: 0.1720 - val_loss: -24.3842 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.31054 to -24.38421, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2031 - acc: 0.1720 - val_loss: -24.4395 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.38421 to -24.43947, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.2565 - acc: 0.1720 - val_loss: -24.4962 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.43947 to -24.49622, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.3065 - acc: 0.1720 - val_loss: -24.5374 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.49622 to -24.53740, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.3452 - acc: 0.1720 - val_loss: -24.5640 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.53740 to -24.56397, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.3690 - acc: 0.1720 - val_loss: -24.5944 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.56397 to -24.59444, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.3954 - acc: 0.1720 - val_loss: -24.6168 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.59444 to -24.61684, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4138 - acc: 0.1720 - val_loss: -24.6309 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.61684 to -24.63091, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4267 - acc: 0.1720 - val_loss: -24.6338 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.63091 to -24.63376, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4305 - acc: 0.1720 - val_loss: -24.6466 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.63376 to -24.64657, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4380 - acc: 0.1720 - val_loss: -24.6448 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -24.64657\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4360 - acc: 0.1720 - val_loss: -24.6459 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -24.64657\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4370 - acc: 0.1720 - val_loss: -24.6470 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.64657 to -24.64696, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4382 - acc: 0.1720 - val_loss: -24.6482 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.64696 to -24.64815, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.4394 - acc: 0.1720 - val_loss: -24.6495 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.64815 to -24.64949, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4409 - acc: 0.1720 - val_loss: -24.6510 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.64949 to -24.65103, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4425 - acc: 0.1720 - val_loss: -24.6528 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.65103 to -24.65281, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4444 - acc: 0.1720 - val_loss: -24.6549 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.65281 to -24.65487, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4466 - acc: 0.1720 - val_loss: -24.6572 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.65487 to -24.65722, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4491 - acc: 0.1720 - val_loss: -24.6598 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.65722 to -24.65983, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4493 - acc: 0.1720 - val_loss: -24.6560 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.65983\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4468 - acc: 0.1720 - val_loss: -24.6564 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.65983\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4473 - acc: 0.1720 - val_loss: -24.6568 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.65983\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4478 - acc: 0.1720 - val_loss: -24.6574 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.65983\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4481 - acc: 0.1720 - val_loss: -24.6575 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.65983\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -7.0935 - acc: 0.1744 - val_loss: -22.9812 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.98120, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -21.8716 - acc: 0.1720 - val_loss: -23.1980 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.98120 to -23.19799, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.0728 - acc: 0.1720 - val_loss: -23.3830 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.19799 to -23.38302, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.2485 - acc: 0.1720 - val_loss: -23.5462 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.38302 to -23.54615, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.4031 - acc: 0.1720 - val_loss: -23.6908 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.54615 to -23.69075, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.5421 - acc: 0.1720 - val_loss: -23.8183 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.69075 to -23.81829, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.6655 - acc: 0.1720 - val_loss: -23.9430 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.81829 to -23.94300, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.7777 - acc: 0.1720 - val_loss: -24.0466 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.94300 to -24.04663, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.8844 - acc: 0.1720 - val_loss: -24.1480 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.04663 to -24.14803, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.9796 - acc: 0.1720 - val_loss: -24.2388 - val_acc: 0.1328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss improved from -24.14803 to -24.23878, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.0647 - acc: 0.1720 - val_loss: -24.3191 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.23878 to -24.31913, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.1400 - acc: 0.1720 - val_loss: -24.3900 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.31913 to -24.39004, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.2064 - acc: 0.1720 - val_loss: -24.4483 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.39004 to -24.44828, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.2601 - acc: 0.1720 - val_loss: -24.4982 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.44828 to -24.49824, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.3037 - acc: 0.1720 - val_loss: -24.5331 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.49824 to -24.53307, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.3399 - acc: 0.1720 - val_loss: -24.5575 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.53307 to -24.55749, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.3641 - acc: 0.1720 - val_loss: -24.5913 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.55749 to -24.59126, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.3855 - acc: 0.1720 - val_loss: -24.6041 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.59126 to -24.60415, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4034 - acc: 0.1720 - val_loss: -24.6171 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.60415 to -24.61708, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4162 - acc: 0.1720 - val_loss: -24.6342 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.61708 to -24.63416, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4267 - acc: 0.1720 - val_loss: -24.6429 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.63416 to -24.64289, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.4343 - acc: 0.1720 - val_loss: -24.6477 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.64289 to -24.64771, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4407 - acc: 0.1720 - val_loss: -24.6514 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.64771 to -24.65144, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4444 - acc: 0.1720 - val_loss: -24.6521 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.65144 to -24.65205, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4460 - acc: 0.1720 - val_loss: -24.6518 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.65205\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 999us/step - loss: -23.4466 - acc: 0.1720 - val_loss: -24.6604 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.65205 to -24.66039, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4523 - acc: 0.1720 - val_loss: -24.6620 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.66039 to -24.66199, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4530 - acc: 0.1720 - val_loss: -24.6638 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.66199 to -24.66385, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4524 - acc: 0.1720 - val_loss: -24.6611 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.66385\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4541 - acc: 0.1720 - val_loss: -24.6660 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.66385 to -24.66599, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4557 - acc: 0.1720 - val_loss: -24.6652 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.66599\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4565 - acc: 0.1720 - val_loss: -24.6624 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.66599\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4553 - acc: 0.1720 - val_loss: -24.6669 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.66599 to -24.66692, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4580 - acc: 0.1720 - val_loss: -24.6663 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.66692\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4583 - acc: 0.1720 - val_loss: -24.6647 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.66692\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4574 - acc: 0.1720 - val_loss: -24.6688 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.66692 to -24.66876, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4575 - acc: 0.1720 - val_loss: -24.6645 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.66876\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4565 - acc: 0.1720 - val_loss: -24.6673 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.66876\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4590 - acc: 0.1720 - val_loss: -24.6695 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.66876 to -24.66947, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.4608 - acc: 0.1720 - val_loss: -24.6701 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.66947 to -24.67008, saving model to model-1.h5\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -11.6746 - acc: 0.1730 - val_loss: -23.0152 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.01518, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -21.8710 - acc: 0.1720 - val_loss: -23.1574 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.01518 to -23.15735, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.0062 - acc: 0.1720 - val_loss: -23.2846 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.15735 to -23.28456, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.1280 - acc: 0.1720 - val_loss: -23.4003 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.28456 to -23.40033, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.2403 - acc: 0.1720 - val_loss: -23.5091 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.40033 to -23.50906, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.3462 - acc: 0.1720 - val_loss: -23.6119 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.50906 to -23.61193, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.4490 - acc: 0.1720 - val_loss: -23.7152 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.61193 to -23.71518, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.5496 - acc: 0.1720 - val_loss: -23.8141 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.71518 to -23.81406, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.6499 - acc: 0.1720 - val_loss: -23.9136 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.81406 to -23.91363, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.7490 - acc: 0.1720 - val_loss: -24.0120 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.91363 to -24.01198, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.8452 - acc: 0.1720 - val_loss: -24.1078 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.01198 to -24.10782, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.9375 - acc: 0.1720 - val_loss: -24.1946 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.10782 to -24.19461, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.0241 - acc: 0.1720 - val_loss: -24.2754 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.19461 to -24.27537, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.1028 - acc: 0.1720 - val_loss: -24.3520 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.27537 to -24.35199, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.1743 - acc: 0.1720 - val_loss: -24.4191 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.35199 to -24.41913, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.2342 - acc: 0.1720 - val_loss: -24.4758 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.41913 to -24.47580, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2870 - acc: 0.1720 - val_loss: -24.5220 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.47580 to -24.52205, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3243 - acc: 0.1720 - val_loss: -24.5519 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.52205 to -24.55192, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.3577 - acc: 0.1720 - val_loss: -24.5807 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.55192 to -24.58065, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.3797 - acc: 0.1720 - val_loss: -24.5883 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.58065 to -24.58834, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.3841 - acc: 0.1720 - val_loss: -24.5994 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.58834 to -24.59940, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.3948 - acc: 0.1720 - val_loss: -24.6097 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.59940 to -24.60970, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4048 - acc: 0.1720 - val_loss: -24.6195 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.60970 to -24.61949, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4144 - acc: 0.1720 - val_loss: -24.6289 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.61949 to -24.62889, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4211 - acc: 0.1720 - val_loss: -24.6321 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.62889 to -24.63206, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4272 - acc: 0.1720 - val_loss: -24.6368 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.63206 to -24.63678, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4321 - acc: 0.1720 - val_loss: -24.6467 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.63678 to -24.64675, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4334 - acc: 0.1720 - val_loss: -24.6436 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -24.64675\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4371 - acc: 0.1720 - val_loss: -24.6497 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.64675 to -24.64973, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4429 - acc: 0.1720 - val_loss: -24.6552 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.64973 to -24.65522, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4465 - acc: 0.1720 - val_loss: -24.6550 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65522\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4480 - acc: 0.1720 - val_loss: -24.6596 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.65522 to -24.65957, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4492 - acc: 0.1720 - val_loss: -24.6606 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.65957 to -24.66060, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4499 - acc: 0.1720 - val_loss: -24.6574 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.66060\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4502 - acc: 0.1720 - val_loss: -24.6619 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.66060 to -24.66195, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4544 - acc: 0.1720 - val_loss: -24.6656 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.66195 to -24.66563, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -23.4354 - acc: 0.1720 - val_loss: -24.6587 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.66563\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4495 - acc: 0.1720 - val_loss: -24.6590 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.66563\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4498 - acc: 0.1720 - val_loss: -24.6592 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.66563\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4501 - acc: 0.1720 - val_loss: -24.6595 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66563\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -12.9057 - acc: 0.1725 - val_loss: -22.9787 - val_acc: 0.1328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.97867, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -21.8110 - acc: 0.1720 - val_loss: -23.0722 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.97867 to -23.07221, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -21.9040 - acc: 0.1720 - val_loss: -23.1646 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.07221 to -23.16462, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -21.9971 - acc: 0.1720 - val_loss: -23.2574 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.16462 to -23.25740, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.0896 - acc: 0.1720 - val_loss: -23.3503 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.25740 to -23.35033, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.1845 - acc: 0.1720 - val_loss: -23.4473 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.35033 to -23.44731, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.2833 - acc: 0.1720 - val_loss: -23.5490 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.44731 to -23.54897, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.3868 - acc: 0.1720 - val_loss: -23.6543 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.54897 to -23.65435, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.4943 - acc: 0.1720 - val_loss: -23.7632 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.65435 to -23.76315, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.6039 - acc: 0.1720 - val_loss: -23.8736 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.76315 to -23.87356, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -22.7130 - acc: 0.1720 - val_loss: -23.9826 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.87356 to -23.98257, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.8225 - acc: 0.1720 - val_loss: -24.0908 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.98257 to -24.09078, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.9278 - acc: 0.1720 - val_loss: -24.1927 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.09078 to -24.19267, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.0240 - acc: 0.1720 - val_loss: -24.2824 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.19267 to -24.28235, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.1106 - acc: 0.1720 - val_loss: -24.3627 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.28235 to -24.36274, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.1851 - acc: 0.1720 - val_loss: -24.4304 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.36274 to -24.43045, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2490 - acc: 0.1720 - val_loss: -24.4905 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.43045 to -24.49052, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.2923 - acc: 0.1720 - val_loss: -24.5251 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.49052 to -24.52514, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.3332 - acc: 0.1720 - val_loss: -24.5591 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.52514 to -24.55915, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.3643 - acc: 0.1720 - val_loss: -24.5809 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.55915 to -24.58092, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3843 - acc: 0.1720 - val_loss: -24.6078 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.58092 to -24.60781, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3987 - acc: 0.1720 - val_loss: -24.6081 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.60781 to -24.60808, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4000 - acc: 0.1720 - val_loss: -24.6109 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.60808 to -24.61091, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4029 - acc: 0.1720 - val_loss: -24.6139 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.61091 to -24.61387, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4060 - acc: 0.1720 - val_loss: -24.6171 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.61387 to -24.61708, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4093 - acc: 0.1720 - val_loss: -24.6207 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.61708 to -24.62066, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4131 - acc: 0.1720 - val_loss: -24.6247 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.62066 to -24.62472, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4175 - acc: 0.1720 - val_loss: -24.6294 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.62472 to -24.62937, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4224 - acc: 0.1720 - val_loss: -24.6346 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.62937 to -24.63462, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4279 - acc: 0.1720 - val_loss: -24.6404 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.63462 to -24.64041, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4318 - acc: 0.1720 - val_loss: -24.6439 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.64041 to -24.64393, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4346 - acc: 0.1720 - val_loss: -24.6411 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.64393\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4332 - acc: 0.1720 - val_loss: -24.6443 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.64393 to -24.64431, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4365 - acc: 0.1720 - val_loss: -24.6476 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.64431 to -24.64763, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4399 - acc: 0.1720 - val_loss: -24.6512 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.64763 to -24.65117, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4435 - acc: 0.1720 - val_loss: -24.6549 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.65117 to -24.65488, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4450 - acc: 0.1720 - val_loss: -24.6511 - val_acc: 0.1328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_loss did not improve from -24.65488\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4433 - acc: 0.1720 - val_loss: -24.6545 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.65488\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4467 - acc: 0.1720 - val_loss: -24.6578 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.65488 to -24.65779, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4500 - acc: 0.1720 - val_loss: -24.6611 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.65779 to -24.66107, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 8s 4ms/step - loss: -13.9188 - acc: 0.1716 - val_loss: -22.9789 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.97893, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -21.8086 - acc: 0.1720 - val_loss: -23.0651 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.97893 to -23.06514, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -21.8934 - acc: 0.1720 - val_loss: -23.1486 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.06514 to -23.14858, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -21.9763 - acc: 0.1720 - val_loss: -23.2312 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.14858 to -23.23117, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.0592 - acc: 0.1720 - val_loss: -23.3148 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.23117 to -23.31483, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.1440 - acc: 0.1720 - val_loss: -23.4013 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.31483 to -23.40133, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.2323 - acc: 0.1720 - val_loss: -23.4921 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.40133 to -23.49212, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.3254 - acc: 0.1720 - val_loss: -23.5882 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.49212 to -23.58815, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.4238 - acc: 0.1720 - val_loss: -23.6896 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.58815 to -23.68957, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.5274 - acc: 0.1720 - val_loss: -23.7956 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.68957 to -23.79560, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.6341 - acc: 0.1720 - val_loss: -23.8999 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.79560 to -23.89993, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.7397 - acc: 0.1720 - val_loss: -24.0092 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.89993 to -24.00918, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.8439 - acc: 0.1720 - val_loss: -24.1106 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.00918 to -24.11063, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -22.9464 - acc: 0.1720 - val_loss: -24.2103 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.11063 to -24.21032, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -23.0407 - acc: 0.1720 - val_loss: -24.2976 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.21032 to -24.29764, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.1251 - acc: 0.1720 - val_loss: -24.3766 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.29764 to -24.37664, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.1965 - acc: 0.1720 - val_loss: -24.4417 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.37664 to -24.44170, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.2591 - acc: 0.1720 - val_loss: -24.4994 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.44170 to -24.49940, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.2954 - acc: 0.1720 - val_loss: -24.5208 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.49940 to -24.52084, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.3256 - acc: 0.1720 - val_loss: -24.5513 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.52084 to -24.55131, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.3539 - acc: 0.1720 - val_loss: -24.5768 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.55131 to -24.57681, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.3753 - acc: 0.1720 - val_loss: -24.5958 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.57681 to -24.59580, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.3954 - acc: 0.1720 - val_loss: -24.6049 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.59580 to -24.60492, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3935 - acc: 0.1720 - val_loss: -24.6069 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.60492 to -24.60695, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3987 - acc: 0.1720 - val_loss: -24.6093 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.60695 to -24.60934, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4012 - acc: 0.1720 - val_loss: -24.6120 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.60934 to -24.61199, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4040 - acc: 0.1720 - val_loss: -24.6150 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.61199 to -24.61499, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4072 - acc: 0.1720 - val_loss: -24.6185 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.61499 to -24.61848, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4110 - acc: 0.1720 - val_loss: -24.6226 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.61848 to -24.62257, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -23.4153 - acc: 0.1720 - val_loss: -24.6273 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.62257 to -24.62733, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4204 - acc: 0.1720 - val_loss: -24.6328 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.62733 to -24.63278, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4261 - acc: 0.1720 - val_loss: -24.6388 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.63278 to -24.63883, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4291 - acc: 0.1720 - val_loss: -24.6394 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.63883 to -24.63937, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.4330 - acc: 0.1720 - val_loss: -24.6459 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.63937 to -24.64590, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4390 - acc: 0.1720 - val_loss: -24.6466 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.64590 to -24.64657, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4405 - acc: 0.1720 - val_loss: -24.6535 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.64657 to -24.65355, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4465 - acc: 0.1720 - val_loss: -24.6585 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.65355 to -24.65845, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4465 - acc: 0.1720 - val_loss: -24.6588 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.65845 to -24.65883, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4512 - acc: 0.1720 - val_loss: -24.6599 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.65883 to -24.65991, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4531 - acc: 0.1720 - val_loss: -24.6630 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.65991 to -24.66300, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -14.9372 - acc: 0.1734 - val_loss: -23.0110 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.01102, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -21.8449 - acc: 0.1720 - val_loss: -23.1068 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.01102 to -23.10683, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -21.9397 - acc: 0.1720 - val_loss: -23.2009 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.10683 to -23.20087, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.0336 - acc: 0.1720 - val_loss: -23.2950 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.20087 to -23.29497, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -22.1284 - acc: 0.1720 - val_loss: -23.3909 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.29497 to -23.39086, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.2256 - acc: 0.1720 - val_loss: -23.4885 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.39086 to -23.48851, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.3250 - acc: 0.1720 - val_loss: -23.5912 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.48851 to -23.59117, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.4293 - acc: 0.1720 - val_loss: -23.6979 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.59117 to -23.69788, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.5360 - acc: 0.1720 - val_loss: -23.8047 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.69788 to -23.80469, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.6443 - acc: 0.1720 - val_loss: -23.9130 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.80469 to -23.91295, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.7528 - acc: 0.1720 - val_loss: -24.0215 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.91295 to -24.02150, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.8594 - acc: 0.1720 - val_loss: -24.1271 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.02150 to -24.12712, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.9613 - acc: 0.1720 - val_loss: -24.2093 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.12712 to -24.20933, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.0373 - acc: 0.1720 - val_loss: -24.2909 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.20933 to -24.29086, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.1145 - acc: 0.1720 - val_loss: -24.3630 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.29086 to -24.36300, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.1819 - acc: 0.1720 - val_loss: -24.4238 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.36300 to -24.42382, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.2383 - acc: 0.1720 - val_loss: -24.4765 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.42382 to -24.47651, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.2893 - acc: 0.1720 - val_loss: -24.5233 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.47651 to -24.52329, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3307 - acc: 0.1720 - val_loss: -24.5591 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.52329 to -24.55911, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.3620 - acc: 0.1720 - val_loss: -24.5822 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.55911 to -24.58225, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3852 - acc: 0.1720 - val_loss: -24.6085 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.58225 to -24.60845, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4061 - acc: 0.1720 - val_loss: -24.6244 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.60845 to -24.62442, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4193 - acc: 0.1720 - val_loss: -24.6359 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.62442 to -24.63591, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4323 - acc: 0.1720 - val_loss: -24.6480 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.63591 to -24.64801, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4391 - acc: 0.1720 - val_loss: -24.6542 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.64801 to -24.65421, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4431 - acc: 0.1720 - val_loss: -24.6563 - val_acc: 0.1328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_loss improved from -24.65421 to -24.65629, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3744 - acc: 0.1720 - val_loss: -24.6542 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -24.65629\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4450 - acc: 0.1720 - val_loss: -24.6544 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -24.65629\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.4452 - acc: 0.1720 - val_loss: -24.6547 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.65629\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4455 - acc: 0.1720 - val_loss: -24.6549 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.65629\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4456 - acc: 0.1720 - val_loss: -24.6549 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65629\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -23.4456 - acc: 0.1720 - val_loss: -24.6550 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.65629\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -23.4457 - acc: 0.1720 - val_loss: -24.6550 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.65629\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4457 - acc: 0.1720 - val_loss: -24.6551 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.65629\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4458 - acc: 0.1720 - val_loss: -24.6551 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.65629\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4458 - acc: 0.1720 - val_loss: -24.6551 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.65629\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4458 - acc: 0.1720 - val_loss: -24.6551 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.65629\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.4458 - acc: 0.1720 - val_loss: -24.6551 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.65629\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4458 - acc: 0.1720 - val_loss: -24.6551 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.65629\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.4458 - acc: 0.1720 - val_loss: -24.6552 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.65629\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -7.0494 - acc: 0.1702 - val_loss: -23.0641 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.06411, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -21.9775 - acc: 0.1720 - val_loss: -23.3275 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.06411 to -23.32750, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.2145 - acc: 0.1720 - val_loss: -23.5388 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.32750 to -23.53883, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.4104 - acc: 0.1720 - val_loss: -23.7157 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.53883 to -23.71574, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.5749 - acc: 0.1720 - val_loss: -23.8653 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.71574 to -23.86532, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.7151 - acc: 0.1720 - val_loss: -23.9955 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.86532 to -23.99547, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.8344 - acc: 0.1720 - val_loss: -24.1041 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.99547 to -24.10409, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.9416 - acc: 0.1720 - val_loss: -24.2022 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.10409 to -24.20218, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.0316 - acc: 0.1720 - val_loss: -24.2870 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.20218 to -24.28703, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.1139 - acc: 0.1720 - val_loss: -24.3637 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.28703 to -24.36373, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.1823 - acc: 0.1720 - val_loss: -24.4277 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.36373 to -24.42772, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.2390 - acc: 0.1720 - val_loss: -24.4643 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.42772 to -24.46434, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.2792 - acc: 0.1720 - val_loss: -24.5163 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.46434 to -24.51628, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.3218 - acc: 0.1720 - val_loss: -24.5487 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.51628 to -24.54872, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.3495 - acc: 0.1720 - val_loss: -24.5750 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.54872 to -24.57499, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3749 - acc: 0.1720 - val_loss: -24.5955 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.57499 to -24.59547, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3914 - acc: 0.1720 - val_loss: -24.6108 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.59547 to -24.61077, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4079 - acc: 0.1720 - val_loss: -24.6286 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.61077 to -24.62863, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4164 - acc: 0.1720 - val_loss: -24.6349 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.62863 to -24.63493, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4229 - acc: 0.1720 - val_loss: -24.6288 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -24.63493\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4233 - acc: 0.1720 - val_loss: -24.6370 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.63493 to -24.63705, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4311 - acc: 0.1720 - val_loss: -24.6443 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.63705 to -24.64432, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4375 - acc: 0.1720 - val_loss: -24.6486 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.64432 to -24.64859, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4393 - acc: 0.1720 - val_loss: -24.6499 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.64859 to -24.64987, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4424 - acc: 0.1720 - val_loss: -24.6540 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.64987 to -24.65400, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4455 - acc: 0.1720 - val_loss: -24.6561 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.65400 to -24.65615, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4467 - acc: 0.1720 - val_loss: -24.6577 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.65615 to -24.65767, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4489 - acc: 0.1720 - val_loss: -24.6597 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.65767 to -24.65972, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4507 - acc: 0.1720 - val_loss: -24.6596 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.65972\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.4464 - acc: 0.1720 - val_loss: -24.6552 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.65972\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4461 - acc: 0.1720 - val_loss: -24.6557 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65972\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4466 - acc: 0.1720 - val_loss: -24.6562 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.65972\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4470 - acc: 0.1720 - val_loss: -24.6563 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.65972\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4470 - acc: 0.1720 - val_loss: -24.6564 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.65972\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4471 - acc: 0.1720 - val_loss: -24.6565 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.65972\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -23.4472 - acc: 0.1720 - val_loss: -24.6566 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.65972\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.4473 - acc: 0.1720 - val_loss: -24.6566 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.65972\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.4473 - acc: 0.1720 - val_loss: -24.6566 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.65972\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4473 - acc: 0.1720 - val_loss: -24.6567 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.65972\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4474 - acc: 0.1720 - val_loss: -24.6567 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.65972\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -12.0225 - acc: 0.1748 - val_loss: -23.0223 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.02232, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -21.8852 - acc: 0.1720 - val_loss: -23.1817 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.02232 to -23.18169, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.0366 - acc: 0.1720 - val_loss: -23.3229 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.18169 to -23.32291, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.1704 - acc: 0.1720 - val_loss: -23.4518 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.32291 to -23.45184, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.2957 - acc: 0.1720 - val_loss: -23.5719 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.45184 to -23.57191, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -22.4111 - acc: 0.1720 - val_loss: -23.6853 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.57191 to -23.68526, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -22.5228 - acc: 0.1720 - val_loss: -23.7933 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.68526 to -23.79334, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.6306 - acc: 0.1720 - val_loss: -23.9001 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.79334 to -23.90011, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.7363 - acc: 0.1720 - val_loss: -24.0018 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.90011 to -24.00182, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.8325 - acc: 0.1720 - val_loss: -24.0976 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.00182 to -24.09759, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.9304 - acc: 0.1720 - val_loss: -24.1902 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.09759 to -24.19024, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.0182 - acc: 0.1720 - val_loss: -24.2764 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.19024 to -24.27639, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.0993 - acc: 0.1720 - val_loss: -24.3517 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.27639 to -24.35165, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.1726 - acc: 0.1720 - val_loss: -24.4180 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.35165 to -24.41800, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.2325 - acc: 0.1720 - val_loss: -24.4749 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.41800 to -24.47491, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.2795 - acc: 0.1720 - val_loss: -24.5044 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.47491 to -24.50438, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.3117 - acc: 0.1720 - val_loss: -24.5410 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.50438 to -24.54098, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3453 - acc: 0.1720 - val_loss: -24.5684 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.54098 to -24.56842, saving model to model-2.h5\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3685 - acc: 0.1720 - val_loss: -24.5919 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.56842 to -24.59187, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.3888 - acc: 0.1720 - val_loss: -24.6066 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.59187 to -24.60659, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4024 - acc: 0.1720 - val_loss: -24.6208 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.60659 to -24.62082, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4163 - acc: 0.1720 - val_loss: -24.6336 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.62082 to -24.63365, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 941us/step - loss: -23.4284 - acc: 0.1720 - val_loss: -24.6393 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.63365 to -24.63929, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4351 - acc: 0.1720 - val_loss: -24.6502 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.63929 to -24.65017, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4381 - acc: 0.1720 - val_loss: -24.6496 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.65017\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4439 - acc: 0.1720 - val_loss: -24.6546 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.65017 to -24.65457, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 945us/step - loss: -23.4440 - acc: 0.1720 - val_loss: -24.6501 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -24.65457\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4411 - acc: 0.1720 - val_loss: -24.6508 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -24.65457\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.4418 - acc: 0.1720 - val_loss: -24.6514 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.65457\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.4425 - acc: 0.1720 - val_loss: -24.6522 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.65457\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -23.4429 - acc: 0.1720 - val_loss: -24.6523 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65457\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4430 - acc: 0.1720 - val_loss: -24.6524 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.65457\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4431 - acc: 0.1720 - val_loss: -24.6525 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.65457\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4433 - acc: 0.1720 - val_loss: -24.6527 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.65457\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4434 - acc: 0.1720 - val_loss: -24.6527 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.65457\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4434 - acc: 0.1720 - val_loss: -24.6527 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.65457\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4435 - acc: 0.1720 - val_loss: -24.6528 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.65457\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.4435 - acc: 0.1720 - val_loss: -24.6528 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.65457\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4436 - acc: 0.1720 - val_loss: -24.6529 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.65457\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4436 - acc: 0.1720 - val_loss: -24.6530 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.65457\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -13.3260 - acc: 0.1711 - val_loss: -22.9704 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.97039, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -21.8109 - acc: 0.1720 - val_loss: -23.0731 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.97039 to -23.07305, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -21.9137 - acc: 0.1720 - val_loss: -23.1743 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.07305 to -23.17427, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.0102 - acc: 0.1720 - val_loss: -23.2719 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.17427 to -23.27185, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.1092 - acc: 0.1720 - val_loss: -23.3690 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.27185 to -23.36903, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.2068 - acc: 0.1720 - val_loss: -23.4696 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.36903 to -23.46961, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.3072 - acc: 0.1720 - val_loss: -23.5703 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.46961 to -23.57027, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.4084 - acc: 0.1720 - val_loss: -23.6765 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.57027 to -23.67645, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -22.5182 - acc: 0.1720 - val_loss: -23.7846 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.67645 to -23.78457, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.6263 - acc: 0.1720 - val_loss: -23.8955 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.78457 to -23.89547, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.7381 - acc: 0.1720 - val_loss: -24.0045 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.89547 to -24.00450, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.8422 - acc: 0.1720 - val_loss: -24.1104 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.00450 to -24.11042, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.9418 - acc: 0.1720 - val_loss: -24.2043 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.11042 to -24.20429, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.0369 - acc: 0.1720 - val_loss: -24.2938 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.20429 to -24.29376, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.1203 - acc: 0.1720 - val_loss: -24.3726 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.29376 to -24.37261, saving model to model-3.h5\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.1944 - acc: 0.1720 - val_loss: -24.4385 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.37261 to -24.43850, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.2542 - acc: 0.1720 - val_loss: -24.4931 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.43850 to -24.49314, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.3007 - acc: 0.1720 - val_loss: -24.5346 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.49314 to -24.53456, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.3431 - acc: 0.1720 - val_loss: -24.5649 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.53456 to -24.56486, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.3710 - acc: 0.1720 - val_loss: -24.5909 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.56486 to -24.59090, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.3941 - acc: 0.1720 - val_loss: -24.6161 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.59090 to -24.61605, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4138 - acc: 0.1720 - val_loss: -24.6320 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.61605 to -24.63202, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4129 - acc: 0.1720 - val_loss: -24.6254 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -24.63202\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.4186 - acc: 0.1720 - val_loss: -24.6308 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -24.63202\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -23.4237 - acc: 0.1720 - val_loss: -24.6357 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.63202 to -24.63571, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4287 - acc: 0.1720 - val_loss: -24.6411 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.63571 to -24.64107, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 940us/step - loss: -23.4340 - acc: 0.1720 - val_loss: -24.6464 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.64107 to -24.64635, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 944us/step - loss: -23.4374 - acc: 0.1720 - val_loss: -24.6498 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.64635 to -24.64979, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4420 - acc: 0.1720 - val_loss: -24.6545 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.64979 to -24.65452, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4443 - acc: 0.1720 - val_loss: -24.6487 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.65452\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4411 - acc: 0.1720 - val_loss: -24.6525 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65452\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.4449 - acc: 0.1720 - val_loss: -24.6561 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.65452 to -24.65613, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4484 - acc: 0.1720 - val_loss: -24.6594 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.65613 to -24.65944, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4485 - acc: 0.1720 - val_loss: -24.6583 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.65944\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4505 - acc: 0.1720 - val_loss: -24.6618 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.65944 to -24.66180, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.4513 - acc: 0.1720 - val_loss: -24.6628 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.66180 to -24.66278, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4512 - acc: 0.1720 - val_loss: -24.6611 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.66278\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 941us/step - loss: -23.4531 - acc: 0.1720 - val_loss: -24.6642 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.66278 to -24.66416, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4549 - acc: 0.1720 - val_loss: -24.6665 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.66416 to -24.66654, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4567 - acc: 0.1720 - val_loss: -24.6661 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66654\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -13.6237 - acc: 0.1734 - val_loss: -23.0006 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.00060, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -21.8410 - acc: 0.1720 - val_loss: -23.1040 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.00060 to -23.10402, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -21.9424 - acc: 0.1720 - val_loss: -23.2020 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.10402 to -23.20198, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -22.0391 - acc: 0.1720 - val_loss: -23.2972 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.20198 to -23.29723, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.1317 - acc: 0.1720 - val_loss: -23.3908 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.29723 to -23.39081, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -22.2250 - acc: 0.1720 - val_loss: -23.4849 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.39081 to -23.48489, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -22.3192 - acc: 0.1720 - val_loss: -23.5818 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.48489 to -23.58179, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -22.4158 - acc: 0.1720 - val_loss: -23.6786 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.58179 to -23.67858, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -22.5160 - acc: 0.1720 - val_loss: -23.7784 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.67858 to -23.77839, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -22.6182 - acc: 0.1720 - val_loss: -23.8812 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.77839 to -23.88119, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.7208 - acc: 0.1720 - val_loss: -23.9852 - val_acc: 0.1328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss improved from -23.88119 to -23.98521, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.8219 - acc: 0.1720 - val_loss: -24.0879 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.98521 to -24.08786, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -22.9208 - acc: 0.1720 - val_loss: -24.1813 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.08786 to -24.18132, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -23.0130 - acc: 0.1720 - val_loss: -24.2689 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.18132 to -24.26893, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 942us/step - loss: -23.0973 - acc: 0.1720 - val_loss: -24.3499 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.26893 to -24.34986, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.1735 - acc: 0.1720 - val_loss: -24.4199 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.34986 to -24.41988, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.2368 - acc: 0.1720 - val_loss: -24.4781 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.41988 to -24.47808, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.2805 - acc: 0.1720 - val_loss: -24.5118 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.47808 to -24.51179, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.3203 - acc: 0.1720 - val_loss: -24.5503 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.51179 to -24.55033, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 943us/step - loss: -23.3517 - acc: 0.1720 - val_loss: -24.5746 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.55033 to -24.57463, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.3766 - acc: 0.1720 - val_loss: -24.6007 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.57463 to -24.60071, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.3900 - acc: 0.1720 - val_loss: -24.6063 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.60071 to -24.60630, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 942us/step - loss: -23.4032 - acc: 0.1720 - val_loss: -24.6199 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.60630 to -24.61993, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4162 - acc: 0.1720 - val_loss: -24.6303 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.61993 to -24.63035, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 942us/step - loss: -23.4252 - acc: 0.1720 - val_loss: -24.6243 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.63035\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4293 - acc: 0.1720 - val_loss: -24.6407 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.63035 to -24.64067, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 943us/step - loss: -23.4350 - acc: 0.1720 - val_loss: -24.6489 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.64067 to -24.64887, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 940us/step - loss: -23.4398 - acc: 0.1720 - val_loss: -24.6494 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.64887 to -24.64937, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 945us/step - loss: -23.4416 - acc: 0.1720 - val_loss: -24.6511 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.64937 to -24.65109, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4448 - acc: 0.1720 - val_loss: -24.6561 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.65109 to -24.65612, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.4491 - acc: 0.1720 - val_loss: -24.6552 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.65612\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -23.4486 - acc: 0.1720 - val_loss: -24.6610 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.65612 to -24.66095, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 943us/step - loss: -23.4520 - acc: 0.1720 - val_loss: -24.6617 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.66095 to -24.66172, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -23.4518 - acc: 0.1720 - val_loss: -24.6576 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.66172\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4493 - acc: 0.1720 - val_loss: -24.6597 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.66172\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 942us/step - loss: -23.4513 - acc: 0.1720 - val_loss: -24.6616 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.66172\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -23.4532 - acc: 0.1720 - val_loss: -24.6636 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.66172 to -24.66355, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4547 - acc: 0.1720 - val_loss: -24.6655 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.66355 to -24.66545, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4551 - acc: 0.1720 - val_loss: -24.6617 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.66545\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.4527 - acc: 0.1720 - val_loss: -24.6623 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66545\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2000\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -14.5537 - acc: 0.1734 - val_loss: -22.9710 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.97096, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -21.7976 - acc: 0.1720 - val_loss: -23.0508 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.97096 to -23.05077, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -21.8762 - acc: 0.1720 - val_loss: -23.1287 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.05077 to -23.12875, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -21.9536 - acc: 0.1720 - val_loss: -23.2065 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.12875 to -23.20648, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -22.0313 - acc: 0.1720 - val_loss: -23.2857 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.20648 to -23.28573, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.1126 - acc: 0.1720 - val_loss: -23.3684 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.28573 to -23.36839, saving model to model-5.h5\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 943us/step - loss: -22.1967 - acc: 0.1720 - val_loss: -23.4562 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.36839 to -23.45619, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -22.2873 - acc: 0.1720 - val_loss: -23.5504 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -23.45619 to -23.55038, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 945us/step - loss: -22.3844 - acc: 0.1720 - val_loss: -23.6518 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -23.55038 to -23.65177, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -22.4888 - acc: 0.1720 - val_loss: -23.7561 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -23.65177 to -23.75608, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -22.5963 - acc: 0.1720 - val_loss: -23.8659 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -23.75608 to -23.86593, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.7065 - acc: 0.1720 - val_loss: -23.9764 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -23.86593 to -23.97640, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -22.8168 - acc: 0.1720 - val_loss: -24.0853 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -23.97640 to -24.08525, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.9258 - acc: 0.1720 - val_loss: -24.1859 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.08525 to -24.18586, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -23.0236 - acc: 0.1720 - val_loss: -24.2788 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.18586 to -24.27880, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.1105 - acc: 0.1720 - val_loss: -24.3606 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.27880 to -24.36064, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.1811 - acc: 0.1720 - val_loss: -24.4272 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.36064 to -24.42724, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.2436 - acc: 0.1720 - val_loss: -24.4640 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.42724 to -24.46401, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -23.2932 - acc: 0.1720 - val_loss: -24.5185 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -24.46401 to -24.51854, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.3270 - acc: 0.1720 - val_loss: -24.5576 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -24.51854 to -24.55761, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 943us/step - loss: -23.3626 - acc: 0.1720 - val_loss: -24.5822 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.55761 to -24.58225, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.3763 - acc: 0.1720 - val_loss: -24.5931 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.58225 to -24.59306, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.3901 - acc: 0.1720 - val_loss: -24.6087 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.59306 to -24.60867, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -23.4061 - acc: 0.1720 - val_loss: -24.6224 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.60867 to -24.62240, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.4163 - acc: 0.1720 - val_loss: -24.6318 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.62240 to -24.63177, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -23.4251 - acc: 0.1720 - val_loss: -24.6398 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.63177 to -24.63980, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 942us/step - loss: -23.4319 - acc: 0.1720 - val_loss: -24.6467 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.63980 to -24.64667, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 943us/step - loss: -23.4370 - acc: 0.1720 - val_loss: -24.6493 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.64667 to -24.64926, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -23.4157 - acc: 0.1720 - val_loss: -24.6484 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.64926\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4394 - acc: 0.1720 - val_loss: -24.6490 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.64926\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4401 - acc: 0.1720 - val_loss: -24.6498 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.64926 to -24.64978, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4408 - acc: 0.1720 - val_loss: -24.6506 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.64978 to -24.65060, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 945us/step - loss: -23.4417 - acc: 0.1720 - val_loss: -24.6516 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.65060 to -24.65156, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4428 - acc: 0.1720 - val_loss: -24.6527 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.65156 to -24.65269, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -23.4440 - acc: 0.1720 - val_loss: -24.6540 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.65269 to -24.65404, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.4454 - acc: 0.1720 - val_loss: -24.6553 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.65404 to -24.65527, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4464 - acc: 0.1720 - val_loss: -24.6573 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.65527 to -24.65726, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.4480 - acc: 0.1720 - val_loss: -24.6595 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.65726 to -24.65953, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.4508 - acc: 0.1720 - val_loss: -24.6607 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.65953 to -24.66074, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.4520 - acc: 0.1720 - val_loss: -24.6596 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.66074\n",
      "Text informations:\n",
      "max length: 98 / min length: 3 / mean length: 13 / limit length: 100\n",
      "vocabulary size: 2218 / limit: 2954\n",
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 4ms/step - loss: -8.6325 - acc: 0.1661 - val_loss: -24.3706 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.37057, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.1843 - acc: 0.1642 - val_loss: -24.4707 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.37057 to -24.47068, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.2850 - acc: 0.1642 - val_loss: -24.5720 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.47068 to -24.57202, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.3873 - acc: 0.1642 - val_loss: -24.6753 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.57202 to -24.67530, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.4906 - acc: 0.1642 - val_loss: -24.7780 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.67530 to -24.77795, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.5937 - acc: 0.1642 - val_loss: -24.8824 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.77795 to -24.88237, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.7021 - acc: 0.1642 - val_loss: -24.9960 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.88237 to -24.99601, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -22.8171 - acc: 0.1642 - val_loss: -25.1122 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.99601 to -25.11216, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -22.9345 - acc: 0.1642 - val_loss: -25.2282 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.11216 to -25.22822, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -23.0519 - acc: 0.1642 - val_loss: -25.3472 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.22822 to -25.34717, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.1698 - acc: 0.1642 - val_loss: -25.4642 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.34717 to -25.46415, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.2841 - acc: 0.1642 - val_loss: -25.5729 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.46415 to -25.57291, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.3892 - acc: 0.1642 - val_loss: -25.6750 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.57291 to -25.67502, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4863 - acc: 0.1642 - val_loss: -25.7657 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.67502 to -25.76571, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 996us/step - loss: -23.5716 - acc: 0.1642 - val_loss: -25.8454 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.76571 to -25.84536, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.6430 - acc: 0.1642 - val_loss: -25.9081 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.84536 to -25.90806, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.7018 - acc: 0.1642 - val_loss: -25.9620 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.90806 to -25.96201, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.7506 - acc: 0.1642 - val_loss: -26.0019 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.96201 to -26.00191, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.7866 - acc: 0.1642 - val_loss: -26.0351 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -26.00191 to -26.03508, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.8167 - acc: 0.1642 - val_loss: -26.0604 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.03508 to -26.06043, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8367 - acc: 0.1642 - val_loss: -26.0751 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.06043 to -26.07508, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.8532 - acc: 0.1642 - val_loss: -26.0902 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.07508 to -26.09017, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.8636 - acc: 0.1642 - val_loss: -26.1011 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.09017 to -26.10107, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8731 - acc: 0.1642 - val_loss: -26.1084 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.10107 to -26.10842, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -23.8770 - acc: 0.1642 - val_loss: -26.1131 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.10842 to -26.11314, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -23.8824 - acc: 0.1642 - val_loss: -26.1170 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.11314 to -26.11705, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8756 - acc: 0.1642 - val_loss: -26.1096 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -26.11705\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8793 - acc: 0.1642 - val_loss: -26.1107 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -26.11705\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -23.8804 - acc: 0.1642 - val_loss: -26.1118 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.11705\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8815 - acc: 0.1642 - val_loss: -26.1130 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -26.11705\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -23.8823 - acc: 0.1642 - val_loss: -26.1131 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.11705\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8824 - acc: 0.1642 - val_loss: -26.1133 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -26.11705\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8826 - acc: 0.1642 - val_loss: -26.1135 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.11705\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8828 - acc: 0.1642 - val_loss: -26.1138 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11705\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8830 - acc: 0.1642 - val_loss: -26.1138 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11705\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8831 - acc: 0.1642 - val_loss: -26.1138 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11705\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8831 - acc: 0.1642 - val_loss: -26.1139 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.11705\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8832 - acc: 0.1642 - val_loss: -26.1140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11705\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8832 - acc: 0.1642 - val_loss: -26.1141 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11705\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8833 - acc: 0.1642 - val_loss: -26.1142 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11705\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -11.2425 - acc: 0.1624 - val_loss: -24.3984 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.39840, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.2044 - acc: 0.1642 - val_loss: -24.4803 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.39840 to -24.48034, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.2864 - acc: 0.1642 - val_loss: -24.5632 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.48034 to -24.56321, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.3706 - acc: 0.1642 - val_loss: -24.6489 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.56321 to -24.64890, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.4573 - acc: 0.1642 - val_loss: -24.7380 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.64890 to -24.73798, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.5490 - acc: 0.1642 - val_loss: -24.8318 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.73798 to -24.83184, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.6462 - acc: 0.1642 - val_loss: -24.9339 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.83184 to -24.93390, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.7502 - acc: 0.1642 - val_loss: -25.0408 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.93390 to -25.04084, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.8599 - acc: 0.1642 - val_loss: -25.1508 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.04084 to -25.15084, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -22.9723 - acc: 0.1642 - val_loss: -25.2679 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.15084 to -25.26789, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.0897 - acc: 0.1642 - val_loss: -25.3839 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.26789 to -25.38394, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.2047 - acc: 0.1642 - val_loss: -25.4992 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.38394 to -25.49916, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.3134 - acc: 0.1642 - val_loss: -25.6032 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.49916 to -25.60317, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.4147 - acc: 0.1642 - val_loss: -25.6997 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.60317 to -25.69968, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.5034 - acc: 0.1642 - val_loss: -25.7788 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.69968 to -25.77882, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.5824 - acc: 0.1642 - val_loss: -25.8518 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.77882 to -25.85179, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.6492 - acc: 0.1642 - val_loss: -25.9137 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.85179 to -25.91366, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.7041 - acc: 0.1642 - val_loss: -25.9642 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.91366 to -25.96419, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.7502 - acc: 0.1642 - val_loss: -26.0054 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.96419 to -26.00536, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.7869 - acc: 0.1642 - val_loss: -26.0335 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.00536 to -26.03346, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8133 - acc: 0.1642 - val_loss: -26.0537 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.03346 to -26.05369, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8341 - acc: 0.1642 - val_loss: -26.0773 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.05369 to -26.07733, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8423 - acc: 0.1642 - val_loss: -26.0748 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -26.07733\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8473 - acc: 0.1642 - val_loss: -26.0819 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.07733 to -26.08186, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8540 - acc: 0.1642 - val_loss: -26.0883 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.08186 to -26.08834, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8604 - acc: 0.1642 - val_loss: -26.0945 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.08834 to -26.09449, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8659 - acc: 0.1642 - val_loss: -26.0976 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.09449 to -26.09761, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8697 - acc: 0.1642 - val_loss: -26.1039 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.09761 to -26.10387, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8697 - acc: 0.1642 - val_loss: -26.1004 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.10387\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.8713 - acc: 0.1642 - val_loss: -26.1041 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.10387 to -26.10413, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8750 - acc: 0.1642 - val_loss: -26.1078 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.10413 to -26.10783, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8787 - acc: 0.1642 - val_loss: -26.1108 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.10783 to -26.11079, saving model to model-2.h5\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8814 - acc: 0.1642 - val_loss: -26.1106 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.11079\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8819 - acc: 0.1642 - val_loss: -26.1139 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -26.11079 to -26.11385, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8845 - acc: 0.1642 - val_loss: -26.1144 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -26.11385 to -26.11436, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8849 - acc: 0.1642 - val_loss: -26.1143 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11436\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8859 - acc: 0.1642 - val_loss: -26.1193 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.11436 to -26.11934, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8822 - acc: 0.1642 - val_loss: -26.1146 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11934\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8841 - acc: 0.1642 - val_loss: -26.1152 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11934\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.8847 - acc: 0.1642 - val_loss: -26.1158 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11934\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -13.9246 - acc: 0.1624 - val_loss: -24.4357 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.43575, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.2399 - acc: 0.1642 - val_loss: -24.5140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.43575 to -24.51404, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.3189 - acc: 0.1642 - val_loss: -24.5938 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.51404 to -24.59378, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.3996 - acc: 0.1642 - val_loss: -24.6758 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.59378 to -24.67582, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.4836 - acc: 0.1642 - val_loss: -24.7624 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.67582 to -24.76239, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -22.5718 - acc: 0.1642 - val_loss: -24.8531 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.76239 to -24.85306, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.6651 - acc: 0.1642 - val_loss: -24.9503 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.85306 to -24.95025, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.7656 - acc: 0.1642 - val_loss: -25.0540 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.95025 to -25.05402, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -22.8719 - acc: 0.1642 - val_loss: -25.1637 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.05402 to -25.16370, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.9822 - acc: 0.1642 - val_loss: -25.2763 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.16370 to -25.27628, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.0954 - acc: 0.1642 - val_loss: -25.3884 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.27628 to -25.38838, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -23.2078 - acc: 0.1642 - val_loss: -25.4997 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.38838 to -25.49975, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.3151 - acc: 0.1642 - val_loss: -25.5986 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.49975 to -25.59864, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.4125 - acc: 0.1642 - val_loss: -25.6966 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.59864 to -25.69660, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.5024 - acc: 0.1642 - val_loss: -25.7795 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.69660 to -25.77947, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.5805 - acc: 0.1642 - val_loss: -25.8512 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.77947 to -25.85120, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.6488 - acc: 0.1642 - val_loss: -25.9136 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.85120 to -25.91363, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.7063 - acc: 0.1642 - val_loss: -25.9651 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.91363 to -25.96507, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.7524 - acc: 0.1642 - val_loss: -26.0016 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.96507 to -26.00157, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.7878 - acc: 0.1642 - val_loss: -26.0309 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.00157 to -26.03091, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8129 - acc: 0.1642 - val_loss: -26.0544 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.03091 to -26.05435, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8349 - acc: 0.1642 - val_loss: -26.0783 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.05435 to -26.07825, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8517 - acc: 0.1642 - val_loss: -26.0798 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.07825 to -26.07981, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8508 - acc: 0.1642 - val_loss: -26.0838 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.07981 to -26.08380, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8548 - acc: 0.1642 - val_loss: -26.0877 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.08380 to -26.08771, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -23.8587 - acc: 0.1642 - val_loss: -26.0917 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.08771 to -26.09168, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8627 - acc: 0.1642 - val_loss: -26.0958 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.09168 to -26.09580, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8670 - acc: 0.1642 - val_loss: -26.1001 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.09580 to -26.10012, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8714 - acc: 0.1642 - val_loss: -26.1046 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.10012 to -26.10464, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8741 - acc: 0.1642 - val_loss: -26.1065 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.10464 to -26.10652, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8778 - acc: 0.1642 - val_loss: -26.1078 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.10652 to -26.10781, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.8796 - acc: 0.1642 - val_loss: -26.1134 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.10781 to -26.11338, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8808 - acc: 0.1642 - val_loss: -26.1095 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.11338\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8791 - acc: 0.1642 - val_loss: -26.1103 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11338\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8799 - acc: 0.1642 - val_loss: -26.1112 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11338\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.8809 - acc: 0.1642 - val_loss: -26.1122 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11338\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8815 - acc: 0.1642 - val_loss: -26.1123 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.11338\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8816 - acc: 0.1642 - val_loss: -26.1125 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11338\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8818 - acc: 0.1642 - val_loss: -26.1126 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11338\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8820 - acc: 0.1642 - val_loss: -26.1129 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11338\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -14.3791 - acc: 0.1596 - val_loss: -24.4256 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.42562, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -22.2269 - acc: 0.1642 - val_loss: -24.4985 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.42562 to -24.49851, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.2993 - acc: 0.1642 - val_loss: -24.5730 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.49851 to -24.57304, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.3772 - acc: 0.1642 - val_loss: -24.6511 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.57304 to -24.65106, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.4575 - acc: 0.1642 - val_loss: -24.7348 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.65106 to -24.73481, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.5432 - acc: 0.1642 - val_loss: -24.8243 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.73481 to -24.82431, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.6373 - acc: 0.1642 - val_loss: -24.9227 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.82431 to -24.92268, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.7371 - acc: 0.1642 - val_loss: -25.0252 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.92268 to -25.02517, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -22.8443 - acc: 0.1642 - val_loss: -25.1371 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.02517 to -25.13708, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -22.9575 - acc: 0.1642 - val_loss: -25.2524 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.13708 to -25.25242, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.0736 - acc: 0.1642 - val_loss: -25.3694 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.25242 to -25.36941, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.1881 - acc: 0.1642 - val_loss: -25.4817 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.36941 to -25.48173, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.3011 - acc: 0.1642 - val_loss: -25.5921 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.48173 to -25.59214, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4038 - acc: 0.1642 - val_loss: -25.6872 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.59214 to -25.68725, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.4986 - acc: 0.1642 - val_loss: -25.7675 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.68725 to -25.76750, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.5722 - acc: 0.1642 - val_loss: -25.8444 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.76750 to -25.84440, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.6435 - acc: 0.1642 - val_loss: -25.9075 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.84440 to -25.90751, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.7004 - acc: 0.1642 - val_loss: -25.9594 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.90751 to -25.95940, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.7456 - acc: 0.1642 - val_loss: -26.0003 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.95940 to -26.00029, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.7841 - acc: 0.1642 - val_loss: -26.0334 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.00029 to -26.03339, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8122 - acc: 0.1642 - val_loss: -26.0501 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.03339 to -26.05010, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8302 - acc: 0.1642 - val_loss: -26.0731 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.05010 to -26.07312, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8496 - acc: 0.1642 - val_loss: -26.0782 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.07312 to -26.07819, saving model to model-4.h5\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8518 - acc: 0.1642 - val_loss: -26.0877 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.07819 to -26.08768, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8607 - acc: 0.1642 - val_loss: -26.0959 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.08768 to -26.09587, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8684 - acc: 0.1642 - val_loss: -26.1030 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.09587 to -26.10303, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.8735 - acc: 0.1642 - val_loss: -26.1066 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.10303 to -26.10658, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8776 - acc: 0.1642 - val_loss: -26.1068 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.10658 to -26.10676, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8788 - acc: 0.1642 - val_loss: -26.1127 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.10676 to -26.11273, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8843 - acc: 0.1642 - val_loss: -26.1100 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -26.11273\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8811 - acc: 0.1642 - val_loss: -26.1141 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.11273 to -26.11407, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8849 - acc: 0.1642 - val_loss: -26.1176 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.11407 to -26.11762, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8883 - acc: 0.1642 - val_loss: -26.1192 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.11762 to -26.11923, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8899 - acc: 0.1642 - val_loss: -26.1192 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11923\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8898 - acc: 0.1642 - val_loss: -26.1196 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -26.11923 to -26.11960, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8906 - acc: 0.1642 - val_loss: -26.1234 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.11960 to -26.12338, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8909 - acc: 0.1642 - val_loss: -26.1225 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.12338\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8922 - acc: 0.1642 - val_loss: -26.1201 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.12338\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8910 - acc: 0.1642 - val_loss: -26.1235 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -26.12338 to -26.12354, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8935 - acc: 0.1642 - val_loss: -26.1201 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.12354\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -15.5453 - acc: 0.1651 - val_loss: -24.4356 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.43556, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.2372 - acc: 0.1642 - val_loss: -24.5079 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.43556 to -24.50794, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -22.3100 - acc: 0.1642 - val_loss: -24.5818 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.50794 to -24.58179, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.3853 - acc: 0.1642 - val_loss: -24.6586 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.58179 to -24.65860, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -22.4636 - acc: 0.1642 - val_loss: -24.7401 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.65860 to -24.74009, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.5475 - acc: 0.1642 - val_loss: -24.8273 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.74009 to -24.82727, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -22.6387 - acc: 0.1642 - val_loss: -24.9229 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.82727 to -24.92291, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.7374 - acc: 0.1642 - val_loss: -25.0253 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.92291 to -25.02532, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -22.8430 - acc: 0.1642 - val_loss: -25.1343 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.02532 to -25.13434, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.9528 - acc: 0.1642 - val_loss: -25.2465 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.13434 to -25.24648, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.0675 - acc: 0.1642 - val_loss: -25.3597 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.24648 to -25.35972, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.1781 - acc: 0.1642 - val_loss: -25.4674 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.35972 to -25.46741, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.2854 - acc: 0.1642 - val_loss: -25.5751 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.46741 to -25.57509, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 996us/step - loss: -23.3891 - acc: 0.1642 - val_loss: -25.6738 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.57509 to -25.67381, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -23.4834 - acc: 0.1642 - val_loss: -25.7632 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.67381 to -25.76323, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.5674 - acc: 0.1642 - val_loss: -25.8366 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.76323 to -25.83664, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.6368 - acc: 0.1642 - val_loss: -25.9000 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.83664 to -25.90005, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.6962 - acc: 0.1642 - val_loss: -25.9579 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.90005 to -25.95794, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 998us/step - loss: -23.7445 - acc: 0.1642 - val_loss: -25.9996 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.95794 to -25.99962, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.7838 - acc: 0.1642 - val_loss: -26.0328 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.99962 to -26.03276, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.8004 - acc: 0.1642 - val_loss: -26.0405 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.03276 to -26.04046, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8114 - acc: 0.1642 - val_loss: -26.0443 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.04046 to -26.04426, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8152 - acc: 0.1642 - val_loss: -26.0481 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.04426 to -26.04814, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.8192 - acc: 0.1642 - val_loss: -26.0523 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.04814 to -26.05227, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.8235 - acc: 0.1642 - val_loss: -26.0568 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.05227 to -26.05681, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8283 - acc: 0.1642 - val_loss: -26.0619 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.05681 to -26.06193, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8337 - acc: 0.1642 - val_loss: -26.0678 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.06193 to -26.06778, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -23.8399 - acc: 0.1642 - val_loss: -26.0744 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.06778 to -26.07440, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8469 - acc: 0.1642 - val_loss: -26.0817 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.07440 to -26.08175, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.8545 - acc: 0.1642 - val_loss: -26.0896 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.08175 to -26.08962, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8600 - acc: 0.1642 - val_loss: -26.0932 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.08962 to -26.09320, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.8661 - acc: 0.1642 - val_loss: -26.1012 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.09320 to -26.10120, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.8726 - acc: 0.1642 - val_loss: -26.1065 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.10120 to -26.10647, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8768 - acc: 0.1642 - val_loss: -26.1089 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -26.10647 to -26.10893, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.8812 - acc: 0.1642 - val_loss: -26.1154 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -26.10893 to -26.11536, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8805 - acc: 0.1642 - val_loss: -26.1122 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11536\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8832 - acc: 0.1642 - val_loss: -26.1160 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.11536 to -26.11597, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8867 - acc: 0.1642 - val_loss: -26.1193 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -26.11597 to -26.11927, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8677 - acc: 0.1642 - val_loss: -26.1156 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11927\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8849 - acc: 0.1642 - val_loss: -26.1157 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11927\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -9.4430 - acc: 0.1651 - val_loss: -24.4347 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.43466, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.3091 - acc: 0.1642 - val_loss: -24.6627 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.43466 to -24.66269, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.5172 - acc: 0.1642 - val_loss: -24.8501 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.66269 to -24.85011, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 992us/step - loss: -22.6924 - acc: 0.1642 - val_loss: -25.0107 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.85011 to -25.01066, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.8463 - acc: 0.1642 - val_loss: -25.1542 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -25.01066 to -25.15420, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -22.9805 - acc: 0.1642 - val_loss: -25.2787 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -25.15420 to -25.27866, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.0997 - acc: 0.1642 - val_loss: -25.3884 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -25.27866 to -25.38838, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.2066 - acc: 0.1642 - val_loss: -25.4959 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.38838 to -25.49591, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.3073 - acc: 0.1642 - val_loss: -25.5902 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.49591 to -25.59019, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.3989 - acc: 0.1642 - val_loss: -25.6742 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.59019 to -25.67418, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.4798 - acc: 0.1642 - val_loss: -25.7527 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.67418 to -25.75268, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.5552 - acc: 0.1642 - val_loss: -25.8236 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.75268 to -25.82356, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.6193 - acc: 0.1642 - val_loss: -25.8815 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.82356 to -25.88147, saving model to model-1.h5\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.6741 - acc: 0.1642 - val_loss: -25.9341 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.88147 to -25.93408, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.7222 - acc: 0.1642 - val_loss: -25.9729 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.93408 to -25.97294, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.7608 - acc: 0.1642 - val_loss: -26.0095 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.97294 to -26.00951, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.7864 - acc: 0.1642 - val_loss: -26.0275 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -26.00951 to -26.02755, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8094 - acc: 0.1642 - val_loss: -26.0544 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -26.02755 to -26.05442, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.8307 - acc: 0.1642 - val_loss: -26.0667 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -26.05442 to -26.06674, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8422 - acc: 0.1642 - val_loss: -26.0785 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.06674 to -26.07849, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -23.8537 - acc: 0.1642 - val_loss: -26.0881 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.07849 to -26.08812, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8626 - acc: 0.1642 - val_loss: -26.0926 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.08812 to -26.09259, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8680 - acc: 0.1642 - val_loss: -26.1056 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.09259 to -26.10557, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8685 - acc: 0.1642 - val_loss: -26.0978 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -26.10557\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.8686 - acc: 0.1642 - val_loss: -26.1013 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -26.10557\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8720 - acc: 0.1642 - val_loss: -26.1047 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -26.10557\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8754 - acc: 0.1642 - val_loss: -26.1081 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.10557 to -26.10806, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8788 - acc: 0.1642 - val_loss: -26.1115 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.10806 to -26.11149, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8797 - acc: 0.1642 - val_loss: -26.1112 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.11149\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8823 - acc: 0.1642 - val_loss: -26.1153 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.11149 to -26.11532, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8804 - acc: 0.1642 - val_loss: -26.1120 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.11532\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8829 - acc: 0.1642 - val_loss: -26.1157 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.11532 to -26.11567, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -23.8846 - acc: 0.1642 - val_loss: -26.1107 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.11567\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8807 - acc: 0.1642 - val_loss: -26.1125 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11567\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8826 - acc: 0.1642 - val_loss: -26.1144 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11567\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8845 - acc: 0.1642 - val_loss: -26.1163 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.11567 to -26.11630, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8864 - acc: 0.1642 - val_loss: -26.1183 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.11630 to -26.11833, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8881 - acc: 0.1642 - val_loss: -26.1192 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -26.11833 to -26.11925, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8889 - acc: 0.1642 - val_loss: -26.1194 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -26.11925 to -26.11940, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8896 - acc: 0.1642 - val_loss: -26.1203 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -26.11940 to -26.12032, saving model to model-1.h5\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -11.7372 - acc: 0.1624 - val_loss: -24.4660 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.46596, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -22.2970 - acc: 0.1642 - val_loss: -24.6026 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.46596 to -24.60263, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.4292 - acc: 0.1642 - val_loss: -24.7287 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.60263 to -24.72873, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.5510 - acc: 0.1642 - val_loss: -24.8467 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.72873 to -24.84670, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.6648 - acc: 0.1642 - val_loss: -24.9549 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.84670 to -24.95486, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.7732 - acc: 0.1642 - val_loss: -25.0624 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.95486 to -25.06243, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.8794 - acc: 0.1642 - val_loss: -25.1684 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -25.06243 to -25.16841, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.9846 - acc: 0.1642 - val_loss: -25.2699 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.16841 to -25.26986, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.0859 - acc: 0.1642 - val_loss: -25.3731 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.26986 to -25.37307, saving model to model-2.h5\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.1891 - acc: 0.1642 - val_loss: -25.4763 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.37307 to -25.47629, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.2876 - acc: 0.1642 - val_loss: -25.5703 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.47629 to -25.57033, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.3822 - acc: 0.1642 - val_loss: -25.6649 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.57033 to -25.66492, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.4716 - acc: 0.1642 - val_loss: -25.7474 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.66492 to -25.74742, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.5495 - acc: 0.1642 - val_loss: -25.8121 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.74742 to -25.81213, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.6135 - acc: 0.1642 - val_loss: -25.8817 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.81213 to -25.88170, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.6709 - acc: 0.1642 - val_loss: -25.9297 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.88170 to -25.92970, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.7191 - acc: 0.1642 - val_loss: -25.9684 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.92970 to -25.96844, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.7573 - acc: 0.1642 - val_loss: -26.0084 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.96844 to -26.00838, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.7917 - acc: 0.1642 - val_loss: -26.0377 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -26.00838 to -26.03772, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8156 - acc: 0.1642 - val_loss: -26.0527 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.03772 to -26.05275, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8341 - acc: 0.1642 - val_loss: -26.0627 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.05275 to -26.06268, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8372 - acc: 0.1642 - val_loss: -26.0742 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.06268 to -26.07423, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8481 - acc: 0.1642 - val_loss: -26.0844 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.07423 to -26.08437, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8578 - acc: 0.1642 - val_loss: -26.0934 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.08437 to -26.09344, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8653 - acc: 0.1642 - val_loss: -26.0935 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.09344 to -26.09354, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8669 - acc: 0.1642 - val_loss: -26.1026 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.09354 to -26.10256, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8740 - acc: 0.1642 - val_loss: -26.1057 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.10256 to -26.10570, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8775 - acc: 0.1642 - val_loss: -26.1069 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.10570 to -26.10694, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8796 - acc: 0.1642 - val_loss: -26.1104 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.10694 to -26.11038, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8822 - acc: 0.1642 - val_loss: -26.1119 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.11038 to -26.11191, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8777 - acc: 0.1642 - val_loss: -26.1100 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.11191\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8795 - acc: 0.1642 - val_loss: -26.1106 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -26.11191\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8800 - acc: 0.1642 - val_loss: -26.1111 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.11191\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8806 - acc: 0.1642 - val_loss: -26.1117 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11191\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8810 - acc: 0.1642 - val_loss: -26.1118 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11191\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8811 - acc: 0.1642 - val_loss: -26.1119 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11191\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8812 - acc: 0.1642 - val_loss: -26.1120 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.11191 to -26.11202, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8813 - acc: 0.1642 - val_loss: -26.1122 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -26.11202 to -26.11217, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8815 - acc: 0.1642 - val_loss: -26.1124 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -26.11217 to -26.11236, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8817 - acc: 0.1642 - val_loss: -26.1126 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -26.11236 to -26.11260, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -13.9056 - acc: 0.1633 - val_loss: -24.4542 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.45419, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -22.2700 - acc: 0.1642 - val_loss: -24.5572 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.45419 to -24.55724, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.3711 - acc: 0.1642 - val_loss: -24.6561 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.55724 to -24.65610, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.4683 - acc: 0.1642 - val_loss: -24.7513 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.65610 to -24.75134, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -22.5622 - acc: 0.1642 - val_loss: -24.8458 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.75134 to -24.84581, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.6577 - acc: 0.1642 - val_loss: -24.9415 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.84581 to -24.94153, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.7552 - acc: 0.1642 - val_loss: -25.0395 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.94153 to -25.03953, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.8547 - acc: 0.1642 - val_loss: -25.1429 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.03953 to -25.14287, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.9598 - acc: 0.1642 - val_loss: -25.2484 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.14287 to -25.24844, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.0657 - acc: 0.1642 - val_loss: -25.3569 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.24844 to -25.35695, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.1720 - acc: 0.1642 - val_loss: -25.4606 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.35695 to -25.46063, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2780 - acc: 0.1642 - val_loss: -25.5674 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.46063 to -25.56743, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.3775 - acc: 0.1642 - val_loss: -25.6622 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.56743 to -25.66220, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4711 - acc: 0.1642 - val_loss: -25.7473 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.66220 to -25.74733, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.5540 - acc: 0.1642 - val_loss: -25.8210 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.74733 to -25.82102, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.6237 - acc: 0.1642 - val_loss: -25.8934 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.82102 to -25.89339, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.6850 - acc: 0.1642 - val_loss: -25.9467 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.89339 to -25.94665, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.7363 - acc: 0.1642 - val_loss: -25.9919 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.94665 to -25.99185, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.7736 - acc: 0.1642 - val_loss: -26.0255 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.99185 to -26.02553, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.8066 - acc: 0.1642 - val_loss: -26.0466 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.02553 to -26.04661, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8289 - acc: 0.1642 - val_loss: -26.0741 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.04661 to -26.07408, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.8492 - acc: 0.1642 - val_loss: -26.0880 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.07408 to -26.08803, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8447 - acc: 0.1642 - val_loss: -26.0824 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -26.08803\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8523 - acc: 0.1642 - val_loss: -26.0838 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -26.08803\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8536 - acc: 0.1642 - val_loss: -26.0852 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -26.08803\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8552 - acc: 0.1642 - val_loss: -26.0868 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -26.08803\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8562 - acc: 0.1642 - val_loss: -26.0870 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -26.08803\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8564 - acc: 0.1642 - val_loss: -26.0873 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -26.08803\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.8566 - acc: 0.1642 - val_loss: -26.0876 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.08803\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8570 - acc: 0.1642 - val_loss: -26.0880 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -26.08803\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.8572 - acc: 0.1642 - val_loss: -26.0880 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.08803\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8573 - acc: 0.1642 - val_loss: -26.0881 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.08803 to -26.08807, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8573 - acc: 0.1642 - val_loss: -26.0881 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.08807 to -26.08815, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8574 - acc: 0.1642 - val_loss: -26.0883 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -26.08815 to -26.08825, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8575 - acc: 0.1642 - val_loss: -26.0884 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -26.08825 to -26.08838, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.8577 - acc: 0.1642 - val_loss: -26.0885 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.08838 to -26.08854, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8579 - acc: 0.1642 - val_loss: -26.0887 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.08854 to -26.08873, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8581 - acc: 0.1642 - val_loss: -26.0890 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -26.08873 to -26.08895, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8583 - acc: 0.1642 - val_loss: -26.0892 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -26.08895 to -26.08920, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8586 - acc: 0.1642 - val_loss: -26.0895 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -26.08920 to -26.08947, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -13.9437 - acc: 0.1684 - val_loss: -24.4422 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.44217, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.2540 - acc: 0.1642 - val_loss: -24.5358 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.44217 to -24.53583, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.3449 - acc: 0.1642 - val_loss: -24.6241 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.53583 to -24.62407, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.4320 - acc: 0.1642 - val_loss: -24.7103 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.62407 to -24.71030, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.5183 - acc: 0.1642 - val_loss: -24.7972 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.71030 to -24.79720, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.6063 - acc: 0.1642 - val_loss: -24.8869 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.79720 to -24.88687, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.6977 - acc: 0.1642 - val_loss: -24.9799 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.88687 to -24.97986, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -22.7928 - acc: 0.1642 - val_loss: -25.0780 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.97986 to -25.07801, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.8922 - acc: 0.1642 - val_loss: -25.1801 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.07801 to -25.18012, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.9960 - acc: 0.1642 - val_loss: -25.2853 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.18012 to -25.28530, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.1032 - acc: 0.1642 - val_loss: -25.3921 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.28530 to -25.39209, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.2094 - acc: 0.1642 - val_loss: -25.4989 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.39209 to -25.49892, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3145 - acc: 0.1642 - val_loss: -25.6018 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.49892 to -25.60182, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.4129 - acc: 0.1642 - val_loss: -25.6952 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.60182 to -25.69522, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.5024 - acc: 0.1642 - val_loss: -25.7807 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.69522 to -25.78068, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.5822 - acc: 0.1642 - val_loss: -25.8508 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.78068 to -25.85080, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.6510 - acc: 0.1642 - val_loss: -25.9113 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.85080 to -25.91132, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -23.7068 - acc: 0.1642 - val_loss: -25.9676 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.91132 to -25.96761, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.7496 - acc: 0.1642 - val_loss: -26.0041 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.96761 to -26.00412, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.7863 - acc: 0.1642 - val_loss: -26.0355 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.00412 to -26.03546, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8166 - acc: 0.1642 - val_loss: -26.0620 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.03546 to -26.06205, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.8354 - acc: 0.1642 - val_loss: -26.0714 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.06205 to -26.07142, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8488 - acc: 0.1642 - val_loss: -26.0887 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.07142 to -26.08872, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -23.8622 - acc: 0.1642 - val_loss: -26.0979 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.08872 to -26.09785, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8692 - acc: 0.1642 - val_loss: -26.1052 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.09785 to -26.10521, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8654 - acc: 0.1642 - val_loss: -26.1002 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -26.10521\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8697 - acc: 0.1642 - val_loss: -26.1008 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -26.10521\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8703 - acc: 0.1642 - val_loss: -26.1015 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -26.10521\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8710 - acc: 0.1642 - val_loss: -26.1022 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.10521\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8715 - acc: 0.1642 - val_loss: -26.1023 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -26.10521\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8715 - acc: 0.1642 - val_loss: -26.1024 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.10521\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8717 - acc: 0.1642 - val_loss: -26.1025 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -26.10521\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8718 - acc: 0.1642 - val_loss: -26.1027 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.10521\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8719 - acc: 0.1642 - val_loss: -26.1027 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.10521\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8720 - acc: 0.1642 - val_loss: -26.1027 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.10521\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8720 - acc: 0.1642 - val_loss: -26.1028 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.10521\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8720 - acc: 0.1642 - val_loss: -26.1028 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.10521\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8721 - acc: 0.1642 - val_loss: -26.1029 - val_acc: 0.1328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss did not improve from -26.10521\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8722 - acc: 0.1642 - val_loss: -26.1030 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.10521\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8722 - acc: 0.1642 - val_loss: -26.1031 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.10521\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 9s 4ms/step - loss: -14.8781 - acc: 0.1647 - val_loss: -24.4322 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.43221, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -22.2444 - acc: 0.1642 - val_loss: -24.5272 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.43221 to -24.52720, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.3374 - acc: 0.1642 - val_loss: -24.6182 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.52720 to -24.61817, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -22.4273 - acc: 0.1642 - val_loss: -24.7071 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.61817 to -24.70705, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -22.5159 - acc: 0.1642 - val_loss: -24.7957 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.70705 to -24.79574, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 991us/step - loss: -22.6052 - acc: 0.1642 - val_loss: -24.8860 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.79574 to -24.88595, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.6966 - acc: 0.1642 - val_loss: -24.9792 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.88595 to -24.97916, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.7915 - acc: 0.1642 - val_loss: -25.0763 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.97916 to -25.07631, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.8906 - acc: 0.1642 - val_loss: -25.1776 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.07631 to -25.17763, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.9936 - acc: 0.1642 - val_loss: -25.2825 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.17763 to -25.28247, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.0999 - acc: 0.1642 - val_loss: -25.3870 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.28247 to -25.38704, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.2037 - acc: 0.1642 - val_loss: -25.4912 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.38704 to -25.49123, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.3072 - acc: 0.1642 - val_loss: -25.5943 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.49123 to -25.59427, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.4046 - acc: 0.1642 - val_loss: -25.6859 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.59427 to -25.68586, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4957 - acc: 0.1642 - val_loss: -25.7747 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.68586 to -25.77470, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.5678 - acc: 0.1642 - val_loss: -25.8362 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.77470 to -25.83618, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.6346 - acc: 0.1642 - val_loss: -25.8996 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.83618 to -25.89959, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.6911 - acc: 0.1642 - val_loss: -25.9510 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.89959 to -25.95100, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.7314 - acc: 0.1642 - val_loss: -25.9696 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.95100 to -25.96963, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.7486 - acc: 0.1642 - val_loss: -25.9911 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.96963 to -25.99106, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.7694 - acc: 0.1642 - val_loss: -26.0111 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.99106 to -26.01115, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.7890 - acc: 0.1642 - val_loss: -26.0302 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.01115 to -26.03024, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8027 - acc: 0.1642 - val_loss: -26.0363 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.03024 to -26.03631, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8113 - acc: 0.1642 - val_loss: -26.0491 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.03631 to -26.04914, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8240 - acc: 0.1642 - val_loss: -26.0615 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.04914 to -26.06153, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8362 - acc: 0.1642 - val_loss: -26.0735 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.06153 to -26.07351, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8384 - acc: 0.1642 - val_loss: -26.0706 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -26.07351\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8424 - acc: 0.1642 - val_loss: -26.0764 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.07351 to -26.07636, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8483 - acc: 0.1642 - val_loss: -26.0824 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.07636 to -26.08239, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8544 - acc: 0.1642 - val_loss: -26.0887 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.08239 to -26.08873, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8609 - acc: 0.1642 - val_loss: -26.0953 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.08873 to -26.09532, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8664 - acc: 0.1642 - val_loss: -26.1006 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.09532 to -26.10056, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.8673 - acc: 0.1642 - val_loss: -26.0959 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.10056\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8654 - acc: 0.1642 - val_loss: -26.0966 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.10056\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.8663 - acc: 0.1642 - val_loss: -26.0975 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.10056\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8672 - acc: 0.1642 - val_loss: -26.0986 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.10056\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8679 - acc: 0.1642 - val_loss: -26.0988 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.10056\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8681 - acc: 0.1642 - val_loss: -26.0989 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.10056\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.8682 - acc: 0.1642 - val_loss: -26.0991 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.10056\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8685 - acc: 0.1642 - val_loss: -26.0994 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.10056\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 4ms/step - loss: -8.1955 - acc: 0.1614 - val_loss: -24.4312 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.43116, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.2958 - acc: 0.1642 - val_loss: -24.6389 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.43116 to -24.63893, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.4921 - acc: 0.1642 - val_loss: -24.8203 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.63893 to -24.82027, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.6625 - acc: 0.1642 - val_loss: -24.9813 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.82027 to -24.98129, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.8183 - acc: 0.1642 - val_loss: -25.1284 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.98129 to -25.12836, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.9561 - acc: 0.1642 - val_loss: -25.2578 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -25.12836 to -25.25780, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.0818 - acc: 0.1642 - val_loss: -25.3766 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -25.25780 to -25.37658, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.1969 - acc: 0.1642 - val_loss: -25.4868 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.37658 to -25.48685, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.3044 - acc: 0.1642 - val_loss: -25.5928 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.48685 to -25.59278, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.4026 - acc: 0.1642 - val_loss: -25.6840 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.59278 to -25.68404, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.4887 - acc: 0.1642 - val_loss: -25.7643 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.68404 to -25.76430, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.5660 - acc: 0.1642 - val_loss: -25.8341 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.76430 to -25.83405, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.6314 - acc: 0.1642 - val_loss: -25.8950 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.83405 to -25.89496, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.6868 - acc: 0.1642 - val_loss: -25.9442 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.89496 to -25.94418, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.7323 - acc: 0.1642 - val_loss: -25.9850 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.94418 to -25.98496, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.7702 - acc: 0.1642 - val_loss: -26.0195 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.98496 to -26.01951, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8004 - acc: 0.1642 - val_loss: -26.0465 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -26.01951 to -26.04655, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8238 - acc: 0.1642 - val_loss: -26.0525 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -26.04655 to -26.05253, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8320 - acc: 0.1642 - val_loss: -26.0742 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -26.05253 to -26.07421, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8488 - acc: 0.1642 - val_loss: -26.0822 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.07421 to -26.08219, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8584 - acc: 0.1642 - val_loss: -26.0959 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.08219 to -26.09588, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8672 - acc: 0.1642 - val_loss: -26.1032 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.09588 to -26.10325, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.8676 - acc: 0.1642 - val_loss: -26.1036 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.10325 to -26.10365, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.8753 - acc: 0.1642 - val_loss: -26.1079 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.10365 to -26.10786, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8751 - acc: 0.1642 - val_loss: -26.1023 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -26.10786\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8722 - acc: 0.1642 - val_loss: -26.1040 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -26.10786\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8740 - acc: 0.1642 - val_loss: -26.1057 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -26.10786\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8758 - acc: 0.1642 - val_loss: -26.1076 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -26.10786\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8770 - acc: 0.1642 - val_loss: -26.1078 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.10786\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.8772 - acc: 0.1642 - val_loss: -26.1081 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.10786 to -26.10811, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8775 - acc: 0.1642 - val_loss: -26.1084 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.10811 to -26.10845, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8779 - acc: 0.1642 - val_loss: -26.1089 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.10845 to -26.10886, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8783 - acc: 0.1642 - val_loss: -26.1094 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.10886 to -26.10939, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8789 - acc: 0.1642 - val_loss: -26.1100 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -26.10939 to -26.11004, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.8796 - acc: 0.1642 - val_loss: -26.1108 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -26.11004 to -26.11083, saving model to model-1.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8805 - acc: 0.1642 - val_loss: -26.1117 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.11083 to -26.11175, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.8814 - acc: 0.1642 - val_loss: -26.1128 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.11175 to -26.11280, saving model to model-1.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -23.8825 - acc: 0.1642 - val_loss: -26.1139 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -26.11280 to -26.11394, saving model to model-1.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8837 - acc: 0.1642 - val_loss: -26.1151 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss improved from -26.11394 to -26.11513, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.8847 - acc: 0.1642 - val_loss: -26.1156 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss improved from -26.11513 to -26.11556, saving model to model-1.h5\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 4ms/step - loss: -12.1854 - acc: 0.1656 - val_loss: -24.4264 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.42638, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.2573 - acc: 0.1642 - val_loss: -24.5622 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.42638 to -24.56218, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.3880 - acc: 0.1642 - val_loss: -24.6865 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.56218 to -24.68646, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.5094 - acc: 0.1642 - val_loss: -24.8060 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.68646 to -24.80596, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.6259 - acc: 0.1642 - val_loss: -24.9192 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.80596 to -24.91923, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.7381 - acc: 0.1642 - val_loss: -25.0303 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.91923 to -25.03030, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.8475 - acc: 0.1642 - val_loss: -25.1384 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -25.03030 to -25.13838, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.9574 - acc: 0.1642 - val_loss: -25.2494 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.13838 to -25.24944, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.0659 - acc: 0.1642 - val_loss: -25.3562 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.24944 to -25.35621, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.1731 - acc: 0.1642 - val_loss: -25.4615 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.35621 to -25.46152, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.2741 - acc: 0.1642 - val_loss: -25.5586 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.46152 to -25.55860, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3711 - acc: 0.1642 - val_loss: -25.6545 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.55860 to -25.65454, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.4627 - acc: 0.1642 - val_loss: -25.7408 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.65454 to -25.74078, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.5440 - acc: 0.1642 - val_loss: -25.8184 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.74078 to -25.81837, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.6163 - acc: 0.1642 - val_loss: -25.8815 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.81837 to -25.88145, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.6779 - acc: 0.1642 - val_loss: -25.9364 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.88145 to -25.93641, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -23.7277 - acc: 0.1642 - val_loss: -25.9840 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.93641 to -25.98398, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.7637 - acc: 0.1642 - val_loss: -26.0142 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.98398 to -26.01415, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 988us/step - loss: -23.7972 - acc: 0.1642 - val_loss: -26.0403 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -26.01415 to -26.04032, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.8212 - acc: 0.1642 - val_loss: -26.0642 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.04032 to -26.06424, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8402 - acc: 0.1642 - val_loss: -26.0750 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.06424 to -26.07501, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.8533 - acc: 0.1642 - val_loss: -26.0881 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.07501 to -26.08808, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8626 - acc: 0.1642 - val_loss: -26.0952 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.08808 to -26.09520, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8710 - acc: 0.1642 - val_loss: -26.1087 - val_acc: 0.1328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_loss improved from -26.09520 to -26.10872, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8713 - acc: 0.1642 - val_loss: -26.1064 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -26.10872\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8792 - acc: 0.1642 - val_loss: -26.1139 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.10872 to -26.11391, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.8785 - acc: 0.1642 - val_loss: -26.1115 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -26.11391\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.8834 - acc: 0.1642 - val_loss: -26.1172 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.11391 to -26.11723, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8862 - acc: 0.1642 - val_loss: -26.1181 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.11723 to -26.11813, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.8678 - acc: 0.1642 - val_loss: -26.1126 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -26.11813\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.8820 - acc: 0.1642 - val_loss: -26.1130 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.11813\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8823 - acc: 0.1642 - val_loss: -26.1133 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -26.11813\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8827 - acc: 0.1642 - val_loss: -26.1137 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.11813\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8830 - acc: 0.1642 - val_loss: -26.1137 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11813\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.8830 - acc: 0.1642 - val_loss: -26.1138 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11813\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.8831 - acc: 0.1642 - val_loss: -26.1139 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11813\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8832 - acc: 0.1642 - val_loss: -26.1140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.11813\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8832 - acc: 0.1642 - val_loss: -26.1140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11813\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8832 - acc: 0.1642 - val_loss: -26.1140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11813\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8833 - acc: 0.1642 - val_loss: -26.1140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11813\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 4ms/step - loss: -13.8197 - acc: 0.1711 - val_loss: -24.4439 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.44395, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.2604 - acc: 0.1642 - val_loss: -24.5485 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.44395 to -24.54845, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.3631 - acc: 0.1642 - val_loss: -24.6498 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.54845 to -24.64976, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.4644 - acc: 0.1642 - val_loss: -24.7508 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.64976 to -24.75075, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.5646 - acc: 0.1642 - val_loss: -24.8513 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.75075 to -24.85135, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.6678 - acc: 0.1642 - val_loss: -24.9566 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.85135 to -24.95664, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -22.7720 - acc: 0.1642 - val_loss: -25.0625 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.95664 to -25.06248, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 985us/step - loss: -22.8802 - acc: 0.1642 - val_loss: -25.1706 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.06248 to -25.17064, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.9900 - acc: 0.1642 - val_loss: -25.2824 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.17064 to -25.28241, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.1022 - acc: 0.1642 - val_loss: -25.3932 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.28241 to -25.39325, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.2110 - acc: 0.1642 - val_loss: -25.5020 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.39325 to -25.50195, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.3150 - acc: 0.1642 - val_loss: -25.6016 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.50195 to -25.60163, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4142 - acc: 0.1642 - val_loss: -25.6957 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.60163 to -25.69571, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.5064 - acc: 0.1642 - val_loss: -25.7821 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.69571 to -25.78211, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.5842 - acc: 0.1642 - val_loss: -25.8466 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.78211 to -25.84659, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.6456 - acc: 0.1642 - val_loss: -25.9110 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.84659 to -25.91098, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.7032 - acc: 0.1642 - val_loss: -25.9615 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.91098 to -25.96153, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.7469 - acc: 0.1642 - val_loss: -25.9986 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.96153 to -25.99858, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.7824 - acc: 0.1642 - val_loss: -26.0299 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.99858 to -26.02993, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8115 - acc: 0.1642 - val_loss: -26.0565 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.02993 to -26.05648, saving model to model-3.h5\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8325 - acc: 0.1642 - val_loss: -26.0760 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.05648 to -26.07600, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8506 - acc: 0.1642 - val_loss: -26.0868 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.07600 to -26.08676, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8621 - acc: 0.1642 - val_loss: -26.0967 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.08676 to -26.09669, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8701 - acc: 0.1642 - val_loss: -26.1019 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.09669 to -26.10194, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8765 - acc: 0.1642 - val_loss: -26.1105 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.10194 to -26.11052, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8812 - acc: 0.1642 - val_loss: -26.1139 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.11052 to -26.11385, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8834 - acc: 0.1642 - val_loss: -26.1147 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.11385 to -26.11470, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8864 - acc: 0.1642 - val_loss: -26.1174 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.11470 to -26.11740, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8869 - acc: 0.1642 - val_loss: -26.1138 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.11740\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8854 - acc: 0.1642 - val_loss: -26.1187 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.11740 to -26.11870, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8896 - acc: 0.1642 - val_loss: -26.1223 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.11870 to -26.12227, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.8908 - acc: 0.1642 - val_loss: -26.1227 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.12227 to -26.12269, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8899 - acc: 0.1642 - val_loss: -26.1222 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.12269\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8053 - acc: 0.1642 - val_loss: -26.1180 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.12269\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8873 - acc: 0.1642 - val_loss: -26.1181 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.12269\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8874 - acc: 0.1642 - val_loss: -26.1182 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.12269\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8875 - acc: 0.1642 - val_loss: -26.1182 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.12269\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8875 - acc: 0.1642 - val_loss: -26.1183 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.12269\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8875 - acc: 0.1642 - val_loss: -26.1183 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.12269\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8875 - acc: 0.1642 - val_loss: -26.1183 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.12269\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 4ms/step - loss: -14.7297 - acc: 0.1587 - val_loss: -24.4298 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.42976, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.2395 - acc: 0.1642 - val_loss: -24.5194 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.42976 to -24.51944, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -22.3276 - acc: 0.1642 - val_loss: -24.6060 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.51944 to -24.60595, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.4135 - acc: 0.1642 - val_loss: -24.6914 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.60595 to -24.69145, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.4993 - acc: 0.1642 - val_loss: -24.7780 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.69145 to -24.77802, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.5870 - acc: 0.1642 - val_loss: -24.8676 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.77802 to -24.86756, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.6785 - acc: 0.1642 - val_loss: -24.9616 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.86756 to -24.96156, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.7748 - acc: 0.1642 - val_loss: -25.0609 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.96156 to -25.06088, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.8765 - acc: 0.1642 - val_loss: -25.1655 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.06088 to -25.16548, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.9824 - acc: 0.1642 - val_loss: -25.2720 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.16548 to -25.27204, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.0908 - acc: 0.1642 - val_loss: -25.3824 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.27204 to -25.38241, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2013 - acc: 0.1642 - val_loss: -25.4889 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.38241 to -25.48890, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3066 - acc: 0.1642 - val_loss: -25.5961 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.48890 to -25.59615, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4098 - acc: 0.1642 - val_loss: -25.6919 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.59615 to -25.69187, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.5016 - acc: 0.1642 - val_loss: -25.7805 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.69187 to -25.78049, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.5856 - acc: 0.1642 - val_loss: -25.8550 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.78049 to -25.85505, saving model to model-4.h5\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.6545 - acc: 0.1642 - val_loss: -25.9204 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.85505 to -25.92039, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.7137 - acc: 0.1642 - val_loss: -25.9706 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.92039 to -25.97062, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.7599 - acc: 0.1642 - val_loss: -26.0125 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.97062 to -26.01247, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.7960 - acc: 0.1642 - val_loss: -26.0299 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.01247 to -26.02995, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8073 - acc: 0.1642 - val_loss: -26.0477 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.02995 to -26.04766, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8240 - acc: 0.1642 - val_loss: -26.0632 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.04766 to -26.06324, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8388 - acc: 0.1642 - val_loss: -26.0771 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.06324 to -26.07708, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.8496 - acc: 0.1642 - val_loss: -26.0829 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.07708 to -26.08294, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8575 - acc: 0.1642 - val_loss: -26.0944 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.08294 to -26.09444, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8653 - acc: 0.1642 - val_loss: -26.0981 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.09444 to -26.09810, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.8715 - acc: 0.1642 - val_loss: -26.1071 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.09810 to -26.10713, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8759 - acc: 0.1642 - val_loss: -26.1103 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.10713 to -26.11025, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8798 - acc: 0.1642 - val_loss: -26.1091 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.11025\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.8811 - acc: 0.1642 - val_loss: -26.1149 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.11025 to -26.11495, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8857 - acc: 0.1642 - val_loss: -26.1161 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.11495 to -26.11608, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -23.8870 - acc: 0.1642 - val_loss: -26.1151 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -26.11608\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8866 - acc: 0.1642 - val_loss: -26.1200 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.11608 to -26.11998, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8403 - acc: 0.1642 - val_loss: -26.1158 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11998\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8851 - acc: 0.1642 - val_loss: -26.1159 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11998\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8852 - acc: 0.1642 - val_loss: -26.1161 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11998\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8854 - acc: 0.1642 - val_loss: -26.1163 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.11998\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8855 - acc: 0.1642 - val_loss: -26.1163 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11998\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.8855 - acc: 0.1642 - val_loss: -26.1163 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11998\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8856 - acc: 0.1642 - val_loss: -26.1163 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11998\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 4ms/step - loss: -14.4852 - acc: 0.1624 - val_loss: -24.4394 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.43944, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.2491 - acc: 0.1642 - val_loss: -24.5292 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.43944 to -24.52924, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.3380 - acc: 0.1642 - val_loss: -24.6173 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.52924 to -24.61729, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.4259 - acc: 0.1642 - val_loss: -24.7054 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.61729 to -24.70537, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.5146 - acc: 0.1642 - val_loss: -24.7951 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.70537 to -24.79510, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.6056 - acc: 0.1642 - val_loss: -24.8878 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.79510 to -24.88780, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.6999 - acc: 0.1642 - val_loss: -24.9844 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.88780 to -24.98438, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.7984 - acc: 0.1642 - val_loss: -25.0852 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.98438 to -25.08515, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.9000 - acc: 0.1642 - val_loss: -25.1880 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.08515 to -25.18796, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.0051 - acc: 0.1642 - val_loss: -25.2952 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.18796 to -25.29521, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.1121 - acc: 0.1642 - val_loss: -25.3999 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.29521 to -25.39992, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.2154 - acc: 0.1642 - val_loss: -25.5015 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.39992 to -25.50146, saving model to model-5.h5\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.3169 - acc: 0.1642 - val_loss: -25.6035 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.50146 to -25.60349, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.4141 - acc: 0.1642 - val_loss: -25.6944 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.60349 to -25.69444, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.5011 - acc: 0.1642 - val_loss: -25.7763 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.69444 to -25.77625, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.5798 - acc: 0.1642 - val_loss: -25.8497 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.77625 to -25.84970, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.6484 - acc: 0.1642 - val_loss: -25.9125 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.84970 to -25.91246, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.7061 - acc: 0.1642 - val_loss: -25.9605 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.91246 to -25.96048, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.7513 - acc: 0.1642 - val_loss: -26.0053 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.96048 to -26.00530, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.7897 - acc: 0.1642 - val_loss: -26.0396 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.00530 to -26.03956, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8061 - acc: 0.1642 - val_loss: -26.0473 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.03956 to -26.04728, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8250 - acc: 0.1642 - val_loss: -26.0655 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.04728 to -26.06554, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8419 - acc: 0.1642 - val_loss: -26.0795 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.06554 to -26.07948, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8534 - acc: 0.1642 - val_loss: -26.0892 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.07948 to -26.08918, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8617 - acc: 0.1642 - val_loss: -26.0889 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -26.08918\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8592 - acc: 0.1642 - val_loss: -26.0913 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.08918 to -26.09128, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8616 - acc: 0.1642 - val_loss: -26.0938 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.09128 to -26.09377, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8642 - acc: 0.1642 - val_loss: -26.0965 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.09377 to -26.09646, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8670 - acc: 0.1642 - val_loss: -26.0994 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.09646 to -26.09942, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8701 - acc: 0.1642 - val_loss: -26.1027 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.09942 to -26.10269, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8735 - acc: 0.1642 - val_loss: -26.1063 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.10269 to -26.10629, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8758 - acc: 0.1642 - val_loss: -26.1085 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.10629 to -26.10850, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8796 - acc: 0.1642 - val_loss: -26.1127 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.10850 to -26.11273, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.8759 - acc: 0.1642 - val_loss: -26.1072 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11273\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8768 - acc: 0.1642 - val_loss: -26.1079 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11273\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8775 - acc: 0.1642 - val_loss: -26.1088 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.11273\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8785 - acc: 0.1642 - val_loss: -26.1098 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.11273\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8791 - acc: 0.1642 - val_loss: -26.1099 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11273\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8792 - acc: 0.1642 - val_loss: -26.1101 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11273\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8794 - acc: 0.1642 - val_loss: -26.1103 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11273\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -7.1411 - acc: 0.1647 - val_loss: -24.4912 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.49116, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.3803 - acc: 0.1642 - val_loss: -24.7496 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.49116 to -24.74963, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -22.6174 - acc: 0.1642 - val_loss: -24.9600 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.74963 to -24.95996, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.8109 - acc: 0.1642 - val_loss: -25.1367 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.95996 to -25.13669, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.9744 - acc: 0.1642 - val_loss: -25.2878 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -25.13669 to -25.28784, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.1123 - acc: 0.1642 - val_loss: -25.4152 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -25.28784 to -25.41518, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.2353 - acc: 0.1642 - val_loss: -25.5287 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -25.41518 to -25.52866, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3443 - acc: 0.1642 - val_loss: -25.6243 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.52866 to -25.62430, saving model to model-1.h5\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4352 - acc: 0.1642 - val_loss: -25.7124 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.62430 to -25.71244, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.5185 - acc: 0.1642 - val_loss: -25.7916 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.71244 to -25.79158, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.5892 - acc: 0.1642 - val_loss: -25.8487 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.79158 to -25.84869, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.6476 - acc: 0.1642 - val_loss: -25.9084 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.84869 to -25.90837, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.6996 - acc: 0.1642 - val_loss: -25.9546 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.90837 to -25.95457, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.7401 - acc: 0.1642 - val_loss: -25.9880 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.95457 to -25.98795, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.7745 - acc: 0.1642 - val_loss: -26.0196 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.98795 to -26.01963, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.7992 - acc: 0.1642 - val_loss: -26.0434 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -26.01963 to -26.04340, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8230 - acc: 0.1642 - val_loss: -26.0657 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -26.04340 to -26.06569, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8294 - acc: 0.1642 - val_loss: -26.0681 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -26.06569 to -26.06808, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8452 - acc: 0.1642 - val_loss: -26.0773 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -26.06808 to -26.07728, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8536 - acc: 0.1642 - val_loss: -26.0929 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.07728 to -26.09290, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.8625 - acc: 0.1642 - val_loss: -26.0967 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.09290 to -26.09668, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8673 - acc: 0.1642 - val_loss: -26.1022 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.09668 to -26.10225, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8655 - acc: 0.1642 - val_loss: -26.0936 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -26.10225\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.8635 - acc: 0.1642 - val_loss: -26.0952 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -26.10225\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8651 - acc: 0.1642 - val_loss: -26.0968 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -26.10225\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8668 - acc: 0.1642 - val_loss: -26.0986 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -26.10225\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8679 - acc: 0.1642 - val_loss: -26.0988 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -26.10225\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8682 - acc: 0.1642 - val_loss: -26.0991 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -26.10225\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8685 - acc: 0.1642 - val_loss: -26.0994 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -26.10225\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8688 - acc: 0.1642 - val_loss: -26.0998 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -26.10225\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8691 - acc: 0.1642 - val_loss: -26.0999 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.10225\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8692 - acc: 0.1642 - val_loss: -26.1000 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -26.10225\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8692 - acc: 0.1642 - val_loss: -26.1001 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.10225\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8693 - acc: 0.1642 - val_loss: -26.1002 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.10225\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8695 - acc: 0.1642 - val_loss: -26.1003 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.10225\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8696 - acc: 0.1642 - val_loss: -26.1005 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -26.10225\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.8698 - acc: 0.1642 - val_loss: -26.1006 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.10225\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8700 - acc: 0.1642 - val_loss: -26.1009 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.10225\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8702 - acc: 0.1642 - val_loss: -26.1011 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.10225\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8704 - acc: 0.1642 - val_loss: -26.1013 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.10225\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -11.8918 - acc: 0.1633 - val_loss: -24.4180 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.41797, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.2656 - acc: 0.1642 - val_loss: -24.5541 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.41797 to -24.55407, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.3990 - acc: 0.1642 - val_loss: -24.6813 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.55407 to -24.68128, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.5227 - acc: 0.1642 - val_loss: -24.7925 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.68128 to -24.79254, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -22.6408 - acc: 0.1642 - val_loss: -24.9156 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.79254 to -24.91564, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.7514 - acc: 0.1642 - val_loss: -25.0263 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.91564 to -25.02634, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.8585 - acc: 0.1642 - val_loss: -25.1355 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -25.02634 to -25.13550, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.9695 - acc: 0.1642 - val_loss: -25.2434 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.13550 to -25.24337, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0744 - acc: 0.1642 - val_loss: -25.3501 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.24337 to -25.35010, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.1813 - acc: 0.1642 - val_loss: -25.4538 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.35010 to -25.45381, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.2833 - acc: 0.1642 - val_loss: -25.5543 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.45381 to -25.55430, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.3788 - acc: 0.1642 - val_loss: -25.6491 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.55430 to -25.64907, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.4706 - acc: 0.1642 - val_loss: -25.7368 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.64907 to -25.73678, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.5507 - acc: 0.1642 - val_loss: -25.8136 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.73678 to -25.81362, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.6138 - acc: 0.1642 - val_loss: -25.8713 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.81362 to -25.87125, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.6727 - acc: 0.1642 - val_loss: -25.9212 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.87125 to -25.92119, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.7177 - acc: 0.1642 - val_loss: -25.9658 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.92119 to -25.96581, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.7571 - acc: 0.1642 - val_loss: -25.9973 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.96581 to -25.99733, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.7856 - acc: 0.1642 - val_loss: -26.0250 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.99733 to -26.02503, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8111 - acc: 0.1642 - val_loss: -26.0440 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -26.02503 to -26.04396, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.8300 - acc: 0.1642 - val_loss: -26.0641 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.04396 to -26.06411, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8431 - acc: 0.1642 - val_loss: -26.0752 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.06411 to -26.07516, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.8527 - acc: 0.1642 - val_loss: -26.0876 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.07516 to -26.08756, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.7868 - acc: 0.1642 - val_loss: -26.0879 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.08756 to -26.08792, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8575 - acc: 0.1642 - val_loss: -26.0886 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.08792 to -26.08863, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.8582 - acc: 0.1642 - val_loss: -26.0894 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.08863 to -26.08938, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -23.8590 - acc: 0.1642 - val_loss: -26.0902 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.08938 to -26.09019, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8598 - acc: 0.1642 - val_loss: -26.0911 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.09019 to -26.09110, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8608 - acc: 0.1642 - val_loss: -26.0922 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.09110 to -26.09218, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8620 - acc: 0.1642 - val_loss: -26.0935 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.09218 to -26.09347, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8634 - acc: 0.1642 - val_loss: -26.0950 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.09347 to -26.09505, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8651 - acc: 0.1642 - val_loss: -26.0970 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.09505 to -26.09698, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.8674 - acc: 0.1642 - val_loss: -26.0967 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.09698\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8698 - acc: 0.1642 - val_loss: -26.0970 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -26.09698 to -26.09699, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8730 - acc: 0.1642 - val_loss: -26.0955 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.09699\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8741 - acc: 0.1642 - val_loss: -26.0994 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.09699 to -26.09943, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.8773 - acc: 0.1642 - val_loss: -26.1027 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.09943 to -26.10273, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8777 - acc: 0.1642 - val_loss: -26.1084 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss improved from -26.10273 to -26.10845, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8805 - acc: 0.1642 - val_loss: -26.1061 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.10845\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.8820 - acc: 0.1642 - val_loss: -26.1070 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.10845\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 10s 5ms/step - loss: -13.5275 - acc: 0.1624 - val_loss: -24.3656 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.36556, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -22.2323 - acc: 0.1642 - val_loss: -24.4869 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.36556 to -24.48693, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -22.3370 - acc: 0.1642 - val_loss: -24.5866 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.48693 to -24.58658, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.4440 - acc: 0.1642 - val_loss: -24.6908 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.58658 to -24.69082, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.5437 - acc: 0.1642 - val_loss: -24.7925 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.69082 to -24.79246, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.6443 - acc: 0.1642 - val_loss: -24.9012 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.79246 to -24.90121, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.7473 - acc: 0.1642 - val_loss: -25.0080 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.90121 to -25.00801, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.8555 - acc: 0.1642 - val_loss: -25.1141 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.00801 to -25.11410, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.9674 - acc: 0.1642 - val_loss: -25.2318 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.11410 to -25.23178, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.0794 - acc: 0.1642 - val_loss: -25.3462 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.23178 to -25.34619, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.1917 - acc: 0.1642 - val_loss: -25.4669 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.34619 to -25.46692, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 983us/step - loss: -23.2999 - acc: 0.1642 - val_loss: -25.5738 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.46692 to -25.57376, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4026 - acc: 0.1642 - val_loss: -25.6722 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.57376 to -25.67216, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4948 - acc: 0.1642 - val_loss: -25.7596 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.67216 to -25.75961, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -23.5803 - acc: 0.1642 - val_loss: -25.7796 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.75961 to -25.77959, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.6261 - acc: 0.1642 - val_loss: -25.8748 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.77959 to -25.87481, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.6728 - acc: 0.1642 - val_loss: -25.9140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.87481 to -25.91402, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.7134 - acc: 0.1642 - val_loss: -25.9499 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.91402 to -25.94991, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.7438 - acc: 0.1642 - val_loss: -25.9814 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.94991 to -25.98137, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.7754 - acc: 0.1642 - val_loss: -26.0066 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.98137 to -26.00664, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.7995 - acc: 0.1642 - val_loss: -26.0305 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.00664 to -26.03047, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8191 - acc: 0.1642 - val_loss: -26.0505 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.03047 to -26.05053, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8362 - acc: 0.1642 - val_loss: -26.0693 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.05053 to -26.06929, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8490 - acc: 0.1642 - val_loss: -26.0800 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.06929 to -26.07996, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.8601 - acc: 0.1642 - val_loss: -26.0874 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.07996 to -26.08739, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.8680 - acc: 0.1642 - val_loss: -26.0719 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -26.08739\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.8672 - acc: 0.1642 - val_loss: -26.0997 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.08739 to -26.09974, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.8756 - acc: 0.1642 - val_loss: -26.0988 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -26.09974\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8799 - acc: 0.1642 - val_loss: -26.1045 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.09974 to -26.10449, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 948us/step - loss: -23.8433 - acc: 0.1642 - val_loss: -26.1065 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.10449 to -26.10645, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8758 - acc: 0.1642 - val_loss: -26.1068 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.10645 to -26.10679, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8762 - acc: 0.1642 - val_loss: -26.1072 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.10679 to -26.10717, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.8766 - acc: 0.1642 - val_loss: -26.1076 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.10717 to -26.10759, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8770 - acc: 0.1642 - val_loss: -26.1081 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -26.10759 to -26.10810, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.8776 - acc: 0.1642 - val_loss: -26.1087 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -26.10810 to -26.10872, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8783 - acc: 0.1642 - val_loss: -26.1095 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.10872 to -26.10947, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8791 - acc: 0.1642 - val_loss: -26.1104 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss improved from -26.10947 to -26.11041, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.8801 - acc: 0.1642 - val_loss: -26.1087 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11041\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.8814 - acc: 0.1642 - val_loss: -26.1084 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11041\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8830 - acc: 0.1642 - val_loss: -26.1075 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11041\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -14.3669 - acc: 0.1614 - val_loss: -24.4345 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.43454, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -22.2915 - acc: 0.1642 - val_loss: -24.5553 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.43454 to -24.55531, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.4050 - acc: 0.1642 - val_loss: -24.6650 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.55531 to -24.66495, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -22.5121 - acc: 0.1642 - val_loss: -24.7706 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.66495 to -24.77062, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.6147 - acc: 0.1642 - val_loss: -24.8742 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.77062 to -24.87423, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.7210 - acc: 0.1642 - val_loss: -24.9774 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.87423 to -24.97738, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.8247 - acc: 0.1642 - val_loss: -25.0813 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.97738 to -25.08134, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.9268 - acc: 0.1642 - val_loss: -25.1862 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -25.08134 to -25.18619, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.0310 - acc: 0.1642 - val_loss: -25.2912 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.18619 to -25.29122, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.1351 - acc: 0.1642 - val_loss: -25.3958 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.29122 to -25.39577, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.2371 - acc: 0.1642 - val_loss: -25.4973 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.39577 to -25.49731, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.3367 - acc: 0.1642 - val_loss: -25.6032 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.49731 to -25.60318, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.4311 - acc: 0.1642 - val_loss: -25.6842 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.60318 to -25.68415, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.5141 - acc: 0.1642 - val_loss: -25.7713 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.68415 to -25.77131, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.5889 - acc: 0.1642 - val_loss: -25.8408 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.77131 to -25.84084, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.6523 - acc: 0.1642 - val_loss: -25.8978 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.84084 to -25.89777, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.7056 - acc: 0.1642 - val_loss: -25.9482 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.89777 to -25.94824, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.7494 - acc: 0.1642 - val_loss: -25.9851 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.94824 to -25.98510, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.7805 - acc: 0.1642 - val_loss: -25.9982 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.98510 to -25.99820, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8057 - acc: 0.1642 - val_loss: -26.0345 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.99820 to -26.03446, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8284 - acc: 0.1642 - val_loss: -26.0545 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.03446 to -26.05455, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8449 - acc: 0.1642 - val_loss: -26.0703 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.05455 to -26.07026, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.8572 - acc: 0.1642 - val_loss: -26.0799 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.07026 to -26.07987, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8673 - acc: 0.1642 - val_loss: -26.0899 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.07987 to -26.08985, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8728 - acc: 0.1642 - val_loss: -26.0968 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.08985 to -26.09681, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8756 - acc: 0.1642 - val_loss: -26.1030 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.09681 to -26.10304, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8766 - acc: 0.1642 - val_loss: -26.1052 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.10304 to -26.10521, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8762 - acc: 0.1642 - val_loss: -26.1091 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.10521 to -26.10906, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8799 - acc: 0.1642 - val_loss: -26.1096 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.10906 to -26.10964, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.8836 - acc: 0.1642 - val_loss: -26.1063 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -26.10964\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8856 - acc: 0.1642 - val_loss: -26.1089 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -26.10964\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.8721 - acc: 0.1642 - val_loss: -26.1134 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.10964 to -26.11339, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -23.8828 - acc: 0.1642 - val_loss: -26.1137 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss improved from -26.11339 to -26.11369, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -23.8831 - acc: 0.1642 - val_loss: -26.1140 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss improved from -26.11369 to -26.11402, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.8834 - acc: 0.1642 - val_loss: -26.1144 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss improved from -26.11402 to -26.11440, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8838 - acc: 0.1642 - val_loss: -26.1149 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.11440 to -26.11486, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.8843 - acc: 0.1642 - val_loss: -26.1126 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.11486\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8850 - acc: 0.1642 - val_loss: -26.1132 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11486\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8857 - acc: 0.1642 - val_loss: -26.1124 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11486\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.8867 - acc: 0.1642 - val_loss: -26.1102 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11486\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -14.5021 - acc: 0.1684 - val_loss: -24.4014 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -24.40137, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.2263 - acc: 0.1642 - val_loss: -24.4826 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00002: val_loss improved from -24.40137 to -24.48258, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -22.3079 - acc: 0.1642 - val_loss: -24.5631 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00003: val_loss improved from -24.48258 to -24.56310, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -22.3896 - acc: 0.1642 - val_loss: -24.6444 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.56310 to -24.64441, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.4714 - acc: 0.1642 - val_loss: -24.7280 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.64441 to -24.72799, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -22.5582 - acc: 0.1642 - val_loss: -24.8152 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.72799 to -24.81522, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.6480 - acc: 0.1642 - val_loss: -24.9073 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.81522 to -24.90734, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -22.7422 - acc: 0.1642 - val_loss: -25.0049 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.90734 to -25.00490, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.8432 - acc: 0.1642 - val_loss: -25.1081 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00009: val_loss improved from -25.00490 to -25.10811, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.9467 - acc: 0.1642 - val_loss: -25.2158 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00010: val_loss improved from -25.10811 to -25.21585, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.0572 - acc: 0.1642 - val_loss: -25.3260 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00011: val_loss improved from -25.21585 to -25.32602, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.1667 - acc: 0.1642 - val_loss: -25.4361 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00012: val_loss improved from -25.32602 to -25.43605, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.2749 - acc: 0.1642 - val_loss: -25.5425 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.43605 to -25.54253, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.3798 - acc: 0.1642 - val_loss: -25.6427 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.54253 to -25.64269, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.4771 - acc: 0.1642 - val_loss: -25.7122 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.64269 to -25.71217, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.5578 - acc: 0.1642 - val_loss: -25.8130 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.71217 to -25.81305, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.6321 - acc: 0.1642 - val_loss: -25.8698 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.81305 to -25.86977, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.6846 - acc: 0.1642 - val_loss: -25.9270 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.86977 to -25.92697, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.7366 - acc: 0.1642 - val_loss: -25.9681 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.92697 to -25.96812, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.7703 - acc: 0.1642 - val_loss: -26.0028 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.96812 to -26.00278, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.7996 - acc: 0.1642 - val_loss: -26.0285 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00021: val_loss improved from -26.00278 to -26.02847, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.8205 - acc: 0.1642 - val_loss: -26.0477 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00022: val_loss improved from -26.02847 to -26.04769, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8327 - acc: 0.1642 - val_loss: -26.0580 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00023: val_loss improved from -26.04769 to -26.05805, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8478 - acc: 0.1642 - val_loss: -26.0682 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00024: val_loss improved from -26.05805 to -26.06817, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8580 - acc: 0.1642 - val_loss: -26.0762 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00025: val_loss improved from -26.06817 to -26.07624, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8651 - acc: 0.1642 - val_loss: -26.0829 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00026: val_loss improved from -26.07624 to -26.08294, saving model to model-5.h5\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8707 - acc: 0.1642 - val_loss: -26.0887 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00027: val_loss improved from -26.08294 to -26.08866, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.8726 - acc: 0.1642 - val_loss: -26.0943 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from -26.08866 to -26.09435, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.8772 - acc: 0.1642 - val_loss: -26.0988 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00029: val_loss improved from -26.09435 to -26.09885, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8805 - acc: 0.1642 - val_loss: -26.1012 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00030: val_loss improved from -26.09885 to -26.10120, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.8825 - acc: 0.1642 - val_loss: -26.1040 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00031: val_loss improved from -26.10120 to -26.10404, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8824 - acc: 0.1642 - val_loss: -26.1109 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00032: val_loss improved from -26.10404 to -26.11091, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8817 - acc: 0.1642 - val_loss: -26.1097 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -26.11091\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.8848 - acc: 0.1642 - val_loss: -26.1069 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -26.11091\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.8880 - acc: 0.1642 - val_loss: -26.1058 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -26.11091\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.8873 - acc: 0.1642 - val_loss: -26.1127 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00036: val_loss improved from -26.11091 to -26.11268, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.8857 - acc: 0.1642 - val_loss: -26.1110 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -26.11268\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.8878 - acc: 0.1642 - val_loss: -26.1085 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -26.11268\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.8903 - acc: 0.1642 - val_loss: -26.0948 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -26.11268\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.8880 - acc: 0.1642 - val_loss: -26.1116 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -26.11268\n",
      "Text informations:\n",
      "max length: 98 / min length: 3 / mean length: 13 / limit length: 100\n",
      "vocabulary size: 2185 / limit: 2700\n",
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -9.1872 - acc: 0.1647 - val_loss: -23.4556 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.45556, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.4535 - acc: 0.1605 - val_loss: -23.6131 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.45556 to -23.61314, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -22.5504 - acc: 0.1605 - val_loss: -23.7104 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.61314 to -23.71037, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.6476 - acc: 0.1605 - val_loss: -23.8071 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.71037 to -23.80711, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -22.7457 - acc: 0.1605 - val_loss: -23.9071 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.80711 to -23.90712, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.8476 - acc: 0.1605 - val_loss: -24.0120 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.90712 to -24.01201, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.9544 - acc: 0.1605 - val_loss: -24.1100 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.01201 to -24.11003, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.0638 - acc: 0.1605 - val_loss: -24.2330 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.11003 to -24.23298, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.1791 - acc: 0.1605 - val_loss: -24.3504 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.23298 to -24.35039, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.2970 - acc: 0.1605 - val_loss: -24.4686 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.35039 to -24.46857, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.4128 - acc: 0.1605 - val_loss: -24.5827 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.46857 to -24.58267, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.5253 - acc: 0.1605 - val_loss: -24.6906 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.58267 to -24.69060, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.6327 - acc: 0.1605 - val_loss: -24.7920 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.69060 to -24.79203, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.7304 - acc: 0.1605 - val_loss: -24.8805 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.79203 to -24.88050, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.8137 - acc: 0.1605 - val_loss: -24.9657 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.88050 to -24.96565, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8871 - acc: 0.1605 - val_loss: -25.0294 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.96565 to -25.02940, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.9497 - acc: 0.1605 - val_loss: -25.0864 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.02940 to -25.08635, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -24.0006 - acc: 0.1605 - val_loss: -25.1274 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.08635 to -25.12736, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.0396 - acc: 0.1605 - val_loss: -25.1554 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.12736 to -25.15541, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.0648 - acc: 0.1605 - val_loss: -25.1883 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.15541 to -25.18832, saving model to model-1.h5\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.0920 - acc: 0.1605 - val_loss: -25.2058 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.18832 to -25.20577, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1086 - acc: 0.1605 - val_loss: -25.2241 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.20577 to -25.22405, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.1214 - acc: 0.1605 - val_loss: -25.2359 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.22405 to -25.23589, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1312 - acc: 0.1605 - val_loss: -25.2424 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.23589 to -25.24238, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1380 - acc: 0.1605 - val_loss: -25.2474 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.24238 to -25.24745, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1441 - acc: 0.1605 - val_loss: -25.2523 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.24745 to -25.25234, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1450 - acc: 0.1605 - val_loss: -25.2487 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.25234\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1449 - acc: 0.1605 - val_loss: -25.2536 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.25234 to -25.25364, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -24.1494 - acc: 0.1605 - val_loss: -25.2577 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.25364 to -25.25768, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1530 - acc: 0.1605 - val_loss: -25.2550 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -25.25768\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1507 - acc: 0.1605 - val_loss: -25.2589 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.25768 to -25.25886, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1539 - acc: 0.1605 - val_loss: -25.2579 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.25886\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1536 - acc: 0.1605 - val_loss: -25.2617 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.25886 to -25.26173, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1548 - acc: 0.1605 - val_loss: -25.2587 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.26173\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1539 - acc: 0.1605 - val_loss: -25.2615 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.26173\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1565 - acc: 0.1605 - val_loss: -25.2637 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -25.26173 to -25.26375, saving model to model-1.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.1562 - acc: 0.1605 - val_loss: -25.2635 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.26375\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1563 - acc: 0.1605 - val_loss: -25.2621 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.26375\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1574 - acc: 0.1605 - val_loss: -25.2649 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.26375 to -25.26488, saving model to model-1.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1558 - acc: 0.1605 - val_loss: -25.2619 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.26488\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -12.2286 - acc: 0.1619 - val_loss: -23.5495 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.54948, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.4762 - acc: 0.1605 - val_loss: -23.6228 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.54948 to -23.62283, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.5496 - acc: 0.1605 - val_loss: -23.6965 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.62283 to -23.69650, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.6246 - acc: 0.1605 - val_loss: -23.7734 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.69650 to -23.77343, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.7030 - acc: 0.1605 - val_loss: -23.8533 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.77343 to -23.85334, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.7857 - acc: 0.1605 - val_loss: -23.9401 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.85334 to -23.94011, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.8755 - acc: 0.1605 - val_loss: -24.0350 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.94011 to -24.03496, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.9726 - acc: 0.1605 - val_loss: -24.1368 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.03496 to -24.13676, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.0792 - acc: 0.1605 - val_loss: -24.2465 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.13676 to -24.24651, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.1916 - acc: 0.1605 - val_loss: -24.3621 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.24651 to -24.36213, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -23.3049 - acc: 0.1605 - val_loss: -24.4727 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.36213 to -24.47266, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.4191 - acc: 0.1605 - val_loss: -24.5884 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.47266 to -24.58842, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 987us/step - loss: -23.5333 - acc: 0.1605 - val_loss: -24.6923 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.58842 to -24.69233, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.6344 - acc: 0.1605 - val_loss: -24.7980 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.69233 to -24.79798, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -23.7343 - acc: 0.1605 - val_loss: -24.8901 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.79798 to -24.89006, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.8200 - acc: 0.1605 - val_loss: -24.9652 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.89006 to -24.96524, saving model to model-2.h5\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.8931 - acc: 0.1605 - val_loss: -25.0309 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.96524 to -25.03092, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.9532 - acc: 0.1605 - val_loss: -25.0915 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.03092 to -25.09148, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.9990 - acc: 0.1605 - val_loss: -25.1293 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.09148 to -25.12930, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.0404 - acc: 0.1605 - val_loss: -25.1603 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.12930 to -25.16027, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.0693 - acc: 0.1605 - val_loss: -25.1913 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.16027 to -25.19128, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.0937 - acc: 0.1605 - val_loss: -25.2116 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.19128 to -25.21162, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.1037 - acc: 0.1605 - val_loss: -25.2162 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.21162 to -25.21617, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1162 - acc: 0.1605 - val_loss: -25.2294 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.21617 to -25.22937, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 997us/step - loss: -24.1275 - acc: 0.1605 - val_loss: -25.2380 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.22937 to -25.23799, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1328 - acc: 0.1605 - val_loss: -25.2436 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.23799 to -25.24360, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1378 - acc: 0.1605 - val_loss: -25.2467 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.24360 to -25.24672, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1434 - acc: 0.1605 - val_loss: -25.2440 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -25.24672\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1406 - acc: 0.1605 - val_loss: -25.2498 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.24672 to -25.24985, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.1460 - acc: 0.1605 - val_loss: -25.2547 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.24985 to -25.25473, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1502 - acc: 0.1605 - val_loss: -25.2577 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.25473 to -25.25771, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1517 - acc: 0.1605 - val_loss: -25.2595 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.25771 to -25.25955, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1529 - acc: 0.1605 - val_loss: -25.2612 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.25955 to -25.26120, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1515 - acc: 0.1605 - val_loss: -25.2587 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.26120\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1543 - acc: 0.1605 - val_loss: -25.2622 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.26120 to -25.26223, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.1204 - acc: 0.1605 - val_loss: -25.2565 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.26223\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1506 - acc: 0.1605 - val_loss: -25.2568 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.26223\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1508 - acc: 0.1605 - val_loss: -25.2570 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.26223\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1511 - acc: 0.1605 - val_loss: -25.2573 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.26223\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1512 - acc: 0.1605 - val_loss: -25.2573 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.26223\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -14.9105 - acc: 0.1610 - val_loss: -23.5586 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.55864, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.4846 - acc: 0.1605 - val_loss: -23.6300 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.55864 to -23.62997, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.5560 - acc: 0.1605 - val_loss: -23.7025 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.62997 to -23.70253, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.6302 - acc: 0.1605 - val_loss: -23.7781 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.70253 to -23.77808, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.7071 - acc: 0.1605 - val_loss: -23.8579 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.77808 to -23.85789, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.7896 - acc: 0.1605 - val_loss: -23.9438 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.85789 to -23.94379, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 999us/step - loss: -22.8789 - acc: 0.1605 - val_loss: -24.0363 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.94379 to -24.03630, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -22.9743 - acc: 0.1605 - val_loss: -24.1362 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.03630 to -24.13618, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.0771 - acc: 0.1605 - val_loss: -24.2433 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.13618 to -24.24325, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.1883 - acc: 0.1605 - val_loss: -24.3583 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.24325 to -24.35829, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.3039 - acc: 0.1605 - val_loss: -24.4740 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.35829 to -24.47395, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.4195 - acc: 0.1605 - val_loss: -24.5888 - val_acc: 0.1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss improved from -24.47395 to -24.58882, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.5330 - acc: 0.1605 - val_loss: -24.7009 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.58882 to -24.70085, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.6391 - acc: 0.1605 - val_loss: -24.7996 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.70085 to -24.79964, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.7366 - acc: 0.1605 - val_loss: -24.8933 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.79964 to -24.89329, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8228 - acc: 0.1605 - val_loss: -24.9724 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.89329 to -24.97244, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8930 - acc: 0.1605 - val_loss: -25.0295 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.97244 to -25.02950, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.9498 - acc: 0.1605 - val_loss: -25.0863 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.02950 to -25.08632, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.0003 - acc: 0.1605 - val_loss: -25.1296 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.08632 to -25.12960, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.0380 - acc: 0.1605 - val_loss: -25.1582 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.12960 to -25.15820, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.0673 - acc: 0.1605 - val_loss: -25.1906 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.15820 to -25.19062, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.0888 - acc: 0.1605 - val_loss: -25.2057 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.19062 to -25.20567, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1083 - acc: 0.1605 - val_loss: -25.2223 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.20567 to -25.22234, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1207 - acc: 0.1605 - val_loss: -25.2262 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.22234 to -25.22624, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1254 - acc: 0.1605 - val_loss: -25.2376 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.22624 to -25.23756, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1357 - acc: 0.1605 - val_loss: -25.2466 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.23756 to -25.24659, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1422 - acc: 0.1605 - val_loss: -25.2501 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.24659 to -25.25013, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1459 - acc: 0.1605 - val_loss: -25.2543 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.25013 to -25.25432, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1284 - acc: 0.1605 - val_loss: -25.2493 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -25.25432\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1434 - acc: 0.1605 - val_loss: -25.2498 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -25.25432\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1439 - acc: 0.1605 - val_loss: -25.2503 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -25.25432\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1445 - acc: 0.1605 - val_loss: -25.2509 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.25432\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1449 - acc: 0.1605 - val_loss: -25.2510 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.25432\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1449 - acc: 0.1605 - val_loss: -25.2511 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.25432\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1450 - acc: 0.1605 - val_loss: -25.2512 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.25432\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1452 - acc: 0.1605 - val_loss: -25.2513 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25432\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1453 - acc: 0.1605 - val_loss: -25.2514 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25432\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1453 - acc: 0.1605 - val_loss: -25.2514 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.25432\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1453 - acc: 0.1605 - val_loss: -25.2514 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.25432\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1454 - acc: 0.1605 - val_loss: -25.2515 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.25432\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -15.5925 - acc: 0.1610 - val_loss: -23.5804 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.58042, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.5053 - acc: 0.1605 - val_loss: -23.6494 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.58042 to -23.64941, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.5743 - acc: 0.1605 - val_loss: -23.7200 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.64941 to -23.72002, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.6470 - acc: 0.1605 - val_loss: -23.7948 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.72002 to -23.79483, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.7239 - acc: 0.1605 - val_loss: -23.8743 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.79483 to -23.87427, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -22.8060 - acc: 0.1605 - val_loss: -23.9601 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.87427 to -23.96008, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.8945 - acc: 0.1605 - val_loss: -24.0525 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.96008 to -24.05248, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.9911 - acc: 0.1605 - val_loss: -24.1537 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.05248 to -24.15371, saving model to model-4.h5\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0950 - acc: 0.1605 - val_loss: -24.2592 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.15371 to -24.25921, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2029 - acc: 0.1605 - val_loss: -24.3712 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.25921 to -24.37120, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.3152 - acc: 0.1605 - val_loss: -24.4826 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.37120 to -24.48257, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.4275 - acc: 0.1605 - val_loss: -24.5959 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.48257 to -24.59589, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.5373 - acc: 0.1605 - val_loss: -24.7019 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.59589 to -24.70185, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.6422 - acc: 0.1605 - val_loss: -24.7985 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.70185 to -24.79852, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.7351 - acc: 0.1605 - val_loss: -24.8918 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.79852 to -24.89184, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8224 - acc: 0.1605 - val_loss: -24.9690 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.89184 to -24.96903, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.8926 - acc: 0.1605 - val_loss: -25.0350 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.96903 to -25.03502, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.9553 - acc: 0.1605 - val_loss: -25.0902 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.03502 to -25.09024, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.0058 - acc: 0.1605 - val_loss: -25.1349 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.09024 to -25.13487, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0397 - acc: 0.1605 - val_loss: -25.1543 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.13487 to -25.15427, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.0570 - acc: 0.1605 - val_loss: -25.1734 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.15427 to -25.17342, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.0751 - acc: 0.1605 - val_loss: -25.1903 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.17342 to -25.19029, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.0911 - acc: 0.1605 - val_loss: -25.2054 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.19029 to -25.20537, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1048 - acc: 0.1605 - val_loss: -25.2171 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.20537 to -25.21714, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1152 - acc: 0.1605 - val_loss: -25.2268 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.21714 to -25.22677, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1228 - acc: 0.1605 - val_loss: -25.2342 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.22677 to -25.23418, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1292 - acc: 0.1605 - val_loss: -25.2340 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.23418\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1287 - acc: 0.1605 - val_loss: -25.2357 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.23418 to -25.23573, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1305 - acc: 0.1605 - val_loss: -25.2376 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.23573 to -25.23756, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.1324 - acc: 0.1605 - val_loss: -25.2395 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.23756 to -25.23955, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1344 - acc: 0.1605 - val_loss: -25.2418 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.23955 to -25.24176, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1368 - acc: 0.1605 - val_loss: -25.2443 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.24176 to -25.24427, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1394 - acc: 0.1605 - val_loss: -25.2471 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.24427 to -25.24710, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1424 - acc: 0.1605 - val_loss: -25.2502 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.24710 to -25.25022, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1443 - acc: 0.1605 - val_loss: -25.2512 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.25022 to -25.25117, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1468 - acc: 0.1605 - val_loss: -25.2549 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -25.25117 to -25.25487, saving model to model-4.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1482 - acc: 0.1605 - val_loss: -25.2538 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25487\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1497 - acc: 0.1605 - val_loss: -25.2581 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.25487 to -25.25812, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1529 - acc: 0.1605 - val_loss: -25.2606 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.25812 to -25.26061, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1504 - acc: 0.1605 - val_loss: -25.2579 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.26061\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -14.7644 - acc: 0.1651 - val_loss: -23.5649 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.56488, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.4881 - acc: 0.1605 - val_loss: -23.6305 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.56488 to -23.63048, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.5530 - acc: 0.1605 - val_loss: -23.6978 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.63048 to -23.69776, saving model to model-5.h5\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.6221 - acc: 0.1605 - val_loss: -23.7679 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.69776 to -23.76789, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.6953 - acc: 0.1605 - val_loss: -23.8436 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.76789 to -23.84359, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -22.7713 - acc: 0.1605 - val_loss: -23.9252 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.84359 to -23.92520, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.8586 - acc: 0.1605 - val_loss: -24.0148 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.92520 to -24.01481, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.9518 - acc: 0.1605 - val_loss: -24.1127 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.01481 to -24.11269, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.0538 - acc: 0.1605 - val_loss: -24.2192 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.11269 to -24.21922, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.1621 - acc: 0.1605 - val_loss: -24.3307 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.21922 to -24.33067, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.2740 - acc: 0.1605 - val_loss: -24.4428 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.33067 to -24.44282, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.3863 - acc: 0.1605 - val_loss: -24.5539 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.44282 to -24.55394, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.4984 - acc: 0.1605 - val_loss: -24.6659 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.55394 to -24.66587, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.6012 - acc: 0.1605 - val_loss: -24.7640 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.66587 to -24.76404, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.7019 - acc: 0.1605 - val_loss: -24.8603 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.76404 to -24.86030, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.7921 - acc: 0.1605 - val_loss: -24.9394 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.86030 to -24.93942, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8680 - acc: 0.1605 - val_loss: -25.0128 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.93942 to -25.01280, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.9320 - acc: 0.1605 - val_loss: -25.0700 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.01280 to -25.06997, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.9852 - acc: 0.1605 - val_loss: -25.1169 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.06997 to -25.11691, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.0256 - acc: 0.1605 - val_loss: -25.1427 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.11691 to -25.14266, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0486 - acc: 0.1605 - val_loss: -25.1687 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.14266 to -25.16871, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.0728 - acc: 0.1605 - val_loss: -25.1907 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.16871 to -25.19067, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -24.0932 - acc: 0.1605 - val_loss: -25.2092 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.19067 to -25.20923, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1065 - acc: 0.1605 - val_loss: -25.2210 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.20923 to -25.22102, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1205 - acc: 0.1605 - val_loss: -25.2286 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.22102 to -25.22862, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1283 - acc: 0.1605 - val_loss: -25.2409 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.22862 to -25.24089, saving model to model-5.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1324 - acc: 0.1605 - val_loss: -25.2383 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.24089\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1346 - acc: 0.1605 - val_loss: -25.2434 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.24089 to -25.24345, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1395 - acc: 0.1605 - val_loss: -25.2482 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.24345 to -25.24818, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.1441 - acc: 0.1605 - val_loss: -25.2526 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.24818 to -25.25257, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1472 - acc: 0.1605 - val_loss: -25.2547 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.25257 to -25.25474, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1413 - acc: 0.1605 - val_loss: -25.2510 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.25474\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1451 - acc: 0.1605 - val_loss: -25.2515 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.25474\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1456 - acc: 0.1605 - val_loss: -25.2520 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.25474\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1462 - acc: 0.1605 - val_loss: -25.2526 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.25474\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1465 - acc: 0.1605 - val_loss: -25.2527 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25474\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1466 - acc: 0.1605 - val_loss: -25.2528 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25474\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1467 - acc: 0.1605 - val_loss: -25.2529 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.25474\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1469 - acc: 0.1605 - val_loss: -25.2530 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.25474\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -24.1470 - acc: 0.1605 - val_loss: -25.2530 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.25474\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -8.7599 - acc: 0.1601 - val_loss: -23.5951 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.59510, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.5864 - acc: 0.1605 - val_loss: -23.8074 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.59510 to -23.80739, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.7842 - acc: 0.1605 - val_loss: -23.9891 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.80739 to -23.98912, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.9535 - acc: 0.1605 - val_loss: -24.1419 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.98912 to -24.14188, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.1008 - acc: 0.1605 - val_loss: -24.2844 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.14188 to -24.28444, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.2347 - acc: 0.1605 - val_loss: -24.4087 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.28444 to -24.40867, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.3552 - acc: 0.1605 - val_loss: -24.5224 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.40867 to -24.52243, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.4623 - acc: 0.1605 - val_loss: -24.6253 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.52243 to -24.62532, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.5642 - acc: 0.1605 - val_loss: -24.7225 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.62532 to -24.72250, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.6564 - acc: 0.1605 - val_loss: -24.8123 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.72250 to -24.81231, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.7410 - acc: 0.1605 - val_loss: -24.8883 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.81231 to -24.88830, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.8162 - acc: 0.1605 - val_loss: -24.9629 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.88830 to -24.96287, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.8841 - acc: 0.1605 - val_loss: -25.0237 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.96287 to -25.02367, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.9374 - acc: 0.1605 - val_loss: -25.0736 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.02367 to -25.07357, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.9859 - acc: 0.1605 - val_loss: -25.1150 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.07357 to -25.11504, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.0206 - acc: 0.1605 - val_loss: -25.1421 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.11504 to -25.14214, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0519 - acc: 0.1605 - val_loss: -25.1761 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.14214 to -25.17612, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.0732 - acc: 0.1605 - val_loss: -25.1939 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.17612 to -25.19385, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.0924 - acc: 0.1605 - val_loss: -25.2020 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.19385 to -25.20196, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1057 - acc: 0.1605 - val_loss: -25.2228 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.20196 to -25.22278, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1169 - acc: 0.1605 - val_loss: -25.2318 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.22278 to -25.23181, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1234 - acc: 0.1605 - val_loss: -25.2302 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -25.23181\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1291 - acc: 0.1605 - val_loss: -25.2409 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.23181 to -25.24085, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1347 - acc: 0.1605 - val_loss: -25.2377 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -25.24085\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1348 - acc: 0.1605 - val_loss: -25.2446 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.24085 to -25.24461, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1413 - acc: 0.1605 - val_loss: -25.2505 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.24461 to -25.25051, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1446 - acc: 0.1605 - val_loss: -25.2503 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.25051\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1462 - acc: 0.1605 - val_loss: -25.2518 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.25051 to -25.25184, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 998us/step - loss: -24.1479 - acc: 0.1605 - val_loss: -25.2555 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.25184 to -25.25554, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1494 - acc: 0.1605 - val_loss: -25.2567 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.25554 to -25.25669, saving model to model-1.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1504 - acc: 0.1605 - val_loss: -25.2566 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -25.25669\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1527 - acc: 0.1605 - val_loss: -25.2393 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.25669\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1422 - acc: 0.1605 - val_loss: -25.2531 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.25669\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1473 - acc: 0.1605 - val_loss: -25.2537 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.25669\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1476 - acc: 0.1605 - val_loss: -25.2538 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.25669\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1477 - acc: 0.1605 - val_loss: -25.2538 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25669\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1478 - acc: 0.1605 - val_loss: -25.2539 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25669\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1479 - acc: 0.1605 - val_loss: -25.2541 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.25669\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1480 - acc: 0.1605 - val_loss: -25.2541 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.25669\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.1480 - acc: 0.1605 - val_loss: -25.2541 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.25669\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 10s 5ms/step - loss: -12.2626 - acc: 0.1624 - val_loss: -23.6204 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.62042, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.5769 - acc: 0.1605 - val_loss: -23.7590 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.62042 to -23.75902, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.7106 - acc: 0.1605 - val_loss: -23.8858 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.75902 to -23.88583, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -22.8347 - acc: 0.1605 - val_loss: -24.0071 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.88583 to -24.00715, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -22.9530 - acc: 0.1605 - val_loss: -24.1226 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.00715 to -24.12261, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.0655 - acc: 0.1605 - val_loss: -24.2317 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.12261 to -24.23173, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.1749 - acc: 0.1605 - val_loss: -24.3413 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.23173 to -24.34129, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.2827 - acc: 0.1605 - val_loss: -24.4469 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.34129 to -24.44685, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.3875 - acc: 0.1605 - val_loss: -24.5508 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.44685 to -24.55080, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.4896 - acc: 0.1605 - val_loss: -24.6476 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.55080 to -24.64758, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.5871 - acc: 0.1605 - val_loss: -24.7482 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.64758 to -24.74823, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.6818 - acc: 0.1605 - val_loss: -24.8382 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.74823 to -24.83821, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.7677 - acc: 0.1605 - val_loss: -24.9201 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.83821 to -24.92008, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.8433 - acc: 0.1605 - val_loss: -24.9882 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.92008 to -24.98823, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.9114 - acc: 0.1605 - val_loss: -25.0525 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.98823 to -25.05253, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.9649 - acc: 0.1605 - val_loss: -25.0894 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.05253 to -25.08941, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0037 - acc: 0.1605 - val_loss: -25.1331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.08941 to -25.13314, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.0422 - acc: 0.1605 - val_loss: -25.1655 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.13314 to -25.16546, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0641 - acc: 0.1605 - val_loss: -25.1846 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.16546 to -25.18458, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.0866 - acc: 0.1605 - val_loss: -25.2001 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.18458 to -25.20011, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1039 - acc: 0.1605 - val_loss: -25.2110 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.20011 to -25.21099, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1029 - acc: 0.1605 - val_loss: -25.2120 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.21099 to -25.21198, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1079 - acc: 0.1605 - val_loss: -25.2164 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.21198 to -25.21639, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1123 - acc: 0.1605 - val_loss: -25.2209 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.21639 to -25.22089, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1169 - acc: 0.1605 - val_loss: -25.2256 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.22089 to -25.22562, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1218 - acc: 0.1605 - val_loss: -25.2307 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.22562 to -25.23067, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1270 - acc: 0.1605 - val_loss: -25.2361 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.23067 to -25.23606, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1278 - acc: 0.1605 - val_loss: -25.2325 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -25.23606\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1284 - acc: 0.1605 - val_loss: -25.2370 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.23606 to -25.23698, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1330 - acc: 0.1605 - val_loss: -25.2416 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.23698 to -25.24158, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1376 - acc: 0.1605 - val_loss: -25.2463 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.24158 to -25.24629, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1394 - acc: 0.1605 - val_loss: -25.2454 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.24629\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.1419 - acc: 0.1605 - val_loss: -25.2510 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.24629 to -25.25101, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1448 - acc: 0.1605 - val_loss: -25.2535 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.25101 to -25.25354, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1468 - acc: 0.1605 - val_loss: -25.2545 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.25354 to -25.25449, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1469 - acc: 0.1605 - val_loss: -25.2508 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25449\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -24.1466 - acc: 0.1605 - val_loss: -25.2550 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -25.25449 to -25.25495, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1506 - acc: 0.1605 - val_loss: -25.2586 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.25495 to -25.25861, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1506 - acc: 0.1605 - val_loss: -25.2543 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.25861\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1497 - acc: 0.1605 - val_loss: -25.2576 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.25861\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -13.8280 - acc: 0.1614 - val_loss: -23.6187 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.61867, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.5696 - acc: 0.1605 - val_loss: -23.7435 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.61867 to -23.74352, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.6898 - acc: 0.1605 - val_loss: -23.8597 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.74352 to -23.85970, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.8023 - acc: 0.1605 - val_loss: -23.9680 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.85970 to -23.96801, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.9088 - acc: 0.1605 - val_loss: -24.0713 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.96801 to -24.07130, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0109 - acc: 0.1605 - val_loss: -24.1731 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.07130 to -24.17308, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.1114 - acc: 0.1605 - val_loss: -24.2716 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.17308 to -24.27164, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.2107 - acc: 0.1605 - val_loss: -24.3716 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.27164 to -24.37165, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.3095 - acc: 0.1605 - val_loss: -24.4697 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.37165 to -24.46967, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4070 - acc: 0.1605 - val_loss: -24.5683 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.46967 to -24.56828, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.5050 - acc: 0.1605 - val_loss: -24.6637 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.56828 to -24.66369, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.5991 - acc: 0.1605 - val_loss: -24.7533 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.66369 to -24.75327, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -23.6880 - acc: 0.1605 - val_loss: -24.8432 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.75327 to -24.84323, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.7731 - acc: 0.1605 - val_loss: -24.9231 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.84323 to -24.92311, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.8476 - acc: 0.1605 - val_loss: -24.9918 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.92311 to -24.99181, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.9119 - acc: 0.1605 - val_loss: -25.0532 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.99181 to -25.05315, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.9672 - acc: 0.1605 - val_loss: -25.0813 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.05315 to -25.08127, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.9840 - acc: 0.1605 - val_loss: -25.1007 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.08127 to -25.10070, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.0030 - acc: 0.1605 - val_loss: -25.1193 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.10070 to -25.11929, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.0214 - acc: 0.1605 - val_loss: -25.1375 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.11929 to -25.13750, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.0396 - acc: 0.1605 - val_loss: -25.1556 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.13750 to -25.15565, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0573 - acc: 0.1605 - val_loss: -25.1724 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.15565 to -25.17243, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.0729 - acc: 0.1605 - val_loss: -25.1878 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.17243 to -25.18776, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0885 - acc: 0.1605 - val_loss: -25.2039 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.18776 to -25.20392, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.0970 - acc: 0.1605 - val_loss: -25.2097 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.20392 to -25.20967, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1098 - acc: 0.1605 - val_loss: -25.2232 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.20967 to -25.22322, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1199 - acc: 0.1605 - val_loss: -25.2312 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.22322 to -25.23124, saving model to model-3.h5\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1281 - acc: 0.1605 - val_loss: -25.2378 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.23124 to -25.23776, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1346 - acc: 0.1605 - val_loss: -25.2414 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.23776 to -25.24143, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1398 - acc: 0.1605 - val_loss: -25.2508 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.24143 to -25.25079, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1434 - acc: 0.1605 - val_loss: -25.2535 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.25079 to -25.25352, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1484 - acc: 0.1605 - val_loss: -25.2571 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.25352 to -25.25714, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1508 - acc: 0.1605 - val_loss: -25.2501 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.25714\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1452 - acc: 0.1605 - val_loss: -25.2526 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.25714\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1476 - acc: 0.1605 - val_loss: -25.2550 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.25714\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1500 - acc: 0.1605 - val_loss: -25.2574 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -25.25714 to -25.25735, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1523 - acc: 0.1605 - val_loss: -25.2596 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -25.25735 to -25.25963, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 947us/step - loss: -24.1545 - acc: 0.1605 - val_loss: -25.2618 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.25963 to -25.26183, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1469 - acc: 0.1605 - val_loss: -25.2562 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.26183\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1503 - acc: 0.1605 - val_loss: -25.2565 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.26183\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -14.4962 - acc: 0.1591 - val_loss: -23.6025 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.60246, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.5462 - acc: 0.1605 - val_loss: -23.7121 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.60246 to -23.71210, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.6519 - acc: 0.1605 - val_loss: -23.8140 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.71210 to -23.81402, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -22.7520 - acc: 0.1605 - val_loss: -23.9115 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.81402 to -23.91154, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -22.8484 - acc: 0.1605 - val_loss: -24.0072 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.91154 to -24.00718, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.9433 - acc: 0.1605 - val_loss: -24.1018 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.00718 to -24.10175, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.0383 - acc: 0.1605 - val_loss: -24.1976 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.10175 to -24.19758, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.1349 - acc: 0.1605 - val_loss: -24.2947 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.19758 to -24.29473, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.2327 - acc: 0.1605 - val_loss: -24.3934 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.29473 to -24.39336, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.3318 - acc: 0.1605 - val_loss: -24.4928 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.39336 to -24.49280, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4302 - acc: 0.1605 - val_loss: -24.5907 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.49280 to -24.59071, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.5285 - acc: 0.1605 - val_loss: -24.6876 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.59071 to -24.68765, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.6239 - acc: 0.1605 - val_loss: -24.7784 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.68765 to -24.77844, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.7117 - acc: 0.1605 - val_loss: -24.8643 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.77844 to -24.86432, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.7949 - acc: 0.1605 - val_loss: -24.9425 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.86432 to -24.94247, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8665 - acc: 0.1605 - val_loss: -25.0107 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.94247 to -25.01066, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.9321 - acc: 0.1605 - val_loss: -25.0692 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.01066 to -25.06915, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.9853 - acc: 0.1605 - val_loss: -25.1150 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.06915 to -25.11499, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.0275 - acc: 0.1605 - val_loss: -25.1473 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.11499 to -25.14734, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.0574 - acc: 0.1605 - val_loss: -25.1817 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.14734 to -25.18174, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0834 - acc: 0.1605 - val_loss: -25.2001 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.18174 to -25.20013, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1044 - acc: 0.1605 - val_loss: -25.2082 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.20013 to -25.20824, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1041 - acc: 0.1605 - val_loss: -25.2126 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.20824 to -25.21258, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1084 - acc: 0.1605 - val_loss: -25.2169 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.21258 to -25.21690, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1128 - acc: 0.1605 - val_loss: -25.2213 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.21690 to -25.22133, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1173 - acc: 0.1605 - val_loss: -25.2260 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.22133 to -25.22598, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1221 - acc: 0.1605 - val_loss: -25.2310 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.22598 to -25.23095, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1272 - acc: 0.1605 - val_loss: -25.2363 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.23095 to -25.23626, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1327 - acc: 0.1605 - val_loss: -25.2418 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.23626 to -25.24183, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1356 - acc: 0.1605 - val_loss: -25.2449 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.24183 to -25.24489, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1401 - acc: 0.1605 - val_loss: -25.2479 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.24489 to -25.24794, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1442 - acc: 0.1605 - val_loss: -25.2529 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.24794 to -25.25291, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1473 - acc: 0.1605 - val_loss: -25.2523 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.25291\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1494 - acc: 0.1605 - val_loss: -25.2588 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.25291 to -25.25882, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.1509 - acc: 0.1605 - val_loss: -25.2598 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.25882 to -25.25979, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1540 - acc: 0.1605 - val_loss: -25.2548 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25979\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1509 - acc: 0.1605 - val_loss: -25.2593 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25979\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1548 - acc: 0.1605 - val_loss: -25.2627 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.25979 to -25.26267, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1551 - acc: 0.1605 - val_loss: -25.2607 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.26267\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1561 - acc: 0.1605 - val_loss: -24.6346 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.26267\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -13.9883 - acc: 0.1601 - val_loss: -23.6294 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.62937, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.5715 - acc: 0.1605 - val_loss: -23.7357 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.62937 to -23.73565, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -22.6749 - acc: 0.1605 - val_loss: -23.8362 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.73565 to -23.83615, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.7739 - acc: 0.1605 - val_loss: -23.9335 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.83615 to -23.93353, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -22.8705 - acc: 0.1605 - val_loss: -24.0297 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.93353 to -24.02974, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.9665 - acc: 0.1605 - val_loss: -24.1255 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.02974 to -24.12548, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0629 - acc: 0.1605 - val_loss: -24.2228 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.12548 to -24.22277, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -23.1605 - acc: 0.1605 - val_loss: -24.3203 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.22277 to -24.32025, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.2586 - acc: 0.1605 - val_loss: -24.4194 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.32025 to -24.41945, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.3568 - acc: 0.1605 - val_loss: -24.5171 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.41945 to -24.51715, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 996us/step - loss: -23.4539 - acc: 0.1605 - val_loss: -24.6116 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.51715 to -24.61163, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.5487 - acc: 0.1605 - val_loss: -24.7061 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.61163 to -24.70614, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.6418 - acc: 0.1605 - val_loss: -24.7985 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.70614 to -24.79853, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.7112 - acc: 0.1605 - val_loss: -24.8546 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.79853 to -24.85461, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.7781 - acc: 0.1605 - val_loss: -24.9197 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.85461 to -24.91967, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.8405 - acc: 0.1605 - val_loss: -24.9777 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.91967 to -24.97774, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.8947 - acc: 0.1605 - val_loss: -25.0292 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.97774 to -25.02918, saving model to model-5.h5\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.9440 - acc: 0.1605 - val_loss: -25.0762 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.02918 to -25.07618, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.9875 - acc: 0.1605 - val_loss: -25.1164 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.07618 to -25.11639, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.0248 - acc: 0.1605 - val_loss: -25.1500 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.11639 to -25.14996, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.0560 - acc: 0.1605 - val_loss: -25.1773 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.14996 to -25.17725, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.0806 - acc: 0.1605 - val_loss: -25.1989 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.17725 to -25.19885, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1026 - acc: 0.1605 - val_loss: -25.2207 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.19885 to -25.22070, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1016 - acc: 0.1605 - val_loss: -25.2115 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -25.22070\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -24.1066 - acc: 0.1605 - val_loss: -25.2142 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -25.22070\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1094 - acc: 0.1605 - val_loss: -25.2171 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -25.22070\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1124 - acc: 0.1605 - val_loss: -25.2203 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.22070\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1143 - acc: 0.1605 - val_loss: -25.2206 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -25.22070\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1147 - acc: 0.1605 - val_loss: -25.2211 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.22070 to -25.22108, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1153 - acc: 0.1605 - val_loss: -25.2217 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.22108 to -25.22166, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1159 - acc: 0.1605 - val_loss: -25.2224 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.22166 to -25.22237, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1167 - acc: 0.1605 - val_loss: -25.2233 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.22237 to -25.22327, saving model to model-5.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1177 - acc: 0.1605 - val_loss: -25.2244 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.22327 to -25.22438, saving model to model-5.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.1189 - acc: 0.1605 - val_loss: -25.2257 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.22438 to -25.22570, saving model to model-5.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1203 - acc: 0.1605 - val_loss: -25.2273 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.22570 to -25.22726, saving model to model-5.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1220 - acc: 0.1605 - val_loss: -25.2290 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -25.22726 to -25.22903, saving model to model-5.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1238 - acc: 0.1605 - val_loss: -25.2310 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -25.22903 to -25.23097, saving model to model-5.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1258 - acc: 0.1605 - val_loss: -25.2331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.23097 to -25.23305, saving model to model-5.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1279 - acc: 0.1605 - val_loss: -25.2352 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.23305 to -25.23522, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.1301 - acc: 0.1605 - val_loss: -25.2374 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -25.23522 to -25.23742, saving model to model-5.h5\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -8.7392 - acc: 0.1656 - val_loss: -23.5507 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.55065, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.5361 - acc: 0.1605 - val_loss: -23.7495 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.55065 to -23.74946, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.7232 - acc: 0.1605 - val_loss: -23.9223 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.74946 to -23.92227, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.8886 - acc: 0.1605 - val_loss: -24.0811 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.92227 to -24.08106, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0379 - acc: 0.1605 - val_loss: -24.2211 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.08106 to -24.22114, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.1724 - acc: 0.1605 - val_loss: -24.3498 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.22114 to -24.34984, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.2975 - acc: 0.1605 - val_loss: -24.4709 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.34984 to -24.47086, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -23.4144 - acc: 0.1605 - val_loss: -24.5815 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.47086 to -24.58149, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.5227 - acc: 0.1605 - val_loss: -24.6847 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.58149 to -24.68469, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.6225 - acc: 0.1605 - val_loss: -24.7798 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.68469 to -24.77979, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 994us/step - loss: -23.7144 - acc: 0.1605 - val_loss: -24.8693 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.77979 to -24.86930, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.7984 - acc: 0.1605 - val_loss: -24.9470 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.86930 to -24.94695, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 996us/step - loss: -23.8690 - acc: 0.1605 - val_loss: -25.0135 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.94695 to -25.01348, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.9324 - acc: 0.1605 - val_loss: -25.0684 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.01348 to -25.06845, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.9818 - acc: 0.1605 - val_loss: -25.1134 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.06845 to -25.11337, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.0255 - acc: 0.1605 - val_loss: -25.1437 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.11337 to -25.14366, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0545 - acc: 0.1605 - val_loss: -25.1762 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.14366 to -25.17621, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.0816 - acc: 0.1605 - val_loss: -25.1999 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.17621 to -25.19993, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1014 - acc: 0.1605 - val_loss: -25.2087 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.19993 to -25.20871, saving model to model-1.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1133 - acc: 0.1605 - val_loss: -25.2270 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.20871 to -25.22698, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1267 - acc: 0.1605 - val_loss: -25.2394 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.22698 to -25.23944, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1338 - acc: 0.1605 - val_loss: -25.2465 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.23944 to -25.24651, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1345 - acc: 0.1605 - val_loss: -25.2440 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -25.24651\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1419 - acc: 0.1605 - val_loss: -25.2523 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.24651 to -25.25232, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1467 - acc: 0.1605 - val_loss: -25.2556 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.25232 to -25.25560, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1456 - acc: 0.1605 - val_loss: -25.2550 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -25.25560\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1430 - acc: 0.1605 - val_loss: -25.2497 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.25560\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1439 - acc: 0.1605 - val_loss: -25.2504 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -25.25560\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1447 - acc: 0.1605 - val_loss: -25.2512 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -25.25560\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1452 - acc: 0.1605 - val_loss: -25.2513 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -25.25560\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1453 - acc: 0.1605 - val_loss: -25.2514 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -25.25560\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1454 - acc: 0.1605 - val_loss: -25.2515 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.25560\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1455 - acc: 0.1605 - val_loss: -25.2517 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.25560\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1456 - acc: 0.1605 - val_loss: -25.2517 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.25560\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 946us/step - loss: -24.1457 - acc: 0.1605 - val_loss: -25.2518 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.25560\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1457 - acc: 0.1605 - val_loss: -25.2518 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25560\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1457 - acc: 0.1605 - val_loss: -25.2519 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25560\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1458 - acc: 0.1605 - val_loss: -25.2519 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.25560\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1459 - acc: 0.1605 - val_loss: -25.2520 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.25560\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1460 - acc: 0.1605 - val_loss: -25.2521 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.25560\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -12.5340 - acc: 0.1601 - val_loss: -23.5696 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.56958, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.5260 - acc: 0.1605 - val_loss: -23.7068 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.56958 to -23.70679, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.6578 - acc: 0.1605 - val_loss: -23.8325 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.70679 to -23.83254, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -22.7791 - acc: 0.1605 - val_loss: -23.9486 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.83254 to -23.94856, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -22.8924 - acc: 0.1605 - val_loss: -24.0592 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.94856 to -24.05925, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.0005 - acc: 0.1605 - val_loss: -24.1651 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.05925 to -24.16505, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.1065 - acc: 0.1605 - val_loss: -24.2707 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.16505 to -24.27068, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.2102 - acc: 0.1605 - val_loss: -24.3728 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.27068 to -24.37283, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.3130 - acc: 0.1605 - val_loss: -24.4760 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.37283 to -24.47600, saving model to model-2.h5\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4156 - acc: 0.1605 - val_loss: -24.5777 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.47600 to -24.57771, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.5163 - acc: 0.1605 - val_loss: -24.6733 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.57771 to -24.67332, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.6118 - acc: 0.1605 - val_loss: -24.7699 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.67332 to -24.76995, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.7030 - acc: 0.1605 - val_loss: -24.8572 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.76995 to -24.85724, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -23.7869 - acc: 0.1605 - val_loss: -24.9336 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.85724 to -24.93363, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.8598 - acc: 0.1605 - val_loss: -25.0057 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.93363 to -25.00571, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.9251 - acc: 0.1605 - val_loss: -25.0637 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.00571 to -25.06373, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -23.9747 - acc: 0.1605 - val_loss: -25.1015 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.06373 to -25.10149, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.0163 - acc: 0.1605 - val_loss: -25.1428 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.10149 to -25.14278, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.0512 - acc: 0.1605 - val_loss: -25.1739 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.14278 to -25.17385, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.0775 - acc: 0.1605 - val_loss: -25.1986 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.17385 to -25.19856, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.9996 - acc: 0.1605 - val_loss: -25.1923 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -25.19856\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 996us/step - loss: -24.0869 - acc: 0.1605 - val_loss: -25.1939 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -25.19856\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.0886 - acc: 0.1605 - val_loss: -25.1956 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -25.19856\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.0904 - acc: 0.1605 - val_loss: -25.1976 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -25.19856\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.0916 - acc: 0.1605 - val_loss: -25.1978 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -25.19856\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0918 - acc: 0.1605 - val_loss: -25.1981 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -25.19856\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.0921 - acc: 0.1605 - val_loss: -25.1984 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.19856\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.0926 - acc: 0.1605 - val_loss: -25.1989 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.19856 to -25.19889, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.0931 - acc: 0.1605 - val_loss: -25.1995 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.19889 to -25.19948, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0937 - acc: 0.1605 - val_loss: -25.2002 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.19948 to -25.20023, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.0946 - acc: 0.1605 - val_loss: -25.2012 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.20023 to -25.20119, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.0956 - acc: 0.1605 - val_loss: -25.2024 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.20119 to -25.20240, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.0970 - acc: 0.1605 - val_loss: -25.2039 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.20240 to -25.20389, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.0986 - acc: 0.1605 - val_loss: -25.2057 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.20389 to -25.20569, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -24.1005 - acc: 0.1605 - val_loss: -25.2078 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.20569 to -25.20779, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1028 - acc: 0.1605 - val_loss: -25.2102 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -25.20779 to -25.21018, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 952us/step - loss: -24.1053 - acc: 0.1605 - val_loss: -25.2128 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -25.21018 to -25.21282, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1080 - acc: 0.1605 - val_loss: -25.2157 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.21282 to -25.21565, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1109 - acc: 0.1605 - val_loss: -25.2186 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.21565 to -25.21860, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1138 - acc: 0.1605 - val_loss: -25.2209 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -25.21860 to -25.22092, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -13.1731 - acc: 0.1596 - val_loss: -23.5900 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.59004, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -22.5325 - acc: 0.1605 - val_loss: -23.6976 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.59004 to -23.69765, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.6383 - acc: 0.1605 - val_loss: -23.8014 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.69765 to -23.80139, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.7409 - acc: 0.1605 - val_loss: -23.9030 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.80139 to -23.90297, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -22.8419 - acc: 0.1605 - val_loss: -24.0033 - val_acc: 0.1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss improved from -23.90297 to -24.00325, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -22.9427 - acc: 0.1605 - val_loss: -24.1052 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.00325 to -24.10523, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.0455 - acc: 0.1605 - val_loss: -24.2091 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.10523 to -24.20910, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.1500 - acc: 0.1605 - val_loss: -24.3140 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.20910 to -24.31397, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.2552 - acc: 0.1605 - val_loss: -24.4204 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.31397 to -24.42038, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.3626 - acc: 0.1605 - val_loss: -24.5259 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.42038 to -24.52589, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -23.4679 - acc: 0.1605 - val_loss: -24.6324 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.52589 to -24.63244, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -23.5681 - acc: 0.1605 - val_loss: -24.7188 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.63244 to -24.71882, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -23.6538 - acc: 0.1605 - val_loss: -24.8090 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.71882 to -24.80903, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 951us/step - loss: -23.7406 - acc: 0.1605 - val_loss: -24.8911 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.80903 to -24.89106, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -23.8168 - acc: 0.1605 - val_loss: -24.9596 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.89106 to -24.95956, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -23.8829 - acc: 0.1605 - val_loss: -25.0248 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.95956 to -25.02483, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -23.9382 - acc: 0.1605 - val_loss: -25.0734 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.02483 to -25.07340, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -23.9882 - acc: 0.1605 - val_loss: -25.1174 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.07340 to -25.11745, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.0276 - acc: 0.1605 - val_loss: -25.1406 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.11745 to -25.14062, saving model to model-3.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.0472 - acc: 0.1605 - val_loss: -25.1680 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.14062 to -25.16797, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.0725 - acc: 0.1605 - val_loss: -25.1910 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.16797 to -25.19103, saving model to model-3.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 955us/step - loss: -24.0913 - acc: 0.1605 - val_loss: -25.2044 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.19103 to -25.20442, saving model to model-3.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1062 - acc: 0.1605 - val_loss: -25.2212 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.20442 to -25.22119, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1106 - acc: 0.1605 - val_loss: -25.2228 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.22119 to -25.22282, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 957us/step - loss: -24.1220 - acc: 0.1605 - val_loss: -25.2342 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.22282 to -25.23422, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1310 - acc: 0.1605 - val_loss: -25.2407 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.23422 to -25.24070, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 953us/step - loss: -24.1301 - acc: 0.1605 - val_loss: -25.2360 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.24070\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 949us/step - loss: -24.1315 - acc: 0.1605 - val_loss: -25.2395 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -25.24070\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 950us/step - loss: -24.1350 - acc: 0.1605 - val_loss: -25.2431 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.24070 to -25.24311, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1387 - acc: 0.1605 - val_loss: -25.2468 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.24311 to -25.24678, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1424 - acc: 0.1605 - val_loss: -25.2506 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.24678 to -25.25056, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 958us/step - loss: -24.1457 - acc: 0.1605 - val_loss: -25.2528 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.25056 to -25.25276, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1471 - acc: 0.1605 - val_loss: -25.2514 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.25276\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1478 - acc: 0.1605 - val_loss: -25.2567 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.25276 to -25.25669, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1489 - acc: 0.1605 - val_loss: -25.2572 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.25669 to -25.25720, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1513 - acc: 0.1605 - val_loss: -25.2579 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -25.25720 to -25.25787, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 954us/step - loss: -24.1531 - acc: 0.1605 - val_loss: -25.2593 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -25.25787 to -25.25928, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1541 - acc: 0.1605 - val_loss: -25.2606 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.25928 to -25.26056, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 984us/step - loss: -24.1532 - acc: 0.1605 - val_loss: -25.2578 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.26056\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1538 - acc: 0.1605 - val_loss: -25.2621 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -25.26056 to -25.26209, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -13.3713 - acc: 0.1624 - val_loss: -23.6078 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.60784, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.5584 - acc: 0.1605 - val_loss: -23.7317 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.60784 to -23.73174, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -22.6774 - acc: 0.1605 - val_loss: -23.8455 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.73174 to -23.84550, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -22.7869 - acc: 0.1605 - val_loss: -23.9508 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.84550 to -23.95076, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -22.8903 - acc: 0.1605 - val_loss: -24.0527 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.95076 to -24.05274, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.9915 - acc: 0.1605 - val_loss: -24.1526 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.05274 to -24.15260, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.0898 - acc: 0.1605 - val_loss: -24.2498 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.15260 to -24.24983, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.1886 - acc: 0.1605 - val_loss: -24.3501 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.24983 to -24.35008, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.2879 - acc: 0.1605 - val_loss: -24.4476 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.35008 to -24.44758, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.3866 - acc: 0.1605 - val_loss: -24.5479 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.44758 to -24.54785, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 986us/step - loss: -23.4842 - acc: 0.1605 - val_loss: -24.6421 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.54785 to -24.64210, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.5794 - acc: 0.1605 - val_loss: -24.7382 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.64210 to -24.73819, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.6684 - acc: 0.1605 - val_loss: -24.8222 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.73819 to -24.82223, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.7529 - acc: 0.1605 - val_loss: -24.9011 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.82223 to -24.90107, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8288 - acc: 0.1605 - val_loss: -24.9755 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.90107 to -24.97554, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -23.8969 - acc: 0.1605 - val_loss: -25.0311 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.97554 to -25.03111, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.9515 - acc: 0.1605 - val_loss: -25.0882 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.03111 to -25.08822, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.9984 - acc: 0.1605 - val_loss: -25.1296 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.08822 to -25.12964, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.0039 - acc: 0.1605 - val_loss: -25.1305 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.12964 to -25.13055, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.0264 - acc: 0.1605 - val_loss: -25.1348 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.13055 to -25.13475, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.0306 - acc: 0.1605 - val_loss: -25.1391 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.13475 to -25.13911, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.0351 - acc: 0.1605 - val_loss: -25.1438 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.13911 to -25.14382, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.0401 - acc: 0.1605 - val_loss: -25.1491 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.14382 to -25.14910, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.0457 - acc: 0.1605 - val_loss: -25.1552 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.14910 to -25.15518, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.0522 - acc: 0.1605 - val_loss: -25.1623 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.15518 to -25.16228, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.0598 - acc: 0.1605 - val_loss: -25.1706 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.16228 to -25.17060, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0687 - acc: 0.1605 - val_loss: -25.1802 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.17060 to -25.18021, saving model to model-4.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.0789 - acc: 0.1605 - val_loss: -25.1905 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.18021 to -25.19054, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.0888 - acc: 0.1605 - val_loss: -25.1998 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.19054 to -25.19981, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.0973 - acc: 0.1605 - val_loss: -25.2038 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.19981 to -25.20376, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1024 - acc: 0.1605 - val_loss: -25.2142 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.20376 to -25.21422, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1127 - acc: 0.1605 - val_loss: -25.2242 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.21422 to -25.22424, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1214 - acc: 0.1605 - val_loss: -25.2322 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.22424 to -25.23216, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1271 - acc: 0.1605 - val_loss: -25.2379 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.23216 to -25.23786, saving model to model-4.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1305 - acc: 0.1605 - val_loss: -25.2347 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.23786\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1295 - acc: 0.1605 - val_loss: -25.2367 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.23786\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1315 - acc: 0.1605 - val_loss: -25.2387 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -25.23786 to -25.23873, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1337 - acc: 0.1605 - val_loss: -25.2410 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.23873 to -25.24102, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1361 - acc: 0.1605 - val_loss: -25.2436 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.24102 to -25.24357, saving model to model-4.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1388 - acc: 0.1605 - val_loss: -25.2465 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -25.24357 to -25.24645, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -15.2403 - acc: 0.1601 - val_loss: -23.5711 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.57114, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -22.4997 - acc: 0.1605 - val_loss: -23.6483 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.57114 to -23.64832, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -22.5765 - acc: 0.1605 - val_loss: -23.7249 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.64832 to -23.72494, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.6536 - acc: 0.1605 - val_loss: -23.8029 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.72494 to -23.80291, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.7329 - acc: 0.1605 - val_loss: -23.8843 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.80291 to -23.88428, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.8165 - acc: 0.1605 - val_loss: -23.9710 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.88428 to -23.97104, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.9063 - acc: 0.1605 - val_loss: -24.0647 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.97104 to -24.06474, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.0034 - acc: 0.1605 - val_loss: -24.1661 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.06474 to -24.16613, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.1080 - acc: 0.1605 - val_loss: -24.2745 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.16613 to -24.27452, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.2183 - acc: 0.1605 - val_loss: -24.3868 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.27452 to -24.38676, saving model to model-5.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.3329 - acc: 0.1605 - val_loss: -24.5029 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.38676 to -24.50295, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4474 - acc: 0.1605 - val_loss: -24.6137 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.50295 to -24.61366, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.5585 - acc: 0.1605 - val_loss: -24.7261 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.61366 to -24.72611, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.6662 - acc: 0.1605 - val_loss: -24.8280 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.72611 to -24.82798, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.7593 - acc: 0.1605 - val_loss: -24.9158 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.82798 to -24.91581, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.8441 - acc: 0.1605 - val_loss: -24.9932 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.91581 to -24.99324, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.9170 - acc: 0.1605 - val_loss: -25.0577 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.99324 to -25.05773, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.9745 - acc: 0.1605 - val_loss: -25.1083 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.05773 to -25.10834, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.0221 - acc: 0.1605 - val_loss: -25.1477 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.10834 to -25.14773, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.0586 - acc: 0.1605 - val_loss: -25.1810 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.14773 to -25.18098, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.0870 - acc: 0.1605 - val_loss: -25.2067 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.18098 to -25.20665, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1066 - acc: 0.1605 - val_loss: -25.2192 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.20665 to -25.21924, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.1218 - acc: 0.1605 - val_loss: -25.2373 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.21924 to -25.23725, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -24.1178 - acc: 0.1605 - val_loss: -25.2340 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -25.23725\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1282 - acc: 0.1605 - val_loss: -25.2346 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -25.23725\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1288 - acc: 0.1605 - val_loss: -25.2353 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -25.23725\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1295 - acc: 0.1605 - val_loss: -25.2360 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.23725\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1300 - acc: 0.1605 - val_loss: -25.2361 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -25.23725\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1300 - acc: 0.1605 - val_loss: -25.2362 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -25.23725\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1302 - acc: 0.1605 - val_loss: -25.2363 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -25.23725\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1303 - acc: 0.1605 - val_loss: -25.2365 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -25.23725\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1304 - acc: 0.1605 - val_loss: -25.2365 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.23725\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1304 - acc: 0.1605 - val_loss: -25.2365 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.23725\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1305 - acc: 0.1605 - val_loss: -25.2366 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.23725\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1305 - acc: 0.1605 - val_loss: -25.2366 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.23725\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1305 - acc: 0.1605 - val_loss: -25.2367 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.23725\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1306 - acc: 0.1605 - val_loss: -25.2367 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.23725\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1307 - acc: 0.1605 - val_loss: -25.2368 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.23725\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1308 - acc: 0.1605 - val_loss: -25.2370 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.23725\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.1309 - acc: 0.1605 - val_loss: -25.2371 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.23725\n",
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -7.6378 - acc: 0.1637 - val_loss: -23.6219 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.62192, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -22.6366 - acc: 0.1605 - val_loss: -23.8822 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.62192 to -23.88220, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.8739 - acc: 0.1605 - val_loss: -24.0947 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.88220 to -24.09466, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.0693 - acc: 0.1605 - val_loss: -24.2680 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -24.09466 to -24.26795, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.2311 - acc: 0.1605 - val_loss: -24.4198 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -24.26795 to -24.41978, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.3733 - acc: 0.1605 - val_loss: -24.5520 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.41978 to -24.55198, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.4966 - acc: 0.1605 - val_loss: -24.6625 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.55198 to -24.66250, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.6028 - acc: 0.1605 - val_loss: -24.7634 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.66250 to -24.76341, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.6980 - acc: 0.1605 - val_loss: -24.8524 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.76341 to -24.85242, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.7812 - acc: 0.1605 - val_loss: -24.9278 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.85242 to -24.92779, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.8536 - acc: 0.1605 - val_loss: -24.9950 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.92779 to -24.99502, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.9153 - acc: 0.1605 - val_loss: -25.0528 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.99502 to -25.05278, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.9675 - acc: 0.1605 - val_loss: -25.0975 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -25.05278 to -25.09747, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.0105 - acc: 0.1605 - val_loss: -25.1401 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -25.09747 to -25.14014, saving model to model-1.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.0461 - acc: 0.1605 - val_loss: -25.1654 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -25.14014 to -25.16539, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.0717 - acc: 0.1605 - val_loss: -25.1857 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.16539 to -25.18568, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.0925 - acc: 0.1605 - val_loss: -25.2090 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.18568 to -25.20897, saving model to model-1.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1102 - acc: 0.1605 - val_loss: -25.2214 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.20897 to -25.22140, saving model to model-1.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.1236 - acc: 0.1605 - val_loss: -25.2214 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -25.22140\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1166 - acc: 0.1605 - val_loss: -25.2242 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.22140 to -25.22418, saving model to model-1.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1194 - acc: 0.1605 - val_loss: -25.2271 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.22418 to -25.22706, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1223 - acc: 0.1605 - val_loss: -25.2301 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.22706 to -25.23011, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.1255 - acc: 0.1605 - val_loss: -25.2334 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.23011 to -25.23341, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.1289 - acc: 0.1605 - val_loss: -25.2371 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.23341 to -25.23705, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1327 - acc: 0.1605 - val_loss: -25.2411 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.23705 to -25.24107, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1368 - acc: 0.1605 - val_loss: -25.2415 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.24107 to -25.24146, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.1371 - acc: 0.1605 - val_loss: -25.2428 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.24146 to -25.24280, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.1394 - acc: 0.1605 - val_loss: -25.2498 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.24280 to -25.24981, saving model to model-1.h5\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1409 - acc: 0.1605 - val_loss: -25.2500 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.24981 to -25.24996, saving model to model-1.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1447 - acc: 0.1605 - val_loss: -25.2499 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -25.24996\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1454 - acc: 0.1605 - val_loss: -25.2511 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.24996 to -25.25115, saving model to model-1.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1478 - acc: 0.1605 - val_loss: -25.2509 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.25115\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1476 - acc: 0.1605 - val_loss: -25.2570 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.25115 to -25.25701, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1509 - acc: 0.1605 - val_loss: -25.2590 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.25701 to -25.25901, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1484 - acc: 0.1605 - val_loss: -25.2517 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.25901\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1458 - acc: 0.1605 - val_loss: -25.2522 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25901\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1464 - acc: 0.1605 - val_loss: -25.2528 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25901\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1470 - acc: 0.1605 - val_loss: -25.2535 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.25901\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1474 - acc: 0.1605 - val_loss: -25.2536 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.25901\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1475 - acc: 0.1605 - val_loss: -25.2537 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.25901\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -12.2050 - acc: 0.1605 - val_loss: -23.5869 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.58692, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -22.5333 - acc: 0.1605 - val_loss: -23.7137 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.58692 to -23.71371, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -22.6611 - acc: 0.1605 - val_loss: -23.8338 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.71371 to -23.83381, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.7779 - acc: 0.1605 - val_loss: -23.9510 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.83381 to -23.95101, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.8929 - acc: 0.1605 - val_loss: -24.0631 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.95101 to -24.06306, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.0034 - acc: 0.1605 - val_loss: -24.1740 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.06306 to -24.17405, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.1136 - acc: 0.1605 - val_loss: -24.2816 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.17405 to -24.28162, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.2216 - acc: 0.1605 - val_loss: -24.3904 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.28162 to -24.39043, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 981us/step - loss: -23.3337 - acc: 0.1605 - val_loss: -24.4986 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.39043 to -24.49859, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.4380 - acc: 0.1605 - val_loss: -24.6015 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.49859 to -24.60148, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.5421 - acc: 0.1605 - val_loss: -24.7066 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.60148 to -24.70660, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.6392 - acc: 0.1605 - val_loss: -24.7999 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.70660 to -24.79987, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.7318 - acc: 0.1605 - val_loss: -24.8822 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.79987 to -24.88218, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -23.8116 - acc: 0.1605 - val_loss: -24.9604 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.88218 to -24.96036, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.8863 - acc: 0.1605 - val_loss: -25.0288 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.96036 to -25.02879, saving model to model-2.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.9397 - acc: 0.1605 - val_loss: -25.0747 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -25.02879 to -25.07466, saving model to model-2.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.9900 - acc: 0.1605 - val_loss: -25.1223 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.07466 to -25.12232, saving model to model-2.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.0271 - acc: 0.1605 - val_loss: -25.1546 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.12232 to -25.15461, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.0592 - acc: 0.1605 - val_loss: -25.1813 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.15461 to -25.18129, saving model to model-2.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.0836 - acc: 0.1605 - val_loss: -25.1990 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.18129 to -25.19899, saving model to model-2.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.0986 - acc: 0.1605 - val_loss: -25.2097 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.19899 to -25.20972, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1119 - acc: 0.1605 - val_loss: -25.2273 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.20972 to -25.22726, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1247 - acc: 0.1605 - val_loss: -25.2320 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.22726 to -25.23202, saving model to model-2.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1313 - acc: 0.1605 - val_loss: -25.2308 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -25.23202\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.1258 - acc: 0.1605 - val_loss: -25.2331 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.23202 to -25.23306, saving model to model-2.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1280 - acc: 0.1605 - val_loss: -25.2353 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.23306 to -25.23533, saving model to model-2.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -24.1303 - acc: 0.1605 - val_loss: -25.2377 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.23533 to -25.23773, saving model to model-2.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1327 - acc: 0.1605 - val_loss: -25.2401 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.23773 to -25.24007, saving model to model-2.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1353 - acc: 0.1605 - val_loss: -25.2430 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.24007 to -25.24296, saving model to model-2.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.1380 - acc: 0.1605 - val_loss: -25.2458 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.24296 to -25.24583, saving model to model-2.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1410 - acc: 0.1605 - val_loss: -25.2464 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.24583 to -25.24635, saving model to model-2.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1420 - acc: 0.1605 - val_loss: -25.2500 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.24635 to -25.25000, saving model to model-2.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1441 - acc: 0.1605 - val_loss: -25.2507 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.25000 to -25.25074, saving model to model-2.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1467 - acc: 0.1605 - val_loss: -25.2547 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.25074 to -25.25469, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.1433 - acc: 0.1605 - val_loss: -25.2488 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.25469\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1435 - acc: 0.1605 - val_loss: -25.2506 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.25469\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1454 - acc: 0.1605 - val_loss: -25.2525 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.25469\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1474 - acc: 0.1605 - val_loss: -25.2546 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.25469\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.1487 - acc: 0.1605 - val_loss: -25.2549 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.25469 to -25.25487, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1489 - acc: 0.1605 - val_loss: -25.2552 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -25.25487 to -25.25517, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -12.7605 - acc: 0.1587 - val_loss: -23.5677 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.56772, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.5085 - acc: 0.1605 - val_loss: -23.6719 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.56772 to -23.67188, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -22.6100 - acc: 0.1605 - val_loss: -23.7710 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.67188 to -23.77101, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 974us/step - loss: -22.7075 - acc: 0.1605 - val_loss: -23.8673 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.77101 to -23.86732, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.8034 - acc: 0.1605 - val_loss: -23.9628 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.86732 to -23.96284, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -22.8992 - acc: 0.1605 - val_loss: -24.0593 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.96284 to -24.05935, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.9934 - acc: 0.1605 - val_loss: -24.1570 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.05935 to -24.15703, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.0944 - acc: 0.1605 - val_loss: -24.2575 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.15703 to -24.25753, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 982us/step - loss: -23.1975 - acc: 0.1605 - val_loss: -24.3625 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.25753 to -24.36250, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 989us/step - loss: -23.3015 - acc: 0.1605 - val_loss: -24.4681 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.36250 to -24.46806, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -23.4071 - acc: 0.1605 - val_loss: -24.5733 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.46806 to -24.57329, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.5109 - acc: 0.1605 - val_loss: -24.6752 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.57329 to -24.67522, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.6113 - acc: 0.1605 - val_loss: -24.7707 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.67522 to -24.77066, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.7045 - acc: 0.1605 - val_loss: -24.8607 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.77066 to -24.86071, saving model to model-3.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -23.7909 - acc: 0.1605 - val_loss: -24.9429 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.86071 to -24.94286, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8629 - acc: 0.1605 - val_loss: -25.0052 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.94286 to -25.00516, saving model to model-3.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.9282 - acc: 0.1605 - val_loss: -25.0628 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.00516 to -25.06282, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -23.9779 - acc: 0.1605 - val_loss: -25.1066 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.06282 to -25.10658, saving model to model-3.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.0205 - acc: 0.1605 - val_loss: -25.1406 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.10658 to -25.14060, saving model to model-3.h5\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 974us/step - loss: -24.0519 - acc: 0.1605 - val_loss: -25.1793 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.14060 to -25.17929, saving model to model-3.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.0172 - acc: 0.1605 - val_loss: -25.1761 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -25.17929\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0709 - acc: 0.1605 - val_loss: -25.1781 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -25.17929\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0730 - acc: 0.1605 - val_loss: -25.1802 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.17929 to -25.18019, saving model to model-3.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.0751 - acc: 0.1605 - val_loss: -25.1824 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.18019 to -25.18239, saving model to model-3.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.0774 - acc: 0.1605 - val_loss: -25.1850 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.18239 to -25.18496, saving model to model-3.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.0798 - acc: 0.1605 - val_loss: -25.1880 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.18496 to -25.18798, saving model to model-3.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.0833 - acc: 0.1605 - val_loss: -25.1914 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.18798 to -25.19143, saving model to model-3.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.0875 - acc: 0.1605 - val_loss: -25.1960 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.19143 to -25.19597, saving model to model-3.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.0924 - acc: 0.1605 - val_loss: -25.2004 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.19597 to -25.20043, saving model to model-3.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.0969 - acc: 0.1605 - val_loss: -25.2069 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.20043 to -25.20690, saving model to model-3.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1031 - acc: 0.1605 - val_loss: -25.2120 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.20690 to -25.21204, saving model to model-3.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1089 - acc: 0.1605 - val_loss: -25.2163 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.21204 to -25.21625, saving model to model-3.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -24.1142 - acc: 0.1605 - val_loss: -25.2255 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.21625 to -25.22551, saving model to model-3.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1218 - acc: 0.1605 - val_loss: -25.2325 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss improved from -25.22551 to -25.23249, saving model to model-3.h5\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1269 - acc: 0.1605 - val_loss: -25.2355 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss improved from -25.23249 to -25.23548, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1333 - acc: 0.1605 - val_loss: -25.2444 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss improved from -25.23548 to -25.24442, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.1382 - acc: 0.1605 - val_loss: -25.2484 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss improved from -25.24442 to -25.24842, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 976us/step - loss: -24.1409 - acc: 0.1605 - val_loss: -25.2511 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss improved from -25.24842 to -25.25110, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1462 - acc: 0.1605 - val_loss: -25.2535 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.25110 to -25.25345, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1421 - acc: 0.1605 - val_loss: -25.2505 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -25.25345\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -14.2841 - acc: 0.1582 - val_loss: -23.6168 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.61680, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -22.5665 - acc: 0.1605 - val_loss: -23.7420 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.61680 to -23.74205, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -22.6858 - acc: 0.1605 - val_loss: -23.8548 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.74205 to -23.85482, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -22.7969 - acc: 0.1605 - val_loss: -23.9587 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.85482 to -23.95870, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -22.8972 - acc: 0.1605 - val_loss: -24.0566 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.95870 to -24.05665, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.9921 - acc: 0.1605 - val_loss: -24.1498 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.05665 to -24.14982, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -23.0828 - acc: 0.1605 - val_loss: -24.2403 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.14982 to -24.24035, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.1768 - acc: 0.1605 - val_loss: -24.3323 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.24035 to -24.33226, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.2668 - acc: 0.1605 - val_loss: -24.4256 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.33226 to -24.42564, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 990us/step - loss: -23.3602 - acc: 0.1605 - val_loss: -24.5167 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.42564 to -24.51667, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.4498 - acc: 0.1605 - val_loss: -24.6085 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.51667 to -24.60855, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 977us/step - loss: -23.5429 - acc: 0.1605 - val_loss: -24.7002 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.60855 to -24.70019, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -23.6337 - acc: 0.1605 - val_loss: -24.7834 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.70019 to -24.78342, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.7166 - acc: 0.1605 - val_loss: -24.8701 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.78342 to -24.87009, saving model to model-4.h5\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.7976 - acc: 0.1605 - val_loss: -24.9345 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.87009 to -24.93449, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 979us/step - loss: -23.8603 - acc: 0.1605 - val_loss: -25.0040 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.93449 to -25.00399, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.9232 - acc: 0.1605 - val_loss: -25.0531 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.00399 to -25.05308, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -23.9703 - acc: 0.1605 - val_loss: -25.1006 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.05308 to -25.10059, saving model to model-4.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.0131 - acc: 0.1605 - val_loss: -25.1405 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.10059 to -25.14045, saving model to model-4.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.0469 - acc: 0.1605 - val_loss: -25.1672 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.14045 to -25.16721, saving model to model-4.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 978us/step - loss: -24.0738 - acc: 0.1605 - val_loss: -25.1886 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.16721 to -25.18856, saving model to model-4.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.0942 - acc: 0.1605 - val_loss: -25.2094 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.18856 to -25.20940, saving model to model-4.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1122 - acc: 0.1605 - val_loss: -25.2260 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.20940 to -25.22597, saving model to model-4.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.1246 - acc: 0.1605 - val_loss: -25.2332 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.22597 to -25.23321, saving model to model-4.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1314 - acc: 0.1605 - val_loss: -25.2417 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.23321 to -25.24170, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1409 - acc: 0.1605 - val_loss: -25.2496 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss improved from -25.24170 to -25.24965, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1347 - acc: 0.1605 - val_loss: -25.2452 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -25.24965\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1415 - acc: 0.1605 - val_loss: -25.2508 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.24965 to -25.25079, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1462 - acc: 0.1605 - val_loss: -25.2540 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.25079 to -25.25400, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1495 - acc: 0.1605 - val_loss: -25.2535 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -25.25400\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1493 - acc: 0.1605 - val_loss: -25.2547 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.25400 to -25.25468, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1497 - acc: 0.1605 - val_loss: -25.2579 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss improved from -25.25468 to -25.25788, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -24.1505 - acc: 0.1605 - val_loss: -25.2603 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss improved from -25.25788 to -25.26034, saving model to model-4.h5\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 966us/step - loss: -24.1488 - acc: 0.1605 - val_loss: -25.2544 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.26034\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 962us/step - loss: -24.1493 - acc: 0.1605 - val_loss: -25.2564 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.26034\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -24.1515 - acc: 0.1605 - val_loss: -25.2588 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.26034\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1535 - acc: 0.1605 - val_loss: -25.2597 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.26034\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1546 - acc: 0.1605 - val_loss: -25.2600 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.26034\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -24.1554 - acc: 0.1605 - val_loss: -25.2603 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -25.26034\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.1552 - acc: 0.1605 - val_loss: -25.2606 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -25.26034 to -25.26064, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2700\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 2168 samples, validate on 241 samples\n",
      "Epoch 1/40\n",
      "2168/2168 [==============================] - 11s 5ms/step - loss: -14.0755 - acc: 0.1637 - val_loss: -23.6137 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -23.61374, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -22.5452 - acc: 0.1605 - val_loss: -23.7078 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00002: val_loss improved from -23.61374 to -23.70778, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -22.6440 - acc: 0.1605 - val_loss: -23.7991 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.70778 to -23.79909, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.7331 - acc: 0.1605 - val_loss: -23.8884 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.79909 to -23.88842, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -22.8232 - acc: 0.1605 - val_loss: -23.9788 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.88842 to -23.97884, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -22.9157 - acc: 0.1605 - val_loss: -24.0724 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.97884 to -24.07240, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "2168/2168 [==============================] - 2s 972us/step - loss: -23.0104 - acc: 0.1605 - val_loss: -24.1695 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.07240 to -24.16950, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.1088 - acc: 0.1605 - val_loss: -24.2688 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.16950 to -24.26876, saving model to model-5.h5\n",
      "Epoch 9/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -23.2072 - acc: 0.1605 - val_loss: -24.3714 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.26876 to -24.37137, saving model to model-5.h5\n",
      "Epoch 10/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -23.3141 - acc: 0.1605 - val_loss: -24.4769 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.37137 to -24.47691, saving model to model-5.h5\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168/2168 [==============================] - 2s 970us/step - loss: -23.4218 - acc: 0.1605 - val_loss: -24.5850 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.47691 to -24.58498, saving model to model-5.h5\n",
      "Epoch 12/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.5258 - acc: 0.1605 - val_loss: -24.6881 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.58498 to -24.68813, saving model to model-5.h5\n",
      "Epoch 13/40\n",
      "2168/2168 [==============================] - 2s 993us/step - loss: -23.6246 - acc: 0.1605 - val_loss: -24.7805 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.68813 to -24.78047, saving model to model-5.h5\n",
      "Epoch 14/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.7177 - acc: 0.1605 - val_loss: -24.8736 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.78047 to -24.87360, saving model to model-5.h5\n",
      "Epoch 15/40\n",
      "2168/2168 [==============================] - 2s 968us/step - loss: -23.8021 - acc: 0.1605 - val_loss: -24.9505 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.87360 to -24.95054, saving model to model-5.h5\n",
      "Epoch 16/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -23.8760 - acc: 0.1605 - val_loss: -25.0206 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.95054 to -25.02057, saving model to model-5.h5\n",
      "Epoch 17/40\n",
      "2168/2168 [==============================] - 2s 964us/step - loss: -23.9387 - acc: 0.1605 - val_loss: -25.0752 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00017: val_loss improved from -25.02057 to -25.07521, saving model to model-5.h5\n",
      "Epoch 18/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -23.9907 - acc: 0.1605 - val_loss: -25.1233 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00018: val_loss improved from -25.07521 to -25.12332, saving model to model-5.h5\n",
      "Epoch 19/40\n",
      "2168/2168 [==============================] - 2s 963us/step - loss: -24.0261 - acc: 0.1605 - val_loss: -25.1523 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00019: val_loss improved from -25.12332 to -25.15232, saving model to model-5.h5\n",
      "Epoch 20/40\n",
      "2168/2168 [==============================] - 2s 975us/step - loss: -24.0612 - acc: 0.1605 - val_loss: -25.1827 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00020: val_loss improved from -25.15232 to -25.18265, saving model to model-5.h5\n",
      "Epoch 21/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.0838 - acc: 0.1605 - val_loss: -25.2016 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from -25.18265 to -25.20156, saving model to model-5.h5\n",
      "Epoch 22/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1022 - acc: 0.1605 - val_loss: -25.2160 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00022: val_loss improved from -25.20156 to -25.21602, saving model to model-5.h5\n",
      "Epoch 23/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1167 - acc: 0.1605 - val_loss: -25.2309 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00023: val_loss improved from -25.21602 to -25.23085, saving model to model-5.h5\n",
      "Epoch 24/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1237 - acc: 0.1605 - val_loss: -25.2370 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00024: val_loss improved from -25.23085 to -25.23699, saving model to model-5.h5\n",
      "Epoch 25/40\n",
      "2168/2168 [==============================] - 2s 959us/step - loss: -24.1341 - acc: 0.1605 - val_loss: -25.2454 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00025: val_loss improved from -25.23699 to -25.24542, saving model to model-5.h5\n",
      "Epoch 26/40\n",
      "2168/2168 [==============================] - 2s 967us/step - loss: -24.1400 - acc: 0.1605 - val_loss: -25.2424 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -25.24542\n",
      "Epoch 27/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1413 - acc: 0.1605 - val_loss: -25.2496 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00027: val_loss improved from -25.24542 to -25.24959, saving model to model-5.h5\n",
      "Epoch 28/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1489 - acc: 0.1605 - val_loss: -25.2499 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00028: val_loss improved from -25.24959 to -25.24994, saving model to model-5.h5\n",
      "Epoch 29/40\n",
      "2168/2168 [==============================] - 2s 980us/step - loss: -24.1486 - acc: 0.1605 - val_loss: -25.2577 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00029: val_loss improved from -25.24994 to -25.25772, saving model to model-5.h5\n",
      "Epoch 30/40\n",
      "2168/2168 [==============================] - 2s 1ms/step - loss: -24.1518 - acc: 0.1605 - val_loss: -25.2586 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00030: val_loss improved from -25.25772 to -25.25865, saving model to model-5.h5\n",
      "Epoch 31/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1512 - acc: 0.1605 - val_loss: -25.2609 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00031: val_loss improved from -25.25865 to -25.26091, saving model to model-5.h5\n",
      "Epoch 32/40\n",
      "2168/2168 [==============================] - 2s 969us/step - loss: -24.1506 - acc: 0.1605 - val_loss: -25.2598 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -25.26091\n",
      "Epoch 33/40\n",
      "2168/2168 [==============================] - 2s 956us/step - loss: -24.1528 - acc: 0.1605 - val_loss: -25.2594 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -25.26091\n",
      "Epoch 34/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1501 - acc: 0.1605 - val_loss: -25.2581 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -25.26091\n",
      "Epoch 35/40\n",
      "2168/2168 [==============================] - 2s 970us/step - loss: -24.1525 - acc: 0.1605 - val_loss: -25.2591 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -25.26091\n",
      "Epoch 36/40\n",
      "2168/2168 [==============================] - 2s 973us/step - loss: -24.1539 - acc: 0.1605 - val_loss: -25.2596 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -25.26091\n",
      "Epoch 37/40\n",
      "2168/2168 [==============================] - 2s 971us/step - loss: -24.1550 - acc: 0.1605 - val_loss: -25.2602 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -25.26091\n",
      "Epoch 38/40\n",
      "2168/2168 [==============================] - 2s 965us/step - loss: -24.1557 - acc: 0.1605 - val_loss: -25.2608 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -25.26091\n",
      "Epoch 39/40\n",
      "2168/2168 [==============================] - 2s 961us/step - loss: -24.1566 - acc: 0.1605 - val_loss: -25.2615 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00039: val_loss improved from -25.26091 to -25.26146, saving model to model-5.h5\n",
      "Epoch 40/40\n",
      "2168/2168 [==============================] - 2s 960us/step - loss: -24.1567 - acc: 0.1605 - val_loss: -25.2616 - val_acc: 0.1867\n",
      "\n",
      "Epoch 00040: val_loss improved from -25.26146 to -25.26161, saving model to model-5.h5\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM_WORDS_AR = [2000, 2201,1800]\n",
    "for num in MAX_NUM_WORDS_AR:\n",
    "    MAX_NUM_WORDS = num\n",
    "    emotional_mapping = {'ang': 0, 'sad': 1, 'exc': 2, 'neu': 3,'fru': 4,'hap': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "    data = load_data(3, emotional_mapping)\n",
    "    data = balance_data(data)\n",
    "    df = data[['text','emotion_code']]\n",
    "    df.head()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.text, data.emotion_code, test_size=TEST_SIZE)\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    sequences = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "    length = max_length(x_train)\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    result = [len(x.split()) for x in x_train]\n",
    "    print('Text informations:')\n",
    "    print('max length: %i / min length: %i / mean length: %i / limit length: %i' % (np.max(result),\n",
    "                                                                                    np.min(result),\n",
    "                                                                                    np.mean(result),\n",
    "                                                                                    MAX_SEQ_LENGTH))\n",
    "\n",
    "    print('vocabulary size: %i / limit: %i' % (len(word_index), MAX_NUM_WORDS))\n",
    "\n",
    "    # Padding all sequences to same length of `MAX_SEQ_LENGTH`\n",
    "    data   = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
    "\n",
    "    embedding_data = [x.split() for x in x_train]\n",
    "    emb_layers = [create_word2vec_embeddings(use_text8=True),\n",
    "                  create_word2vec_embeddings(embedding_data),\n",
    "                  create_glove_embeddings(use_text8=True),\n",
    "                  create_glove_embeddings(embedding_data)\n",
    "                 ]\n",
    "    \n",
    "    ######################################################\n",
    "    for index,lay in enumerate(emb_layers):\n",
    "    \n",
    "        histories = []\n",
    "\n",
    "        for i in range(RUNS):\n",
    "            print('Running iteration %i/%i' % (i+1, RUNS))\n",
    "\n",
    "            X_train, X_val, labels, y_val = train_test_split(data, y_train, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "            emb_layer = None\n",
    "            if USE_GLOVE:\n",
    "                emb_layer = lay#emb_layers[2] #create_word2vec_embeddings(result)\n",
    "\n",
    "            model = cnn_model.build_cnn(\n",
    "                embedding_layer=emb_layer,\n",
    "                num_words=MAX_NUM_WORDS,\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                filter_sizes=FILTER_SIZES,\n",
    "                feature_maps=FEATURE_MAPS,\n",
    "                max_seq_length=MAX_SEQ_LENGTH,\n",
    "                dropout_rate=DROPOUT_RATE\n",
    "            )\n",
    "\n",
    "            model.compile(\n",
    "                loss='binary_crossentropy',\n",
    "                optimizer=Adadelta(clipvalue=3),\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train, labels,\n",
    "                epochs=NB_EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n",
    "                                           verbose=1, save_best_only=True, mode='min'),\n",
    "                           ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.01)\n",
    "                          ]\n",
    "            )\n",
    "            histories.append(history.history)\n",
    "\n",
    "        with open('history/balanced_'+emb_layers_names[index]+'_'+str(MAX_NUM_WORDS)+'.pkl', 'wb') as f:\n",
    "            pickle.dump(histories, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "history_dir = os.listdir('history/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('history/unbalanced_glovetext8_2954.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = pickle.load(open('history/balanced_glovetext8_2500.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \t-24.4072 loss / 0.1619 acc\n",
      "Validation: \t-23.3395 loss / 0.1867 acc\n"
     ]
    }
   ],
   "source": [
    "def get_avg(histories, his_key):\n",
    "    tmp = []\n",
    "    for history in histories:\n",
    "        tmp.append(history[his_key][np.argmin(history['val_loss'])])\n",
    "    return np.mean(tmp)\n",
    "    \n",
    "print('Training: \\t%0.4f loss / %0.4f acc' % (get_avg(histories, 'loss'),\n",
    "                                              get_avg(histories, 'acc')))\n",
    "print('Validation: \\t%0.4f loss / %0.4f acc' % (get_avg(histories, 'val_loss'),\n",
    "                                                get_avg(histories, 'val_acc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def  plot_acc_loss(title, histories, key_acc, key_loss):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # Accuracy\n",
    "    ax1.set_title('Model accuracy (%s)' % title)\n",
    "    names = []\n",
    "    for i, model in enumerate(histories):\n",
    "        ax1.plot(model[key_acc])\n",
    "        ax1.set_xlabel('epoch')\n",
    "        names.append('Model %i' % (i+1))\n",
    "        ax1.set_ylabel('accuracy')\n",
    "    ax1.legend(names, loc='lower right')\n",
    "    # Loss\n",
    "    ax2.set_title('Model loss (%s)' % title)\n",
    "    for model in histories:\n",
    "        ax2.plot(model[key_loss])\n",
    "        ax2.set_xlabel('epoch')\n",
    "        ax2.set_ylabel('loss')\n",
    "    ax2.legend(names, loc='upper right')\n",
    "    fig.set_size_inches(20, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAFNCAYAAACuQ87yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzs3Xt4VfWV//H3SnKSkAQMCSAnRMBW\n2wolYgfRdtQiKHYAAVsVsFYtpdrOdJw6w7R2ihVbq+3M1N7Gdup0Oj9abtqK1g4y3tqUgbajUGkK\n0ou1ERAUkoAk5HqS9ftj74RDCJDLOTkn4fN6njxh3757bfDpfGft9V3b3B0REREREREREZFkyEh1\nACIiIiIiIiIiMngp+SQiIiIiIiIiIkmj5JOIiIiIiIiIiCSNkk8iIiIiIiIiIpI0Sj6JiIiIiIiI\niEjSKPkkIiIiIiIiIiJJo+STyGnKzMabmZtZVjfOvcXMNvVHXOnOzNaY2fwEjjfWzOrMLDOR53Zj\nrL81sy/3dRwRERHpX4maw/VknEQxs/vN7JMJHrPOzN6S6HNPMc7VZvZwX8cROZ0o+SQyAJhZpZk1\nm9mITvtfDCcN41MT2enFzMqA84Efh9t9Tsq5+y53L3D31kSe2w3/AXzQzEYlYCwRERHpguZwR5nZ\nSOAm4Dvh9jQz29PXccO50SuJPvcU4/wEmBjODUWkG5R8Ehk4/gwsat8ws0lAXurCSQ/9+bYOuA1Y\n5e7e3QsSUaWUDO7eCGwgmASKiIhI8mgOF7gFeNLdG7p7QT/P83pqDXBrqoMQGSiUfBIZOH7AsYmC\nm4Hvx59gZmeY2ffN7ICZvWpmy8wsIzyWaWb/amZVZvYKMLuLa//TzPaZ2Wtmdm93Eydm9kMze93M\n3jSzjWY2Me7YEDP7ShjPm2a2ycyGhMcuMbNfmNkhM9ttZreE+8vNbEncGMdUGIVvCv/GzP4I/DHc\n9/VwjMNmttXMLo07P9PM/snM/mRmteHxs8zsQTP7SqdnecLM7jjBo/4V8PPwvPOAfwfeHZZwHwr3\n/z8z+7aZPWlmR4DLzWx2+IbzcBjj8rj7HVPyHj77F8xscxjr0+1vS3tybnj8pvDvvdrM7grfvl4R\n9zzldPrvQERERBIubedwncYpCedBNWb2spl9NO7YVDPbEs5l3jCzB8L9uWa2MpxrHDKzF8zszBPc\nIn4elU/wEqwknEfVhfdfbmY/Csc8DNwS3vuX4fj7zOzfzCw7LjY3s3PCP/+/cH63Ppwb/Z+ZvbWX\n5840s99bMH/9lpn9PH5+iuZRIj2i5JPIwPErYJiZnRdOKBYCKzud803gDOAtwHsJJjofDo99FJgD\nXABMAa7tdO3/A2LAOeE5M4EldM8G4FxgFPBrYFXcsX8F/gJ4D1AEfApoM7Nx4XXfBEYCk4Ft3bwf\nwHzgImBCuP1COEYRsBr4oZnlhsf+nuCN4yxgGLAYqAdWAIviJncjgCvC648RTpLOBn4P4O47gY8B\nvwxLuAvjTr8B+CIwFNgEHCH4tygkmKR83E7eN+oGgn+3UUA2sLSn55rZBOBbwAeBKMF/F2M6XbuT\nYBmhiIiIJE86z+HirQX2ACXhPe4zs+nhsa8DX3f3YcBbgUfC/TeHcZ8FFBPMjU5U2TSJo/OoIwTJ\nqL3hPKrA3feG580DfkQwb1oFtAJ3ACOAdwMzgL8+yXMsBO4BhgMvE8zJenRuOCf8EfCZ8Ll+TzCX\njbcTGG9mw04yvoiElHwSGVja35xdSfB/8F5rPxA3mfmMu9e6eyXwFeBD4SnXA19z993uXgPcH3ft\nmQSJmU+6+xF33w98NRzvlNz9e+E9m4DlwPnhW7gMgkTP37n7a+7e6u6/CM+7AXjW3de4e4u7V7t7\nT5JP97t7TXvptruvDMeIuftXgBzg7eG5S4Bl7v57D/wmPPd54E2CSQzh85a7+xtd3K89uVTbjdh+\n7O6b3b3N3RvdvdzdfxtuVxCUab/3JNf/l7v/IXy2RwiSaj0991rgJ+6+yd2bgc8BnZcL1hJMGEVE\nRCS50nIOFzfOWcBfAp8O5y7bgO9ytGKrBTjHzEa4e527/ypufzFwTjjP2+ruh09wm0K6N4/6pbs/\nHs6bGsIxfxXO8SoJekadbB71mLs/7+4xguTVyeZRJzp3FrDD3deFx74BvN7p2vZnKURETimd19CK\nyPF+AGwkqMD5fqdjI4AI8Grcvlc5Wu1SAuzudKzduPDafWbWvi+j0/ldCidMXwSuI6hgaouLJwfI\nBf7UxaVnnWB/dx0Tm5ktBT5C8JxOUOHUvgTtZPdaAdwIPBP+/voJzjsU/h4KNPYwtouALwHvJKhO\nygF+eJLr4yc39UBBL8495t/b3evNrLrTtUMJkm8iIiKSXGk3h+ukBKhx9/jk0KsElVYQzLE+D/zO\nzP4M3OPu/x0+11nAWjMrJKjo+qy7t3Rxj4MEc49T6TyPehvwQBhLHsH/D7v1JNcnYx7ldnxz9PZn\nOYSInJIqn0QGEHd/laBp5SxgXafDVQRvn8bF7RvL0Tdr+wgmB/HH2u0GmoAR7l4Y/gxz94mc2g0E\n5dFXEFTRjA/3WxhTI0F5dme7T7AfgmVq8Y04R3dxTkcVjwX9nT5F8GZweLgE7s0whlPdayUwz8zO\nB84DHu/qpLA8/E/A27qK4USxhVYDTwBnufsZBL2i7LirEmsfUNq+YUGfreJO55wH/CbJcYiIiJz2\n0nQOF28vUGRm8cmhjhjc/Y/uvohgmf+XgR+ZWX5YvX6Pu08gWJY2hxN/zKSC3s2jvg38Djg3XPb3\nT/T/PMrit0PnAZUnqfQSkThKPokMPB8BpofJkA7u3kqw7OqLZjY07Kn09xztKfAIcLuZlZrZcODO\nuGv3AU8DXzGzYWaWYWZvNbOTlTS3G0ow6akmSBjdFzduG/A94IGwiWSmmb3bzHIISpuvMLPrzSzL\nzIrNrL3UeRvwfjPLC5tCfqQbMcSAA0CWmX2OoPKp3XeBL5jZuRYoM7PiMMY9BP2ifgA8eoovsDzJ\nsWXebwCl8U0vTxJfjbs3mtlUgoRdsv0IuNrM3hPGt5zjJ2rvJei7JSIiIsmXbnO4+Bh2A78A7g+b\niJeF8a4EMLMbzWxkOLdrr/RpM7PLzWxSWAl/mCCJ1tbFLaDreVSxmZ2qBcDQcOw6M3sH8PGePFsv\nrQcmmdl8Cz708jcc/zJU8yiRHlDySWSAcfc/ufuWExz+W4KqoVcIGl2vJkj+APwH8BRBpcuvOf6t\n200ES8JeIiiL/hFBo+pT+T5BWfZr4bW/6nR8KfBbggRPDcHbsgx330Xw9u8fwv3bONr8+qtAM8Gk\nZAXHNjDvylPA/wB/CGNp5NiS7QcIJm5PE0xe/hMYEnd8BUETzB+c4j4PAR+0o3XtPwV2AK+bWdVJ\nrvtr4PNmVkvQe+mRk5ybEO6+g+C/h7UEb+/qgP0EiULCZuyzCJ5dREREkiwN53CdLSKoYN8LPAbc\n7e7PhsfeB+wwszqCFgULwxd2o8P7HSboZfVzTjyf+j4wK6zGxt1/R9AH85XwS3YlJ7huKcGLu1qC\nv4uHe/FsPeLuVQQtJf6Z4AXrBGAL4TwqtIig/5SIdIO5n6jaUUTk9GBmlxG82Rvnp/gfRTNbDTzi\n7l0uz0tXZlZA8KbyXHf/s5n9LcEywE+lODQRERE5TZjZfcB+d/9aqmPpifAjOnuAD7r7z8zsauBD\n7n59ikMTGTCUfBKR05qZRQiqg37j7p9PdTyJFE6MniNYbvcV4CLgXadKsImIiIic7szsKuD/gAbg\nHwmW3r3lFC0aROQEtOxORE5bZnYeQTVQFBhQb+C6aR5B6fxe4FyCEnklnkRERERO7d0EH5upAq4G\n5ivxJNJ7qnwSEREREREREZGkUeWTiIiIiIiIiIgkjZJPIiIiIiIiIiKSNFmpDqA/jBgxwsePH5/q\nMERERCRJtm7dWuXuI1MdhxxLczAREZHBrbtzsNMi+TR+/Hi2bNmS6jBEREQkSczs1VTHIMfTHExE\nRGRw6+4cTMvuREREREREREQkaZR8EhERERERERGRpFHySUREREREREREkua06PkkIiIiIiIiIhKv\npaWFPXv20NjYmOpQ0l5ubi6lpaVEIpFeXa/kk4iIiIiIiIicdvbs2cPQoUMZP348ZpbqcNKWu1Nd\nXc2ePXs4++yzezWGlt2JiIiIiIiIyGmnsbGR4uJiJZ5OwcwoLi7uU4WYkk8iIiIiIiIiclpS4ql7\n+vr3lNTkk5m9z8x+b2Yvm9mdXRy/zMx+bWYxM7s2bv/lZrYt7qfRzOaHx2aE12wzs01mdk4yn0FE\nREREREREJBnMjBtvvLFjOxaLMXLkSObMmdOjccaPH09VVVWvzvnsZz/LWWedRUFBQY/u2RNJSz6Z\nWSbwIPBXwARgkZlN6HTaLuAWYHX8Tnf/mbtPdvfJwHSgHng6PPxt4IPhsdXAsmQ9g4iIiIiIiIhI\nsuTn57N9+3YaGhoAeOaZZxgzZky/xnD11Vfz/PPPJ/Ueyax8mgq87O6vuHszsBaYF3+Cu1e6ewXQ\ndpJxrgU2uHt9+2XAsPDPZwB7Ext29x3esIEjv/q/VN1eRERE5LTzZkMLa57fRWXVkVSHIiIikhCz\nZs1i/fr1AKxZs4ZFixZ1HKupqWH+/PmUlZVx8cUXU1FRAUB1dTUzZ85k4sSJLFmyBHfvuGblypVM\nnTqVyZMnc9ttt9Ha2nrS+1988cVEo9EkPNlRyUw+jQF2x23vCff11EJgTdz2EuBJM9sDfAj4Uq8j\n7KP9X/sahx55JFW3FxERETntHKpv5jPrfsvWVw+mOhQREZGEWLhwIWvXrqWxsZGKigouuuiijmN3\n3303F1xwARUVFdx3333cdNNNANxzzz1ccskl7Nixg2uuuYZdu3YBsHPnTh5++GE2b97Mtm3byMzM\nZNWqVSl5rnhZqQ7gZMwsCkwCnorbfQcwy93/z8z+EXiAICHV+dpbgVsBxo4dm5T4ItESWvbtS8rY\nIiIiIunCzCYD/w7kAjHgr909ufX5J1CQE0xf65piqbi9iIgMUvf8ZAcv7T2c0DEnlAzj7qsnnvK8\nsrIyKisrWbNmDbNmzTrm2KZNm3j00UcBmD59OtXV1Rw+fJiNGzeybt06AGbPns3w4cMBeO6559i6\ndSsXXnghAA0NDYwaNSqRj9UryUw+vQacFbddGu7rieuBx9y9BcDMRgLnu3v7WreHgf/p6kJ3fwh4\nCGDKlCne1Tl9FYlGOfLLXyZjaBEREZF08s/APe6+wcxmhdvTUhFIQa6STyIiMvjMnTuXpUuXUl5e\nTnV1da/HcXduvvlm7r///gRG13fJTD69AJxrZmcTJJ0WAjf0cIxFwGfitg8CZ5jZ29z9D8CVwM5E\nBNsbkWiU2P79eEsLFomkKgwRERGRZEubnps5WZlEMo3aRiWfREQkcbpToZRMixcvprCwkEmTJlFe\nXt6x/9JLL2XVqlXcddddlJeXM2LECIYNG8Zll13G6tWrWbZsGRs2bODgwWA5+owZM5g3bx533HEH\no0aNoqamhtraWsaNG5eiJwskreeTu8eATxAsmdsJPOLuO8zs82Y2F8DMLgx7N10HfMfMdrRfb2bj\nCSqnft5pzI8Cj5rZbwh6Pv1jsp7hVCIlUWhro+WN/akKQURERKQ/fBL4FzPbDfwrx74c7HcFOVkc\nUeWTiIgMIqWlpdx+++3H7V++fDlbt26lrKyMO++8kxUrVgBBL6iNGzcyceJE1q1b19FuaMKECdx7\n773MnDmTsrIyrrzySvadol3Qpz71KUpLS6mvr6e0tJTly5cn/PksviP6YDVlyhTfsmVLwset27yZ\n3R9ZwrgffJ+8cD2liIiI9D8z2+ruU1Idx0BmZs8Co7s49FlgBvBzd3/UzK4HbnX3K04wTnzfzb94\n9dVXEx7rpf/8U6aMK+KrCyYnfGwRETl97Ny5k/POOy/VYQwYXf19dXcOltYNx9NdJFoCoKbjIiIi\nMuCdKJkEYGbfB/4u3Pwh8N2TjJP0vpsFOREtuxMRERlAkrbs7nQQKYkC0LJXyScREREZ1PYC7w3/\nPB34YwpjoSAnk7qmllSGICIiIj2gyqc+yMjNJbOoSJVPIiIiMth9FPi6mWUBjYTL6lKlICeLqrrm\nVIYgIiIiPaDkUx9FolFa9qXsgy8iIiIiSefum4C/SHUc7QpyI1RW16c6DBEREekmLbvro0hJlJa9\nSj6JiIiI9JeCnCz1fBIRERlAlHzqo6xolNjefZwOXw0UERERSQfq+SQiIjKwKPnUR5FoCW319bQd\nPpzqUEREREROCwU5ERpb2oi1tqU6FBERkT4xM2688caO7VgsxsiRI5kzZ06Pxhk/fjxVVVU9Pqe+\nvp7Zs2fzjne8g4kTJ3LnnXf26L7dpeRTH0VKSgDUdFxERESknxTkBm1LjzS1pjgSERGRvsnPz2f7\n9u00NDQA8MwzzzBmzJh+jWHp0qX87ne/48UXX2Tz5s1s2LAh4fdQ8qmPIiVRAFr2KvkkIiIi0h+G\n5gTJp1otvRMRkUFg1qxZrF+/HoA1a9awaNGijmM1NTXMnz+fsrIyLr74YioqKgCorq5m5syZTJw4\nkSVLlhzTCmjlypVMnTqVyZMnc9ttt9HaeuKXNXl5eVx++eUAZGdn8653vYs9e/Yk/BmVfOqjSDRM\nPumLdyIiIiL9Ij9MPtU1qem4iIgMfAsXLmTt2rU0NjZSUVHBRRdd1HHs7rvv5oILLqCiooL77ruP\nm266CYB77rmHSy65hB07dnDNNdewa9cuAHbu3MnDDz/M5s2b2bZtG5mZmaxatapbcRw6dIif/OQn\nzJgxI+HPmJXwEU8zmUVFWHa2vngnIiIi0k+OLrtT8klERBJkw53w+m8TO+boSfBXXzrlaWVlZVRW\nVrJmzRpmzZp1zLFNmzbx6KOPAjB9+nSqq6s5fPgwGzduZN26dQDMnj2b4cOHA/Dcc8+xdetWLrzw\nQgAaGhoYNWrUKWOIxWIsWrSI22+/nbe85S09eszuUPKpjywjg6zoaGLq+SQiIiLSLwral901Kvkk\nIiKDw9y5c1m6dCnl5eVUV1f3ehx35+abb+b+++/v0XW33nor5557Lp/85Cd7fe+TUfIpASLREvV8\nEhEREeknQ3O17E5ERBKsGxVKybR48WIKCwuZNGkS5eXlHfsvvfRSVq1axV133UV5eTkjRoxg2LBh\nXHbZZaxevZply5axYcMGDh48CMCMGTOYN28ed9xxB6NGjaKmpoba2lrGjRt3wnsvW7aMN998k+9+\n97tJez71fEqASDSqr92JiIiI9JOOnk+qfBIRkUGitLSU22+//bj9y5cvZ+vWrZSVlXHnnXeyYsUK\nIOgFtXHjRiZOnMi6desYO3YsABMmTODee+9l5syZlJWVceWVV7LvJPmKPXv28MUvfpGXXnqJd73r\nXUyePDkpSShVPiVApKSE2P79eEsLFomkOhwRERGRQa1ADcdFRGSQqKurO27ftGnTmDZtGgBFRUU8\n/vjjx51TXFzM008/3eWYCxYsYMGCBcftr6ysPG5faWnpMV/KSxZVPiVApCQK7rS8sT/VoYiIiIgM\neko+iYiIDCxKPiVAJBoFoGXvaymORERERGTwy8ww8rIztexORERkgFDyKQGywuSTvngnIiIi0j/y\nc7JU+SQiIjJAKPmUAB2VT0o+iYiIiPSLoUo+iYiIDBhKPiVARm4umUVFtOxV8klERESkPxTkKvkk\nIiIyUCj5lCCRaFSVTyIiIiL9JD87Sz2fREREBgglnxIkUlJCy769qQ5DRERE5LSgyicRERkMzIwb\nb7yxYzsWizFy5EjmzJnTo3HGjx9PVVVVr8553/vex/nnn8/EiRP52Mc+Rmtra4/u3R1KPiVIpCRK\ny959uHuqQxEREREZ9NTzSUREBoP8/Hy2b99OQ0MDAM888wxjxozp1xgeeeQRfvOb37B9+3YOHDjA\nD3/4w4TfQ8mnBMmKRvH6etrefDPVoYiIiIgMeqp8EhGRwWLWrFmsX78egDVr1rBo0aKOYzU1Ncyf\nP5+ysjIuvvhiKioqAKiurmbmzJlMnDiRJUuWHFMIs3LlSqZOncrkyZO57bbbTlnJNGzYMCCoumpu\nbsbMEv2ISj4lSiRaAuiLdyIiIiL9IT8n6PmkqnMRERnoFi5cyNq1a2lsbKSiooKLLrqo49jdd9/N\nBRdcQEVFBffddx833XQTAPfccw+XXHIJO3bs4JprrmHXrl0A7Ny5k4cffpjNmzezbds2MjMzWbVq\n1SljuOqqqxg1ahRDhw7l2muvTfgzZiV8xDhm9j7g60Am8F13/1Kn45cBXwPKgIXu/qNw/+XAV+NO\nfUd4/HELUnD3AtcBrcC33f0byXyO7oiURIEg+ZR73nkpjkZERERkcCvIySLW5jTF2siNZKY6HBER\nGeC+/PyX+V3N7xI65juK3sGnp376lOeVlZVRWVnJmjVrmDVr1jHHNm3axKOPPgrA9OnTqa6u5vDh\nw2zcuJF169YBMHv2bIYPHw7Ac889x9atW7nwwgsBaGhoYNSoUaeM4amnnqKxsZEPfvCD/PSnP+XK\nK6/s0bOeStKST2aWCTwIXAnsAV4wsyfc/aW403YBtwBL4691958Bk8NxioCXgafDw7cAZwHvcPc2\nMzv132I/iETD5NNeVT6JiIjIwGRm1wHLgfOAqe6+Je7YZ4CPELz8u93dn0pJkKGhucE0tq4ppuST\niIgMeHPnzmXp0qWUl5dTXV3d63HcnZtvvpn777+/x9fm5uYyb948fvzjHw+c5BMwFXjZ3V8BMLO1\nwDygI/nk7pXhsbaTjHMtsMHd68PtjwM3uHtbOMb+xIfec5nFxVh2tr54JyIiIgPZduD9wHfid5rZ\nBGAhMBEoAZ41s7e5e+I/h9NNBTlh8qkxxoiCnFSFISIig0R3KpSSafHixRQWFjJp0iTKy8s79l96\n6aWsWrWKu+66i/LyckaMGMGwYcO47LLLWL16NcuWLWPDhg0cPHgQgBkzZjBv3jzuuOMORo0aRU1N\nDbW1tYwbN67L+9bV1VFbW0s0GiUWi7F+/XouvfTShD9fMpNPY4Ddcdt7gItOcO7JLAQeiNt+K7DA\nzK4BDhC8eftjr6NMEDMjEo3SslfJJxERERmY3H0n0FWj0XnAWndvAv5sZi8TvGj8Zf9GeFR+ztHK\nJxERkYGutLSU22+//bj9y5cvZ/HixZSVlZGXl8eKFSuAoBfUokWLmDhxIu95z3sYO3YsABMmTODe\ne+9l5syZtLW1EYlEePDBB0+YfDpy5Ahz586lqamJtrY2Lr/8cj72sY8l/PmS2vOpr8wsCkwC4su6\nc4BGd59iZu8Hvgccl5Yzs1uBW4GOf4RkyyqJEtOyOxERERl8xgC/itveE+5LmaFKPomIyCBQV1d3\n3L5p06Yxbdo0AIqKinj88cePO6e4uJinn376uP0ACxYsYMGCBcftr6ysPG7fmWeeyQsvvNCzoHsh\nmV+7e42gN1O70nBfT1wPPObuLXH79gDrwj8/RtCs/Dju/pC7T3H3KSNHjuzhbXsnEi3R1+5EREQk\nrZnZs2a2vYufeQka/1Yz22JmWw4cOJCIIbtUkHt02Z2IiIikt2RWPr0AnGtmZxMknRYCN/RwjEXA\nZzrtexy4HPgz8F7gD32MM2Ei0SixAwfw5mYsOzvV4YiIiIgcx92v6MVl3X6p6O4PAQ8BTJkyxXtx\nr24pUOWTiIjIgJG0yid3jwGfIFgytxN4xN13mNnnzWwugJldaGZ7gOuA75jZjvbrzWw8wSTn552G\n/hLwATP7LXA/sCRZz3BKa26A8i91bEZKouBOy/606IEuIiIikihPAAvNLCd8sXgu8HwqA2pPPtUq\n+SQiIpL2ktrzyd2fBJ7stO9zcX9+geDNWVfXVtJFLwF3PwTMTmigvVX3BlRu6tiMRKMAtOzdS3Zp\nl48lIiIikrbCD7p8ExgJrDezbe5+VfgC8RGCrxbHgL9J5Zfu4OiyuyNKPomIiKS9tG44nvaiZbD9\nUXAHMyIlJQDE1PdJREREBiB3f4ygp2ZXx74IfLF/IzqxIZFMMkw9n0RERAaCZDYcH/xGl0Hjm3Do\nVQCyRo8GgsonEREREUkeM6MgJ0s9n0RERAYAJZ/6Ihp+aG9fBQAZublkFhfTsleVTyIiIiLJVpCT\nRa0qn0REZAAzM2688caO7VgsxsiRI5kzZ06Pxhk/fjxVVVV9Omfu3Lm8853v7NF9u0vJp74YNREs\nE16v6NgViUZp0bI7ERERkaQryM1SzycRERnQ8vPz2b59Ow0NDQA888wzjBlzXPvrpFu3bh0FBQVJ\nG1/Jp76I5MLIt3dUPoGSTyIiIiL9RcvuRERkMJg1axbr168HYM2aNSxatKjjWE1NDfPnz6esrIyL\nL76Yioog/1BdXc3MmTOZOHEiS5Yswd07rlm5ciVTp05l8uTJ3HbbbbS2nvwbIXV1dTzwwAMsW7Ys\nCU8XUPKpr0aXHVv5VBIkn+L/4UVEREQk8QpyI9Qq+SQiIgPcwoULWbt2LY2NjVRUVHDRRRd1HLv7\n7ru54IILqKio4L777uOmm24C4J577uGSSy5hx44dXHPNNezatQuAnTt38vDDD7N582a2bdtGZmYm\nq1atOun977rrLv7hH/6BvLy8pD2jvnbXV9EyqFgLdQegYCSRkhK8vp62N98ks7Aw1dGJiIiIDFoF\nOZm8drA+1WGIiMgg8Pp999G083cJHTPnvHcw+p/+6ZTnlZWVUVlZyZo1a5g1a9YxxzZt2sSjjz4K\nwPTp06murubw4cNs3LiRdevWATB79myGDx8OwHPPPcfWrVu58MILAWhoaGDUqFEnvPe2bdv405/+\nxFe/+lUqKyt785jdouRTX40Om46//hs45wqyolEg+OKdkk8iIiIiyVOQk8WRppMvJRARERkI5s6d\ny9KlSykvL6e6urrX47g7N998M/fff3+3zv/lL3/Jli1bGD9+PLFYjP379zNt2jTKy8t7HUNXlHzq\nq9GTgt/7KuCcK4hESwBo2beP3AkTUhiYiIiIyOBWkBNRzycREUmI7lQoJdPixYspLCxk0qRJxyR+\nLr30UlatWsVdd91FeXk5I0ZDXpzIAAAgAElEQVSMYNiwYVx22WWsXr2aZcuWsWHDBg4ePAjAjBkz\nmDdvHnfccQejRo2ipqaG2tpaxo0b1+V9P/7xj/Pxj38cgMrKSubMmZPwxBMo+dR3QwqhcFxH36dI\nSXvlk5qOi4iIiCRTQW7QcLytzcnIsFSHIyIi0mulpaXcfvvtx+1fvnw5ixcvpqysjLy8PFasWAEE\nvaAWLVrExIkTec973sPYsWMBmDBhAvfeey8zZ86kra2NSCTCgw8+eMLkU39R8ikRomUdX7zLLCrC\nsrP1xTsRERGRJCvIyQTgSHOMobmRFEcjIiLSc3V1dcftmzZtGtOmTQOgqKiIxx9//LhziouLefrp\np7scc8GCBSxYsOC4/afq6TR+/Hi2b99+6qB7QV+7S4TR50PNn6DxMGZGJBqlZd/eVEclIiIiMqgV\n5AQJJ/V9EhERSW9KPiVCNGw6/kaQIcwqiRLTsjsRERGRpCrIDYr465paUhyJiIiInIyST4nQ/sW7\nfe19n0po2avKJxEREZFkGpoTJJ9qG9V0XEREJJ0p+ZQIQ0dD/sijTcejJcQOHKCtuTnFgYmIiIgM\nXvk57ZVPSj6JiIikMyWfEsEsqH5qr3yKBl+8i73xRiqjEhERERnUCsLk0xEln0RERNKakk+JEi2D\nAzsh1kSkJEg+tajvk4iIiEjSDM3VsjsREZGBQMmnRBldBm0x2L+zo/JJX7wTERERSZ4CLbsTEZEB\nzsy48cYbO7ZjsRgjR45kzpw5PRpn/PjxVFVV9eqcadOm8fa3v53JkyczefJk9u/f36N7d0dWwkc8\nXUXPD36/XkHWhOsBiO1T5ZOIiIhIsnT0fFLlk4iIDFD5+fls376dhoYGhgwZwjPPPMOYMWP6PY5V\nq1YxZcqUpI2vyqdEGX42ZA+FfRVk5OaSWVysL96JiIiIJFF2VgbZWRnUNSv5JCIiA9esWbNYv349\nAGvWrGHRokUdx2pqapg/fz5lZWVcfPHFVFQEvaarq6uZOXMmEydOZMmSJbh7xzUrV65k6tSpTJ48\nmdtuu43W1tb+faAuKPmUKBkZMPqdR794V1Kink8iIiIiSTY0J0uVTyIiMqAtXLiQtWvX0tjYSEVF\nBRdddFHHsbvvvpsLLriAiooK7rvvPm666SYA7rnnHi655BJ27NjBNddcw65duwDYuXMnDz/8MJs3\nb2bbtm1kZmayatWqU8bw4Q9/mMmTJ/OFL3zhmERWomjZXSKNLoMXV0JbK5FolKaXX051RCIiIiKD\nWkFulno+iYhIn/3vI3+ganddQscccVYBl17/tlOeV1ZWRmVlJWvWrGHWrFnHHNu0aROPPvooANOn\nT6e6uprDhw+zceNG1q1bB8Ds2bMZPnw4AM899xxbt27lwgsvBKChoYFRo0ad9P6rVq1izJgx1NbW\n8oEPfIAf/OAHHUmuRFHyKZGiZfD8Eah5hUg0St3//i/ujpmlOjIRERGRQSk/O4sjSj6JiMgAN3fu\nXJYuXUp5eTnV1dW9Hsfdufnmm7n//vu7fU17j6mhQ4dyww038Pzzzyv5lNZGlwW/9/2GSEkUb2ig\n9dAhssIMpIiIiIgkVkFuFrVadiciIn3UnQqlZFq8eDGFhYVMmjSJ8vLyjv2XXnopq1at4q677qK8\nvJwRI0YwbNgwLrvsMlavXs2yZcvYsGEDBw8eBGDGjBnMmzePO+64g1GjRlFTU0NtbS3jxo3r8r6x\nWIxDhw4xYsQIWlpa+O///m+uuOKKhD9fUns+mdn7zOz3Zvaymd3ZxfHLzOzXZhYzs2vj9l9uZtvi\nfhrNbH6na79hZomtieurke+AjEjwxbtoFNAX70RERGTgMLPrzGyHmbWZ2ZS4/Vea2VYz+234e3oq\n44w3NEfL7kREZOArLS3l9ttvP27/8uXL2bp1K2VlZdx5552sWLECCHpBbdy4kYkTJ7Ju3TrGjh0L\nwIQJE7j33nuZOXMmZWVlXHnllew7SV6iqamJq666irKyMiZPnsyYMWP46Ec/mvDnS1rlk5llAg8C\nVwJ7gBfM7Al3fynutF3ALcDS+Gvd/WfA5HCcIuBl4Om4sacA6VdOlJUNo86DfRVELrgegJZ9+8id\nMCHFgYmIiIh0y3bg/cB3Ou2vAq52971m9k7gKaD/vwPdhYLcLOoOKPkkIiIDU13d8TU106ZNY9q0\naQAUFRXx+OOPH3dOcXExTz/99HH7ARYsWMCCBQuO219ZWXncvvz8fLZu3dqzoHshmZVPU4GX3f0V\nd28G1gLz4k9w90p3rwDaTjLOtcAGd6+HjqTWvwCfSk7YfRQtg9criJQElU8tr+1NcUAiIiIi3ePu\nO939913sf9Hd2yc1O4AhZpbTv9F1LT9HPZ9ERETSXTKTT2OA3XHbe+jdG7KFwJq47U8AT7h7eq5n\nG30+1FeTmdmA5eTQomV3IiIiMrh8APi1uzd1ddDMbjWzLWa25cCBA0kPZmiOej6JiIiku6T2fOor\nM4sCkwhKuzGzEuA64JvduLZfJz4dokHTcXvjt0SiUSWfREREJK2Y2bNmtr2Ln3nduHYi8GXgthOd\n4+4PufsUd58ycuTIRIYeOFIF5V+C17cDUJCTRVOsjebYyQrpRUREJJWS+bW714Cz4rZLw309cT3w\nmLu3hNsXAOcAL5sZQJ6Zvezu53S+0N0fAh4CmDJlivfwvr135jsBC/o+lURp2adldyIiIpI+3L1X\nn7Axs1LgMeAmd/9TYqPqgeYjUH4/DBsDo99JQW4wnT3SFCM7KztlYYmIyMDk7oT5BTkJ976lVZJZ\n+fQCcK6ZnW1m2QTL557o4RiLiFty5+7r3X20u4939/FAfVeJp5TKKYDit3Z88S62V5VPIiIiMrCZ\nWSGwHrjT3TenNJi84uB3fTUQ9HwC9MU7ERHpsdzcXKqrq/ucWBns3J3q6mpyc3N7PUbSKp/cPWZm\nnyBYMpcJfM/dd5jZ54Et7v6EmV1I8AZtOHC1md3j7hMBzGw8QeXUz5MVY9KMLoM9W4hE30PswAHa\nmpvJyNabOBEREUlvZnYNQXuDkcB6M9vm7lcR9Nw8B/icmX0uPH2mu+/v9yCz8yEzBxpqgKDnEyj5\nJCIiPVdaWsqePXvo11Y9A1Rubi6lpaW9vj6Zy+5w9yeBJzvt+1zcn18gWI7X1bWVnKJBubsX9D3K\nJIiWwY51RN4+DIDY66+TPXZsioMSEREROTl3f4zgxWDn/fcC9/Z/RF0wC6qfwsqn9mV3Sj6JiEhP\nRSIRzj777FSHcVpI64bjA9booOl4JKcegBYtvRMRERFJnLxiqA8qnzqW3emLdyIiImlLyadkiJ4P\nQMSC0j198U5EREQkgfKKOiqftOxOREQk/Sn5lAz5I2BoCVlNfwbQF+9EREREEknL7kRERAYUJZ+S\nJVpGRvV2MkeMIKbKJxEREZHEiU8+admdiIhI2lPyKVlGl0HVH4iMPlM9n0REREQSKa8YGg5Ba4z8\n7CD5VKvKJxERkbSl5FOyRMvA24gMz6Nlr5bdiYiIiCRMXjHg0HiIjAwjPzuTI0o+iYiIpC0ln5Kl\n/Yt3+W207NuHu6c4IBEREZFBIq8o+B3X90nL7kRERNKXkk/JUjgWcguJZNfhjY20HjqU6ohERERE\nBoe84uB3XN8nNRwXERFJX0o+JYsZjJ5Elr8BoKV3IiIiIonSufIpJ0s9n0RERNKYkk/JFD2fSOxV\nAH3xTkRERCRROlc+5Wap55OIiEgaU/IpmUaXEclpANAX70REREQSZcjxlU/q+SQiIpK+lHxKpmgZ\nmTltWCRLy+5EREREEiU7DyJ5UF8DQEFORD2fRERE0piST8lUfC4WySVSmEuLlt2JiIiIJE5ecVzl\nUya1jS0pDkhERERORMmnZMrMgjMnEslvVfJJREREJJHyio5WPuVmcaS5FXdPcVAiIiLSFSWfkm10\nGVmRw1p2JyIiIpJIx1Q+RWhtcxpb2lIclIiIiHRFyadkiwZNx1urqmhrbk51NCIiIiKDQ3zyKTcL\ngNomLb0TERFJR0o+Jdvo84nktQIQe/31FAcjIiIiMkjkFcc1HM8E0BfvRERE0pSST8l25gQi+UH/\nAS29ExEREUmQvGJoehNaWyjIiQBwpKk1xUGJiIhIV5R86oNuNbWMDCFSOhaAlr1qOi4iIiKSEHlF\nwe/6GgpytOxOREQknSn51Evuzqc3fpqHKh6ipe3kE52sc84HoGWfKp9EREREEiKvOPhdX83QsOeT\nlt2JiIikJyWfeqmlrYU22vjmi9/khvU3sLN65wnPzRh7AZm5rbTs+nM/RigiIiIyiMUln/LDyqcj\nzUo+iYiIpCMln3opOzObf33vv/K1y79GVUMVi9Yv4hu//gZNrU3Hnzy6jEheK7Fdf+r/QEVEREQG\no7jkU/uyO1U+iYiIpCcln/poxtgZPD7vcea8ZQ7/8dv/4LqfXMe2/duOPWn0JCL5rbTsU88nERER\nSV9mdp2Z7TCzNjOb0sXxsWZWZ2ZLUxHfMbpYdlfbpOSTiIhIOlLyKQHOyDmDey+5l3+/4t9pjDVy\n04ab+PLzX6a+pT44YUghkeH5tFTXdq9JuYiIiEhqbAfeD2w8wfEHgA39F85JDDnacDwnK4OsDFPl\nk4iISJpS8imB/nLMX/LYvMdY8PYFrNy5kvc/8X5+te9XAERKSvCWNloPHkxxlCIiIiJdc/ed7v77\nro6Z2Xzgz8CO/o3qBLKyIXso1FdjZuTnZHFElU8iIiJpKanJJzN7n5n93sxeNrM7uzh+mZn92sxi\nZnZt3P7LzWxb3E9jOOHBzFaFY243s++ZWSSZz9BT+ZF8PnvxZ/mvq/6LrIwsPvr0R1n+i+XExr0F\ngJZXX05xhCIiIiI9Y2YFwKeBe1IdyzHyiqC+GoCCnCwtuxMREUlTWcka2MwygQeBK4E9wAtm9oS7\nvxR32i7gFuCYvgHu/jNgcjhOEfAy8HR4eBVwY/jn1cAS4NvJeYremzJ6Cj+6+kd8a9u3WPHSCipb\nc/kURt1vNtH21renOjwREZGUyB92RqpDOO2Z2bPA6C4Ofdbdf3yCy5YDX3X3OjM71fi3ArcCjB07\ntg+RdkNecUfyaWhulpbdiYiIpKmkJZ+AqcDL7v4KgJmtBeYBHcknd68Mj7WdZJxrgQ3uXh9e82T7\nATN7HihNeOQJkpuVy99P+Xtmjp/J/U9+hl9c/CmafjUcfrU11aGJiIj0u5yGSpasWJzqME577n5F\nLy67CLjWzP4ZKATazKzR3f+ti/EfAh4CmDJlSnKbXeYVw5EDQFD5VKfKJxERkbSUzOTTGGB33PYe\ngolLTy0kaG55jHC53YeAv+tVdP3onSPeyacveIj//cVOslpfJGLq+yQiIqefzKKTvWuSdObul7b/\n2cyWA3VdJZ76XV4xVAUtqvJzsjhU35zigERERKQryUw+9ZmZRYFJwFNdHP4WsNHd//cE1/ZfyXc3\nvPHqEQBKbrmOq/8y9fGIiIiIdGZm1wDfBEYC681sm7tfleKwTiyvGOprACjIzWL3wfoUByQiIiJd\nSWby6TXgrLjt0nBfT1wPPObuLfE7zexugknRbSe6sF9LvruhencdjThnluSnOhQRERGRLrn7Y8Bj\npzhnef9E0w15RdBcBy2NDM1RzycREZF01a2v3ZnZOjObbWY9+TreC8C5Zna2mWUTLJ97oofxLQLW\ndIplCXAVsMjdB0z9fu3r9ezPbKMoPyfVoYiIiIgMWM17XqNy0Q3UbdocVD4BNNSo55OIiEga624y\n6VvADcAfzexLZnbKz7W5ewz4BMGSuZ3AI+6+w8w+b2ZzAczsQjPbA1wHfMfMdrRfb2bjCSqnft5p\n6H8HzgR+aWbbzOxz3XyGlGlrc5qrmtif5RTnZ6c6HBEREZEBKyM3h4YXX6T51cqjyaf6avJzsqhv\nbqW1LeUF7yIiItJJt5bdufuzwLNmdgZBNdKzZrYb+A9gZedlcXHXPQk82Wnf5+L+/AIn+Fpd+CW8\nMV3sT+s+VV059EY9tDoHcto4Y0gk1eGIiIiIDFiZRUWQmUnswAHIGx/srK9maG7QU/NIc4xhuZpv\niYiIpJNuL6Mzs2LgFmAJ8CLwdeBdwDNJiWwQObCrFoDGgkwyMizF0YiIiIgMXJaRQdaIEcT2Hzim\n8qkgJ3g/qb5PIiIi6adbVURm9hjwduAHwNXuvi889LCZbUlWcINF1e5a2gwyztBbOBEREZG+yho1\nitj+/XHJpxoKcsPkk/o+iYiIpJ3uLmH7hrv/rKsD7j4lgfEMSgd211E3xBheoGbjIiIiIn2VNWoU\nLbt3w5DhwY76avLPUPJJREQkXXV32d0EMyts3zCz4Wb210mKaVBxd6p211IdgSI1GxcRERHpk0ON\nh3gl6yBNb7wOmVmQWxj0fNKyOxERkbTV3eTTR939UPuGux8EPpqckAaX2ppGmupj7KNVyScRERGR\nPjoSO8JPG7bBm4dpa24Olt7VV2vZnYiISBrrbvIp08w6OmWbWSagTEo3VO2uA6CyrVnJJxEREZE+\nKmgpJDP7amrzxxxtOq6G4yIiImmtuz2f/oegufh3wu3bwn1yCgd212IGb2S4kk8iIiIifZThmRTH\nZnJ42AFi+/eTnVcEh187mnxS5ZOIiEja6W7y6dMECaePh9vPAN9NSkSDTNXuOvJG5BJraVDySURE\nRKSP8s7IxnGacoYf/eLd678lX8knERGRtNWt5JO7twHfDn+kB6p215ITzYO9B5V8EhEREemjzMwM\nWnMaacopDJJPo4ugvppIZga5kQwln0RERNJQt3o+mdm5ZvYjM3vJzF5p/0l2cANdQ10zdQebsMII\noK/diYiIiCREQYzGnEJiB8LKp1gjNNdTkBOhVj2fRERE0k53G47/F0HVUwy4HPg+sDJZQQ0WVbuC\nZuNNQ4MCs+L8nFSGIyIiIoOImf2dmQ2zwH+a2a/NbGaq4+oPkWFG/ZDhNL2+L0g+Qdh0PJMjqnwS\nERFJO91NPg1x9+cAc/dX3X05MDt5YQ0OB3bXAlCbG2wPz4+kMBoREREZZBa7+2FgJjAc+BDwpdSG\n1D/yC7Npzi6k/vXXjk0+5WZp2Z2IiEga6m7D8SYzywD+aGafAF4DCpIX1uBQtbuWgqIcXo21UZCT\nRU5WZqpDEhERkcHDwt+zgB+4+w4zs5NdMFgMK8qjLjNG44FDnSqf8qjTsjsREZG0093Kp78D8oDb\ngb8AbgRuTlZQg8WB3XWMPGsoNUeaVPUkIiIiibbVzJ4mSD49ZWZDgbYUx9QvRo4sBKCxti0u+VRD\nQU4Wtap8EhERSTunTD6ZWSawwN3r3H2Pu3/Y3T/g7r/qh/gGrObGGIf21zPirKFUH2mmSP2eRERE\nJLE+AtwJXOju9UAE+HBqQ+ofJWeOBCDWlkeb5QU766spyMlSzycREZE0dMrkk7u3Apf0QyyDSvVr\nR8Bh5FkFHKxvplhfuhMREZHEejfwe3c/ZGY3AsuAN1McU78Y0V75lFNI7HAzWIZ6PomIiKSx7i67\ne9HMnjCzD5nZ+9t/khrZAFcVNhsfcdZQauqaGZ6n5JOIiIgk1LeBejM7H/gH4E8EXyQe9PLPCCrK\nm3IKiVVVwZDhYeVTRD2fRERE0lB3G47nAtXA9Lh9DqxLeESDxIHdteTmRygYnkNNfTPFBUo+iYiI\nSELF3N3NbB7wb+7+n2b2kVQH1R8yIxm0RhpoyhlOy/79Qd+n+moKRmTS3NpGU6xVH3oRERFJI91K\nPrn7adE/IJGqdtcx4qwCGlpaaWxpo0jL7kRERCSxas3sM8CHgEvDLxOfNl848fxmmnKGE9t/4Gjy\nKSeY2h5pUvJJREQknXRr2Z2Z/ZeZfa/zT7KDG6haW9uo3ht86a66rhmAIi27ExERkcRaADQBi939\ndaAU+Je+DGhm15nZDjNrM7MpnY6Vmdkvw+O/NbPcvtyrrzLPMBpyC2l+4/Uw+VRDQW6Qe9PSOxER\nkfTS3Z5P/w2sD3+eA4YBdckKaqA7uO8IbTFnxNig2TigyicRERFJqDDhtAo4w8zmAI3u3teeT9uB\n9wMb43eaWRawEviYu08EpgEtfbxXnwwpjNCYU8iRfbshr+iYyqfappSGJiIiIp10d9ndo/HbZrYG\n2JSUiAaBA7uCvNzIs4ay7c0jABSp55OIiIgkkJldT1DpVA4Y8E0z+0d3/1Fvx3T3neHYnQ/NBCrc\n/TfhedW9vUeinDE8jzeynPo3qiDvvCD5lB0stTvS1Jri6ERERCRedxuOd3YuMCqRgQwmVbtrycrO\n4IxRedS8dhDQsjsRERFJuM8CF7r7fgAzGwk8C/Q6+XQSbwPczJ4CRgJr3f2fk3CfbiseeQZvcIj6\nQ80wpAjaWhiW2QhAnSqfRERE0kq3kk9mVkvwdbt2rwOfTkpEg8CB3bWMKC0gI8OOLrtT5ZOIiIgk\nVkZ74ilUTTdaKpjZs8DoLg591t1/fILLsoBLgAuBeuA5M9vq7s91Mf6twK0AY8eOPVU4vTZ6VDEv\ncYiW+gx8SBEGDGs7DECtej6JiIiklW71fHL3oe4+LO7nbZ2X4nXFzN5nZr83s5fN7M4ujl9mZr82\ns5iZXRu3/3Iz2xb302hm88NjZ5vZ/4VjPmxmaZXV8Tanak8dI84aCkD1kWYimcbQnN4WmYmIiIh0\n6X/M7Ckzu8XMbiHozfnkqS5y9yvc/Z1d/Jwo8QSwB9jo7lXuXh/e510nGP8hd5/i7lNGjhzZi8fq\nntGjRgDQYgW0WQEAQz1IPtU1KfkkIiKSTrr7tbtrzOyMuO3C9mTQSa7JBB4E/gqYACwyswmdTtsF\n3AKsjt/p7j9z98nuPhmYTvCG7enw8JeBr7r7OcBB4CPdeYb+8mZVAy2NrYwMk081dc0Mz8vuqneC\niIiISK+5+z8CDwFl4c9D7p6syvSngElmlhc2H38v8FKS7tUtBcODj+015QwnVh/Ms/JibwJwRMkn\nERGRtNLdr93d7e5vtm+4+yHg7lNcMxV42d1fcfdmYC0wL/4Ed6909wqg7STjXAtscPd6CzI40zna\ny2AFcNIkWH+r2h00Gx9xVvAGrqa+WV+6ExERkaRw90fd/e/Dn8f6Ol74wnEP8G5gfdjjCXc/CDwA\nvABsA37t7uv7er++iGRn0pbZQFNOIbEjQYPxnOaDmEGdlt2JiIikle6uBesqSXWqa8cAu+O29wAX\ndfN+8RYSTHYAioFD7t4+o9gT3idtHNhdS0aGUVwSJp+OKPkkIiIiidNFL86OQ4C7+7Dejh0msLpM\nYrn7SmBlb8dOhrYhTUHy6XDQYzOjoYaC7CJqVfkkIiKSVrpb+bTFzB4ws7eGPw8AW5MZGICZRYFJ\nBKXePb32VjPbYmZbDhw4kPjgTqBqdy3Do/lkRoK/2oNKPomIiEgCddGLs/1naF8STwNRxjCnMaeQ\nloO1YJlQX01BbpYqn0RERNJMd5NPfws0Aw8TLJ9rBP7mFNe8BpwVt10a7uuJ6/n/7N17mNx1fff/\n53vOhz3M7CmnJQcrCkRWsOGgN9AAEjHEYH9iIeod7N4UlbsX1pZavEUCXHjT2vvS/ryKv7tUepeW\nkGIhRmukEqEph6utEO80BoJKQs6B7M7sZndm5zyf3x8zm2ySzXkns4fX47rG+X4/38O8PzO4O3nv\n5/P+wPedc8Pr5SaAWLXWwHHvebaKXR6pZ1eK9uqUO6gUHG9V8klERERkzIVaAmRDcdL7dkOkFYYS\nRIM+0nkln0RERMaTk5p255xLA0etVncCrwDnmtk8KgmiW4BPneI9lgFfGRGHM7N/oVIH6h+AW4Hj\nrcxyVqUP5MgM5A+udFcolTmQKRBX8klERERkzDXGQyT8Xgb37YX3VZJPDUEfgxr5JCIiMq6c7Gp3\n68wsNmI/PlyA8liqdZl+n8qUuS3A95xzr5nZA2a2tHqfS6pFLT8J/JWZvTbiNeZSGTn1r0fc+k+A\nPzSzN6nUgHr0ZPpwNvTsHASgfXZl5FP/UGXAlkY+iYiIiIy9lrbKLMN071B15FOSxpCPlGo+iYiI\njCsnW3C8rbrCHVBZ8cTMOk50kXPux8CPj2i7d8T2K1Smzo127XZGKSbunNtGZSW9cefgSnedlZFP\nyXSl+KVGPomIiIiMvWkdrfyaNLmUg0gL9P6KhmYfbx/I1js0ERERGeFkaz6VzWz28E51VNJoq6xM\nab27BmlqDxMIV3J6iXQOQAXHRURERGpg5rRKXc9CLoALtxyq+aSRTyIiIuPKyY58+irwkpn9K5Vl\nfK8Ebq9ZVBNUz65B2mc3HtzvSw9PuwvWKyQRERGRSau5JQpAwdtE2ZrwDiVpDHgYVPJJRERkXDmp\nkU/OuX8GFgC/BFYBfwRkahjXhJPLFBnozR4sNg6QrI58ikf99QpLREREZNIKhHyULUsuGKOYC4Ar\n0erPksoVcU6D9EVERMaLkxr5ZGa3AV+kUp9pI3A58G/ANbULbWLp3VUtNj4i+ZQYrvkU0bQ7ERER\nkVpwwQzZYIxCJksQaLUUzsFQvkQ0eLKD/EVERKSWTrbm0xeBS4AdzrmrgYuB/uNfMrUcLDZ+TsPB\ntr50nuawH7/3ZN9mERERETkV1lAiF4xTTJcBiFP5g6DqPomIiIwfJ5sVyTrnsgBmFnTOvQG8t3Zh\nTTw9uwaJNAWINh+q75RI51VsXERERKSG/C0+csEYmQOVihAxBgBU90lERGQcOdmxyLvNLAasAdaZ\nWR+wo3ZhTTy9uwYPq/cE0Dek5JOIiIhILTW0RTgQ8HEg0c+MCDS5QSBOKqvkk4iIyHhxUskn59xv\nVzfvM7N/AZqBf65ZVBNMsVAiuW+IuRe2HdaeSOU5pyVSp6hEREREJr+WtkYOWI6BRB4iEC0dACCl\nkU8iIiLjxikXI3LO/atz7ofOuXwtApqIknvTuLI7auRTMp2nRcXGRURERGqmvb0FgKEDJfAGiBQr\nZUmVfBIRERk/VAl7DMQU5u8AACAASURBVPTsrK50N/tQsXHnXGXaXYOSTyIiIiK1Mmt6BwCFjAci\nrYQK1eSTpt2JiIiMG0o+jYHeXSkCIS9NreGDbYO5IoWS08gnERERkRpqbWsGoFgI48ItBPN9gEY+\niYiIjCdKPo2BnmqxcfPYwbZkqjIrUQXHRURERGonEPLiyJEPNFOyGL6skk8iIiLjjZJPZ6hcdiT2\npGg7p+Gw9uRQNfmkaXciIiIiNWNmOH+aXDBOsRDFk0ni95qSTyIiIuPISa12J8fW/84QxXyZ9iOL\njQ+PfNK0OxEREZGaskiBXDBGMR+CUoKGoE81n0RERMYRjXw6Q727KsXGR1vpDjTtTkRERKTWfDEP\nuWCMXMYLmT6aghr5JCIiMp4o+XSGenal8Po8xGdEDmsfnnbXqml3IiIiIjUV7oiQCzTTN1gEHNMD\nOQY18klERGTcUPLpDPXuGqRlZhSv9/C3MpnOE/R5CPu9dYpMREREZGpobmsE89A/UFn8Zbo/TVoj\nn0RERMYNJZ/OgHOOnl2DtB9RbBwqyafWaAAzG+VKERERERkr7R1xAFKpSjnTad60pt2JiIiMI0o+\nnYFUX45cunhUvSeoJJ/iqvckIiIiE4iZfdLMXjOzspktGNHuN7PHzOwXZrbFzL5SzziPNGtaBwC5\nIT8A7d6Ukk8iIiLjiJJPZ6BnZ6XYePvso5NPiXRexcZFRERkotkM/D/AC0e0fxIIOucuBH4T+JyZ\nzT27oR3btI5WAIqFMAAtpuSTiIjIeOKrdwATWe+uQcygtfPoaXd96TzzWiOjXCUiIiIyPjnntgCj\nlQ1wQNTMfEAYyAMDZze6YwtF/TjyFMtRXBniNkBKBcdFRETGDY18OgM9u1LEpkXwB44uKq5pdyIi\nIjKJPAWkgX3ATuB/OeeS9Q3pEDMDb4p8MEaxGKHZpcgUShRL5XqHJiIiImjk0xnp3TXIjHfHjmrP\nFUukckValXwSERGRccbMfgpMH+XQV51zPzjGZZcCJWAmEAdeNLOfOue2jXL/24HbAWbPnj02QZ8E\nC+XIBeMUXZzG8gEA0rkSzRH9rVVERKTelHw6Ax/9/IV4fUd/oelLFwBoiQbPdkgiIiIix+Wc+/Bp\nXPYp4J+dcwVgv5m9DCwAjko+OeceAR4BWLBggTuTWE+Fp9GRDcYplBpoKFWST6l8keaI/2yFICIi\nIsegPwWdgY45TbTOOrreUyKdA6Alqi87IiIiMinsBK4BMLMocDnwRl0jOkKoNUg+0Ex/LkS42A+g\nuk8iIiLjRE2TT2Z2vZn90szeNLO7Rzl+lZn93MyKZnbTEcdmm9mz1eV8Xx9eUcXMrq1es9HMXjKz\nd9eyD6cjmc4DGvkkIiIiE4uZ/baZ7QY+CKw1s59UDz0MNJjZa8ArwP9xzm2qV5yjaZwZw3m8JLJN\nBPPV5FOuUOeoREREBGo47c7MvFS+qFwH7AZeMbMfOudeH3HaTuCzwF2j3OLvgK8759aZWQMwXDHy\n/wNudM5tMbM7gHuq9xg3DiWfVPNJREREJg7n3PeB74/SngI+efYjOnltHS28wwEGsg0E8n0ADGrk\nk4iIyLhQy5FPlwJvOue2OefywD8AN448wTm3vfpXs8OWIjGzCwCfc25d9byUc25o+DKgqbrdDOyt\nYR9Oi5JPIiIiImfXjGltAGSyUXz5AXwUSedKdY5KREREoLYFx2cBu0bs7wYuO8lr3wP0m9lqYB7w\nU+Bu51wJuA34sZllgAEqNQeOUq+VVgD60nk8Bs1h1XwSERERORtmTesAtpIvRAGIkda0OxERkXFi\nvBYc9wFXUpmOdwnwLg5NrfsSsNg51wn8H+Cbo93AOfeIc26Bc25Be3t77SMeIZHOE4sE8HrsrL6u\niIiIyFQVbQyBK1IqVRaDidugpt2JiIiME7VMPu0Bzhmx31ltOxm7gY3VKXtFYA3wATNrB97vnPuP\n6nlPAh8aq4DHSjKd15Q7ERERkbPIPAY2SMnTjCtDC4Okcko+iYiIjAe1TD69ApxrZvPMLADcAvzw\nFK6NVZNNUFna93WgD2g2s/dU268DtoxhzGNCyScRERGROghkyAVjFDMepvnSpJV8EhERGRdqlnyq\njlj6feAnVBJE33POvWZmD5jZUgAzu6S6nO8ngb+qLt9LtbbTXcBzZvYLwIC/rt7z94Cnzew/gf8K\n/HGt+nC6kuk8LREln0RERETOJm+0SDYYo5D1Mt2f1sgnERGRcaKWBcdxzv0Y+PERbfeO2H6FynS8\n0a5dB3SN0j7qEsDjSTKd55J5Sj6JiIiInE2BuJ9sIsZg1ss0X4q9qvkkIiIyLozXguMTVrns6BvK\n06ppdyIiIiJnVXRaA87jZ39xOm2elEY+iYiIjBNKPo2xA5kCZQdxTbsTEREROatazqmUC+0rTaPF\nUqr5JCIiMk4o+TTGEuk8AK0NSj6JiIiInE3TpleST+liKzEGGdS0OxERkXGhpjWfpqK+oUrySSOf\nRETkVBQKBXbv3k02m613KONaKBSis7MTv99f71BkHDpn+nRgF/linGa3TdPuRERExgkln8ZYIlVJ\nPrWo5pOIiJyC3bt309jYyNy5czGzeoczLjnnSCQS7N69m3nz5tU7HBmHmmMN4EoUys00lAdIFZV8\nEhERGQ807W6MDY980rQ7ERE5FdlsltbWViWejsPMaG1t1egwOSaPxzAGKblmoqV+0rkizrl6hyUi\nIjLlKfk0xpJpTbsTEZHTo8TTiek9khMxb5qirxl/fggr5ckVy/UOSUREZMpT8mmMJVJ5ogEvIb+3\n3qGIiIicEjPjM5/5zMH9YrFIe3s7S5YsOaX7zJ07l97e3tM656tf/SrnnHMODQ0Np/SaIsM84Ty5\nYIxixkuMlOo+iYiIjANKPo2xvqE8LZpyJyIiE1A0GmXz5s1kMhkA1q1bx6xZs85qDB/72Mf42c9+\ndlZfUyYXf5OHXDDOUMZDiw2S0op3IiIidafk0xhLpPO0aMqdiIhMUIsXL2bt2rUArFq1imXLlh08\nlkwm+fjHP05XVxeXX345mzZtAiCRSLBo0SLmz5/PbbfddliNnccff5xLL72Uiy66iM997nOUSqXj\nvv7ll1/OjBkzatAzmSrCbSHK3gDv5GPEbVAjn0RERMYBrXY3xpLpHO0NwXqHISIiE9j9//Qar+8d\nGNN7XjCziRUfm3/C82655RYeeOABlixZwqZNm+ju7ubFF18EYMWKFVx88cWsWbOG559/nuXLl7Nx\n40buv/9+rrjiCu69917Wrl3Lo48+CsCWLVt48sknefnll/H7/dxxxx2sXLmS5cuXj2nfREZqPqeV\n5C+gN99BC0o+iYiIjAdKPo2xvnSB905rqncYIiIip6Wrq4vt27ezatUqFi9efNixl156iaeffhqA\na665hkQiwcDAAC+88AKrV68G4IYbbiAejwPw3HPPsWHDBi655BIAMpkMHR0dZ7E3MhV1zJnFW7zD\nYLGtMvJJ0+5ERETqTsmnMZZI52iJ+usdhoiITGAnM0KplpYuXcpdd93F+vXrSSQSp30f5xy33nor\nDz300BhGJ3J850yfwX/wDplim0Y+iYiIjBOq+TSGhvJFsoUyLVFNuxMRkYmru7ubFStWcOGFFx7W\nfuWVV7Jy5UoA1q9fT1tbG01NTVx11VU88cQTADzzzDP09fUBcO211/LUU0+xf/9+oFIzaseOHWex\nJzIVtbfFwJUpuBbVfBIRERknlHwaQ8l0HkAjn0REZELr7OzkzjvvPKr9vvvuY8OGDXR1dXH33Xfz\n2GOPAZVaUC+88ALz589n9erVzJ49G4ALLriABx98kEWLFtHV1cV1113Hvn37jvvaX/7yl+ns7GRo\naIjOzk7uu+++Me+fTG4erwdPeZAS8cpqd0o+iYiI1J2m3Y2hQ8knjXwSEZGJJ5VKHdW2cOFCFi5c\nCEBLSwtr1qw56pzW1laeffbZUe958803c/PNNx/Vvn379lHP/8Y3vsE3vvGNkw9axpSZ/TnwMSAP\nbAV+1znXXz32FeC/ASXgTufcT+oW6AmYZ5CSJ0aLDfJr1XwSERGpO418GkOHkk+BOkciIiIiclrW\nAe9zznUBvwK+AmBmFwC3APOB64HvmJm3blGegCeQo+CP01rWyCcREZHxQMmnMaTkk4iIiExkzrln\nnXPD2Zp/Bzqr2zcC/+Ccyznn3gLeBC6tR4wnw9dQJheK0zCUUvJJRERkHFDyaQwp+SQiIiKTSDfw\nTHV7FrBrxLHd1bZxKdQSoOQNkst5SGnanYiISN2p5tMYSqbz+DxGU0hvq4iIiIxPZvZTYPooh77q\nnPtB9ZyvAkVg5Wnc/3bgduBg8fmzrXFGM31bIZmPk88cXctMREREzi5lScZQMp0nHg1gZvUORURE\nRGRUzrkPH++4mX0WWAJc65xz1eY9wDkjTuusto12/0eARwAWLFjgRjun1lrnzGDnSxn6C+14sn31\nCEFERERG0LS7MZRI52nVlDsRERGZoMzseuDLwFLn3NCIQz8EbjGzoJnNA84FflaPGE/GrHlzABgq\ntuLLJescjYiIiCj5NIb60nniESWfRERkYjIzPvOZzxzcLxaLtLe3s2TJklO6z9y5c+nt7T3lc4aG\nhrjhhhs477zzmD9/Pnffffcpva6Mib8EGoF1ZrbRzP43gHPuNeB7wOvAPwP/3TlXql+YxzdzWge4\nMvlSK4GcRj6JiIjUm6bdjaFkOs/5M5vqHYaIiMhpiUajbN68mUwmQzgcZt26dcyadXZrSt91111c\nffXV5PN5rr32Wp555hk++tGPntUYpjLn3LuPc+zrwNfPYjinze/34S2lKBInWOivdzgiIiJTXk1H\nPpnZ9Wb2SzN708yO+vOlmV1lZj83s6KZ3XTEsdlm9qyZbTGz181sbrXdzOzrZvar6rE7a9mHU6Fp\ndyIiMtEtXryYtWvXArBq1SqWLVt28FgymeTjH/84XV1dXH755WzatAmARCLBokWLmD9/PrfddhuH\nygTB448/zqWXXspFF13E5z73OUqlYw+WiUQiXH311QAEAgE+8IEPsHv37lp0U6YAY4CSxYkWD1Au\n16X0lIiIiFTVbOSTmXmBh4HrqCzH+4qZ/dA59/qI03YCnwXuGuUWfwd83Tm3zswagHK1/bNUCl6e\n55wrm1lHjbpwSoqlMgcyBU27ExGRM/fM3fD2L8b2ntMvhI/+6QlPu+WWW3jggQdYsmQJmzZtoru7\nmxdffBGAFStWcPHFF7NmzRqef/55li9fzsaNG7n//vu54ooruPfee1m7di2PPvooAFu2bOHJJ5/k\n5Zdfxu/3c8cdd7By5UqWL19+wjj6+/v5p3/6J774xS+eWb9lyvL4MpS8ceIMMFQo0RDUgH8REZF6\nqeVv4UuBN51z2wDM7B+AG6nUCgDAObe9eqw88kIzuwDwOefWVc8buUbuF4BPOefK1WP7a9iHk9Y3\nVACgtUHJJxERmbi6urrYvn07q1atYvHixYcde+mll3j66acBuOaaa0gkEgwMDPDCCy+wevVqAG64\n4Qbi8TgAzz33HBs2bOCSSy4BIJPJ0NFx4r8ZFYtFli1bxp133sm73vWuseyeTCG+SJF8MUZLsZ9U\ntqjkk4iISB3V8rfwLGDXiP3dwGUnee17gH4zWw3MA34K3F0tbPkbwM1m9ttAD3Cnc+7XYxf26ekb\nygPQoml3IiJypk5ihFItLV26lLvuuov169eTSCRO+z7OOW699VYeeuihU7ru9ttv59xzz+UP/uAP\nTvu1RQLNXoaGIjTkhkjlCkCo3iGJiIhMWeN1tTsfcCWV6XiXAO+iMt0OIAhknXMLgL8G/ma0G5jZ\n7Wb2qpm92tPTU/OAE6lq8knT7kREZILr7u5mxYoVXHjhhYe1X3nllaxcuRKA9evX09bWRlNTE1dd\ndRVPPPEEAM888wx9fZXVxa699lqeeuop9u+vDFJOJpPs2LHjuK99zz33cODAAf7iL/5irLslU0y0\nPVLZyHtI5cbtwnwiIiJTQi2TT3uo1GYa1lltOxm7gY3OuW3OuSKwBvjAiGOrq9vfB7pGu4Fz7hHn\n3ALn3IL29vZTDv5UJdPV5JOm3YmIyATX2dnJnXcevZ7Hfffdx4YNG+jq6uLuu+/mscceAyq1oF54\n4QXmz5/P6tWrmT17NgAXXHABDz74IIsWLaKrq4vrrruOffv2HfN1d+/ezde//nVef/11PvCBD3DR\nRRfx3e9+tzadlEmvZXZlime5ECGVLdY5GhERkamtltPuXgHONbN5VJJOtwCfOoVrY2bW7pzrAa4B\nXq0eWwNcDbwF/BbwqzGN+jQlhzTySUREJrZUKnVU28KFC1m4cCEALS0trFmz5qhzWltbefbZZ0e9\n580338zNN998VPv27duPauvs7DxspTyRMzH9N+byC/ZSKjZWp92JiIhIvdRs5FN1xNLvAz8BtgDf\nc869ZmYPmNlSADO7xMx2A58E/srMXqteW6Iy5e45M/sFYFSm2AH8KfCJavtDwG216sOpSFan3cVV\n80lERESk7s551zwASqUYgxkln0REROqppst+OOd+DPz4iLZ7R2y/QmU63mjXrmOUKXXOuX7ghrGN\n9Mwl0zmaQj783vFaRktERERk6ggHg3iLgxTLcUpDg/UOR0REZErTmrNjJDlU0Ep3IiIiIuOIt3yA\nEnEs3VvvUERERKY0DdMZI8l0TsknERERkXHEYylKnhjldKLeoYiIiExpSj6NkUQqT0s0WO8wRERE\nRKTKG8hQ9Gvkk4iISL0p+TRG+obytET99Q5DRERERKoCDWWK/gZc3956hyIiIjKlKfk0BpxzJNMa\n+SQiIhObmfGZz3zm4H6xWKS9vZ0lS5ac0n3mzp1Lb+/xR5oc65zrr7+e97///cyfP5/Pf/7zlEql\nU3ptkZFCrWEAXFLT7kREROpJyacxkMoVKZQcrar5JCIiE1g0GmXz5s1kMhkA1q1bx6xZs85qDN/7\n3vf4z//8TzZv3kxPTw//+I//eFZfXyaX5pltALjBQp0jERERmdqUfBoDyXQegLiSTyIiMsEtXryY\ntWvXArBq1SqWLVt28FgymeTjH/84XV1dXH755WzatAmARCLBokWLmD9/PrfddhvOuYPXPP7441x6\n6aVcdNFFfO5znzvhSKampiagMuoqn89jZmPdRZlC2t/VWdnI6iuviIhIPfnqHcBkkKgmnzTySURE\nxsKf/ezPeCP5xpje87yW8/iTS//khOfdcsstPPDAAyxZsoRNmzbR3d3Niy++CMCKFSu4+OKLWbNm\nDc8//zzLly9n48aN3H///VxxxRXce++9rF27lkcffRSALVu28OSTT/Lyyy/j9/u54447WLlyJcuX\nLz9uDB/5yEf42c9+xkc/+lFuuummM++8TFnnnPceYDMUIvUORUREZEpT8mkM9Gnkk4iITBJdXV1s\n376dVatWsXjx4sOOvfTSSzz99NMAXHPNNSQSCQYGBnjhhRdYvXo1ADfccAPxeByA5557jg0bNnDJ\nJZcAkMlk6OjoOGEMP/nJT8hms3z605/m+eef57rrrhvLLsoUEm/rwFtMY6XGeociIiIypSn5NAY0\n8klERMbSyYxQqqWlS5dy1113sX79ehKJ0y/U7Jzj1ltv5aGHHjrla0OhEDfeeCM/+MEPlHySM+Ir\n9ONorncYIiIiU5omwI+B4ZpPLUo+iYjIJNDd3c2KFSu48MILD2u/8sorWblyJQDr16+nra2NpqYm\nrrrqKp544gkAnnnmGfr6+gC49tpreeqpp9i/fz9QqRm1Y8eOY75uKpVi3759QKXm09q1aznvvPPG\nvH8ytXjcAZzFKJTK9Q5FRERkytLIpzHQl84T8HmIBLz1DkVEROSMdXZ2cueddx7Vft9999Hd3U1X\nVxeRSITHHnsMqNSCWrZsGfPnz+dDH/oQs2fPBuCCCy7gwQcfZNGiRZTLZfx+Pw8//DBz5swZ9XXT\n6TRLly4ll8tRLpe5+uqr+fznP1+7jsqUYJ5BSt5O0tkCsWiw3uGIiIhMSUo+jYFEOk9rNKAVeURE\nZEJLpVJHtS1cuJCFCxcC0NLSwpo1a446p7W1lWeffXbUe958883cfPPNR7Vv3779qLZp06bxyiuv\nnFrQIidgviGKviZ69+8jNm9uvcMRERGZkpR8GgPJdF5T7kRERETGIV+0CDn4wTd/QD5choifcGMz\nsfYZTJs1hzmdLcyZ2UCkQX9IFBERqRUln8aAkk8iIiIyGZjZnwMfA/LAVuB3nXP9ZnYd8KdAoHrs\nj51zz9cv0pP33vd38stn3yQUnEEh20hpIAhvQ/rXsI1dbGMXAI4i2BDOl8UTLBNoChBrizFz1kzi\nbTHCjQHCjX4ijQHCjQH8QZVbEBEROVlKPo2BZDrPnNZIvcMQEREROVPrgK8454pm9mfAV4A/AXqB\njznn9prZ+4CfALPqGOdJW/DZL3DB/FdJ73qLgd0/Z2DPTtI9B8gdKFDK+qAQAhoo+BvIBxoo+BvJ\n+xso9Hjp3Zlj/6a3gbePvrEV8QeLRBr9NLY20djaRKQxQKS5kpyKVp8jTQECYZ9GVYmIyJSm5NMY\n6EvniUc08klEREQmNufcyOJd/w7cVG3/vyPaXwPCZhZ0zuXOZnynwzweopddSvSyS+k4xjnlfJ5S\nIkGht5fBXW/yzpub6Nv5Jtn9b1Pen8aT8eEtRPAVGyj7KsmpfKCxkqgKNNIXaOLtYCNFXwPY0SOi\nPB5HuNFHNB4h0hQk0hwg2hQgGgsSaQ4SbQ4QbQ4SbvTj8WoxahERmXyUfDpDuWKJwVyRVk27ExER\nkcmlG3hylPZPAD+fCImnk+UJBPDMmIF/xgwiF17INH571POccwwl+9n+xhvseeMVcjvfoNy7m2Bf\ngsaeIUJDBULZMIFiEx5rJB9oIu9vqjwHGskGGxkINVHwN1PyNR51fzMqo6Zi1QRVc+W5IRakIR6i\nIR4kGgsSjGgklYiITCxKPp2hvnQBgJYGJZ9ERERk/DOznwLTRzn0VefcD6rnfBUoAiuPuHY+8GfA\nouPc/3bgdoDZs2ePUdTjg5kRbY0z/798kPn/5YNHHS+XHe8MZtmRGGLnjp30/Prfye59DU/yNQKD\nCSJDQzT25YkMlWhIeYjkmnC+ZnKBZnLBZvKBJnLBZobCzQyGmikGYhStoZKVGsEX8NAQDxGNBWmI\nB2mIBQ9tx0M0tAQJRf1KUImIyLih5NMZSqbzALRo2p2IiExwZsanP/1pHn/8cQCKxSIzZszgsssu\n40c/+tFJ32fu3Lm8+uqrtLW1nfY5S5cuZdu2bWzevPnUOiEn5Jz78PGOm9lngSXAtc45N6K9E/g+\nsNw5t/U4938EeARgwYIF7ljnTUYejzGjOcyM5jCXv6sVrr74sOMHhgrsSKbZkRhicyLNznd2M7R3\nA/6eLTSmd9Gc7achmyGaLhDvL9OYgvigBy9N5IIxcsE42WCMbChOOhqnP9JCjz9O3tMIHD5dzxf0\n0hgP0tgaoqElROPIR2uIaHNAU/xEROSsUfLpDB1MPmnanYiITHDRaJTNmzeTyWQIh8OsW7eOWbPO\nfk3p1atX09DQcNZfV8DMrge+DPyWc25oRHsMWAvc7Zx7uV7xTXTNET9dkRhdnbFqy7nA1QCkc0V2\nJofYkUizPTHEa4k0O3oP0N/3S4KDrzOrsIO27B6aMm/QMJQnkioT63W0DkA8ZRT9jeSCMbLBOLlQ\nC4ONrWSTbfTuaWOfL07BhQ6LxTxGNBagsSVEc1uYxrYwzW2h6nOYSFMA82jklIiIjA0ln85QIl0p\nd9CqaXciIjIJLF68mLVr13LTTTexatUqli1bxosvvghAMpmku7ubbdu2EYlEeOSRR+jq6iKRSLBs\n2TL27NnDBz/4QUYMluHxxx/n29/+Nvl8nssuu4zvfOc7eL3HXqI+lUrxzW9+k0ceeYTf+Z3fqXl/\n5Sh/CQSBddUpW//unPs88PvAu4F7zeze6rmLnHP76xPm5BMN+jh/RhPnz2g64siVZAsldiSGeKs3\nzfZEmq09ad5KpNnR04fLbqXDt51ZhZ205PcTz/yaaDpHeLBM0zuOc/qhdRCcBciG4mSDLWTCcVLN\n7eRSHaSTHfS91UK2FAQOJZu8Pg9NbSEaWytJqab2ME2tYZraQzS3R/AHj/3/YxERkSMp+XSG+qoj\nn7TanYiIjJW3/+f/JLfljTG9Z/D885j+P/7HCc+75ZZbeOCBB1iyZAmbNm2iu7v7YPJpxYoVXHzx\nxaxZs4bnn3+e5cuXs3HjRu6//36uuOIK7r33XtauXcujjz4KwJYtW3jyySd5+eWX8fv93HHHHaxc\nuZLly5cf8/W/9rWv8Ud/9EdEIpGx6bicEufcu4/R/iDw4FkOR6pCfi/vnd7Ie6cfXaQ8lSuyvZqU\n2t6bZltvmrd602zrSZPN9jE98BZt3u3MKO6iPddHNL2V0GCByAC07nbM7YfmISh5fGSDLWTDbQw2\ntZOJTSefn0lfooN9v2ygUDx8il6kOUBze5jmjgjN7WFi1efm9jCBsP6JISIih9NvhjOUTOcxg5iS\nTyIiMgl0dXWxfft2Vq1axeLFiw879tJLL/H0008DcM0115BIJBgYGOCFF15g9erVANxwww3E43EA\nnnvuOTZs2MAll1wCQCaToaPjWIvdw8aNG9m6dSvf+ta32L59ew16JzL5NAR9vG9WM++b1XzUsb50\n/mAy6q3e1MGk1PZEmlwhT5tvLx2BrUz37mJGYT/R1AECA72EDmyhrR9mvOVoGwBzUPRFyIRaSTV2\nMNQ6k1zxHHKZmezY2Uwmf3hiKtzop7k9QnNHmFhHJUEVmxYh1qERUyIiU5WST2cokc4TjwTwak68\niIiMkZMZoVRLS5cu5a677mL9+vUkEonTvo9zjltvvZWHHnropM7/t3/7N1599VXmzp1LsVhk//79\nLFy4kPXr1592ObCRmAAAG1pJREFUDCJTWTwa4DejAX5zTvyw9nLZ8fZAlrd602ztSbGtJ82b+1Ns\n7Umxz5eFlhJtvj1MD21jZmQP7bm3CQ4ewH9gD8EDu5nW93Om73V09IOvDEVvkEyojVRTB5m2TnKl\n2RQKM9m5p4lf5g5PTEVjQWLTwsSmRYl1hA8mpRrbQnhVAF1EZNKqafKpWrTy/wW8wHedc396xPGr\ngL8AuoBbnHNPjTg2G/gucA7ggMXOue0jjn8b6HbO1bUiad9QnnjEX88QRERExlR3dzexWIwLL7zw\nsMTPlVdeycqVK/na177G+vXraWtro6mpiauuuoonnniCe+65h2eeeYa+vj4Arr32Wm688Ua+9KUv\n0dHRQTKZZHBwkDlz5oz6ul/4whf4whe+AMD27dtZsmSJEk8iNeDxGDNjYWbGwvyXdx++4mQqV+St\nnjRv9gyydX8lOfVKT4q3UmkKjQ4aS7TN28m7mrbTEd5DQ/ZtAv0H8PXto6F/L9P7NjJjl6P9AHgd\nlDwBhsLtpGIzyLTPJm9zyOZm8uttYfIFOyympvbwoYTUtAjx6RFi06KEG/1Ua5CJiMgEVbPkk5l5\ngYeB64DdwCtm9kPn3OsjTtsJfBa4a5Rb/B3wdefcOjNrAMoj7r0AiI9yzVmXSOVpjQbrHYaIiMiY\n6ezs5M477zyq/b777qO7u5uuri4ikQiPPfYYUKkFtWzZMubPn8+HPvQhZs+eDcAFF1zAgw8+yKJF\niyiXy/j9fh5++OFjJp9EpP4agj4u7Gzmws7Dp/EVS2V29WWqI6Tms7U6UurNVIqBYhEawduUYfb5\nbzGveReN/r2EUm/j6RvE17eXtr69zEhuYOZWR+tg5Z4FX5ShSAeDrbPItc0h751L30AbO18LUC4f\neu1gxHcwIRWbFiE+LUJseoRYewSvX6OlREQmAhu5Is2Y3tjsg8B9zrmPVPe/AuCcO2rsvZn9LfCj\n4ZFPZnYB8Ihz7opRzvUCPwU+Bfz6ZEY+LViwwL366qtn0JtjW/Stf2VeW5S/+q8LanJ/ERGZGrZs\n2cL5559f7zAmhNHeKzPb4JzTL+NxppbfwWR8cM7Rm8pXElHVhNTWnjRb96fY058ZPougP8H8+A6m\nRXcRdHvx9ffiSaaJ9JWZkYQZScfMJERz4DCyoRZSDdMYap9NrnUeuYZOUq6JzIhpfGbQ2BoiNi16\nKCFVTU5FmgMaLSUichac7HewWk67mwXsGrG/G7jsJK99D9BvZquBeVSSTXc750pUlvr9oXNu3/F+\noZjZ7cDtwMG/wNZCMp3nN+e01Oz+IiIiIiLjlZnR3hikvTHI5e9qPezYUL7Itp7KCnyVkVIXVvdT\nZAtl8ABtBabP3cO5sZ00Bnfhz76DL9mHt6+P1mSSmYktzHjd8a4R9aWGwh2k4jPJtM8hzxwGUtPY\n80aIUunQvw38IS+xjpHT9yqP5vYwgZDK3oqInG3j9SevD7gSuJjK1Lwngc+a2TPAJ4GFJ7qBc+4R\n4BGo/NWtFkGWy46+oQKtUa10JyIiIiIyUiQw+kp85bJj30CWrftTbOtJsbXn3WztSbFhf4p3BnKV\nk4IOzzmDvLdrN50NOwh79uIfeAdPcpBgcjfT+nYzs+c/mP4raElVRkvlgs0MRaaRis0k0zKbfK6T\nPfva+HXBDxxKTEWaA5XE1PBKfB0RmqeFaW4P4/NrNT4RkVqoZfJpD5Vi4cM6q20nYzew0Tm3DcDM\n1gCXA28D7wberI56ipjZm865d49Z1KdgIFugVHbElXwSERERETkpHo8xKxZmVizMVe9pP+xYOlfk\nrd7KaKm3etK81Xvewe3BXLFyUnOJxum9nB/fTmtoD/7yPnwHerG+FOH+A0zv+xXTemDGrxxtg1Dy\n+MmE2yuJqabpZFOzyByYSWJrC7nyiIWDDBriwUoyqpqcamqrJKWa2sP4A0pMiYicrlomn14BzjWz\neVSSTrdQqdN0stfGzKzdOdcDXAO86pxbC0wfPsnMUvVKPAEk0nkAjXwSERERERkD0eDoo6WGa0tt\n60nxVm+at3rTbO3p4s1Emp3JIXLFaoXyeIGmGW9zbvNO4pE9+N3b+A4ksb53aOh/m+n9G5nWCzPf\nrKzIV/aEGIp0MBRuZ6hhGkMHZjLYM4N3ftlKwR2+onWkOUBze5jmtkoyajgx1dweJtSgFflERI6n\nZskn51zRzH4f+AngBf7GOfeamT1AJZH0QzO7BPg+lZXrPmZm9zvn5jvnSmZ2F/CcVX6KbwD+ulax\nnq5kNfnUouSTiIiIiEjNjKwtddkRtaXKZcc7g1m29w6xM5lme2KInYkhtifS7EgMkRoeMRXPEe7Y\ny7ym3bRG3sbv2U9wMInvwD5C/bvp6HdM74NpOx3T+sGIkgm3VR6hNoaapjH0zjSSwTZydviaR/6Q\nl6a2MI0tIZpaQzQOP1oqz6GoklMiMrXVtOaTc+7HwI+PaLt3xPYrVKbjjXbtOqDrBPc/4Up3taTk\nk4iIiIhIfXk8xozmMDOaw3zwNw5PTDnnSKbzlYRUMs2evgy7q49tfUPs6c9QKDmIlvDEkrS8Zwcz\nGvbSENpPQ7aX4OB+/AO7aT7gaD/g6NgH5/Q7Yik/hWBrNTnVzlCojcw77fSE29jlj1Oyw/994At4\nKompaoJqODEVjQdpiAWJxoJ4fR5ERCar8VpwfEJQ8klERCYTM+PTn/40jz/+OADFYpEZM2Zw2WWX\n8aMf/eik7zN37lxeffVV2traTvmchQsXsm/fPsLhMADPPvssHR0dp9EbEZHKz7XWhiCtDUF+c078\nqOOlsqNnMMfuvqFqUmroYHLq16kh9uWz5HxlaM/in9lLS2AXscA+moO9NOeSRFJvEhzYQuNAmfYD\n0JKEzgFHcyaC87WQDbWSDbWQDbaQ2dtCb6SVPcFWit7IUbGEIx6isQCNbVEa4tXEVDxUSU7Fg0Sb\ng/iDqjslIhOTkk9nQMknERGZTKLRKJs3byaTyRAOh1m3bh2zZs0663GsXLmSBQsWnPXXFZGpx+sx\npjeHmN4cYsHco48Pj5zadyDL3v5M5flAhr39Wfb1Z3i9lOXtQpZSKItnVpKY/x2a/PuIeHuI0Ucs\nu4PI0BsE0wXCKUfrILTsh3gqQLgQxzwxcsE4uWCs+oizPxhjVyhG0Rc9Kh6fp0wobEQafISbgkRb\nIkRao0RjISKNAcJNASJNfiJNSlSJyPii5NMZSKbzRAJeQlqSVUREJonFixezdu1abrrpJlatWsWy\nZct48cUXAUgmk3R3d7Nt2zYikQiPPPIIXV1dJBIJli1bxp49e/jgBz+Ic+7g/R5//HG+/e1vk8/n\nueyyy/jOd76D16vfmyIyMYwcOXVkEfRhw6On3h7I0juYozeVo2f4OZVj52CenlSO3sEhUqU+Gnzv\nEPfvJeJPEC0naSpsoyE/RCSbI5ApEsw4mlLQPBSgIdtMuBjD7+KUfE3kA43kA03kA02kA43sDTRR\n8I9eicQo4vfk8ftLBENGMOon0hikIRYlGm8g3NpApLWBcEOAUIOfYNiHP+RVbSoRqQkln85AMp3X\nqCcRERlzL37vV/TuSo3pPdvOaeDK33nPCc+75ZZbeOCBB1iyZAmbNm2iu7v7YPJpxYoVXHzxxaxZ\ns4bnn3+e5cuXs3HjRu6//36uuOIK7r33XtauXcujjz4KwJYtW3jyySd5+eWX8fv93HHHHaxcuZLl\ny5cfN4bf/d3fxev18olPfIJ77rlH/xASkXFt5OipE8kWSgcTU8l0nr6hAn3pPH1Dle3eoTyJdI6+\nzAEGsu9gxd2EvT2Evb00lt+iMT9ENJ8hkssRzhcJ5UoEsxDINxDMN+IvNVUerhGjAeeJUvA3UPBH\nyfij9PgbKPoB0sA7RwfoynhcFq/L4rEcXk8Br6+A11fGFwR/2Esg6ifYGCLY2ECoqfKINDcSiTXR\n0NREMBzAH/Dg8aqGlYgcouTTGVDySUREJpuuri62b9/OqlWrWLx48WHHXnrpJZ5++mkArrnmGhKJ\nBAMDA7zwwgusXr0agBtuuIF4vFJX5bnnnmPDhg1ccsklAGQymRPWb1q5ciWzZs1icHCQT3ziE/z9\n3//9CZNVIiITRcjv5ZyWCOe0HF3zaTTOOdL5En3pPAcyBQYyBQayhep2kYFsgcRw+1COfOYALvM2\n5PbjKffhKe2mqXSAaDFFpJgmVMgRLBQIFPz4ikG8xQieUhRPKYq5MLgwRgQsjLMwzhOh7A2T94Up\n+iKUvMEjIiwBB6qPw1m5gJVzmMtXHhSAAlCsPFsRrICzInhLOCuBd/jhwFeu/GvV5zA/mN8DAQ8W\nNMzvwxPyYkEfnnAQbzCAJ+DHE/LjDYbxBYN4AwF8Xh9+rw+vefF5fPjMh9fjPbjvNe+o+yPP85oX\nj8dTebbKs5kd3BeRk6Pk0xlIpvO0Nij5JCIiY+tkRijV0tKlS7nrrrtYv349iUTitO/jnOPWW2/l\noYceOulrhmtMNTY28qlPfYqf/exnSj6JyJRlZjQEfTQEfZxzGteXy46hQomhXJFUrkg6VyKVKzKU\nP7Q/vJ3Nlyjks7h8mnJ+CJdPUSqkKOYSeLP9eDJ9+HOD+PJFfPkS/qLDW/LgKxnekhev8+Ep+zDn\nx+MC4PyYCwIBIIAzP878gB9nIcqeSlvZ46fs/JV9563kpsbyPSyXgDzmspgrgythlMGVsSO2oVw5\nh1L13DIw/HC46vOh/UPbUK7smwMMVx2064ZH75rhAKzyPw6rbFv1citXzmd46vrwvarb1X1zYM7h\nGX4uu+p+5WFlqs+VfQDnqd7XwHkcDsN5qvs2/Fw57xCHjdg+7D0duW8+HD7Ai8Nb2TYv4Du0jxdn\nvmpnK+955f0uYdUHlA9uG6XKZ0L5+J/tcY8ecfwUBlG74x6xY97q6HY75jEbNbhDr+wOC8IdJ6aR\ndxk9MgNazm/huj/8w5O4S+0o+XQGkuk8504bfY61iIjIRNXd3U0sFuPCCy9k/fr1B9uvvPJKVq5c\nyde+9jXWr19PW1sbTU1NXHXVVTzxxBPcc889PPPMM/T19QFw7bXXcuONN/KlL32Jjo4Okskkg4OD\nzJkzZ9TXLRaL9Pf309bWRqFQ4Ec/+hEf/vCHz0aXRUQmJY/nUPKqVuuGOufIl8rki9XHiO3ciP1i\nyVEolykUyxRKjmKpRKGQp1TI4wpZypkU5cwQlk7jclksm8NyecgXsGIR8kWsWIJCCSuWoVR5lMuV\nRIs7mAdy1VxN9R/i5UqGxw1nWPBUki94Kg/zVNsO7Tu8YB6ceQF/NQ1jYJ7qvSrPjGivnOOpZBVG\nZA48uMP2beR22R1KTo2432FtZgdff2R72VPZLvpGv67Sfc+Ie1ONv3asXMBTLuIpFTFXxFM+9Owp\nFwGHsyDOvJQ9lYRU+eC2t9ruq7zvGlU2plKvr693CEo+nYnHui/Br7nMIiIyyXR2dnLnnXce1X7f\nfffR3d1NV1cXkUiExx57DKjUglq2bBnz58/nQx/6ELNnzwbgggsu4MEHH2TRokWUy2X8fj8PP/zw\nMZNPuVyOj3zkIxQKBUqlEh/+8If5vd/7vdp1VEREzpiZEfR5Cfq0mMTJcq6SLCu7yoiWSr6s0nbY\n9vC51XOOHP5y5HgYd9TxEa9X3S6X3cGFQVx5xGuVwVE+dA8HZTfips5RPhRg5dXLZTw+Dx6fYdVk\nmBseETYcP8Ov5w6O/Dp0S3dYPw5G6aBYKmMj7sHBc0ZujXjF6ns6/D4cej+rxxg+Xn3vcRh2KFdY\nvXZ4/6gxSyNuPjKeQyPgHGaVz7QSePX9Go7tYFzlEZ/7iLhcZVSVxyrjl8xT2T7YZmB4MAMPh97r\n8vC74dzB+x+Kc/ijcsyK30a92cgVaSarBQsWuFdffbXeYYiIiBzTli1bOP/88+sdxoQw2ntlZhuc\ncwvqFJIcg76DiYiITG4n+x1Mw3ZERERERERERKRmlHwSEREREREREZGaUfJJRERERAAwsz83szfM\nbJOZfd/MYkccn21mKTO7q14xioiIyMSj5JOIiMg4MRXqMJ4pvUc1tw54n3OuC/gV8JUjjn8TeOas\nRyUiIiITmpJPIiIi40AoFCKRSCi5chzOORKJBKFQqN6hTFrOuWedc8Xq7r8DncPHzOzjwFvAa/WI\nTURERCYuX70DEBEREejs7GT37t309PTUO5RxLRQK0dnZeeITZSx0A08CmFkD8CfAdYCm3ImIiMgp\nUfJJRERkHPD7/cybN6/eYcgUYGY/BaaPcuirzrkfVM/5KlAEVlaP3Qd8yzmXMrMT3f924HaA2bNn\nj1HUIiIiMpEp+SQiIiIyhTjnPny842b2WWAJcK07NA/0MuAmM/sGEAPKZpZ1zv3lKPd/BHgEYMGC\nBZpHKiIiIko+iYiIiEiFmV0PfBn4Lefc0HC7c+7KEefcB6RGSzyJiIiIjEYFx0VERERk2F8CjcA6\nM9toZv+73gGJiIjIxGdTYVUdM+sBdtTo9m1Ab43uPd6or5OT+jo5TaW+wtTqr/o6ujnOufZaBiOn\nTt/Bxoz6Ojmpr5OT+jo5TaW+Qg2+g02J5FMtmdmrzrkF9Y7jbFBfJyf1dXKaSn2FqdVf9VWkYir9\n96G+Tk7q6+Skvk5OU6mvUJv+atqdiIiIiIiIiIjUjJJPIiIiIiIiIiJSM0o+nblH6h3AWaS+Tk7q\n6+Q0lfoKU6u/6qtIxVT670N9nZzU18lJfZ2cplJfoQb9Vc0nERERERERERGpGY18EhERERERERGR\nmlHy6TSZ2fVm9ksze9PM7q53PLVmZtvN7BdmttHMXq13PGPJzP7GzPab2eYRbS1mts7Mfl19jtcz\nxrFyjL7eZ2Z7qp/tRjNbXM8Yx4qZnWNm/2Jmr5vZa2b2xWr7pPtsj9PXSffZmlnIzH5mZv9Z7ev9\n1fZ5ZvYf1Z/JT5pZoN6xnqnj9PVvzeytEZ/rRfWOdayYmdfM/q+Z/ai6P+k+VzlzU+k72GT+/gX6\nDjYZf0+DvoNV2yfdZ6vvYPoOdqavoeTTaTAzL/Aw8FHgAmCZmV1Q36jOiqudcxdNwiUm/xa4/oi2\nu4HnnHPnAs9V9yeDv+XovgJ8q/rZXuSc+/FZjqlWisAfOecuAC4H/nv1/6eT8bM9Vl9h8n22OeAa\n59z7gYuA683scuDPqPT13UAf8N/qGONYOVZfAf54xOe6sX4hjrkvAltG7E/Gz1XOwBT9DjZZv3+B\nvoPB5Ps9DfoOpu9gE5++g9Xgc1Xy6fRcCrzpnNvmnMsD/wDcWOeY5DQ5514Akkc03wg8Vt1+DPj4\nWQ2qRo7R10nJObfPOffz6vYglR+ms5iEn+1x+jrpuIpUdddffTjgGuCpavtk+VyP1ddJycw6gRuA\n71b3jUn4ucoZ03ewSUTfwSYnfQfTd7A6hDem9B2sNt/BlHw6PbOAXSP2dzNJf8iM4IBnzWyDmd1e\n72DOgmnOuX3V7beBafUM5iz4fTPbVB0SPuGHQB/JzOYCFwP/wST/bI/oK0zCz7Y6LHgjsB9YB2wF\n+p1zxeopk+Zn8pF9dc4Nf65fr36u3zKzYB1DHEt/AXwZKFf3W5mkn6uckan2HWyqff+CSf57ehST\n7vf0SP9/e3cTasdZx3H8+zNRSZNiGhqhmGpIK9gXYlQq2LQSWpQuQqkQX5sQXLWQTRZCSKkEAi61\ndlFsEJWK0TZqU4Or0iaEdiFtbaP1pauSQkvI3diXFAwl+buYJ3gsN8He3Mk5Z873s7nnPmfO3Ofh\nDzM//mdmrhlsWLU1gwFmsAWz+aT/1y1V9Xm6y9x3JPnyuCd0qVT3LyEH2+kGfgJcQ3dJ6Qngh+Od\nzuJKsgL4PbCzqt4efW9otZ1nrYOsbVWdqaoNwBq6qyA+M+Yp9eb9a01yI7Cbbs03AauAXWOc4qJI\nshmYq6o/j3su0oSZ2fwFwztPz2OQ5+lzzGDDq60ZzAx2MWw+LcwbwNUjv69pY4NVVW+0n3PAQbqD\nzZCdTHIVQPs5N+b59KaqTraD61ngpwyotkk+TBcE9lfV4214kLWdb61Dri1AVb0JHAG+BKxMsrS9\nNbhj8sha72iX+FdVnQZ+wTDquhG4M8lxutuobgMeZOB11YLMVAabwfwFAz1Pz2fI52kz2HBrC2Yw\nM9jC2HxamOeBT7cnwH8E+BZwaMxz6k2S5UkuP/ca+Crwtwt/auodAra319uBP4xxLr06FwKarzGQ\n2rZ7lX8G/LOqfjTy1uBqe761DrG2SVYnWdleLwO+Qvd8hSPAlrbZUOo631pfGQnuobv/furrWlW7\nq2pNVa2lO6cerqq7GWBdddFmJoPNaP6CAZ6nz2eI52kwg7XxwdXWDGYGu9i/le6KR31Q6f5d5o+B\nJcDPq+oHY55Sb5Kso/u2DWAp8OshrTfJb4BNwJXASWAP8ARwAPgk8Brwjaqa+odEnmetm+guCS7g\nOHDPyP34UyvJLcAzwMv89/7l++juwx9UbS+w1m8zsNomWU/30MMldF+gHKiqve049SjdJdAvAVvb\nt1JT6wJrPQysBgIcA+4deSjm1EuyCfheVW0eYl118WYlgw09f4EZDDPY1NfWDGYGM4N9gP3bfJIk\nSZIkSVJfvO1OkiRJkiRJvbH5JEmSJEmSpN7YfJIkSZIkSVJvbD5JkiRJkiSpNzafJEmSJEmS1Bub\nT5JmUpJNSf447nlIkiTNEjOYNJtsPkmSJEmSJKk3Np8kTbQkW5M8l+RYkn1JliQ5leSBJH9P8nSS\n1W3bDUn+lOSvSQ4muaKNX5vkqSR/SfJikmva7lck+V2SV5LsT5KxLVSSJGmCmMEkLSabT5ImVpLr\ngG8CG6tqA3AGuBtYDrxQVTcAR4E97SO/BHZV1Xrg5ZHx/cBDVfVZ4GbgRBv/HLATuB5YB2zsfVGS\nJEkTzgwmabEtHfcEJOkCbge+ADzfvhBbBswBZ4HH2ja/Ah5P8jFgZVUdbeOPAL9Ncjnwiao6CFBV\n/wZo+3uuql5vvx8D1gLP9r8sSZKkiWYGk7SobD5JmmQBHqmq3f8zmHz/fdvVAvd/euT1GTwmSpIk\ngRlM0iLztjtJk+xpYEuSjwMkWZXkU3THri1tm+8Az1bVW8C/ktzaxrcBR6vqHeD1JHe1fXw0yWWX\ndBWSJEnTxQwmaVHZYZY0sarqH0nuB55M8iHgPWAH8C7wxfbeHN0zCQC2Aw+3YPMq8N02vg3Yl2Rv\n28fXL+EyJEmSpooZTNJiS9VCr5SUpPFIcqqqVox7HpIkSbPEDCZpobztTpIkSZIkSb3xyidJkiRJ\nkiT1xiufJEmSJEmS1BubT5IkSZIkSeqNzSdJkiRJkiT1xuaTJEmSJEmSemPzSZIkSZIkSb2x+SRJ\nkiRJkqTe/AeNISlWUoM7AQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAFNCAYAAACuQ87yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_loss('training', histories, 'acc', 'loss')\n",
    "plot_acc_loss('validation', histories, 'val_acc', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
