{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Input, Dense, Flatten, Dropout, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word2vec_text8(saveTo = 'models/text8.model'):\n",
    "    sentences = word2vec.Text8Corpus('data/text8')\n",
    "    model = word2vec.Word2Vec(sentences, size=EMBEDDING_DIM)\n",
    "    model.save(saveTo)\n",
    "    model.wv.save_word2vec_format(saveTo + '.bin', binary=True)\n",
    "    print('DONE! Saved to', saveTo)\n",
    "\n",
    "def generate_glove_text8(saveTo = 'models/glovetext8.model'):\n",
    "    import itertools\n",
    "    sentences = list(itertools.islice(word2vec.Text8Corpus('data/text8'),None))\n",
    "    corpus = Corpus()\n",
    "    corpus.fit(sentences, window=10)\n",
    "    glove = Glove(no_components=EMBEDDING_DIM,learning_rate=0.05)\n",
    "    glove.fit(corpus.matrix, epochs=30,no_threads=4,verbose=True)\n",
    "    glove.add_dictionary(corpus.dictionary)\n",
    "    glove.save(saveTo)\n",
    "    print('DONE! Saved to', saveTo)\n",
    "    \n",
    "def load_data(word_count, emotional_mapping):\n",
    "    # full = generate_IEMOCAP_df()\n",
    "    data = pd.read_csv('data/IEMOCAP_sentences.csv',index_col=0)\n",
    "    data['emotion_code'] = data['emotion'].map( emotional_mapping ).astype(int)\n",
    "    # Take away fear, surprise,disgust, xxx and others. Not enough data\n",
    "    data = data[data.emotion_code < 6]\n",
    "    # Clean Transcripts\n",
    "    data['text'] = data['text'].apply(clean_text)\n",
    "    # Filter Word Count\n",
    "    data = filter_word_count(data, word_count)\n",
    "#     data,patterns = remove_empty_patterns(data,patterns)\n",
    "    return data\n",
    "\n",
    "def clean_text(text):\n",
    "    punct_str = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~«»“…‘”\\t'\n",
    "    for p in punct_str:\n",
    "        text = text.replace(p,' ')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = re.sub(\".*?\\[(.*?)\\]\",\"\",text) # Take out any [action] text in the transcript\n",
    "    return text.lower().strip()\n",
    "\n",
    "def filter_word_count(data, n_count):\n",
    "    return data[list(map(lambda x: len(x.split(' ')) >= n_count,data['text']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_mapping = {'ang': 0, 'sad': 1, 'exc': 2, 'neu': 3,'fru': 4,'hap': 5,'fea': 6,'sur': 7,'dis': 8, 'xxx':9,'oth':10}\n",
    "data = load_data(3, emotional_mapping)\n",
    "df = data[['text','emotion_code']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "TEST_SIZE      = 0.2\n",
    "\n",
    "# EMBEDDING\n",
    "MAX_NUM_WORDS  = 2954 # 2500, 2000, 2700\n",
    "EMBEDDING_DIM  = 200\n",
    "MAX_SEQ_LENGTH = 100\n",
    "USE_GLOVE      = True\n",
    "\n",
    "# MODEL\n",
    "FILTER_SIZES   = [3,4,5]\n",
    "FEATURE_MAPS   = [10,10,10]\n",
    "DROPOUT_RATE   = 0.5\n",
    "\n",
    "# LEARNING\n",
    "BATCH_SIZE     = 200\n",
    "NB_EPOCHS      = 40\n",
    "RUNS           = 5\n",
    "VAL_SIZE       = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.text, data.emotion_code, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])\n",
    "\n",
    "tokenizer = Tokenizer()#num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "length = max_length(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "result = [len(x.split()) for x in x_train]\n",
    "print('Text informations:')\n",
    "print('max length: %i / min length: %i / mean length: %i / limit length: %i' % (np.max(result),\n",
    "                                                                                np.min(result),\n",
    "                                                                                np.mean(result),\n",
    "                                                                                MAX_SEQ_LENGTH))\n",
    "\n",
    "print('vocabulary size: %i / limit: %i' % (len(word_index), MAX_NUM_WORDS))\n",
    "\n",
    "# Padding all sequences to same length of `MAX_SEQ_LENGTH`\n",
    "data   = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glove_embeddings(data = None, use_text8 = False, LEARNING_RATE=0.05, EPOCHS=30, NO_THREADS=4):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = Glove.load('models/glovetext8.model')\n",
    "    else:\n",
    "        if(data != None):\n",
    "            corpus = Corpus()\n",
    "            corpus.fit(data, window=10)\n",
    "            model = Glove(no_components=EMBEDDING_DIM,learning_rate=LEARNING_RATE)\n",
    "            model.fit(corpus.matrix, epochs=EPOCHS,no_threads=NO_THREADS,verbose=True)\n",
    "            model.add_dictionary(corpus.dictionary)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = Glove.load('models/glovetext8.model')\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word,index in model.dictionary.items():\n",
    "        embeddings_index[word] = model.word_vectors[index]\n",
    "    \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM,\n",
    "                     weights=[embedding_matrix], trainable=True)\n",
    "    \n",
    "def create_word2vec_embeddings(data = None, use_text8 = False):\n",
    "    model = None\n",
    "    if(use_text8):\n",
    "        model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    else:\n",
    "        if(data != None):  \n",
    "            model = word2vec.Word2Vec(data, size=EMBEDDING_DIM)\n",
    "        else:\n",
    "            print('No data found. Using text8 Corpus')\n",
    "            model = KeyedVectors.load_word2vec_format('models/text8.model.bin',binary=True)\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    for word in model.wv.index2word:\n",
    "        embeddings_index[word] = model[word]\n",
    "        \n",
    "    embedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if(embedding_vector is not None):\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length = MAX_SEQ_LENGTH,\n",
    "                    weights= [embedding_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/Users/roblescoulter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "embedding_data = [x.split() for x in x_train]\n",
    "model = word2vec.Word2Vec(embedding_data, size=EMBEDDING_DIM)\n",
    "emb_layers = [create_word2vec_embeddings(use_text8=True),\n",
    "              create_word2vec_embeddings(embedding_data),\n",
    "              create_glove_embeddings(use_text8=True),\n",
    "              create_glove_embeddings(embedding_data)\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5116 5116\n"
     ]
    }
   ],
   "source": [
    "print(len(data),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 1/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 4604 samples, validate on 512 samples\n",
      "Epoch 1/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -15.3636 - acc: 0.1503 - val_loss: -22.9391 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.93910, saving model to model-1.h5\n",
      "Epoch 2/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -23.1032 - acc: 0.1466 - val_loss: -23.3033 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.93910 to -23.30326, saving model to model-1.h5\n",
      "Epoch 3/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.4342 - acc: 0.1466 - val_loss: -23.6008 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.30326 to -23.60085, saving model to model-1.h5\n",
      "Epoch 4/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.7089 - acc: 0.1466 - val_loss: -23.8484 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.60085 to -23.84841, saving model to model-1.h5\n",
      "Epoch 5/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.9341 - acc: 0.1466 - val_loss: -24.0441 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.84841 to -24.04411, saving model to model-1.h5\n",
      "Epoch 6/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.1068 - acc: 0.1466 - val_loss: -24.1893 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00006: val_loss improved from -24.04411 to -24.18930, saving model to model-1.h5\n",
      "Epoch 7/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.2286 - acc: 0.1466 - val_loss: -24.2895 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.18930 to -24.28945, saving model to model-1.h5\n",
      "Epoch 8/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3028 - acc: 0.1466 - val_loss: -24.3420 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.28945 to -24.34196, saving model to model-1.h5\n",
      "Epoch 9/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3466 - acc: 0.1466 - val_loss: -24.3712 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.34196 to -24.37117, saving model to model-1.h5\n",
      "Epoch 10/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3698 - acc: 0.1466 - val_loss: -24.3771 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.37117 to -24.37708, saving model to model-1.h5\n",
      "Epoch 11/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3733 - acc: 0.1466 - val_loss: -24.3897 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.37708 to -24.38969, saving model to model-1.h5\n",
      "Epoch 12/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3832 - acc: 0.1466 - val_loss: -24.3975 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.38969 to -24.39748, saving model to model-1.h5\n",
      "Epoch 13/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3861 - acc: 0.1466 - val_loss: -24.3985 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.39748 to -24.39849, saving model to model-1.h5\n",
      "Epoch 14/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3861 - acc: 0.1466 - val_loss: -24.3972 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -24.39849\n",
      "Epoch 15/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3900 - acc: 0.1466 - val_loss: -24.4023 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.39849 to -24.40232, saving model to model-1.h5\n",
      "Epoch 16/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3925 - acc: 0.1466 - val_loss: -24.4025 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.40232 to -24.40245, saving model to model-1.h5\n",
      "Epoch 17/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3808 - acc: 0.1466 - val_loss: -24.4000 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -24.40245\n",
      "Epoch 18/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3903 - acc: 0.1466 - val_loss: -24.4006 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -24.40245\n",
      "Epoch 19/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3909 - acc: 0.1466 - val_loss: -24.4013 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -24.40245\n",
      "Epoch 20/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3918 - acc: 0.1466 - val_loss: -24.4024 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -24.40245\n",
      "Epoch 21/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3925 - acc: 0.1466 - val_loss: -24.4026 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.40245 to -24.40257, saving model to model-1.h5\n",
      "Epoch 22/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3927 - acc: 0.1466 - val_loss: -24.4029 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.40257 to -24.40289, saving model to model-1.h5\n",
      "Epoch 23/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3932 - acc: 0.1466 - val_loss: -24.4034 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00023: val_loss improved from -24.40289 to -24.40342, saving model to model-1.h5\n",
      "Epoch 24/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3938 - acc: 0.1466 - val_loss: -24.4042 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.40342 to -24.40424, saving model to model-1.h5\n",
      "Epoch 25/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3948 - acc: 0.1466 - val_loss: -24.4053 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.40424 to -24.40534, saving model to model-1.h5\n",
      "Epoch 26/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3959 - acc: 0.1466 - val_loss: -24.4062 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.40534 to -24.40621, saving model to model-1.h5\n",
      "Epoch 27/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3964 - acc: 0.1466 - val_loss: -24.4063 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.40621 to -24.40625, saving model to model-1.h5\n",
      "Epoch 28/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3964 - acc: 0.1466 - val_loss: -24.4067 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.40625 to -24.40667, saving model to model-1.h5\n",
      "Epoch 29/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3967 - acc: 0.1466 - val_loss: -24.4063 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.40667\n",
      "Epoch 30/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3966 - acc: 0.1466 - val_loss: -24.4066 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.40667\n",
      "Epoch 31/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3965 - acc: 0.1466 - val_loss: -24.4066 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.40667\n",
      "Epoch 32/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3967 - acc: 0.1466 - val_loss: -24.4068 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.40667 to -24.40681, saving model to model-1.h5\n",
      "Epoch 33/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3969 - acc: 0.1466 - val_loss: -24.4070 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00033: val_loss improved from -24.40681 to -24.40700, saving model to model-1.h5\n",
      "Epoch 34/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3971 - acc: 0.1466 - val_loss: -24.4070 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00034: val_loss improved from -24.40700 to -24.40705, saving model to model-1.h5\n",
      "Epoch 35/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3972 - acc: 0.1466 - val_loss: -24.4067 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -24.40705\n",
      "Epoch 36/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3967 - acc: 0.1466 - val_loss: -24.4067 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.40705\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3968 - acc: 0.1466 - val_loss: -24.4068 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -24.40705\n",
      "Epoch 38/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3968 - acc: 0.1466 - val_loss: -24.4068 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -24.40705\n",
      "Epoch 39/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3968 - acc: 0.1466 - val_loss: -24.4068 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.40705\n",
      "Epoch 40/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3968 - acc: 0.1466 - val_loss: -24.4068 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -24.40705\n",
      "Running iteration 2/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 4604 samples, validate on 512 samples\n",
      "Epoch 1/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -17.9605 - acc: 0.1488 - val_loss: -22.8837 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.88369, saving model to model-2.h5\n",
      "Epoch 2/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -22.9917 - acc: 0.1466 - val_loss: -23.1375 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.88369 to -23.13750, saving model to model-2.h5\n",
      "Epoch 3/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.2400 - acc: 0.1466 - val_loss: -23.3820 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.13750 to -23.38199, saving model to model-2.h5\n",
      "Epoch 4/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.4851 - acc: 0.1466 - val_loss: -23.6287 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.38199 to -23.62875, saving model to model-2.h5\n",
      "Epoch 5/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.7250 - acc: 0.1466 - val_loss: -23.8606 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.62875 to -23.86056, saving model to model-2.h5\n",
      "Epoch 6/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.9451 - acc: 0.1466 - val_loss: -24.0496 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.86056 to -24.04964, saving model to model-2.h5\n",
      "Epoch 7/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.1137 - acc: 0.1466 - val_loss: -24.1994 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.04964 to -24.19942, saving model to model-2.h5\n",
      "Epoch 8/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.2184 - acc: 0.1466 - val_loss: -24.2734 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.19942 to -24.27340, saving model to model-2.h5\n",
      "Epoch 9/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.2889 - acc: 0.1466 - val_loss: -24.3249 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.27340 to -24.32485, saving model to model-2.h5\n",
      "Epoch 10/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3345 - acc: 0.1466 - val_loss: -24.3537 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.32485 to -24.35366, saving model to model-2.h5\n",
      "Epoch 11/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3578 - acc: 0.1466 - val_loss: -24.3809 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.35366 to -24.38085, saving model to model-2.h5\n",
      "Epoch 12/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3731 - acc: 0.1466 - val_loss: -24.3893 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.38085 to -24.38928, saving model to model-2.h5\n",
      "Epoch 13/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3816 - acc: 0.1466 - val_loss: -24.3967 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.38928 to -24.39668, saving model to model-2.h5\n",
      "Epoch 14/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3854 - acc: 0.1466 - val_loss: -24.4004 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.39668 to -24.40037, saving model to model-2.h5\n",
      "Epoch 15/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3869 - acc: 0.1466 - val_loss: -24.3946 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -24.40037\n",
      "Epoch 16/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3853 - acc: 0.1466 - val_loss: -24.3960 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -24.40037\n",
      "Epoch 17/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3869 - acc: 0.1466 - val_loss: -24.3980 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -24.40037\n",
      "Epoch 18/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3893 - acc: 0.1466 - val_loss: -24.4008 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00018: val_loss improved from -24.40037 to -24.40080, saving model to model-2.h5\n",
      "Epoch 19/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3920 - acc: 0.1466 - val_loss: -24.3981 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -24.40080\n",
      "Epoch 20/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3887 - acc: 0.1466 - val_loss: -24.3994 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -24.40080\n",
      "Epoch 21/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3902 - acc: 0.1466 - val_loss: -24.4012 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00021: val_loss improved from -24.40080 to -24.40119, saving model to model-2.h5\n",
      "Epoch 22/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3923 - acc: 0.1466 - val_loss: -24.4037 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00022: val_loss improved from -24.40119 to -24.40368, saving model to model-2.h5\n",
      "Epoch 23/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3941 - acc: 0.1466 - val_loss: -24.4035 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -24.40368\n",
      "Epoch 24/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3940 - acc: 0.1466 - val_loss: -24.4043 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00024: val_loss improved from -24.40368 to -24.40428, saving model to model-2.h5\n",
      "Epoch 25/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3556 - acc: 0.1466 - val_loss: -24.4018 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.40428\n",
      "Epoch 26/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3919 - acc: 0.1466 - val_loss: -24.4020 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -24.40428\n",
      "Epoch 27/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3922 - acc: 0.1466 - val_loss: -24.4023 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -24.40428\n",
      "Epoch 28/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3926 - acc: 0.1466 - val_loss: -24.4029 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -24.40428\n",
      "Epoch 29/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3930 - acc: 0.1466 - val_loss: -24.4030 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.40428\n",
      "Epoch 30/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3932 - acc: 0.1466 - val_loss: -24.4032 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.40428\n",
      "Epoch 31/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3934 - acc: 0.1466 - val_loss: -24.4035 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -24.40428\n",
      "Epoch 32/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3938 - acc: 0.1466 - val_loss: -24.4041 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.40428\n",
      "Epoch 33/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3942 - acc: 0.1466 - val_loss: -24.4042 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.40428\n",
      "Epoch 34/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3943 - acc: 0.1466 - val_loss: -24.4043 - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from -24.40428 to -24.40430, saving model to model-2.h5\n",
      "Epoch 35/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3944 - acc: 0.1466 - val_loss: -24.4045 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.40430 to -24.40446, saving model to model-2.h5\n",
      "Epoch 36/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3946 - acc: 0.1466 - val_loss: -24.4046 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.40446 to -24.40464, saving model to model-2.h5\n",
      "Epoch 37/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3948 - acc: 0.1466 - val_loss: -24.4048 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.40464 to -24.40483, saving model to model-2.h5\n",
      "Epoch 38/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3950 - acc: 0.1466 - val_loss: -24.4050 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.40483 to -24.40503, saving model to model-2.h5\n",
      "Epoch 39/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3952 - acc: 0.1466 - val_loss: -24.4052 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.40503 to -24.40521, saving model to model-2.h5\n",
      "Epoch 40/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3953 - acc: 0.1466 - val_loss: -24.4054 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.40521 to -24.40540, saving model to model-2.h5\n",
      "Running iteration 3/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 4604 samples, validate on 512 samples\n",
      "Epoch 1/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -18.2590 - acc: 0.1462 - val_loss: -22.8972 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.89720, saving model to model-3.h5\n",
      "Epoch 2/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.0090 - acc: 0.1466 - val_loss: -23.1575 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.89720 to -23.15754, saving model to model-3.h5\n",
      "Epoch 3/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.2597 - acc: 0.1466 - val_loss: -23.3999 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.15754 to -23.39995, saving model to model-3.h5\n",
      "Epoch 4/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.4979 - acc: 0.1466 - val_loss: -23.6337 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.39995 to -23.63366, saving model to model-3.h5\n",
      "Epoch 5/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.7246 - acc: 0.1466 - val_loss: -23.8458 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.63366 to -23.84577, saving model to model-3.h5\n",
      "Epoch 6/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.9268 - acc: 0.1466 - val_loss: -24.0358 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.84577 to -24.03578, saving model to model-3.h5\n",
      "Epoch 7/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.0960 - acc: 0.1466 - val_loss: -24.1819 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00007: val_loss improved from -24.03578 to -24.18191, saving model to model-3.h5\n",
      "Epoch 8/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.2212 - acc: 0.1466 - val_loss: -24.2820 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.18191 to -24.28195, saving model to model-3.h5\n",
      "Epoch 9/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3024 - acc: 0.1466 - val_loss: -24.3435 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.28195 to -24.34353, saving model to model-3.h5\n",
      "Epoch 10/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3478 - acc: 0.1466 - val_loss: -24.3755 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.34353 to -24.37548, saving model to model-3.h5\n",
      "Epoch 11/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3705 - acc: 0.1466 - val_loss: -24.3895 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.37548 to -24.38955, saving model to model-3.h5\n",
      "Epoch 12/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3828 - acc: 0.1466 - val_loss: -24.3965 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.38955 to -24.39649, saving model to model-3.h5\n",
      "Epoch 13/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3883 - acc: 0.1466 - val_loss: -24.4005 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.39649 to -24.40051, saving model to model-3.h5\n",
      "Epoch 14/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3899 - acc: 0.1466 - val_loss: -24.4003 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -24.40051\n",
      "Epoch 15/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3931 - acc: 0.1466 - val_loss: -24.4044 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.40051 to -24.40438, saving model to model-3.h5\n",
      "Epoch 16/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3929 - acc: 0.1466 - val_loss: -24.4042 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -24.40438\n",
      "Epoch 17/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3955 - acc: 0.1466 - val_loss: -24.4065 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.40438 to -24.40653, saving model to model-3.h5\n",
      "Epoch 18/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.2990 - acc: 0.1466 - val_loss: -24.4028 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -24.40653\n",
      "Epoch 19/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3930 - acc: 0.1466 - val_loss: -24.4031 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -24.40653\n",
      "Epoch 20/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3933 - acc: 0.1466 - val_loss: -24.4034 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -24.40653\n",
      "Epoch 21/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3937 - acc: 0.1466 - val_loss: -24.4040 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -24.40653\n",
      "Epoch 22/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3941 - acc: 0.1466 - val_loss: -24.4041 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -24.40653\n",
      "Epoch 23/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3942 - acc: 0.1466 - val_loss: -24.4043 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -24.40653\n",
      "Epoch 24/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3944 - acc: 0.1466 - val_loss: -24.4046 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -24.40653\n",
      "Epoch 25/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3948 - acc: 0.1466 - val_loss: -24.4051 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -24.40653\n",
      "Epoch 26/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3952 - acc: 0.1466 - val_loss: -24.4052 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -24.40653\n",
      "Epoch 27/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3953 - acc: 0.1466 - val_loss: -24.4053 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -24.40653\n",
      "Epoch 28/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3954 - acc: 0.1466 - val_loss: -24.4054 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -24.40653\n",
      "Epoch 29/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3956 - acc: 0.1466 - val_loss: -24.4056 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -24.40653\n",
      "Epoch 30/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3957 - acc: 0.1466 - val_loss: -24.4058 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -24.40653\n",
      "Epoch 31/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3959 - acc: 0.1466 - val_loss: -24.4059 - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss did not improve from -24.40653\n",
      "Epoch 32/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3961 - acc: 0.1466 - val_loss: -24.4061 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -24.40653\n",
      "Epoch 33/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3962 - acc: 0.1466 - val_loss: -24.4063 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.40653\n",
      "Epoch 34/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3964 - acc: 0.1466 - val_loss: -24.4064 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.40653\n",
      "Epoch 35/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3965 - acc: 0.1466 - val_loss: -24.4066 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.40653 to -24.40657, saving model to model-3.h5\n",
      "Epoch 36/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3967 - acc: 0.1466 - val_loss: -24.4067 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00036: val_loss improved from -24.40657 to -24.40672, saving model to model-3.h5\n",
      "Epoch 37/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3968 - acc: 0.1466 - val_loss: -24.4069 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.40672 to -24.40686, saving model to model-3.h5\n",
      "Epoch 38/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3970 - acc: 0.1466 - val_loss: -24.4070 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.40686 to -24.40700, saving model to model-3.h5\n",
      "Epoch 39/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3971 - acc: 0.1466 - val_loss: -24.4071 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00039: val_loss improved from -24.40700 to -24.40714, saving model to model-3.h5\n",
      "Epoch 40/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3972 - acc: 0.1466 - val_loss: -24.4073 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.40714 to -24.40727, saving model to model-3.h5\n",
      "Running iteration 4/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 4604 samples, validate on 512 samples\n",
      "Epoch 1/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -19.0351 - acc: 0.1475 - val_loss: -22.8652 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.86518, saving model to model-4.h5\n",
      "Epoch 2/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -22.9508 - acc: 0.1466 - val_loss: -23.0743 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.86518 to -23.07433, saving model to model-4.h5\n",
      "Epoch 3/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.1628 - acc: 0.1466 - val_loss: -23.2916 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.07433 to -23.29158, saving model to model-4.h5\n",
      "Epoch 4/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.3859 - acc: 0.1466 - val_loss: -23.5210 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.29158 to -23.52097, saving model to model-4.h5\n",
      "Epoch 5/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.6174 - acc: 0.1466 - val_loss: -23.7489 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.52097 to -23.74886, saving model to model-4.h5\n",
      "Epoch 6/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.8383 - acc: 0.1466 - val_loss: -23.9608 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.74886 to -23.96077, saving model to model-4.h5\n",
      "Epoch 7/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.0325 - acc: 0.1466 - val_loss: -24.1310 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.96077 to -24.13096, saving model to model-4.h5\n",
      "Epoch 8/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.1516 - acc: 0.1466 - val_loss: -24.1846 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00008: val_loss improved from -24.13096 to -24.18465, saving model to model-4.h5\n",
      "Epoch 9/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.1924 - acc: 0.1466 - val_loss: -24.2234 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00009: val_loss improved from -24.18465 to -24.22336, saving model to model-4.h5\n",
      "Epoch 10/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.2319 - acc: 0.1466 - val_loss: -24.2645 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00010: val_loss improved from -24.22336 to -24.26453, saving model to model-4.h5\n",
      "Epoch 11/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.2730 - acc: 0.1466 - val_loss: -24.3058 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00011: val_loss improved from -24.26453 to -24.30579, saving model to model-4.h5\n",
      "Epoch 12/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3127 - acc: 0.1466 - val_loss: -24.3415 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00012: val_loss improved from -24.30579 to -24.34149, saving model to model-4.h5\n",
      "Epoch 13/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3445 - acc: 0.1466 - val_loss: -24.3691 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00013: val_loss improved from -24.34149 to -24.36905, saving model to model-4.h5\n",
      "Epoch 14/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3654 - acc: 0.1466 - val_loss: -24.3831 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00014: val_loss improved from -24.36905 to -24.38312, saving model to model-4.h5\n",
      "Epoch 15/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3789 - acc: 0.1466 - val_loss: -24.3943 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00015: val_loss improved from -24.38312 to -24.39433, saving model to model-4.h5\n",
      "Epoch 16/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3845 - acc: 0.1466 - val_loss: -24.3996 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00016: val_loss improved from -24.39433 to -24.39961, saving model to model-4.h5\n",
      "Epoch 17/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3902 - acc: 0.1466 - val_loss: -24.4027 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00017: val_loss improved from -24.39961 to -24.40269, saving model to model-4.h5\n",
      "Epoch 18/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3859 - acc: 0.1466 - val_loss: -24.3974 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -24.40269\n",
      "Epoch 19/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3877 - acc: 0.1466 - val_loss: -24.3980 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -24.40269\n",
      "Epoch 20/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3885 - acc: 0.1466 - val_loss: -24.3990 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -24.40269\n",
      "Epoch 21/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3897 - acc: 0.1466 - val_loss: -24.4005 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -24.40269\n",
      "Epoch 22/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3907 - acc: 0.1466 - val_loss: -24.4008 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -24.40269\n",
      "Epoch 23/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3910 - acc: 0.1466 - val_loss: -24.4012 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -24.40269\n",
      "Epoch 24/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3916 - acc: 0.1466 - val_loss: -24.4019 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -24.40269\n",
      "Epoch 25/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.3925 - acc: 0.1466 - val_loss: -24.4030 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00025: val_loss improved from -24.40269 to -24.40302, saving model to model-4.h5\n",
      "Epoch 26/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3937 - acc: 0.1466 - val_loss: -24.4044 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00026: val_loss improved from -24.40302 to -24.40436, saving model to model-4.h5\n",
      "Epoch 27/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3949 - acc: 0.1466 - val_loss: -24.4051 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00027: val_loss improved from -24.40436 to -24.40506, saving model to model-4.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3952 - acc: 0.1466 - val_loss: -24.4053 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00028: val_loss improved from -24.40506 to -24.40527, saving model to model-4.h5\n",
      "Epoch 29/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3956 - acc: 0.1466 - val_loss: -24.4057 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00029: val_loss improved from -24.40527 to -24.40565, saving model to model-4.h5\n",
      "Epoch 30/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3957 - acc: 0.1466 - val_loss: -24.4060 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00030: val_loss improved from -24.40565 to -24.40602, saving model to model-4.h5\n",
      "Epoch 31/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3961 - acc: 0.1466 - val_loss: -24.4062 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00031: val_loss improved from -24.40602 to -24.40617, saving model to model-4.h5\n",
      "Epoch 32/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3964 - acc: 0.1466 - val_loss: -24.4065 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00032: val_loss improved from -24.40617 to -24.40653, saving model to model-4.h5\n",
      "Epoch 33/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3962 - acc: 0.1466 - val_loss: -24.4065 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -24.40653\n",
      "Epoch 34/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3966 - acc: 0.1466 - val_loss: -24.4065 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -24.40653\n",
      "Epoch 35/40\n",
      "4604/4604 [==============================] - 5s 989us/step - loss: -24.3966 - acc: 0.1466 - val_loss: -24.4067 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00035: val_loss improved from -24.40653 to -24.40667, saving model to model-4.h5\n",
      "Epoch 36/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -24.3966 - acc: 0.1466 - val_loss: -24.4066 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -24.40667\n",
      "Epoch 37/40\n",
      "4604/4604 [==============================] - 5s 996us/step - loss: -24.3967 - acc: 0.1466 - val_loss: -24.4067 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00037: val_loss improved from -24.40667 to -24.40667, saving model to model-4.h5\n",
      "Epoch 38/40\n",
      "4604/4604 [==============================] - 5s 995us/step - loss: -24.3970 - acc: 0.1466 - val_loss: -24.4070 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00038: val_loss improved from -24.40667 to -24.40705, saving model to model-4.h5\n",
      "Epoch 39/40\n",
      "4604/4604 [==============================] - 5s 993us/step - loss: -24.3967 - acc: 0.1466 - val_loss: -24.4067 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -24.40705\n",
      "Epoch 40/40\n",
      "4604/4604 [==============================] - 5s 999us/step - loss: -24.3969 - acc: 0.1466 - val_loss: -24.4071 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00040: val_loss improved from -24.40705 to -24.40712, saving model to model-4.h5\n",
      "Running iteration 5/5\n",
      "Creating CNN 0.0.1\n",
      "#############################################\n",
      "Embedding:    using pre-trained embedding\n",
      "Vocabulary size: 2954\n",
      "Embedding dim: 200\n",
      "Filter sizes: [3, 4, 5]\n",
      "Feature maps: [10, 10, 10]\n",
      "Max sequence: 100\n",
      "#############################################\n",
      "Train on 4604 samples, validate on 512 samples\n",
      "Epoch 1/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -18.7710 - acc: 0.1449 - val_loss: -22.8549 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -22.85490, saving model to model-5.h5\n",
      "Epoch 2/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -22.9385 - acc: 0.1466 - val_loss: -23.0604 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_loss improved from -22.85490 to -23.06040, saving model to model-5.h5\n",
      "Epoch 3/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.1482 - acc: 0.1466 - val_loss: -23.2766 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00003: val_loss improved from -23.06040 to -23.27661, saving model to model-5.h5\n",
      "Epoch 4/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.3706 - acc: 0.1466 - val_loss: -23.5063 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00004: val_loss improved from -23.27661 to -23.50634, saving model to model-5.h5\n",
      "Epoch 5/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.6031 - acc: 0.1466 - val_loss: -23.7356 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00005: val_loss improved from -23.50634 to -23.73558, saving model to model-5.h5\n",
      "Epoch 6/40\n",
      "4604/4604 [==============================] - 5s 1ms/step - loss: -23.8259 - acc: 0.1466 - val_loss: -23.9491 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00006: val_loss improved from -23.73558 to -23.94905, saving model to model-5.h5\n",
      "Epoch 7/40\n",
      "4604/4604 [==============================] - 6s 1ms/step - loss: -24.0211 - acc: 0.1466 - val_loss: -24.1198 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00007: val_loss improved from -23.94905 to -24.11976, saving model to model-5.h5\n",
      "Epoch 8/40\n",
      "3600/4604 [======================>.......] - ETA: 1s - loss: -24.3040 - acc: 0.1511"
     ]
    }
   ],
   "source": [
    "import cnn_model\n",
    "\n",
    "histories = []\n",
    "\n",
    "for i in range(RUNS):\n",
    "    print('Running iteration %i/%i' % (i+1, RUNS))\n",
    "    \n",
    "    X_train, X_val, labels, y_val = train_test_split(data, y_train, test_size=VAL_SIZE, random_state=42)\n",
    "    \n",
    "    emb_layer = None\n",
    "    if USE_GLOVE:\n",
    "        emb_layer = emb_layers[2] #create_word2vec_embeddings(result)\n",
    "        \n",
    "    model = cnn_model.build_cnn(\n",
    "        embedding_layer=emb_layer,\n",
    "        num_words=MAX_NUM_WORDS,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        filter_sizes=FILTER_SIZES,\n",
    "        feature_maps=FEATURE_MAPS,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        dropout_rate=DROPOUT_RATE\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adadelta(clipvalue=3),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, labels,\n",
    "        epochs=NB_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[ModelCheckpoint('model-%i.h5'%(i+1), monitor='val_loss',\n",
    "                                   verbose=1, save_best_only=True, mode='min'),\n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.01)\n",
    "                  ]\n",
    "    )\n",
    "    histories.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/glovetext8.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
